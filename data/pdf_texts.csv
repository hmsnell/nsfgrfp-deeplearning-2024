title,text
1.0,"Background:Children who are victims of interpersonalviolence have an elevated risk of engaging inaggressive behavior and perpetrating violence in adolescence and adulthood1. Youth currently in the fostercare system are particularly vulnerable to this cycle2,and are considerably more likely than theircounterparts to have contact with the criminal justice system. This has created substantial public costs forthe United States3. However, while research has shownhigh rates of criminal involvement within fosterpopulations4, not all victimized children engage inviolent behavior. In fact, a significant portion of thispopulation demonstrates relatively uncompromised, or “resilient” functioning5. Factors such as presenceof supportive adults, satisfaction in school, and participation in extracurricular activities were found to beprotective factors in high-risk populations6. However,access to and enhancement of these resources dueto foster placement and stability has been less well studied. Similarly, while risks associated with negativeoutcomes have been identified, such as previous physical abuse and delinquency in youths’ originalfamilies7, an examination of how these factors areamplified and affected by the foster care system has nottaken place. So while adverse childhood experiences often predict aggressive behavior4, there isvariability in delinquency rates within this population and little agreement about what is responsible forincreased or decreased risk of violent behavior. The lack of understanding of contributions to thisvariability complicates the development of effective social interventions within the foster care system andadds greatly to economic burden in the United States3.Proposed Research:To better understand this variability,I aim to examine the relationship betweenhistory of violence and rates of delinquency, focusing on the factors that potentially moderate thisassociation. The proposed study will focus on factors which mayplace children at increasedrisk, butalsofactors that may explain resiliencein this population.My analytic strategy will incorporatebothquantitative and qualitative techniques. Combiningthese approaches will provide multidimensionalunderstanding of complex issues that cannot be obtained through one method alone8. Large scalequantitative research will provide precise foundational information used to conduct the study, analyze thedata, identify factors that can be intervened on, and verify the findings. Smaller scale qualitative analyseswill expand understanding by exploring subjective factors, identifying other factors not captured in thequantitative data, gaining insight into social processes, and giving voice to participants in the study.First, I will analyze the Midwest Evaluation of the Adult Functioning of Former Foster Youth atChapin Hall9, self-reported survey data collectedfrom 732 study participants when they were 17 or 18years old. Within this data set, I will examinehistoryof maltreatment, delinquency, foster care servicefactors, access to protective factors, and placement satisfaction.History of maltreatmentwill beassessed by The Lifetime Experiences Questionnaire.Delinquencywill be measured by surveys regardinghistory of arrest, conviction for committing a crime, and overnight stay in a correctional facility. Thisanalysis will also include surveys collected regarding victimization in the past 12 months, as well asperpetrator status in the past 12 months.Foster servicefactorswill be measured by data regarding age atentry into foster care system, number of placements, type of placements, and total length of stay in fostercare system.Access to protective factorswill beassessed by The MOS Social Support Survey, surveysregarding the impact of foster care on ability to attend school, and information regarding educationalattainment, such as last grade level completed. Lastly,placement satisfactionwill be analyzed by a surveyconcerning attitudes and satisfaction with most recent placement situations, and a survey regarding thelikelihood of turning to the child welfare system for support in the future. A series of linear regressionmodels will explore the effects of maltreatment, foster care service factors, protective access, andsatisfaction on delinquency.I aim to(1) comparedelinquency rates for maltreated andnon-maltreated foster youth, (2) within maltreated foster youth, identify which factors areassociated with increased or decreased delinquency,and(3) determine whether foster care servicefactors, access to protective factors, and placement satisfaction moderate the relationship betweenviolence exposure and violent behavior within the foster care system.Second, I will conduct qualitative analysis using a smaller sample of foster youth, recruited atUniversity of Illinois at Chicago. I will interview foster care youth (n=50), ages 16 to 18 with a history ofmaltreatment and delinquency history tounderstandself-reported protective and risk factors in thecurrent operation of foster care.Example questionsare ""What do you think could be improved in yourexperience with foster care?"", and ""what do you feel has been useful to you during your foster careexperience?"". After transcription of these interviews, a code book will then be developed for theidentification and interpretation of patterns and themes in the textual data. This qualitative research willallow for better insight into social interactions, foster care delivery processes, and subjective factorsthat may not have been included in the surveys of the Midwest Evaluation. This qualitative researchwill generate explanatory models and theories, which will also be useful in the creation of interventions.Working collaboratively with the quantitative data, these interviews will provide valuable insight, allowfoster youth to have a voice, and add a more comprehensive analysis to numeric methods.HypothesesI hypothesize thatHypothesis (1)Maltreatedyouth will experience higher rates ofdelinquency.Hypothesis (2)Within the populationof maltreated youth, higher violence exposure will beassociated with lower rates of foster care service factors, access to protective factors, and placementsatisfaction.Hypothesis (3)Differences in thesefactors will identify which victims of abuse are morelikely to engage in delinquency, and thus strengthen or weaken the association between violence exposureand future violence.Hypothesis (4)The qualitativeinterviews will provide unique insight on complexsocial issues that will give voice to children in foster care and generate explanatory models that can serveto devise new kinds of interventions.Intellectual MeritThis study will address the relationshipbetween maltreatment and incarceration in anovel way that will advance understanding of variabilities in violent behavior among maltreated fosteryouth. By interpreting these factors that contribute to variabilities, I will add to research that willdetermine what is responsible for increased or decreased risk of delinquency and incarceration. As thistopic has never been addressed from both qualitative and quantitative perspectives, this study will offercomprehensive and unprecedented data that will begin to address the enormity of cycles of violenceamong foster youth.FeasibilityThe Midwest Evaluation is a longitudinaldataset that has already been collected and ispublicly available with data use agreements. My proposed qualitative interviews will add an unexploredconstruct to ongoing studies with minimal burden to participants. Preparation and analysis of this datawill be conducted with support from Dr. Kathryn Grant, an expert in maltreatment, or with Dr. ElizabethRaposa, who has worked extensively with foster youth and juvenile delinquents. This NSF award willpermit me to pursue coursework that will be critical to the success of my project and allow for dedicatedmentored training. The success of the research will be assessed via communication of these results bypublications of peer-reviewed first-authored manuscripts, presentations at research conferences such asthe International Association for Child and Adolescent Psychology and the International Society forTraumatic Stress Studies, and the development of interventions based on this research.Broader ImpactsThe estimated economic burden resultingfrom cases of child maltreatment in theUnited States is approximately $124 billion3. An additional $5.1 billion is used annually to incarcerateformer foster youth in State and Federal prisons10.Not only are we ethically bound to serve and providefor these underrepresented children, but we are also bound to advance the progress of science and reduceeconomic burdens for our nation. This research will identify which factors strengthen or weaken cycles ofviolence, and outline how to specifically support children within the system who have been exposed toviolence. This work will enhance and improve foster care procedures that specifically decrease rates ofviolent behavior and incarceration. My goal is to ultimately improve foster care service factors, access toprotective factors, and placement satisfaction. This research will lead to better interventions, decreasedrates of incarceration, and therefore a decreased economic burden for maltreatment in the United States.References1. Widom,Science1989 2. McMillen et al.Child Psychiatry2005 3. Fang et al.,Child AbuseNegl. 2012 4. Font et al.Crime Delinquency2021 5.Jones,Soc. Work J.2012 6. Luthar,Developmentalpsychopathology2006 7. Datta et al. 2019 8. Bartunek& Seo,Journal of Organizational Behavior20029. Courtney, Terao, Bost,Midwest Evaluation of theAdult Functioning of Former Foster Youth:Conditions of Youth Preparing to Leave State Care2011 10.Administration for Children and Families,Preliminary Fiscal Year 2009U.S. Department of Healthand Human Services 2010"
2.0,"PRIMARY RESEARCH OBJECTIVE: The primary objective of my PhD research is to formulatenovel statistical methods for accurately quantifying uncertainty and variability in life-cycle assessments(LCA), the primary method used to assess embodied carbon (greenhouse gas emissions associated withthe production, transport, construction,andend-of-lifeofbuildingmaterials).Theresultsofmyworkwilladvance LCA research by enabling more robust decision-making,moreaccuratesensitivityanalyses,andenhanced comparability between whole-building LCAs. Academics, practitioners, and policymakerswillthus be empowered to more effectively understand, quantify, and ultimately reduce embodied carbon.Immediate embodied carbon reduction is necessary for curbing the catastrophic effects of theclimate crisis, yet the current body of research is severely limited, and few policies or industrystandards incorporate embodied carbon into emission reduction strategies.JUSTIFICATION: Although whole-building LCA methodology is standardized by an internationalcoalition of technical standard-setting bodies (ISO 14040/14044),thereisconsiderablevariabilityindataquality, impact assumptions, and scope. This variability is particularly appreciable for biogenic carbon,the physical carbon that is stored in biological materials such as wood, hemp, and straw. Negativebiogenic carbon emissions due to carbon storage are treated inconsistently across whole-building LCAsbecause these assumptions are not standardized. In a five-building case study series, embodied carbonnormalized by floor arearangedfrom-936to207kgCO e/m2whenbiogeniccarbonstoragewasincluded2in theanalysisand132to557kgCO e/m2whenbiogeniccarbonstoragewasexcluded[1].Scientistshave2investigated several approaches to incorporate uncertainty in whole-building LCA, including but notlimited to: probability density functions to model building element service-life [2], probability densityfunctions to model manufacturing emissions [3], and more advanced, exhaustive methods that involveconducting aglobalsensitivityanalysisacrossparameterspacesdeterminedviaLatinhypercubesampling[4]. Unfortunately, these modeling practices are not yet standardized or integrated into whole-buildingLCA. From 2014-2019, 44% of published LCA studies did not mention uncertainty and 36%mentioneduncertainty but did not incorporate it in the analysis [5]. In summary, there is no consensus amongavailable methods to incorporate uncertainty in whole-building LCA, and available methods are seldomincorporated in LCA research. I aim to build upon theseavailablemethodsbyintroducingaprobabilisticframework to standardize uncertainty characterization in biogenic carbon accounting, enabling betterdecision-making and comparability between whole-building LCAs.Objective 1: Literature Review. Intent: To assess sources of uncertainty and uncertaintycharacterization methods in scientific literature and industry case studies. Methods: I will conduct aliterature review of academic LCA studies,whole-buildingLCAs,material-specificLCAs,andembodiedcarbon benchmarks. I will select the most appropriate sources and characterization methods for LCAuncertainty. I hypothesize that Monte Carlo simulation with probabilistic modeling will most accuratelycharacterize emission uncertainty for a linear model like whole-building LCA.Objective 2: A Probabilistic Framework for Whole-Building LCA. Intent: To increase the potentialfor synthesis between data sets for whole-building LCA in academic research and in practice. Methods:Based on my findings from the literature review, I will develop a statistical framework for classifying,characterizing, andquantifyinguncertaintyinLCA.Ihypothesizethatrunningwhole-buildingLCAswithmy proposed probabilistic approach will more accurately modelthisuncertainty,whichwillallowme(1)to standardize uncertainty quantification in LCA research and (2) to enable more accurate comparisonsand better decision-making.Objective 3: StandardizingBiogenicCarbonAccounting.Intentandbackground:Currentapproachesto biogenic carbon accounting are deterministicandquantifyneitheruncertaintynorvariabilitythatcomefrom widely varying assumptions. The ‘0/0approach’assumesnetcarbonsequestrationfromtreegrowthbalances with end-of-life carbon emissions, and thus, the biogenic carbon storage and its subsequentrelease are ignored [6]. The ‘-1/+1 approach’ considers biogenic carbon as a negative carbon emissionduring Life Cycle Stage A (the production stage) with carbon released during Life Cycle Stage C (theend-of-life stage) [6]. Dynamic LCA relies on the regrowth of biogenic carbon put into a building byaccounting for forest rotation periods over a period leading up to or during the building life [7].Carbondiscounting methods calculate a net present value of carbon emissions avoided with biogenic carbonstorage [8]. Ton-year accounting converts the time-value of biogenic carbon storage into a carbon offsetequivalent that yields anestimateofnegativeemissionsperton-yearofstorage[9].Insummary,thereisavital need toformulateanaccurateandstandardizedmodelingmethodologythatproperlyaccountsforthebenefits of biogenic carbon storage in buildings while also quantifying variability and uncertainty in thecalculation. Methods: I will formulate stochastic models for biogenic carbon that producemoreaccurateand consistent whole-building LCA results. I hypothesize that introducing these stochastic models todynamic LCA will yield the most accurate and descriptive results but will becomputationallyexpensiveand difficult to implement for regular use. Therefore, I posit that a stochastic model based on ton-yearaccounting will yield a viable, but easy-to-implement approach. My proposed method (likely to bestochastic ton-year accounting) will enable practitioners to circumvent end-of-life assumptions forbiogenic carbon, which are often the source of significant uncertainty.INTELLECTUAL MERIT: Despite being a necessary component to solving the climate crisis,embodied carbon reduction is not widely studied in theUS.LCAistheprimarymethodusedtoresearch,understand, and reduce embodiedcarbon,butdisparatedatasetswithwidelyvariedassumptionsprecludecomparison ofexistingstudiesandmoreadvancedanalysis.Withmyresearch,Iwillsteerresearchersandpractitioners towards a more complete understanding of the most important data needed to describe thetotal embodied carbon footprint of a building. With support from the National Renewable EnergyLaboratory (NREL) and the University of Colorado, Boulder’s Center for Research Data & DigitalScholarship, I will elevate the standards for embodied carbon and LCA research.BROADER IMPACTS: The two most impactful ways to facilitate widespread, effective embodiedcarbon reduction are (1) establishingembodiedcarbonbenchmarkingmethodologyand(2)disseminatingstatistically rigorous embodied carbon reduction tools. Benchmarks: Designers need science-basedembodied benchmarks to inform effective target setting, though none currently exist. These benchmarksmust describe expectedrangesofembodiedcarbonperusablefloorareaandaccountforvariablessuchaslateral design requirements, building geometry, building type, and soil quality. My research will beintegrated with ongoing research in Dr. Srubar’s Living Materials Laboratory to establish embodiedcarbon benchmarking methodology. Our lab group has collaborators at NREL who are particularlyinterested in integrating this methodology with their analyses of operational carbon (greenhouse gasemissions associated with building energy use). Embodied carbon reduction tools: Industry-standardLCA software programs are proprietary and provide conflicting results with ill-constrained uncertainty.My research will culminate in publishing an open-source, easy-to-implement software packagetoensurebroad implementation by researchers and practitioners. I will then distribute my findings throughprominent academic and industry organizations (e.g., CLF, AIA, SEI, UNFCCC, USGBC, WGBC).CONCLUSION: I am uniquely suited to conduct this research because of (1) my first-hand experiencewith LCA, engineering design work, and computational research, (2) the exemplary leadership I havedemonstrated in the embodied carbon space, and (3) my position in a leading embodied carbon researchgroupwithimportantrelationshipssuchasthatwithNREL.Myresearchwillelevatethestandardforhowacademic and industry practitioners conductLCA,whichwillbeessentialformoreeffectivelycombatingthe climate crisis. I will ensure the findings of my research are disseminated to salient technicalcommunities and so that they are applied ubiquitously in industry and academia.[1] TallWood Design Institute CLT Case Studies (2020); [2]K.Goulotiet.al.,BuildingandEnvironment(2020); [3] M.A. DeRousseau et. al., Journal of Cleaner Production (2020); [4] E. Igos et. al., TheInternational Journal ofLifeCycleAssessment(2019);[5]N.Bamberet.al.,TheInternationalJournalofLife Cycle Assessment (2020); [6] Hoxha et. al., Buildings & Cities (2020); [7] A. Levasseur et. al.,Environmental Science &Technology(2010);[8]L.Marshall,A.Kelly,WorldResourcesInstitute(2010);[9]P. Moura Costa, C. Wilson,Mitigation and AdaptationStrategies for Global Change(2000)"
3.0,"The problem: While most plants rely on soil nitrogen (N), plants capable of symbiotic Nfixation (SNF) can acquire N directly from the atmospheric N . Because N is inexhaustible,2 2SNF is convenient. However, SNF has a high cost2 due to the need to break the triple bond of N .2Following previous literature1,2, I define the C cost of SNF as the respiration (CO flux) needed2to drive SNF divided by SNF itself (N flux). Biochemical calculations estimate the C cost of2SNF to be slightly higher than using nitrate and much higher than using ammonium1.Measurements of these costs in nodules (the root structures that house symbiotic bacteria) havebeen close to the biochemical predictions2. However, these measurements have been carried outat constant temperatures. As explained below, the cost might vary widely across temperature.The cost of SNF helps determine its effectiveness, both within a plant (using SNF vs. soilN) and across species (competition between N-fixing and non-fixing plants). A lower cost makesSNF viable even when soil N is abundant, whereas a higher cost makes SNF untenable evenwhen soil N is scarce. Therefore, variation in the cost of SNF across temperature would have far-reaching implications. For example, it could help explain why N-fixing trees are successful inwarm areas3, and could also affect how SNF will change with climate. Despite its importance tofundamental biology, research on temperature responses of SNF has long been beset bytechnological constraints. Using a novel method that overcomes these constraints, I will ask onemain question: What is the temperature response of the C costs of SNF? I will address thisquestion using the tree Robinia pseudoacacia, which lives across a wide climatic range, accountsfor 64% of tree-based SNF in the contiguous USA5, and is common across Eurasia3.Hypotheses: My hypotheses are based on previous measurements of the components ofthe cost: respiration and SNF itself. Previous work6 has observed that SNF plummets at low(near 0°C) and high (near 50°C) temperatures. There are few data on nodule respiration atdifferent temperatures, but leaf respiration continues across 0-50°C7, suggesting nodulerespiration might too. Respiration rates well above 0 dividedby SNF rates near 0 mean that (H1) the C cost of SNF will bewell above the biochemical predictions at low and hightemperatures.My hypotheses about temperature optima stem frommeasurements from my lab, which recently developed a systemfor non-destructive, extremely sensitive, and continuousmeasurements of nitrogenase activity6. Preliminary researchusing this system has shown that the optimal temperature forSNF is much higher (29-36°C) than previously assumed(25°C)4, as shown in Fig. 1a. I do not know how nodulerespiration will change with temperature, so I have competinghypotheses. (H2a) If respiration peaks near the sametemperature as SNF (green curve, Fig. 1b), then the C costwill have a similar temperature optimum as SNF (greencurve, Fig. 1c). (H2b) Alternatively, if respiration risescontinually (blue curve, Fig. 1b), as leaf respiration does6,then the temperature optimum of the C cost will be lower thanthe optimum of SNF (blue curve, Fig. 1c).Hypotheses H1, H2a, and H2b are represented in Fig.1c, which also shows the equation for the C cost of SNF that is used in manymodels8(black curve). This equation assumes that the change in C cost of SNF with temperatureis inversely proportional to the SNF rate and is scaled to the biochemical C cost of SNF (7.5-12.5g C g N−1). As explained above, I believe this model is flawed as it does not account for hownodule respiration changes with temperature.Methods: Using growth chambers at Columbia University, I will grow 30 Robiniapseudoacacia seedlings (from seed) under a temperature regime of 26°C during day and 20°Cduring night using a 14-hour light and 10-hour dark photoperiod with relative humidity and CO₂concentrations of 70% and 400 ppm to emulate controlled climate conditions6. The seedlings willbe inoculated with slurries of crushed nodules as well as bacteria cultured from these nodules toensure the plants can establish symbiotic partnerships, and will be fertilized with limited levelsof N (1.5 g N m−2 yr−1) but ample amounts of all other nutrients to promote SNF.The nodules will be measured for SNF and respiration continuously across 1-50°C overthe course of 3 hours. The excised nodules will be placed in a sealed chamber with 2% acetylene(the concentration at which the system measures nitrogenase activity most precisely andaccurately6). After accounting for leakage and other factors6, the rate at which acetylene isreduced to ethylene (measured with a Picarro G2106 laser) gives a measurement of nitrogenaseactivity9. Preliminary work in our lab has shown that Robinia nodules have stable nitrogenaseactivity at least 6 hours after excision, and that the ratio of 15N to acetylene reduction is stable2across the temperature range of our study (TA Bytnerowicz, pers. comm.).CO₂ flux in the chamber will be synchronously measured by a Licor LI-62626 todetermine the temperature response of nodule respiration. I will process and analyze the data bymodifying R scripts previously developed in the Menge lab (ref. 4 for processing, TABytnerowicz, pers. comm. for temperature responses of SNF). The analysis will yieldtemperature response curves for SNF, respiration, and the ratio of the two (the C cost of SNF).Intellectual Merit: This research will answer questions fundamental to the biology of thesymbiotic relationship between legumes and N-fixing bacteria. At the level of plantecophysiology, at what temperatures is it energetically favorable for Robinia pseudoacacia to fixN? At the level of community ecology, how does Robinia pseudoacacia compete against non-fixing plants if it relies on SNF?Broader Impacts: The paucity of knowledge on how SNF and its C cost respond totemperature has been a major constraint on global biogeochemistry and climate modeling. Asdescribed above, temperature response functions for SNF and for the C cost of SNF are alreadyin use in terrestrial biosphere models, despite few data for the temperature response of SNF itselfand zero data for the temperature response of the C cost of SNF. My work will lead to directimprovements in the representation of SNF in these models, and thus will directly influence ourability to predict global biogeochemistry and climate change.In addition to publishing in academic journals, I will present my work at academicconferences, such as SACNAS’ National Diversity in STEM Conference, and outreachprograms, such as the Ecological Society of America’s SEEDS program and Women In Scienceat Columbia (WISC). As a former McNair Scholar, I am well aware of the disparity of resourceswithin underrepresented populations. Because of this, I willalso contribute my mentorship to theEnvironmental Justice and Urban Ecology Summer Research Program, a funded program forhigh school students at the Washington Heights Expeditionary Learning School.1Gutschick 1981, The American Naturalist. 2Tjepkema & Winship 1980, Science. 3Steidinger et al. 2019,Nature. 4Houlton et al. 2008, Nature. 5Staccone et al. 2020, Global Biogeochemical Cycles. 6Bytnerowiczet al. 2019, Methods in Ecology & Evolution. 7Heskel et al. 2016, PNAS. 8Fisher et al. 2010, GlobalBiogeochemical Cycles. 9Hardy et al. 1968, Plant Physiology."
4.0,"Key Terms: wildfire, water stress, land surface temperatureMotivation: The primary wildfire monitoring system in the United States is the National FireDanger Rating System (NFDRS)1,2. NFDRS maps are routinely used by land managers andregional governments to allocate fire mitigation resources and track fire risk. Although NFDRS isa standard risk assessment tool, it faces several disadvantages. Calculation of a NFDRS ratingrequires advance knowledge of site conditions and manual input of user parameters into closedsource software. For non-experts, NFDRS is difficult to use. Despite the complexity of NFDRS,its primary fire danger metric is a coarse 5-level categorical scale (from “low” to “extreme”) thatcannot be forecasted beyond 24 hours. This project will improve wildfire modeling withempirical techniques that enable proactive wildfire mitigation and long-term forecasting.Objectives: Climate change is expected to produce more intense wildfires more frequently in theAmerican West3. Wildfires are intensified by high plant biomass (i.e. fuel load) and low fuelmoisture. Both of these factors can be remotely sensed over large areas4,5. Given that vasculareffects of water stress linger in plants weeks to months after a drought6, drought conditions earlyin spring may predispose water-stressed forests to wildfire the following summer.This project will produce remote sensing data streams of plant water stress and vegetationgrowth as inputs for an open source wildfire predictive model covering forested regions of thewestern United States at 1 km2 spatial resolution. I hypothesize that (1) water stress in earlyspring increases wildfire intensity the following summer, (2) fuel load can be estimated froma time series of a vegetation growth index and (3) by measuring these variables in early spring(Fig. 1a), wildfire-prone regions can be identified weeks before ignition (Fig. 1b). In short,water-stressed locations with high plant biomass will be identified as wildfire hotspots before thefire season begins. I will perform computationally-intensive spatial analysis using open sourcecloud infrastructure to ensure usability by non-experts.Aim 1: Calculate and validate water stressindex. Water stress can be estimatedquantitatively from canopy temperature (i.e.leaf temperature) and vapor pressure deficitusing the crop water stress index (CWSI)5.CWSI is related to evapotranspiration and isapplicable to all leaved plants. To calculateCWSI, I will use vapor pressure deficit atdaily temporal resolution and 1 km2 spatialresolution from Daymet, a continuous,Figure 1. (a) Raster stacks of CWSI and GSIgridded meteorological product covering thebecome a time series for each grid cell. (b) Earlycontiguous United States7. To determineplant stress may indicate wildfire hotspots.canopy temperature, I will use land surfacetemperature (LST) calibrated with the normalized difference vegetation index (NDVI)8. My sourceof LST and NDVI data will be the Terra MODIS satellite, for which cloud-free, gap-filled LSTdata have recently been developed9. This method of determining canopy temperature requires onlyoccasional NDVI values, so clouds will not prevent canopy temperature measurement8. AlthoughMODIS is approaching retirement, its 20-year data archive is desirable. For recent fire years I willalso work with the current-generation LST sensor ECOSTRESS. A field campaign will beperformed in fire-prone western forests to calibrate CWSI, to validate canopy temperaturemeasurements, and to determine the relationship between CWSI and plant water potential.Aim 2: Calculate and validate fuel load index. I will employ the growing season index (GSI)to estimate fuel load over time. The GSI quantifies how plant growth is limited or unconstrainedby humidity, air temperature, or photoperiod4. GSI therefore remains measurable under all weatherconditions using Daymet data, unlike spectral biomass indices such as the leaf area index. GSI willbe validated against in situ measurements of fuel load as part of the field campaign in Aim 1.Aim 3: Model wildfire likelihood. I will use an existing dataset of wildfire occurrence from 2000-2019 to produce annual wildfire presence maps aligned on the same grid as the CWSI and GSIcalculations. For each year of data, I will calculate CWSI and GSI for each grid cell at dailytemporal resolution from February 1 to May 31 to produce a stack of CWSI and GSI grids throughtime (Fig. 1a). Possibly, the end of the data collection period will be adjusted later or earlier in theyear to optimize model performance and parsimony. Each cell of the raster stack will be insertedinto a high-dimensional dataset where each row is a time series of CWSI and GSI values and asingle column indicating whether the cell experienced fire that year. I will use the CWSI and GSItime series as predictors in a partial least squares regression (PLSR) model with a logarithm linkfunction. PLSR reprojects the predictor variables in a typical linear regression to a lower-dimensional space that is maximally correlated with the response matrix. PLSR therefore resolvesissues with correlated predictor variables and, via weights, identifies which CWSI and GSImeasurements contribute most to the model prediction. Wildfire occurrence is a binary responsevariable, so a logarithm link function will enable calculation of wildfire likelihood for each cell inthe modeling area. A variant of PLSR for binary classification tasks, partial least squaresdiscriminant analysis, is also a candidate modeling approach.I will evaluate the proposed model with standard measures for a binary classifier with animbalanced response variable. I will also compare the proposed model against NFDRS mapsproduced on May 31 the same year. Project success is defined as accurate prediction of 1 km2pixels as fire-present or fire-absent, emphasizing a low false negative rate, and a model whichland managers prefer over existing NFDRS maps for allocating management resources.Intellectual Merit: This study will improve wildfire prediction by employing empirical methodsand longer forecasting times. Improved wildfire modeling will enable proactive wildfiremitigation and clarify factors that drive wildfire occurrence. In particular, this project will producethe most spatially extensive measurement of forest water stress to date and determine how wildfireis influenced by water stress early in the growing season. This study will also demonstrate howremote sensing datasets can be combined to model ecosystem processes.Broader Impacts: Wildfire intensity and frequency is expected to increase in the American Westas climate change continues3. Wildland firefighters must effectively allocate tens of billions ofdollars to mitigate this annual emergency. Advance warning of fire risk will enable proactivemanagement that utilizes resources effectively. Such warnings also enable the public to avoidinjury and property damage. In society at large, less wildfire smoke reduces respiratory illness andavoids air travel disruption. Knowledge of forest response to drought conditions will also improvetimber production in the logging industry. All computer code and data products generated by thisproject will be open source. Model results will be distributed via a non-technical online dashboard.I will demonstrate the analysis workflow at workshops and reach out to potential users who wouldbe interested in using the wildfire model produced by this work.References: [1] U.S. Forest Service p. INT-GTR-169. [2] W.M. Jolly, National NFDRS 2016 RolloutWorkshop (2018). [3] A.P. Williams et al., Earths Future 7, 892 (2019). [4] W.M. Jolly et al., Glob. ChangeBiol. 11, 619 (2005). [5] S.B. Idso et al., Agric. Meteorol. 24, 45 (1981). [6] C.R. Brodersen et al., Annu.Rev. Plant Biol. 70, 407 (2019). [7] J.T. Abatzoglou, Int. J. Climatol. 33, 121 (2013).[8] M. Blum et al., Agric. For. Meteorol. 176, 90 (2013). [9] S. Shiff et al., Sci. Data 8, 74 (2021)."
5.0,"IntroductionMany metabolites are reactive and unstable, making them prone to undesired chemicalmodification outside of the intended pathways1. While metabolism as a whole is well-studied, thebiochemical mechanisms of managing such reactive metabolites are not. Proteins which are closelymetabolically involved with each other can frequently be found in protein-protein interactions which areessential for nearly all cellular function. It is currently believed that most, if not all, proteins participate inprotein-protein interaction networks2. Such a network suggests the possibility of metabolic substratechanneling, in which a metabolite travels from one enzymatic active site to another without freely diffusinginto the surrounding medium. Evidence for substrate channeling has been observed in enzymes of manymajor biochemical pathways and is being increasingly recognized as foundational to metabolic regulation3.Through substrate channeling, an intermediate metabolite may be retained for use in a specific pathway,protected from degradation, or prevented from causing damage to the cell4.The goal of my proposed research is to discover mechanisms by which unstable metabolitesare managed in biochemical systems. This research will provide insight into cellular control overreactive metabolites, protein-protein interactions, and substrate channeling. To achieve this goal, Iwill uncover mechanisms of substrate channeling for the reactive metabolite Δ1-pyrroline-5-carboxylate(P5C). P5C is an unstable intermediate at the intersection of proline, glutamate, and ornithine metabolicpathways (Figure 1). P5C has been shown to react with other metabolites and inhibit enzymes and is linkedwith human disease including hyperprolinemia type II5.Under physiological conditions, P5C existsin dynamic equilibrium with glutamic semialdehyde(GSA) via spontaneous nonenzymatic hydrolysis andcondensation reactions. In the proline biosyntheticpathway, P5C serves as an intermediate forproduction of proline from glutamate. Glutamate isreduced to GSA by P5C synthetase (P5CS), then P5Cis reduced to proline by P5C reductase (P5CR).Similarly, the glutamate biosynthetic pathway usesP5C as an intermediate in the production of Figure 1. Involvement of P5C with proline,glutamate from proline. Proline is oxidized to P5C by glutamate, and ornithine metabolism.proline dehydrogenase (PRODH), then GSA is Adapted from Stránská et al6.oxidized to glutamate by P5C dehydrogenase(P5CDH). In an alternative pathway, P5C can be produced or consumed by ornithine aminotransferase(OAT), which uses ornithine as a reactant or product for P5C production or consumption. Under normalphysiological conditions, OAT functions in the “forward” direction from ornithine to P5C, however, underextreme dysregulation, OAT may catalyze the opposite “reverse” reaction from P5C to ornithine6.Aim 1: Protein-protein interactions among enzymes of the proline/glutamate/ornithine pathways.Existing research already supports protein-protein interactions between PRODH and P5CDH7.However, the involvement of other enzymes in the proline, glutamate, and ornithine pathways is unknown.This aim will focus on potential protein-protein interactions between P5CS–P5CR, OAT–PRODH, andOAT–P5CDH. Because of the current discord surrounding the cellular locations of P5CS and P5CR (e.g.,mitochondrial vs. cytosolic), OAT–P5CS and OAT–P5CR complexes will also be considered. In fact, theexpression in some organisms of ornithine cyclodeaminase, which directly catalyzes ornithine to proline,supports potential protein-protein interactions between OAT and P5CR8.Enzymes used in these studies will be expressed as His-tagged proteins, as done previously withPRODH and P5CDH7. Stable protein-protein interactions will be examined through coimmunoprecipitationwith anti-His-tag antibodies and supplemented with pull-down assays via Ni-NTA chromatography. In eachexperiment, the identification of specific proteins will be accomplished through Western blot.Transient protein-protein interactions will be observed through surface plasmon resonance (SPR)at the BIAcore 3000 instrument maintained by the Nanomaterials Characterization Core Facility at theUniversity of Nebraska Medical Center. For SPR, an enzyme’s His-tag will be used to anchor the proteinto a Ni-NTA sensor chip. SPR will allow the characterization of protein-protein interaction association anddissociation constants. For cellular characterization of protein-protein interactions, fluorescence resonanceenergy transfer and yeast two-hybrid system experiments will be carried out2,7.Aim 2: Kinetics of P5C channeling among enzymes of the proline/glutamate/ornithine pathways.Even in the case of weak, transient protein-protein interactions, substrate channeling may occur.Substrate channeling of P5C has been identified in the glutamate biosynthetic pathway but has yet to becharacterized among other protein pairs of the proline, glutamate, and ornithine pathways7.Previous studies with PRODH and P5CDH have used a free diffusion two-enzyme model tosimulate reaction progress curves. In these models, the presence of substrate channeling can be inferred bycomparing theoretical non-channeling versus experimental differences in transient time7. In addition, P5Ctrapping studies will be carried out to support results from the simulated progress curves. In theseexperiments, ortho-aminobenzaldehyde (oAB) is conveniently used to “trap” P5C in aspectrophotometrically-monitored oAB–P5C complex. In the presence of P5C channeling, less P5C willfreely diffuse to be complexed with oAB as compared to a negative non-channeling control. In addition, Iwill use stopped-flow kinetics to measure the transient time of P5C channeling between the enzymes.Intellectual MeritMy proposed graduate research plan to examine unstable metabolite management is a naturalcontinuation of research I have been involved with in the Becker lab at the University of Nebraska-Lincoln.Previously, I conducted research investigating P5C channeling in the glutamate biosynthetic pathway, so Iam well-prepared to expand into protein-protein interactions and broader aspects of substrate channeling. Ihave experience with fundamental methods used for protein and metabolic research, including proteinoverexpression, purification, UV-visible spectroscopy, stopped-flow, and steady state enzyme kinetics.This research will be well-supported in the Becker lab at the University of Nebraska-Lincoln, homeof the Center for Biological Chemistry and the Redox Biology Center. My projects will be pursued incollaboration with existing structural biology partners in the Tanner lab at the University of Missouri.Broader ImpactsIt is estimated that over 80% of proteins rely on protein-protein interactions2, and substratechanneling has been identified in many major metabolic pathways3. My research will provide specificknowledge in unstudied interactions and channeling between proteins of the proline, glutamate, andornithine pathways, offering insight into the biochemical methods of unstable and reactive metabolitemanagement. Additionally, this research will serve as a case study to lay the foundation for metabolitemanagement experiments in other major pathways. Research surrounding P5C has implications forbiological mechanisms of metabolism relevant to all life.Outside of strict academics, I will leverage this graduate research in a way that benefits thescientific community and the general public. I will present results at regional and national conferences andpublish using accessible language in open-access journals. Through this research, I will take advantage ofimportant mentorship opportunities. Mentoring undergraduate or beginning graduate students in the labwill allow me to help develop the next generation of scientists as I provide a rigorous yet supportiveenvironment to foster academic, professional, and personal growth.References1Lerma-Ortiz et al. Biochem. Soc. Trans. 2016. 2Berggård et al. Proteomics. 2007. 3Sweetlove et al. Nat.Commun. 2018. 4Liu et al. Arch. of Biochem. & Biophys. 2017. 5Farrant et al. J. Biol. Chem. 2001. 6Stránskáet al. Plant Sig. & Behav. 2008. 7Sanyal et al. J. Biol. Chem. 2015. 8Goodman et al. Biochem. 2004."
6.0,"billion breeding birds11. Among the species that showed some of the steepest declines were migratoryshorebirds, one of which is the Lesser Yellowlegs (LEYE, Tringa flavipes). LEYE, a once common birdthat breeds in the boreal forest, has declined by 80% range-wide since 19661,3 and is estimated to lose anadditional 50% of its global population within 11 years9. As a result, LEYE has been designated asfederally threatened in Canada and a species of high conservation concern in the U.S.9 This species likelyencounters multiple threats during its 8000-mile migration journey3, but agricultural practices in one oftheir most critical stopover regions, the Prairie Pothole Region (PPR) have the potential to impact muchof the breeding population3. Reductions in survival due to exposure to agricultural insecticides in the PPRis one novel hypothesis that has been proposed to explain why many shorebirds in North America havedeclined, including LEYE. However, this hypothesis has not been thoroughly explored. Investigatingpopulation-level threats to rapidly declining species like LEYE is a critical conservation priority.The migratory period may be the most critical to annual survival due to the high energetic demands thatif not fulfilled can lead to reduced survival and reproductive success10. However, to ensure a timely arrivalat breeding and wintering sites, migratory birds must balance their time spent refueling at stopover siteswith their migration speed10. The optimal bird migration theory predicts that migrants constrained bytime should adjust their stopover duration to their refueling rate, and thus minimize time spent on migrationto maximize their fitness2. Research has shown that individuals with low refueling rates depart later fromtheir stopover sites relative to individuals with higher refueling rates, indicating that birds wait until theyreach a threshold of fuel stores before departing10. This suggests that the quality of stopover habitat affectsthe decision of when to leave a stopover site, which is of critical importance for migration success.During migration, shorebirds are exposed to neonicotinoids6, the most widely used class of insecticidesin the world, which pose significant risks to birds and other wildlife2,4. Neonicotinoids cause impairedimmune function, rapid reduction in food consumption, and lower reproductive success, which can resultin greater energetic demand, reduced fat stores, delayed migration and low survival1,4. Because migrationdelays can carry over to affect survival and reproduction1, neonicotinoids have the potential to imposepopulation-level impacts. Although their adverse impacts have been established in songbirds1,4, we havelittle information regarding their effect on shorebirds, highlighting a critical information gap. In a recentstudy, GPS transmitters were deployed on over 100 LEYE in Alaska and Canada3. Of the birds that bredwest of James Bay, Ontario, 90% stopped in the PPR to refuel during their migration to South America,with stopover duration times varying from a few days to over a month, indicating the importance of thisregion during migration. High presence of neonicotinoids has been reported in these prairie wetlandsand agricultural fields5, which are important foraging habitats for migrating shorebirds.Proposed Research: Using the optimal bird migration theory as a framework, I will investigate the threatof neonicotinoids on the fitness and migration of fourteen shorebird species of high conservation concern9that heavily rely on the PPR. This study will investigate a potential contributor to the observed populationdeclines of shorebirds and will help guide on-the-ground management decisions for agricultural solutions.Hypothesis: Migrating shorebirds with high plasma concentrations of neonicotinoids will bephysiologically and behaviorally impaired relative to birds with low concentrations. Similar to whathas been observed in studies of captive birds1, I predict that wild shorebirds with high neonicotinoidconcentrations will exhibit: A) lower plasma triglyceride and higher uric acid levels, indicating lowerfueling rates and fat deposition, B) poorer body condition (measured by body mass and fat scores), C)reduced foraging behavior, D) prolonged migration stopovers, and E) later migration departure dates.Research Plan: To establish an environmental gradient in pesticide contamination, I will pre-screenwetlands by measuring neonicotinoid concentrations in water samples. At sites with low and highconcentrations of this pesticide, I will capture LEYE and thirteen other shorebird species, collect bloodsamples, and measure body mass and fat over two fall and two spring migration seasons. I will measurethe concentrations of neonicotinoids in bird plasma as well as key metabolites in blood using cutting-edge LC-MS/MS techniques8. Prediction A: I will measure plasma concentrations of triglycerides anduric acid and correlate them to plasma neonicotinoid concentrations7, thereby testing for a link betweenpesticides and fuel deposition rates. Prediction B: I will compare body mass and fat scores of birds withhigh, moderate, and low neonicotinoid concentrations to better understand how neonicotinoids affectbody condition. Prediction C: I will conduct behavioral surveys on shorebirds at high and lowcontamination wetlands to determine if there is a relationship between neonicotinoid exposure andforaging behavior. After randomly selecting an individual, I will record the length of time spent indifferent behavior categories (foraging, resting, etc.) for a duration of 5 minutes. This will be repeated for10 individuals per wetland. To account for time and weather, I will conduct surveys in the morning andwill record temperature, wind, and cloud cover. Predictions D & E: To understand if neonicotinoids areimpairing migratory ability and causing migration delays, I will deploy Lotek PinPoint GPS transmittersthat will allow me to track the migration, departure dates, and stopover durations of birds with varyinglevels of neonicotinoid exposure. The results of this study will provide critical information on howenvironmental contaminants interfere with optimal migration. To minimize confounding factors, I willonly capture adults, and will stratify results by sex, species, and migration season.Facilities & Mentorship: I have two mentors: Dr. Christy Morrissey at the University of Saskatchewanand Dr. Courtney Conway at the University of Idaho (UI) where I will matriculate. Dr. Morrissey is aglobal leader in avian ecotoxicology and has developed novel and extremely sensitive methods forneonicotinoid analysis8. Dr. Conway is a renowned expert in ecology and migration of birds.Intellectual Merit: Regional efforts to study neonicotinoids in songbirds1 and wetlands6 in the PPR areongoing and our project expands on this by investigating the effects of neonicotinoids on shorebirdhealth, a novel yet timely research topic. This project would build upon an existing and growingpartnership among 8 state agencies, federal agencies, South American agencies, and universities in boththe U.S. and Canada, as well as farmers and landowners in both countries. My findings will advance thefields of migration ecology and ecotoxicology and will be highly applicable to developing conservationstrategies for shorebirds in the PPR because it will improve our understanding of the effects ofagricultural insecticides. This project aligns with the 3-Billion Birds Campaign11 to reverse populationdeclines and is part of an international effort to understand threats impacting LEYE throughout theirannual cycle. This study fills a critical information gap by investigating a major threat during migrationthat may have carry over effects to survival and reproduction and will inform managers and farmingcommunities about the effects of agricultural insecticides on birds.Broader Impacts: To increase participation of underrepresented minorities in STEM, I will developan internship opportunity through the Doris Duke Conservation Scholars Program at UI that will engagestudents from diverse backgrounds to participate in my research and develop their own independentprojects. To improve STEM education and outreach, I will create a program called Backyard BirdBanding for underrepresented students from rural schools and tribal communities to watch how wecapture and band shorebirds and participate when deemed appropriate. I will enhance the experience withengaging kid-friendly games and shorebird ID cards for teachers and students to use while out in the field.This event will be recorded and made publicly available world-wide on social media. I plan to developthis program with the following rural ND schools: Glenburn, Kenmare, and Turtle Mountain CommunityHigh School. In addition to hands-on field activities, I will use real-time shorebird migration data to linkschools through social media platforms in ND and Alaska, and through the Outreach InternationalEnvironmental program in South America. Students will be able to track the migrations of birds tagged inor passing through their neighborhoods via Movebank, an animal tracking database. Our outreach goal isto engage with at least 200 students in our programs. To increase public engagement, I will develophigh-impact outreach and educational materials about shorebird friendly agricultural practices andalternative biological pesticides in the PPR. I will work closely with the Lesser Yellowlegs workinggroup, the Coalition for Conservation & Environmental Education, farmers, and landowners in the PPR tofind practical, long-term solutions that will benefit bird populations and farming communities.1Eng et al. 2019. Sci. 365:1177; 2Alerstam et al. 1990. Bird Mig. 331-351 ; 3McDuffie et al. 2021. Pro. 1-134; 4Gibbons et al. 2015. Env. Sci. Poll. Res. 22:103; 5Main et al. 2014. PLOS 9:1; 6Malaj et al. 2020.Sci. Tot. Env. 1-10. 7Li et al. 2020. Nat. Sus. 8Bianchini et al. 2018. Env. Sci. & Tech. 52:13562; 9U.S.Shore. Cons. Plan. 2016. 10Zhao et al. 2017. Move. Eco. 5-23; 11Rosenberg et al. 2019. Sci. 120-124."
7.0,"Hypothesis: Ocean wave energy has vast potential as a renewable power source, but traditionalsequential design methods perpetuate prohibitively high device costs. Applying systems optimizationtechniques to wave energy would unlock new architectures that are cost-competitive at utility scale.Introduction: Climate change is the most critical problem facing humanity. It threatens warming,flooding, erosion, and storms that damage infrastructure, agriculture, health, and biodiversity. The fatalpotential for 4oC of warming can be limited to 1.4oC if complete decarbonization occurs by 2055 [1]. Theelectricity sector contributes 40% of global CO emissions, representing perhaps the largest challenge and2opportunity for decarbonization [2]. Existing renewables have limitations: wind and solar are intermittentand unpredictable; hydropower and geothermal have few suitable sites. To reach 100% clean electricity,we must supplement these sources by developing diverse renewables to technical and economic maturity.Ocean wave energy is uniquely attractive due to its predictability, geographic abundance, and continuousavailability [3]. Despite an ability to fulfill 34% of US electricity demand [4], wave energy technology’shigh cost, long design cycles, and risk-intensive investment have prevented full-scale deployment [3].The wave energy converter (WEC) industry has so far followed a trajectory similar to aerospace,focusing on technical risk reduction with an expectation that costs will fall after the technology matures.However, recent analysis indicates that this path is infeasible, and success hinges on a reinvention of thetypical design cycle to emphasize early cost and performance innovation before deploying expensiveprototypes [5]. Multidisciplinary Design Optimization (MDO) and Control Co-Design (CCD)techniques can provide the design paradigm shift that is required for dramatic cost reduction.MDO and CCD are emerging techniques that depart from the standard sequential design processby considering subsystem interactions early on. MDO is an optimization framework for interdisciplinarydesign problems. MDO has been used successfully in the automotive, energy, and aerospace sectors butnever attempted for wave energy due to novelty and computational costs [6]. CCD, the use of controlprinciples to inspire device design, has never been applied to a utility-scale WEC for similar reasons.CCD offers significant benefits: in offshore wind turbines, CCD decreased structural loading by 99% [7],and one estimate predicts 30% cost reduction potential for wave energy [8]. Overall, MDO and CCD arepromising methods to advance wave energy design towards full decarbonization of the electricity sector.Research Plan: This project will be completed over the course of my PhD studies at CornellUniversity in the Symbiotic Engineering Analysis (SEA) Lab, led by Professor Maha Haji.Objective 1: Develop a novel WEC design framework using principles of MDO and CCD.I will create a multidisciplinary model of WEC dynamics and performance. As shown in Fig. 1, the modelwill bridge previously disparate simulations in controls, structures, powertrain, and hydrodynamics,which are recognized as the four most impactful subsystems to drive down WEC costs [9]. I willprioritize appropriate model fidelity, simplifyingwherever feasible while still capturing importantsubsystem interactions. One key tradeoff is thedecision to model in the stochastic, frequency,or time domain. Degrees of freedom will beselected strategically, balancing computationaltractability against flexibility to describe diversearchitectures. Objective 1 is attained when adesign optimization process can be clearlyarticulated and validation efforts show that themodel can correctly predict performance ofexisting WECs. This framework forms thefoundation for the second research stage.Objective 2: Utilize the design framework to obtain a novel WEC architecture that is cost-competitive at utility-scale. The MDO-CCD model and process developed in Objective 1 will beimplemented and iterated upon, focusing on interactions between device controls and structures. Initially,optimization will identify the best combination of existing configurations; ultimately, model degrees offreedom will be extended, allowing optimization to yield new architectures altogether. Sensitivities willquantify impacts to inform further innovation. Objective 2 is complete when a WEC design with levelizedenergy cost below $0.30/kWh is found, representing a 75% cost reduction from current technology [10].Objective 3: Validate key features of the optimal design through wave tank testing. The finalstage of research involves the detail-design of a scaled prototype of the optimal solution, followed by themanufacturing, testing, and data analysis of the prototype. The testing investigates real-time controlimplementation, validates model robustness, and provides a practical industry-relevant realization of thenew design process and design. Cornell University is equipped with the facilities to enable this testingthrough the DeFrees Hydraulics Lab wave tank, and collaborations with nearby institutions including theUniversity of New Hampshire or the University of Maine could be leveraged for larger wave tank access.Objective 3 is complete when any major differences between model and test are identified and explained.Intellectual Merit: Wave energy is an under-utilized and under-researched renewable sourcewith great potential. Multidisciplinary integration is expected to be a key enabler of future cost-competitive wave energy. The proposed work will be the first to apply MDO and CCD techniques to autility-scale wave energy converter, potentially unlocking radical cost savings. My design process will bethe first to unify disparate WEC domains; my optimization will provide new insights to advance the fieldtoward design convergence; and my test data will confirm understanding and applicability of these novelcontributions. My undergraduate background provides relevant technical depth in mechanical design,power electronics, hydrodynamics, and controls, and above all I have the systems mindset to effectivelyunify these fields. This experience, coupled with the SEA Lab’s expertise exploiting synergies in marinetechnologies, uniquely qualifies me to succeed at the proposed research.Broader Impacts: Wave energy has the potential to meet 34% of national electricity demand [4].My research will enable cost-competitive wave energy, adding to the renewables mix to combat climatechange. The integrated MDO-CCD design process applies widely to any system with multidisciplinaryinteractions and embedded dynamic controllers. Thus, the proposed research advances knowledge in bothrenewable energy alternatives and systems optimization methods, both of which broadly benefit society.To circulate my research to the academic community, I will publish in journals such as OceanEngineering and Renewable Energy and present at diverse venues such as IEEE OCEANS and CESUN.Leveraging my advisor’s connections, I will initiate collaborations with the National Renewable EnergyLab and companies such as CalWave. These partnerships will amplify the impact of my research byensuring its alignment with current industry goals and its rapid dissemination to others upon completion.Finally, I will engage in outreach to both the general public and students of all backgrounds.Societal acceptance is key for widespread adoption of wave energy technology, and education about theopportunities and challenges of renewable energy encourages sustainable habits as well as an interest inengineering. My contributions to STEM outreach and curriculum development through SWE, Splash, andGRASSHOPR are detailed in my personal statement. In sum, my work as an NSF fellow wouldpromote STEM engagement, advance systems design techniques, and enable a carbon-free future.References:[1] “Climate change 2021,” IPCC, 2021. [2] “Net zero by 2050,” IEA, 2021. [3] F. Mwasilu and J. Jung,IET Renewable Power Gener, 2019. [4] L. Kilcher, et al., NREL, TP-5700-78773, 2021. [5] D. Bull etal., Sandia, SAND2017-4507, 2017. [6] J. Sobieszczanski-Sobieski and R. Haftka, Struct. Optim., 1997.[7] X. Du, et al., ASME 2020 Int. Mech. Eng. Congr. and Expo., 2021. [8] M. Garcia-Sanz, ARPA-E,2018. [9] D. Bull, et al., Sandia, SAND2013-7204, 2013. [10] G. Chang, et al., Renewable Energy, 2018."
8.0,"of bacteria (~99%), followed by archaea, then eukaryota, collectively forming the human microbiome.1,2Over the past decade, research has revealed impacts of colon microbiota on human physiology, includingroles in digestion, metabolism, immune system regulation, hormone signaling, and development.3,4 Colonmicrobiota reside in a specialized niche—a layer of mucus secreted by the colon epithelium, heavilycomprised of the gel-forming protein MUC2.5 Adenomatous Polyposis Coli (APC) is a scaffolding proteinthat has long been studied as a tumor suppressor antagonist of the Wnt/-catenin signaling pathway, withadditional roles less defined. In Dr. Kristi Neufeld’s lab at the University of Kansas, we have accumulatedevidence suggesting multiple novel functions of APC, including in the expression of MUC2. Given thisevidence, I hypothesize that APC directly or indirectly promotes MUC2 expression, and therefore hasa role in colonic mucus generation, microbiome homeostasis, and colon function. Uncovering roles ofAPC in MUC2 expression would fill a critical knowledge gap not only in our understanding of the humanmicrobiome and its homeostasis, but also in the cellular function of highly conserved APC-like orthologsfound nearly universally across invertebrates and vertebrates.6In a recent study, using Human Colon Epithelial Cells(HCECs), we found that reduction of APC led to a 75% decreasein IL-1R, an integral membrane receptor protein that, when boundto a ligand, promotes MUC2 expression.7 We found a similar trendin the IL-1R ligand, IL-1. To further investigate the relationshipbetween APC, IL-1 signaling, and MUC2 expression, we modifieda human colon cancer cell line, DLD-1, using CRISPR/Cas9. Weinserted wildtype (WT) APC under control of a doxycycline (Dox)responsive promoter, which allowed us to treat cells with Dox andinduce expression of WT APC. Using unmodified (parental) DLD-1s as a control, we found that IL-1 and WT APC individuallyincreased MUC2 expression 2-fold, but when expressedsimultaneously, MUC2 expression increased 15-fold (Fig. 1).7 Figure 1. RT-qPCR for MUC2 inThis evidence suggests that IL-1 signaling and APC act Parental and APC-Inducible DLD-1synergistically to promote MUC2. This evidence also suggests that cells. (Two-way ANOVA withIL-1R activation increases MUC2 expression, which may occur Tukey’s range test, **P <0.005,through signaling of PKC-, a protein previously correlated with IL- ***P<0.0005, ****P<0.0001)1R activation and MUC2 expression.8 To investigate DNA-binding of APC that might be involved in MUC2 promotion,we used a dataset from a recent ChIP-seq study9 and foundthat APC binds to the promoter of the MUC2 gene.Combined with our APC gain and loss of function studies, Icreated a simple model to reflect hypothesized interactionsbetween IL-1R, APC, PKC-, and MUC2 (Fig. 2).Aim 1: Elucidate the Molecular Roles of APC in MUC2Expression. As evidenced by our research, APC expressionFigure 2. Model of relationships that wouldleads to an increase in MUC2 mRNA levels and APC lossallow IL-1R and APC to increase MUC2leads to reduction in IL-1R. However, whether APC inducesexpression individually and synergistically.*translation of MUC2 or IL-1R is yet to be determined. Withthe help of Dr. Yoshiaki Azuma, a CRISPR/Cas9 expert at the University of Kansas, I have designed andbegun creation of two novel cell lines to uncover the molecular roles of APC. By modifying HCEC andDLD-1 cells, we will be able to perform quick, cheap, efficient, and consistent 1) APC KO using an Auxin-Inducible-Degron (AID), 2) basal-level APC expression with no treatment, and 3) APC overexpressionusing Tetracycline-Inducible-Expression (TIE). The AID system uses OsTIR1, an auxin-responsiveubiquitin ligase, to polyubiquitinate AID-tagged proteins for degradation in the proteosome.10 I am taggingendogenous WT APC with an AID for APC KO. The TIE system initiates transcription of a gene througha tetracycline (TET)-responsive promoter11 and will be paired with the endogenous AID-tagged APC. I willuse MUC2 promoter/Luciferase Reporter Assays (LRAs) and our in-lab luminometer to confirm responseto various levels of cellular APC. An increase in luciferase indicates that APC increases MUC2 promoteractivity, a neutral result indicates no effect of APC, and a negative result indicates APC reduces MUC2promoter activity. This design can be repeated with reporters for all my candidate gene promotors, includingIL-1R, MUC2, synergism between APC and IL-1 for MUC, etc. Regardless of my findings, these resultswill direct my further studies on APC and the other proteins of interest in this system, includinginvestigation on protein localization, protein modifications, and signaling pathways. I will use co-immunoprecipitation followed by mass spectrometry performed at KU’s Core Mass Spec Lab to identifysignaling proteins, florescence microscopy using our in-lab microscope to understand protein localizationsand treatment phenotypes, SDS-PAGE and western blots for exposing signaling pathway patterns, mobilityshift assays for uncovering post-translational modifications and protein activation, and much more tounderstand my proteins of interest and their signaling pathways.Aim 2. Monitor Impacts of APC on Colon Microbiome Homeostasis. In another recent study, we createdtransgenic mice with an APC allele containing mutations in the protein’s Nuclear Localization Sequences(APC-mNLS), preventing APC from entering the nucleus, and thus, inhibiting potential direct APC-drivennuclear promotion of gene expression. In this study, we uncovered that APC-mNLS mice had a >90%decrease in MUC2 expression following colon epithelial injury compared to control mice.12 I hypothesizethat APC-mNLS mice have lower levels of MUC2, reducing the amount of mucus habitable by microbiotain the colon and thereby decreasing microbiome diversity and microbiota count. Using this mouse strain,with our extensive mouse care facilities and IACUC approval (137-01), I will collect fecal and colonicmucus swab samples of both mutant mice and control littermates for Zymo Research’s MicrobiomeAnalysis Service,13 which provides publication-ready data of a list of microbiomic data, including absolutemicrobiota counts, multi-kingdom accounts of microbiome diversity within and between samples, andmore. In addition to these data, I will use immunohistochemistry to visualize MUC2 in the colon epitheliumusing anti-MUC2 antibodies, comparing mutant and control littermates. This will provide comprehensiveevidence of any changes to the microbiome and the colonic mucus layer in response to loss of nuclear APC,providing insight into APC’s physiological function and connection to the microbiome in vivo.Broader Impacts: The proposed research will expand our understanding of non-Wnt functions of APC,the function of APC in the generation of the colon mucus layer, the impact of APC on the microbiome, andprovide insight on the function of APC orthologs across the animal kingdom. These data have the potentialto uncover numerous novel functions of APC and better our understanding of microbiome homeostasis inrelation to physiological function, a field of study that is still in its infancy. The cell lines I will create anddata I will collect will be powerful research tools for myself, the Neufeld lab, and other researchers studyingAPC and colon microbiomics. I will communicate the conclusions of my research through publications, aswell as through posters and oral presentations at regional and national conferences. I will also continue todevelop the Rural Scientist Initiative (RSI) outlined in my personal statement; the NSF GRF would allowme to dedicate more time to the RSI while attending graduate school. Development of the RSI includespresenting this research to rural students along with information on scientific careers to ~15-30 of the 70high school students at Norwich High School per year, based on student interest. I will continuecommunicating my experience as a scientist from several underrepresented communities to these students,encouraging rural students to pursue careers in scientific research.References. 1. Sender et al (2016) PLOS Biol 14(8):e1002533; 2. Qin et al (2010) Nature 464:59-65; 3.Heintz-Buschart et al (2018) Trends Microbiol 26(7):563-74; 4. Schroeder et al (2016) Nat Med 22:1079-89; 5. Johansson et al (2016) Nat Rev Immunol 16:639-49; 6. Bienz et al (2002) Nat Rev Mol Cell Biol3:328-38; 7. Gomez et al (2020) Exp Physiol 105(12):2154-67; 8. Tiwari et al (2011) J Immunol187(5):2632-45; 9. Hankey et al (2018) Oncotarget 9(58):31214-30; 10. Natsume et al (2016) Cell Reports15, 210-18; 11. Das et al (2016) Curr Gene Ther 16(3):156-67; 12. Zeineldin et al (2014) Carcinogenesis35(8):1881-90; 13. Zymobiomics (2020) 5:159-63; *Created with BioRender.com"
9.0,"Introduction:In recent decades, reports of re-emergingand novel phytopathogens have increaseddramatically in forests.1These pathogens threatenforest health and pose serious risks to plantbiodiversity. Studies indicate climate change (e.g. warmer temperatures, wetter growing seasons) hasaccelerated forest decline within the United States by expanding plant pathogen ranges.2The effectsofclimate change have heightened and extended the infection period for pathogens, making treesmore vulnerable to outbreaks of less aggressive phytopathogens.3Plant pathogens in the familyNectriaceae, including undescribed species, have been indirectly linked to climate change.4In addition,these changes in temperature are known to increase sporulation and virulence of fungal pathogens, as coldperiods would ordinarily reduce the populations of pathogens by arresting their growth. Trees at highelevations including red spruce, Fraser magnolia, yellow birch, striped maple and mountain ash arebuffered from many pathogenic fungi due to persistent cold temperatures in their habitat; however,warmer winters have increased the risk for biological invasion of these species.5Although significant progress has been made regarding the taxonomy of these nectriaceous fungi,additional data are needed to clarify species boundaries and their evolutionary relationships. Likewise,these fungi pose risks that must be fully assessed by more robust studies on host range and pathogenicity.Long studied forests are now experiencing epidemics of these emergent plant pathogens (EPPs).6Whilebeech bark disease andFusarium-associated diseasesare highly-studied pathosystems, native, often lessvirulent, nectriaceous fungi are becoming more abundant. My objective is to protect Appalachian forestsby 1) drawing connections between abiotic stressors and the prevalence of nectriaceous fungal pathogens,2) identifying these fungal pathogens, and 3) assessing the effects of temperature on the aggressiveness ofthese pathogens.I propose to expound upon currentclimate change models and forest pestpredictions, particularly for nectriaceous fungi on these high-elevation tree hosts.Aim 1:Assessing abiotic stressors contributing tothe emergence of fungal pathogens.Using the ‘Climate by Forest’ tool provided by the U.S. Forest Service, I will review changes in foresthealth and climate projections for forests throughout the Appalachian region. The ‘Climate by Forest’ toolis a novel interface in which users can select regions of national forests and look at various climate trendsand variables.7From these projections, forests thatare predicted to have significantly warmer winters willbe selected for sampling. High-elevation tree species will be selected based on their known range acrosshigh elevation zones throughout Appalachia. Symptomatic tissues and conspicuous fungal fruiting bodiesfrom these species in our sample sites will be surveyed, collected and processed for culture- andDNA-based studies. I will also compile and analyze temperature data across the Appalachian region toquantify and evaluate the abiotic stress these forests have endured.Hypothesis: Fungal pathogens andabiotic stresses are synergizing declines in native tree species.Aim 2: Characterizing known and unknown nectriaceousfungal diversity in Appalachian forests.Hypothesis: Despite known diversity of Nectriaceous fungal pathogens across Appalachian forests,many remain undetected.Molecular tools must be usedin combination with existing morphologicalmethods to capture the full diversity of phytopathogenic fungi. Sanger sequencing will be used for purecultures of my suspected fungal pathogens recovered from trees sampled inAim 1. Targeted loci (LSUand EF1-α) are widely used for phylogenetic inference in Nectriaceae.8Illumina amplicon sequencing—amultiplexed PCR approach—will be used to identify asymptomatic fungi that may also be contributing toforest decline.Aim 3: Determining the interaction between individualnectriaceous fungi and targeted tree species incentral Appalachia along a temperature gradient. Hypothesis:Nectriaceousfungi have contributeddifferentially to tree disease epidemics, which are driven in part by changes in temperaturethroughout our Appalachian forests. To simulate globalwarming and to assess the effects oftemperature on fungal growth and pathogenicity, temperature-dependent pathogenicity assays will beconducted. In climate-controlled growth chambers, saplings of the aforementioned five species will begrown at varying temperature ranges (0°C, 10°C, 20°C, and 30°C). Trees will be inoculated with selectnectriaceous fungi discovered inAim 2and tree healthwill be monitored at 6-MPI and 12-MPI. Anynotable canker formation will be measured at the end of the inoculation period. To fulfill Koch’spostulates, trees will also be sampled to see if the original inoculum can be recovered. This experimentwill quantify the aggressiveness of suspected nectriaceous pathogens at varying temperatures, allowingme to infer the impact novel phytopathogens will have on our forests as global warming worsens.Intellectual Merit:As a member of Dr. Kasson’s forestpathology lab since mid-2020, I have directexperience identifying and characterizing diverse fungal phytopathogens in West Virginia. During myefforts to delimit the species boundaries ofNeonectriamagnoliae,I have already identified numerousnectriaceous fungi on a wide range of hosts, including some novel species we are describing. Putativepathogens in the Nectriaceae are abundant and appear to be emerging as the result of the unique overlapof biotic and abiotic factors. I have and will continue to collaborate with forest pathologists throughoutthe Appalachian region to compare DNA sequences, host range, and pathogenicity of these fungi undersupervision of Dr. Matt Kasson (WVU), my current advisor and forest pathology expert. With his supportand the support of my forest pathology colleagues, I will not only unravel the contributions of thesefungal phytopathogens to the decline of our forests, but provide novel information to our Appalachiancommunities, our foresters, and our scientists.WestVirginia is the “black box” of biodiversity:severely understudied with much to discover. There are an estimated 150 different tree species in WV:more than anywhere else in North America. My contributions to forest pathology will revolutionize howwe look at and care for our trees in Appalachia.Broader Impacts:West Virginia (WV), my homestate, is suffering from educational neglect. It hasthe lowest number of Bachelor’s degrees (20.6%) per capita of any state, and we have the second lowestper capita graduate degrees.9In Appalachia—and WV specifically—we deal with low science literacy anda fear of science. Our region once powered the country with coal, but the profits of this mono-culturaleconomy were not reinvested in our communities. As coal has faded away and global temperatures rise,there is much skepticism and fear around climate action in West Virginia. West Virginians needscientists from our own communities trained to identify the challenges we face, develop solutions tothese problems and share them with our own.Thesescientists, like myself, will have a broad andimmensely positive impact on my community.As science outreach has been an integral part of my undergraduate career, I will curate my ownenvironmental science outreach program to invest my project in our Appalachian youth. Through myAppalachian Children’s Environmental Research program(ACER), I will recruit fellow youngscientists to bring presentations to K-12 students and also offer field trips to teach a variety ofenvironmental concepts. In this novel program, I will provide resources (i.e., guides, lessons, andaccessible information) on climate change, forest health, mycology, and other topics pertaining topreserving the integrity of our ecosystems.My lifetimeof learning has prepared me to fulfill this nextstage of my career, one that will ensure West Virginians are not left behind.References:[1] Karunarathna et al. 2021.Front CellInfect Microbiol. [2] Kasson et al. 2009.Mycologia.[3] Dukes et al. 2008.Can J For Res. [4] Pavlov etal. 2020.Sci Rep. [5] Pauchard et al. 2015.BiolInvasions. [6] Corredor-Moreno et al. 2019.New Phytologist.[7] U.S. Forest Service. 2018. Climate byForest. [8] Stauder et al. 2020.Fungal Ecol. [9]West Virginia QuickFacts. U.S. Census Bureau."
10.0,"actions allow them to control their external environment. Studiesoncausallearningshowthatasearlyasinfancy, humans learn the relations between actions and their outcomes1 and are able to use thisknowledgetoactassuccessfulagentsintheirenvironment.Mostexistingliteratureonagencyemphasizescomparing the outcome of one’s own actions with their internal predictions of thoseactions2-5.However,these processes have been limited to sensory perception and stimulus-response learning, precluding theability to explore the effects of agency on episodic memory6 and how sequences of information whichunfold due to causal actions drive brain regions to support memory.Background. Exercising agency over learning environments has been shown to improvememory7,8, even when the choices do not relate to the content of the to-be-learned items. Previous workfrom ourlabgaveparticipantsasimplechoicebetweentwo‘cards’whichwouldrevealanunrelateditem.Participants better remembered items that appeared as a result of their choice9,10. Further, this memoryenhancement was driven by an interaction between anticipatory activation within the striatum, a regionassociated with causal actions and motivation, and hippocampal (HPC) engagement during encoding.While this shows how agency over a choice can positively affect memory fortheoutcomeofachoice,itdoes not shed much light onto memory for the overall decision sequence.To explore how agency over a series of events affectsassociativememoryforthecomponentsofthe sequence, I developed a task where participant's agency was manipulated via a choice. In the “gameshow” task, participants assisted contestants in choosing one of three doors which reveal a hiddenprize.On each trial, participants saw a trial-unique contestant and either freely chose between the doors(“agency” trials) or selected a highlighted door (“forced-choice”trials).Unbeknownsttotheparticipants,the prize image presented was predetermined. After completion of the task, participants completed asurprise retrieval taskwhichtestedmemoryforthecontestantspresentedintheencodingtask,whichdoorthey selected, and the outcome hidden behind the door in three separate, consecutive memory tasks.Across two studies (study 1 n = 28; study 2 n = 131), which serve as the foundation for thisproposal, participants showed enhanced memory for the contestants (p<0.001), constant-prize pairs(p<0.05), contestant-door pairs (p<0.01), and prize-door pairs (p<0.01). These results show that bymanipulating participant’s agency to select which door to open, we are able toenhancememoryforcuesas well as associative memory between cues and outcomes. However, these results do not discriminatewhether agency enhances memory separately for each individual pair, or whether agency facilitates thebinding of all associations into one integrated sequence. Follow-up analysis explored whether agencyfacilitates memory integration by examining whether there was an inter-dependence upon memorymeasures such that memory for one pair was dependent onmemoryfortheotherpairs.Indeed,wefoundmemory for the contestant-prize pair was modulated by memory for recalling both the contestant-doorand door-prize pairs (p<0.01). Further, this effect was significantly higher for pairs that occurred inagency trials vs the forced-choice trials.Intellectual Merit. While I have established a paradigm that modulates associative memory viaagency, it isstillunclearhowmesolimbic-hippocampalengagementsupportsthislearning.Understandingthe timescale of how these systems interact will inform us on how agency modulates encoding andconnect human and animal research. Much of the existing human literature exploring mesolimbiccontributions to memory focus onhowphasicdopaminedriveslearninginresponsetorewardfeedback11.However, rodent research has shown hippocampal engagement during exploration prompts sustainedventral tegmental area (VTA) engagement leading to greater response feedback to the hippocampus12. Ipropose exploring these temporal dynamics within the same paradigm to address the gaps in these twolines of research and contribute to the translation of rodent-to-human research. Using neuroimagingtechniques, the current research seeks to: 1) examine sustained mesolimbic during encoding, 2)examineevent-evoked VTA and hippocampal activationduringencodinganditseffectsonmemory,3)exploretheinteractions between engagement at these different timescales. I hypothesize sustained mesolimbicactivity during learning when an individual has agency increases cue and outcome basedmesolimbic-hippocampal interactions. The relationship with the sustained and event-evoked activitywillbias encoding to promote associative learning across and within decision sequences.Methodology. Eighty healthy participants will berecruitedtoparticipateinastudyattheTempleUniversity Brain Research and Imaging Center, which houses a Siemens Prisma 3T MRI scanner.Participants will complete a modified version of the game show task. On each trial, they will see atrial-unique contestant (2s), and then will seeandselectoneofthethreedoors(2-4s).Uponselection,thedoor will be highlighted, then removed to presentatrial-uniqueprizeimage(2s).Again,participantswilleither get to freely choose one of the three doors (agency trials) or be forcedtoselectahighlighteddoor(forced-choice trials). Participants will complete three runs of each condition, each run containing 20trials. Runs will be pseudo-randomized across participants so no more than 2 runs ofthesameconditionappear consecutively. Temporal jitters will be placed between cues and outcomes and between trials toimprove both temporal and spatial resolution. Following encoding, participants will complete the threeretrieval phases described earlier: contestant recognition, and contestant-prize, contestant-door, anddoor-prize associative memory.Analyses. Behavior: In brief, item memory will be calculated for contestants using correctedrecognition, which accounts for false alarm rates. Associative memory metrics will be calculated as hitrates (percent correct in selecting the old item). I will compare memoryacrossagencyandforced-choiceconditions using paired t-tests. In line with my previous findings, I expect memory for items and itempairs to be enhanced for those that appear in agency compared to forced-choice trials.Neuroimaging: 1) In order to examine sustained mesolimbic activation, Iwillcomparesustainedbaseline VTA engagementusingpairedt-testsonparameterestimatesfromanatomicalROIs.Ipredictthesustained activation to be higher for agencycomparedtoforced-choicerunsandtrials.2)Toexplorehowthe event-evoked VTA-HPC coupling may drive memory, I will use a 2x2 within-subjectsANOVAwithcondition (agency, forced-choice) and memory (sequence intact, sequence disrupted) on parameterestimates from anatomical ROIs during cues and outcomes. I expect this couplingtopredictmemoryforagency but not forced-choice trials. 3) To examine the interaction betweenengagementofthesedifferenttime scales, I will relate measures of sustained VTA and VTA-HPC activations on the event-evokedmemory signals acrossrunsforbothconditions,separately,usingmulti-levelGLMmodelswitharandomeffect of participant. Post-hoc analysis willmakedirectcomparisonsacrossconditions.IexpectsustainedVTA activation and VTA-HPC coupling during agency runs to be associatedwithevent-evokedmemoryeffects in the VTA and the hippocampus on agency trials, across runs.Broader Impacts. Much of the literature exploring motivated learning comes from work that isparticularly interested in response to reward feedback. However, motivated learning in the absence ofreward may contribute toriskfordevelopmentofsubstanceabuse.Suchlearningmaypotentiatecuesandcontextual factors that strengthen drug associations independent of the anticipation or experience of thereward. I will use agency as a model to elucidate the neural underpinnings of motivated learning in theabsence of rewards. This model will allow for the isolation of the core mechanisms that underliesubstance abuse, which may depend on VTA-HPC interactions. The proposed research will dissect howVTA-HPC interactions contribute to the complexity of behaviors associated with substance abuse byelucidating how both state-dependent and event-evoked interactions drive memory encoding.Additionally, the results of the proposed research may provide valuable contributions toimproving pedagogical techniques. Understanding how agency might enhance learning at differenttimescales could support new teaching methods which incorporate agentic choices over both short andlong term goals. Even inmyanecdotalexperienceemployingactivetechniquestoengagementees,Ihavefound that giving individuals’ agency over minor choices, such as choosing what topic to read anddiscuss, and more substantial choices, such as choosing a research topic, leads to significantly moreengagement and long-term retention. The proposed research will directly test how agency can affectmotivation and learning at various timescales, which will contribute both to our understanding of howitcan support learning and how we may utilize it to broadly enhance teaching methods.References. 1Kuhn, 2012 2Haggard et al., 2002 3Haggard, 2009 4Wolpert et al., 1995 5Chambon et al,20146Hon, 20177Gureckis&Markant,20128Markantetal.,20169Murtyetal.,201510Murtyetal.,201911Shohamy & Adcock, 2010 12Lisman & Grace, 2005"
11.0,"language pairs and translation tasks. However, two of the most pressingopenproblems inNMTare domain adaptation and low-resource scenarios [1] (i.e., language pairs for which largeparallel corpora do not exist). This project will address both issues via cross-lingual domainadaptation in an extremely low-resource setting. The work is motivated by an urgenthumanitarian crisis: refugees seeking asylum in the US who speak only Central Americanindigenous languages like K’iche’, Mam, Kanjobal, and Mixtec [2]. The scarcity of interpretersin these languages makes itdifficult for speakers toaccess legalservices,andexistingnonprofitsand NGOs providing legal aidto refugeesdonothaveadequate resourcestoprovideinterpreters.Additionally, existing methods for low-resource NMT do not scale down to the extremelylow-resource situation for these Central American languages. Improving both extremelylow-resource applicability anddomain adaptationfor NMT will increasethenumberof scenariosin which NMT is a viable solution. Additionally, domain adaptation techniques that workinthechallenging low-resource setting will also improve NMT domain adaptation in higher-resourcesettings. Thus, this project addressesachallenging andwidelyapplicable scientific problemwithimmediate humanitarian impacts.Objectives and Hypothesis: The objective of my proposed research is atwo-prongedapproachto domain adaptation in low-resource NMT. I will address the domain issue by fine-tuning apretrained NMT model on synthetic parallel data generated via backtranslation [3] ofmonolingual in-domain data in the target language. I will first validate my approach in ahigh-resource setting by fine-tuning a baseline Spanish-English model using backtranslatedin-domain English data. Independent of the performance on low-resource languages, aSpanish-English translation system that is well-adapted for asylum testimonials will be of greatuse to organizations providing legal aid to refugees. Then, I will apply the fine-tuning viabacktranslation approach to the low-resource case. In order to successfully backtranslate theEnglish finetuning data, a decent English-LR model is needed. Thus, I plan to apply acombination of unsupervised NMT, transfer learning, multilingual translation models, andvarious data augmentation approaches totheproblem ofextremelylow-resource NMT.Althoughvarious methods to augment parallel corpora have been proposed [4-7], they typically augmentcorpus size from a few hundred thousand sentences to a few million . They do not adequatelyaddress a context in which only thousands or tens of thousands of sentences are available, as isthe case for K’iche’ and other indigenous languages. This project will develop alinguistically-informed method to generate enough plausible, syntactically correctsyntheticdatathat existing corpus augmentation techniques like backtranslation can be applied, bridging thechasm between researchers’ assumptionsabout theamount of availablemonolingual dataand thereality for many low-resource languages.Method and Research Plan: In this research, I will use K'iche as a case study language todevelop methods, then I will apply those methods to Kanjobal, Mam, and Mixtec. BLEU score,the standard evaluation metric for machine translation [8], will be the primary metric forevaluation of this proposed research. Possible BLEU scores range from 0 to 100, with higherscores indicating a closer match to the reference translation. In my exploratory work on theMagdalena Peñasco Mixtec dialect,achievinga maximumBLEU scoreof7with amodel trainedfrom scratch on 8000 Mixtec-English parallel sentences. After this preliminary work, I decidedto use K’iche’ as the test language in further study for two reasons: first, monolingual K’iche’speakers are more common among migrants to the US than monolingual Mixtec speakers;second, there are more than fiftydistinct dialectsof Mixtec,each withvaryingdegrees ofmutualintelligibility, which makes collection and cleaning of data intractably difficult.The first year of my work will focus on domain adaptation to asylum testimonialsin thehigh-resource Spanish-English setting. High-resource NMT models are primarily trained onparallel data extracted from news articles, while LR models are generally trained on whateverportions of the Bible are available for a givenlanguage.Because theultimate goal ofmyprojectis to translate first-person testimonials ofasylees aboutthe violencefromwhich theyarefleeing,I needto adapttheNMT modelsto fluentlytranslatefirst-person narrativesandto understandthespecific vocabulary relevant to asylees. One way to accomplish this adaptation is to fine-tune apretrained translation model on in-domain data. While parallel data is ideal,itis also possibletouse monolingual target-language data via backtranslation. I plan to use the transcripts from theMALACH dataset [9], compiled from the USC Shoah Foundation’s Video History Archive,which collects testimonials from Holocaust survivors. I hypothesize that these testimonials aresimilar enough to the stories of modern asylees to be useful as in-domain training data.In the subsequent years of the project, I will apply the domain adaptation techniquedevelopedin thefirstyear totheextremelylow-resource setting.Thefirst priority for Year2is togather and clean a K’iche’-English parallel corpus (at least the New Testament and someJehovah’s Witness literature is readily available). Next, I will establish a baseline machinetranslation result for K’iche’-Englishusing available parallelcorporawithnodata augmentation.Then, I will apply the same backtranslation for domain adaptation technique used forSpanish-English. However, I expect that the backtranslation results will be unsatisfactorybecause of the limitations of the English-K’iche’ model used for backtranslation. Thus,I plantodevelop a data augmentation scheme syntax-aware compositional data augmentation methodsfrom [10], withsome simplifications necessaryduetodata scarcity. Sentencesproducedwiththismethod are guaranteed to be grammatically correct, but may not make sense semantically;however, they are much easier to produce than semantically correct sentences, especially in alow-resource setting. This research will investigate whether NMT systems can learn usefulinformation from synthetic data that is syntactically, but not semantically, correct. In additiontodata augmentation, I plan to explore whether the K’iche’-English and English-K’iche’ modelscan be further improved by transfer learning and unsupervised NMT techniques.Intellectual Merit:Thiswork addressesacrucial gapincurrent methodsfor low-resource NMT:cases where there are fewer than 10,000 sentences of monolingual data available. My proposeddata augmentation method would allow researchers to generate enough synthetic monolingualdata to apply state-of-the-art methods in low-resource NMT to languages that would otherwisebe intractable due to lack of data. If this data augmentation is successful,it willshowthat NMTsystems can learn grammar and syntax from synthetic training data that is semantically verynoisy, opening up future research on how exactly NMT systems learn grammar and how thislearning differs from learning vocabulary.Broader Impacts: The human rights impact of my proposed research is immediate andtransformative. Interpreters for K’iche’ and related languages are hard to find and oftenprohibitively expensive. Translation systems, even imperfect ones, would allownon-governmental organizations and pro bono immigration lawyers to help asylees they werepreviously unable to serve. Widespread access to legal assistance would speed up backloggedimmigration courts and give thousands of asylum seekers per year a chance to enter the USlegally. This work could save lives, because many of these asylees are children and teenagersfleeing from horrific gang violence.References[1] Koehn, Philipp, and Rebecca Knowles. ""Six Challenges for Neural Machine Translation.""Proceedings of the First Workshop on Neural Machine Translation. 2017.[2] Medina, Jennifer. “Anyone Speak K'iche' or Mam? Immigration Courts Overwhelmed byIndigenous Languages” New York Times (2019).[3] Sennrich, R., Haddow, B., & Birch, A. (2015). Improving neuralmachinetranslationmodelswith monolingual data. arXiv preprint arXiv:1511.06709.[4] Zhang,Jinyi, andTadahiroMatsumoto. ""CorpusAugmentationbySentenceSegmentation forLow-Resource Neural Machine Translation."" arXiv preprint arXiv:1905.08945(2019).[5] Li, Hongheng, & Heyan Huang. “Evaluating Low-Resource Machine Translation betweenChinese and Vietnamese with Back-Translation”. arXivpreprint arXiv:2003.02197(2020).[6] Currey, Anna, Antonio Valerio Miceli-Barone, and Kenneth Heafield. ""Copied MonolingualData Improves Low-Resource Neural Machine Translation."" WMT 2017.[7] Fadaee, Marzieh et al. ""Data Augmentation for Low-ResourceNeuralMachine Translation.""ACL 2017.[8] Papineni, Kishore, et al. ""BLEU: a Method for Automatic Evaluation of MachineTranslation."" ACL 2002.[9] Ramabhadran, Bhuvana, et al. USC-SFI MALACH Interviews and Transcripts English –Speech Recognition Edition LDC2019S11.[10] Andreas, Jacob. ""Good-enough compositional data augmentation."" arXiv preprintarXiv:1904.09545(2019)."
12.0,"Introduction. The question of how a child learns her native language remains highly debated in linguisticresearch. Cross-linguistically, children learn much of the morphology (word structure) of their nativelanguage by age three, when their vocabulary is approximately 1000 words.1 Yet the frequencies of wordsin child-directed speech follow a skewed, roughly Zipfian distribution, with the frequency of a wordbeing proportional to the inverse of its rank.2 This means that a few words may occur hundreds of times inthe child's linguistic input, but most occur only a few times. Similarly, most words only appear in a few oftheir possible inflected forms (e.g. the child may hear fall and fell, but not falls or fallen).3 Such inputcontrasts with the larger, more saturated data used by most machine learning systems today. How, then,does a child learn the morphology of her native language from such a skewed, sparse input? During myPhD, I seek to answer this question via computational modeling of morphological acquisition.A plausible model of morphological acquisition should follow the developmental and behavioralpatterns of children, which may be studied experimentally and through analysis of errors in children'sspeech. Productivity of a linguistic process is marked by its ability to generalize to novel contexts, and isa foundational component of language. In the famous wug study, for example, most English-learningchildren generalized -ed, -ing and -s to novel verbs (e.g. gling) by age three, demonstrating that they hadlearned the productivity of these suffixes.4 Further, most errors in children's speech are caused by over-application of productive processes: English verb acquisition is known to follow a ""U-shaped"" curve,where a sudden dip in performance is caused by the overapplication of -ed to irregular verbs (e.g. goed,feeled) when the child discovers its productivity.5 Several promising computational models that accountfor these facts utilize the Tolerance Principle (TP), a threshold of productivity which posits that a childgeneralizes a process when it is more computationally efficient to do so under a Zipfian distribution.2Such distributional learning models have been the focus of my undergraduate research: working with Dr.Charles Yang, I developed a model that acquires meaning-form mappings (e.g. PAST = -ed) betweensuffixes and their corresponding semantic features, such as person (first, second or third), number (e.g.singular, plural), and tense (e.g. past, present, future).6 This model follows developmental patterns andcorrectly acquires morphological rules on small vocabularies of Spanish and English verbs. I also createda model that acquires such mappings for German plural nouns and English verbs, even displaying U-shaped regression in English, and contributed to a third model with comparable results.7 It is my goal tobuild on these models to create an integrated, incremental, and cognitively-plausible model ofmorphological acquisition that succeeds on a wide array of languages.Aim 1: To create a model of incremental morphological acquisition that succeeds on a typologicallydiverse set of languages. While the models outlined above provide promising results, no single model isable to account for all languages: the latter two succeed on concatenative, non-agglutinative languages(e.g. English, German), but fail to model non-concatenative (e.g. Hebrew, Arabic) and agglutinative (e.g.Spanish, Swahili, Japanese) languages. Segmenting a word into morphemes is more challenging in suchlanguages: in Spanish, for example, a verb may take multiple suffixes (e.g. ama-ba-s = love-past-2nd+singular = ""you loved""). These models are also not incremental learners, but extract morphological rulesfrom fixed-size vocabularies; this contrasts with the incremental nature of language acquisition. In myfirst aim, I thus plan to build on the models above to design a novel algorithm that incrementally acquiresmorphological rules across agglutinative, non-agglutinative, and non-concatenative languages. Whilecurrent models take in each item as a lemma, inflected form, and semantic feature set (e.g. walk, walked,{PAST}), the child may be able to group each of the inflected forms in which she has seen a word (e.g.get, gets, gotten). I hypothesize that doing so will allow for cleaner segmentation and identification ofmorphemes, helping the learner to succeed on a wider array of languages. To test this, I will create such amodel and compare it with experimental findings on the aforementioned languages and others. I will workclosely with linguists and cognitive scientists from differing subfields to ensure that this work benefitsfrom both theoretical and experimental insights and provides a plausible account of acquisition.Aim 2: To extend this model by incorporating models of other portions of language acquisition.Morphological acquisition does not happen in isolation, and morphology is known to interact with otherlevels of linguistic representation, particularly phonology (e.g. -s is pronounced /s/ in cats but /z/ in dogs).The nature of the input to the models discussed above assumes that the child has already learned much ofthe phonology of their native language and extracted the relevant semantic features such as person,number and tense onto which they will map the segmented input. The grouping of forms as discussed inAim 1 makes the additional assumption that the child is able to form these groups. To create a moreholistic account of acquisition, I will thus integrate models of morphological learning like the above withmodels of acquisition of other levels of linguistic representation, particularly those on which Aim 1 relies.It is highly plausible that similar learning algorithms are used for each level of representation, so I willbegin by testing the ability of the algorithm developed above to account for these other levels. I will alsotest integration of the model developed under Aim 1 with existing models in the literature. With the endgoal of an algorithmic hypothesis about how children acquire their native language, I will collaborate withexperts on each of the levels of representation I will consider. I will compare the integrated model'spredictions with experimental findings on a typologically diverse set of languages to ensure that thisalgorithmic account of learning is a plausible and generalizable one.Intellectual Merit. The end goal of this work, an input-to-grammar model of morphological acquisition,will provide insight into linguistic theory and the learning mechanisms employed by children. The modeldeveloped under Aim 1 will provide an algorithmic hypothesis regarding how children learn fromskewed, sparse data, and structural hypotheses regarding morphological knowledge in the mind as the endresult of acquisition. Both will be valuable in answering questions of learnability and the structure oflinguistic knowledge, and may also provide insight into atypical language development. The modelsdeveloped under Aim 2 will yield hypotheses about the interactions between linguistic levels ofrepresentation, which may be compared with theoretical hypotheses to provide new insight into linguisticstructure. Further, these models will give a bottom-up account of language acquisition, and thus yieldtestable hypotheses regarding the innate factors that may enable it, a highly-debated topic. This modelwill, to my knowledge, be the first to model morphological acquisition from phonological input to astructured grammar, and it will thus provide a basis for further integrated models of language acquisition.Broader Impacts. This work has applications to Natural Language Processing (NLP), which focuses onthe creation of language technologies. Models used in NLP are typically trained on data several orders ofmagnitude larger than that to which the child is exposed. This can lead to biases and makes modelsinaccessible for “low-resource” languages for which large corpora do not exist, such as Indigenouslanguages and languages of Africa and Asia.7 Cognitively-motivated approaches already show promisingresults,8 and since the algorithms I will develop are designed to succeed on small, sparse input, they willbe strong candidates for use with low-resource languages and for testing bias mitigation strategies. This,in turn, will allow for the creation of more accessible, equitable language technologies for all.References. [1] Brown, R. 1973. A first language: The early stages. Harvard University Press. [2] Yang,C. 2016. The price of linguistic productivity: How children learn to break the rules of language. MITPress. [3] Chan, E. 2008. Structures and distributions in morphological learning. UPenn Dissertation. [4]Berko, J. 1958. “The child’s learning of English morphology.” Word. [5] Pinker, S. and Prince, A. 1988.“On language and connectionism: Analysis of a parallel distributed processing model of languageacquisition.” Cognition. [6] Payne, S, et al. 2021. “Learning Morphological Productivity as Meaning-Form Mappings.” Proceedings of the Society for Computation in Linguistics. [7] Belth, C, Payne S, et al.2021. “The Greedy and Recursive Search for Morphological Productivity.” Proceedings of the CognitiveScience Society. [8] Bender, E, et al. 2021. “On the Dangers of Stochastic Parrots: Can Language ModelsBe Too Big?” Proceedings of the ACM Conference on Fairness, Accountability, and Transparency. [9]Xu, Chao et al. 2020. “A Cognitively Motivated Approach to Spatial Information Extraction.”Proceedings of the Third International Workshop on Spatial Language Understanding."
13.0,"Progress in neuroscience is limited by the lack of proper tools available to biologists and neuroscientists tostudy neural circuits with high spatial resolution and cell type specificity. One area of neuroscience that isparticularly affected by this absence is the study of somatosensory and motor control systems. Currentlyavailable tools used to study these systems and mimic their functions consist of electrode arrays, such asthe polymer cuff electrode, attached to the peripheral nervous system1 or the Utah electrode array implanteddirectly into the motor cortex2. These electrode arrays, however, lack the ability to induce or record neuralactivation with cell specificity.Herein, I propose the development of a novel class of miniaturized, battery-free, wireless, soft, implantableneural machine interfaces (NMIs) utilizing optogenetics to study the somatosensory system in non-humanprimate (NHP) models via the peripheral nervous system (PNS). This proposal considers the recentadvancements within the fields of optogenetics and photometry, advanced micro- and nano-fabricationmethods, and the necessary collaborations to bring this project to fruition within a three-year period.BackgroundOptogenetics is a growing neuroscience tool which utilizes viral injections to genetically modify neuronpopulations to express light-sensitive ion channels. The targeted neurons can be selectively stimulatedamong other tissues by selecting viral vectors and opsins with preferential tropisms. In NHPs, initialresearch in optogenetic stimulation of the peripheral nervous system shows channelrhodopsin-2 (ChR2)and Chronos delivered via adeno-associated virus and stimulating muscle injection to be successful3. Oncethe opsins are virally delivered, these neuron populations can be excited or silenced by targeting them withvarying wavelengths and stimulation frequencies from light-emitting diodes. Recent papers have shown thesuccess of optogenetics in stimulating the central nervous system via the brain and the spinal cord4,5.Similarly, genetically-encoded calcium indicators (GECI’s) and photometry can be used to visualize neuralactivation of defined cellular populations in-vivo6. These tools have significant advantages over electricalprobes which lack the stimulation and recording specificity required for high resolution research into lighttouch information propagation through the low-threshold mechanoreceptor afferent neurons in the dorsalroot ganglia (DRG). Neuron populations of particular interest for this study are the low-thresholdmechanoreceptor afferent neurons within the DRG located in cord segments C6, C7, and C8, which areresponsible for light touch information propagation from the lower forelimb and hand7.Aim 1: Optical Recording and Stimulation of Low-Threshold Mechanoreceptor Afferent NeuronsThe primary functions of the proposed device are to optically record the neural activity of low-thresholdmechanoreceptor afferent neurons in a healthy NHP’s DRG, and to stimulate those neurons to replicatelight touch information being transmitted through the neural circuit up A- and A- fibers. The cells willbe targeted following the methods outlined by Williams et al. using ChR2 and Chronos, and with GECI’s.To enable both recording and stimulation, the device will employ a colloc𝛽𝛽ated micr𝛿𝛿oscale inorganic light-emitting diode (μ-LED) and photodetector (μ-IPD), both interfaced with a microcontroller for stimulationcontrol and data processing respectively.Additional functional requirements to ensure device reliability are highly deformable mechanics and ausable lifetime of 10 years or longer. To ensure the device function for applications lateral the spinal columnserpentine geometries, polymer substrate and encapsulations, and thin annealed metal traces will beemployed to keep local strains under fatigue limits even under high bending and linear loads. To extend theusable lifetime of these devices, dielectric interlayers of thermally grown Silicon Dioxide and HafniumOxide will be used. These interlayers, employed in a total thickness up to 100µm, work to extend usablelifetime by retarding the ingress of ions and water vapor and disrupting pin-hole defects while remainingtranslucent8.Device encapsulation and fatigue mechanics will be tested using accelerated life testing (ALT) in an 87℃phosphate buffered saline bath with complex mechanical loading conditions for 4 months, simulating animplanted lifetime of 10 years and 8 months. While ALT is being performed, the long-term reliability ofthe stimulating and recording capabilities will be assessed by measuring the irradiance of the μ-LED andthe recorded signal of an external light source via the μ-IPD over time. Device electronics and wirelesspower harvesting will be assessed via continuous data logging.Aim 2: In-Vivo Testing in Non-Human PrimatesThe final aim of the proposed research is to implant the proposed device into NHPs to conduct research onlight touch propagation via low-threshold mechanoreceptor afferent neurons in the DRG. The anatomicalsimilarities of mechanoreception between NHPs and humans allows for the study of light touch perceptionin the forelimbs that could not be studied in small animal models. This work will be done with collaboratorswho conduct NHP behavioral studies, external to the Yoon Lab at the University of Michigan where Ipropose to do my PhD. One study of interest includes training the NHPs to perform two-alternative forcedchoice tasks involving the differentiation of textures on their fingertips or palms and studying the neuralactivity for each of the presented textures. After the behavior is learned with accuracy of 95% or greaterand the neural activity has been recorded and decoded, the NHP will perform the task again. However, thistime the NHP will receive light touch information from the device via optogenetic stimulation of themechanoreceptor afferent neurons in the C6 C7 and C8 DRG without any textures presented.Future DirectionsUpon completion of this work, the goal is to transition from the study of the peripheral nervous system’srole in light touch perception to implantation within a NHP amputee. Once implanted, this device willinterface with an upper-limb prosthetic via near field communication and used to replace the lost light touchperception abilities of the amputated limb. If shown to be successful, the next step is to use this device inconjunction with functional magnetic resonance imaging to study the long-range neural circuits of thesomatosensory system, a study never before possible.Intellectual MeritThe development of this device will utilize recent advances in materials science, fabrication, andoptogenetics to advance neuroscience tools. The design process and in-vivo testing will also requirecollaboration with the departments of Biology and Neuroscience as well as external collaborators to informthe selection of virus, opsin, μ-LED, and μ-IPD. Once developed, these devices would directly promote anadvancement in the understanding of the peripheral nervous system’s role in somatosensory processing andpropagation and introduce a platform of devices for the targeted study of the somatosensory system andother short- and long- range neural circuits in-vivo.Broader ImpactsThese devices would be applicable not only in the study of light touch information but any neuron type andthus have broad impacts in neuroscience, neurotherapies, and limb rehabilitation or replacement forparalyzed or amputated individuals. Outside of the medical field, the ability to transmit somatosensory froman external input to the peripheral nervous system could also be used to advance entertainment systems andvirtual reality to include touch perception.References1. Elyahoodayan, S., et al.. Acute in vivo testing of a polymer cuff electrode with integratedmicrofluidic channels for stimulation, recording, and drug delivery on rat sciatic nerve. J.Neurosci. Methods 336, 108634 (2020).2. Maynard, E., et al.. The Utah Intracortical Electrode Array: A recording structure for potentialbrain-computer interfaces. Electroencephalogr. Clin. Neurophysiol. 102, 228–239 (1997).3. Williams, J., et al.Viral-Mediated Optogenetic Stimulation of Peripheral Motor Nerves in Non-human Primates . Frontiers in Neuroscience vol. 13 759 (2019).4. Ausra, J. et al. Wireless, battery-free, subdermally implantable platforms for transcranial and long-range optogenetics in freely moving animals. Proc. Natl. Acad. Sci. 118, e2025775118 (2021).5. Kathe, C. et al. Wireless closed-loop optogenetics across the entire dorsoventral spinal cord inmice. Nat. Biotechnol. (2021)6. Burton, A. et al. Wireless, battery-free subdermally implantable photometry systems for chronicrecording of neural dynamics. Proc. Natl. Acad. Sci. 117, 2835 LP – 2845 (2020).7. Vanderah, T. W. & Gould, D. J. Nolte’s the Human Brain: An Introduction to its FunctionalAnatomy. (Elsevier, 2021).8. Jeong, J. et al. Conformal Hermetic Sealing of Wireless Microelectronic Implantable Chiplets byMultilayered Atomic Layer Deposition (ALD). Adv. Funct. Mater. 29, 1806440 (2019)."
14.0,"Background: The vestibular system, located in the inner ear, provides sensory information regardingspatial positioning and balance, enabling coordination of movement and orientation1. Additionally, thevestibular system plays a key role in enacting compensatory eye movements in response to body movementthrough the vestibulo-ocular reflex (VOR)1. This system can become unilaterally impaired in the presenceof vestibular schwannoma, a benign tumor that develops on the vestibulocochlear nerve connecting thesensory organs to the brain2. Due to the vestibular system’s active role in locomotion, impairment viavestibular schwannoma may lead to balance deficiency, vertigo, and oculomotor process changes2. Previouswork has demonstrated that in patients with vestibular schwannoma, head movements during locomotionand gaze stability exercises are less rapid and the VOR is impaired2,3. Encouragingly, resection, or removal,of vestibular schwannoma has been demonstrated to result in improvement of kinematic parameters andother head movements, with major changes occurring within the first six weeks post-operation4. Generally,normal vestibular activity is reflected in the parieto-insular and temporo-parietal junctions; however, littleis known about cortical changes that occur due to vestibular impairment, with most studies focusing onkinematic parameters and quantification of specific visual reflexes5. Therefore, there is a need to examinethe impact of vestibular schwannoma on neural activity at large. Obtaining this information about theways the human brain copes with vestibular system deficiency will elucidate both patterns of neuralplasticity in response to specific sensory input alteration, and how best to approach treatment of those whoare impacted by vestibular schwannoma. I propose to determine the patterns of neural activity and gazefocus in response to locomotor tasks in people with vestibular schwannoma, both pre- and post-resection.This work will be conducted across three Aims: first, a comparison of electroencephalography (EEG) andgaze-tracking patterns in healthy subjects and vestibular schwannoma patients; second, a longitudinal studyof EEG and gaze patterns in vestibular schwannoma patients pre- and post-resection; finally, generation ofa support vector machine (SVM), a machine-learning technique which will discriminate between gazepatterns of patients with vestibular schwannoma and healthy controls.Intellectual Merit: This project will contribute to the body of knowledge surrounding normal vestibularfunction, as well as provide insight into the specific pathological state inherent to vestibular schwannoma.The insight into the changes in gaze functionality will be especially important because the impact ofvestibular schwannoma on overall gaze patterns is not well-understood beyond interruption to the VOR.Changes to further parameters such as saccade frequency, fixation time, and primary areas of focus duringlocomotion are unknown. This project will elucidate changes in those patterns.Research Plan:Aim 1: Collection of baseline patterns in vestibular schwannoma patients vs. healthy subjectsHypothesis: Vestibular schwannoma patients will display greater primary motor cortex activation thanhealthy control subjects during gait, representing a more effortful process due to balance impairment.In this phase, we will focus on establishing a baseline of functionality in healthy subjects and patients withvestibular schwannoma, recruited from Johns Hopkins Acoustic Neuroma Center, a specialty clinic focusedon the treatment of vestibular schwannoma. Testing will consist of a modified functional gait assessment(FGA) battery. The ‘gait with eyes closed’ portion of the FGA will be excluded, due to the inability torecord gaze location while eyes are closed. During the FGA, subjects will have gross brain activity recordedvia a 58-channel EEG cap connected to a wearable Arduino Uno microcontroller to allow for continuousmobile data collection. Additionally, subjects will don wearable eye-tracking glasses to assess continuousgaze location. This phase will conclude with successful collection of gaze-tracking and EEG data for amatched number of healthy subjects and vestibular schwannoma patients executing the FGA tasks.Aim 2: Longitudinal study of vestibular schwannoma resectionHypothesis: Between six weeks and six months after vestibular schwannoma resection, patterns of neuralactivity in vestibular schwannoma patients will become more like that of healthy subjects during gait.This phase will enact a longitudinal study of patients with vestibular schwannoma pre-resection,approximately six weeks post-resection, and at least six months post-resection. This experimentation willconsist of the same paradigm as Aim 1, with subjects performing the modified FGA. Additionally, duringthis phase, the EEG signal collected in Aim 1 and Aim 2 will be processed and analyzed. Preprocessingwill consist of an independent component analysis, wherein the multivariate EEG signal for each subjectwill be decomposed into additive ‘components’, which combine at different weights to compose the overallEEG signal. These components will be assessed via visual inspection to remove extraneous signal, such aseye blinks and motion artifacts. Then, processed data will be examined for event-related potentials at severalkey points in the gait cycle. This phase will conclude with the accomplishment of two tasks: successfulcollection of gaze-tracking and EEG data for vestibular schwannoma patients pre- and post-resection, andanalysis of differences in patterns of neural activation between healthy controls, pre-resection vestibularschwannoma patients, and post-resection vestibular schwannoma patients.Aim 3: Generation of Support Vector Machine to categorize gaze patternsHypothesis: Individuals with vestibular schwannoma will display distinct gaze patterns, including greatergaze latency to area of interest, as compared to healthy control subjects.This phase will center around the generation and validation of asupport vector machine (SVM) that will enable automatic machineclassification of vestibular schwannoma patients versus healthycontrols. An SVM is a supervised machine learning approach that usesa hyperplane to split groups of variables, or support vectors, intodiscrete classes (shown in two dimensions in Figure 1); once trainedon the stereotypical values for each class, it compares new data tothose clusters to classify the state of the new input6. An SVM has beenused to accurately detect pathology based on gaze patterns; Figure 1: Design of an SVM 7specifically, individuals with dyslexia versus healthy controls while reading text6. Measured parameterswill include number of saccades, number of gaze fixations in key areas of interest (ground underfoot, groundahead of stride, wall), length of gaze fixations, and latency of gaze arriving at areas of interest. Within thismodel, some erroneous classification is inevitable. Because the primary purpose of the model is quantifyingimpacts of vestibular schwannoma to the ocular system, it is preferable to bias the model towards detectingvestibular schwannoma in order to find any and all gaze-pattern disruptions. Accordingly, the SVM will betuned to have higher sensitivity to prevent false negatives. This phase will conclude with the demonstrationthat the resultant SVM is able to discriminate between the gaze patterns of healthy individuals and thosewho suffer from vestibular schwannoma, with at least an 85% detection rate for positive cases.Alternative Approaches: An SVM can have limited efficacy if the training dataset is of insufficient size.If there is not be a significant dataset that will allow for training of the model and model accuracy is belowthe 85% threshold, an alternative approach may be the use of a convolutional neural network (CNN), whichconsists of a cluster of signal-transmitting kernels that loosely resemble neurons. A CNN has previouslybeen used to classify gaze-tracking data based on what website a user was viewing; however, thismethodology has not been extended to pathology detection8. If needed, this possibility could be explored.Facilities: This work will be conducted with Dr. Kathleen Cullen at the Cullen Laboratory at Johns HopkinsUniversity. This laboratory has previously conducted studies of vestibular schwannoma patients usingkinematic parameters and is equipped to continue this work with other methodologies.Broader Impact: While the primary purpose of this work is to learn about the unimpaired vestibular systemthrough a study of vestibular schwannoma as a disease state there is potential for secondary application asa diagnostic measure. The diagnostic process for vestibular schwannoma is two-stage – first-round testingconsists of a battery of hearing tests, and if those tests suggest the presence of a tumor, second-round testingconsists of an MRI with contrast. With the rising costs of healthcare in the United States, finances can be aprohibiting factor to patients pursuing this diagnostic testing. The creation of a lower-cost intermediatediagnostic would prevent unnecessary clinic visits for final diagnostic testing for patients whose hearingloss may have a different cause. If the SVM can recognize patients with vestibular schwannoma, then anintermediate gaze-tracking diagnostic tool could be developed and used to screen patients with hearing lossto determine whether vestibular schwannoma is a likely culprit for their symptoms.References: 1. K. Cullen, Nat Rev Neurosci, 2019; 2. A. Batuecas-Caletrio et al. Laryngoscope, 2015; 3.L. Wang et al. Sci Rep, 2021; 4. O. Zobeiri et al. Sci Rep, 2020; 5. E. Nakul et al. Front Neurol, 2021; 6. L.Rello et al. W4A ’15, 2015; 7. “Support Vector Machine”, javaTpoint; 8. Y. Yin et al. ICMLA ’18, 2018."
15.0,"in coral reef environments and providing ecosystem services that are intrinsic to the longevity of society.The diverse microhabitats provided by the elaborate morphologies of corals function as predation refugeand are essential for supporting the low trophic level (LTL) fish community.1 Specialist fish species willlive within one coral colony (or others of similar morphology) for much of their lives, whereas generalistfish can associate with a wider variety of microhabitats. Trophic cascading of the LTL fish communityresults in flourishing commercial fisheries, which are estimated to be globally valued at $5.7 billion USDannually.2 Yet, the existence of coral dominated tropical reefs is largely threatened by global scale,anthropogenic warming-induced coral bleaching events—which has in part contributed to a 50-75%decline in worldwide coral cover over the last ~35 years.3,4 The loss of microhabitat often leads to drasticdeclines in the reef fish community5 and can crash commercial fishery markets. To mitigate against thefurther decline of coral reefs and the fisheries they support, restoration strategists in-part rely on large-scale coral propagation and outplanting—involving the artificial fragmentation of reef-obtained donorcolonies and returning the clonal population back to the reef.6 Often, studies attempting to describe coralreef environments solely focus on percent coral cover and fail to capture the complex nature of coral reefecosystems.7 It remains unclear how reef fish community assemblages are directly affected by bleaching-induced changes in microhabitat availability. Understanding fish-microhabitat associations is essential fordevising targeted, efficient fisheries restoration efforts. The proposed research aims to elucidate theunique fish-microhabitat associations to better inform outplanting-based fisheries restoration efforts.Revealing fish-microhabitat associations would lead to the development of a comprehensive CoralOutplanting for Fisheries Guide (COFG) to be leveraged by coral restoration and fisheries managers. Thisresearch also aims to capture changes in the population levels and spatial distributions of commerciallyvaluable high trophic level (HTL) populations while under the presumed pressure of depleted LTL preypopulations following a bleaching event.Hypotheses: I hypothesize that (1) bleaching events will induce the largest decreases in specialist, LTLfish populations relative to generalist fish populations (H1), (2) bleaching events drive HTL predatorpopulations to relocate to less-affected regions of the reef where food sources are sufficient, or in moreextreme cases, recruit to nearby reefs owing to the reductions of LTL fishes associated with H1 (H2), and(3) outplanting of fisheries-specific coral taxa will facilitate the recovery of the fishery stock (H3).Experimental Approach: Timeseries Density Maps: The framework of one entire reef would be imagedbefore and after a single bleaching event, which would be scheduled according to existing local degreeheating week (DHW) data. DHW is a measure of accumulated thermal stress obtained by the 12-weektime-integration of sea surface temperature data exceeding the local bleaching threshold and is a reliablebleaching predictor.8 The onset of bleaching is expected when DHW values reach 4 °C-weeks, whereasmass bleaching and mortality is expected at 8 °C-weeks.9 The framework would be characterized bygenerating high taxonomic resolution photomosaics10 of the benthic coral community coupled withArcGIS-generated density maps of coral colony microhabitat volume approximated using structure-from-motion (SfM). SfM is a computationally intensive software that would allow me to digitally reconstructthe reef and extract microhabitat volume data from each colony. The movements of lower and highertrophic level fish populations would be continuously monitored utilizing size-specific acoustic telemetrytransmitters and receivers to create 3D population density maps in ArcGIS. It is imperative to implantsize-specific transmitters to minimize potential adverse health impacts to best isolate for tracking thenatural movements of the fish.11 Fish populations would be estimated for all implanted fish taxa usingwell-established tag-recapture techniques and the appropriate stock assessment model according to thespecies-specific life history traits.Statistics: To determine specific fish-microhabitat associations and build the COFG, colony location andtaxonomic classification will be tested against the time-based location density of the tagged LTL fish. Totest for potential reef-level population reduction differences in LTL fish species (specialists vs.generalists) (H1), I would linearly model the tag-recapture-obtained population abundance data andevaluate whether species, time, and the interaction of species and time are significant predictors of meanabundance. To test for potential significant changes in the movements of HTL predator populations (H2),I would model the time-based location density of tagged LTL fish populations paired with the time-basedlocation density of tagged HTL predators. I would encourage future studies to utilize the COFG producedby this research to answer H3. These studies would require quantifying the background recruitment ratesof LTL fish populations and the new recruitment rates following a large-scale outplanting effort. I wouldalso overlay the microhabitat volume density maps with the fish population density maps to allow forbetter visual interpretation of the data.Resources: I am applying to be advised by Dr. Sandin who is a leading expert in coral reef ecology at theScripps Institution of Oceanography (SIO). Dr. Sandin’s team is comprised of many individuals withyears of experience who would assist me in reliably imaging the reef and identifying coral colonies. Ihope to also receive guidance from Dr. Brice Semmens (SIO), who often uses telemetry techniques in hisresearch, to safely implant fish with acoustic transmitters and reliably track their movements. This studywould rely on the resources available to SIO, especially the use of custom-framed, study-optimizedcameras12 and SfM to digitally reconstruct the reef from imagery and perform the colony microhabitatvolume calculations. The spatial monitoring of LTL populations would require surgically implanting fishwith Juvenile Salmon Acoustic Telemetry System (JSATS)13 microacoustic transmitters and installingJSATS N201 receivers around the perimeter of the reef. The spatial monitoring of HTL populationswould follow the same methods but require Vemco™ V16p-4H transmitters and VR2 receivers.Intellectual Merit: This research would provide valuable insight to ecologist’s holistic understanding ofsuccessional reef fish communities. Although previous work has evaluated the role of decreased reefframework on fish community composition using transect based methods,14 it remains unknown howshifts in specific coral species alter the population level and distribution of specific fish species. Thisresearch aims to reveal these mysteries with the increased quantized framework resolution from SfM andthe paired monitoring of fish movements. This project would provide great predictive value to infer whatreef-associated fish communities may look like in the future if the current frequency of bleaching eventscontinues. Particularly, which fish species we might expect to decline at a given reef site if targetedconservation efforts, such as those that would be made possible by the COFG, are not enacted.Broader Impacts: The COFG developed from this research could guide the decisions of coral restorationand fisheries managers by detailing which coral species serve as primary microhabitat for a particularLTL fish population—enabling managers to easily identify which coral species to outplant to maximizethe available microhabitat for LTL prey species for a specific fishery. In theory, increased microhabitatavailability and trophic cascading would result in increased LTL prey population(s) and the HTL fisherystock. However, the world’s leading coral outplanting organization, the Coral Restoration Foundation(CRF), has only optimized the large-scale propagation and outplanting of 4 coral species. The fisheries-relevant coral species identified by this research that are not currently being outplanted would providereason to increase funding for the development of new programs working to optimize the large-scalepropagation of these species. The realization of this optimized restoration strategy would require acollaborative effort between SIO, CRF, and fisheries managers around the world to outplant the specificcoral taxa that provide the most relevant microhabitat for prey of target fisheries. This innovativerestoration optimization would be a valuable strategy to help work towards sustainable fisheries andmaintaining their incredible economic value for future generations. I intend to disseminate the findingsfrom this project via publications in peer-reviewed journals to drive similar studies that would build uponmy findings and broaden the geographic relevancy of the COFG. I will present my findings to students atnearby institutions to inform aspiring ecologists of the problems our worlds reefs are facing, hopefullyinspiring them to pursue related careers and research.References: [1] Bellwood et al (2004) Nature 429:827-833. [2] Cesar et al (2003) Cesar Environ EconConsul, NLD. [3] Goreau & Hayes (1994) Ambio 23:176-180. [4] Bruno et al (2019) Ann Rev Mar Sci11:307-334. [5] Jones et al (2004) PNAS 101:8251-8253. [6] Rinkevich (1995) Restor Ecol 3:241-251. [7]Brito-Millán et al (2019) Mar Ecol Prog Ser 630:55-68. [8] Liu et al (2014) Remote Sens 6:11579-11606.[9] Liu et al (2003) Eos 84:137-144. [10] Gracias et al (2003) IEEE J Ocean 28:609-624. [11] Lefrancoiset al (2001) Mar Biol 139:13-17. [12] Kodera et al (2020) Coral Reefs 39:1091-1105. [13] McMichael etal (2010) Fish Res 35:9-22. [14] Richardson et al (2018) Glob Change Biol 24:3117-3129."
16.0,"Introduction: Development of personalized medical treatments and diagnostics is limited by our ability toengineer tools that can keep up with demand. Exosomes are a type of nano-sized extracellular vesicle (EV)naturally produced by cells and released via endosomal fusion with the plasma membrane. Althoughprimarily utilized in the detection of diseases such as cancer, exosomes are increasingly being investigatedas a means of drug delivery due to their potential for multi-functional targeting and inherentbiocompatibility [1]. A longstanding setback in the study and application of exosomes for therapeuticpurposes is the lack of standardized methods with which to isolate, concentrate, and characterize them [2].Although scientists can functionalize exosomes with targeting molecules and drug payloads, scale-up islimited by the ability to quickly identify favorable processing conditions and thus good manufacturingpractices. In this project, I propose creating a system that will reduce the burden of the screeningprocess by developing a tool to rapidly assess exosome production and functionality. This study willhelp others engineer EVs as a tool for medical and non-medical applications.Traditional methods quantify exosomes via nanoparticle tracking analysis (NTA) which relies on lightscattering of particles to judge size and concentration via analysis of Brownian motion. However, NTA alsocounts non-exosome particles such as protein aggregates, leading to large discrepancies in actualdetermination of exosome quantity in solution. Moreover, NTA does not account for functionality ofengineered exosomes, which typically display targeting molecules on their surfaces. Current exosomepurification methods are labor intensive, requiring multiple days of centrifugation and gradient separationto remove the crude EV material prior to quantification and analysis of the exosome product [2]. Therefore,developing a method to rapidly quantify and assess exosome functionality with targeting molecules wouldenable scientists to focus their attention on scaling up and purifying only the most promising therapeuticexosome processes. This development would bypass the current time-consuming roadblocks associatedwith engineered exosome production, advancing the field.Objective: I will establish a high-throughput method to screen processing conditions for engineeredexosomes. Protein microarrays, which have previously been used in diagnostic exosome assays [3], havethe potential to quantify functionalized exosomes in an efficient and accurate manner. Therefore, Ihypothesize that protein microarrays can be utilized as a high-throughput method to screen processingconditions for engineered exosomes. I plan to (1) investigate optimal microarray conditions by engineeringspot formulations and process steps and (2) evaluate ideal processing specifications for exosome productionby running protein microarrays in tandem with cholesterol-based quantification standards.Aim 1: Investigate optimal microarray conditions to create a high-throughput screening tool forfunctionalized exosomes. Protein microarrays can be modified to include different antibodies in each spot.The ideal formulation would be one that binds only targeted exosomes. Exosomes express the surfaceligands CD9, CD63, and CD81 as unique identifiers from other EVs [2,3]. Antibody cocktails for theseligands, as well as the expressed targeting molecules, would enable binding of only the desired exosomes—even in the presence of a crude EV sample—while washing away all other materials in solution. I willdetermine the concentration of each antibody for optimal exosome binding kinetics, which is a function ofthe desired targeting molecule antibody. The formulation must also be modified to include a solventmaterial that is suitable for microarray printing but that does not interfere with the antibody-exosomeinteractions. Once I find the ideal antibody cocktail ratios, I will test the formulation to ensure that it printsappropriately on the microarray slides. The solution’s fluid properties must enable it to flow easily forspotting on the slides, dry quickly,and spread evenly. Differentadditives noted in literature wouldbe investigated to find those thatwork best with the solution. Iexpect that a 5% glycerol contentwill produce the desired results,as it was used in a previouspublication illustrating a methodfor exosome phenotyping using protein microarrays [3]. Various factors affect microarray accuracy,including sample application times, wash and blocking buffer identities and concentrations, number andduration of washes, and drying times. Each of these factors will be explored systematically using a factorialdesign of experiments (Fig.1a). If the microarray cannot be optimized for EVs, a column-based affinityseparation method could be used to purify and confirm functionalization of exosomes. Completion of thisaim will optimize the microarray as a tool for engineered exosome analysis.Aim 2: Evaluate ideal process conditions for engineered exosome production. Having identified themost favorable microarray conditions, I will compare processing conditions for engineered exosomes toprove the rigor of the quantification method. With this high-throughput method, dozens of differentprocessing specifications—such as days in culture, feed conditions, pH setpoints, and centrifugationsteps—could be analyzed simultaneously with a minimal demand on sample volume. The first step inengineering a suitable high-throughput method is to create a reliable standard for comparison. Whileworking at Codiak Biosciences, I pioneered a cholesterol assay that circumvented time-consuming NTAby quantifying exosomes based on their cholesterol content and presented a poster on this work at theInternational Society for Extracellular Vesicles (ISEV) 2020 Annual Meeting. The fluorescence plate-basedAmplex Red Cholesterol Assay was quick and accurate within a prescribed range of 0-8 µg/mL. Employingit also enabled me to quantify exosomes without the need for purification, reducing cost and time spent. Iwill utilize this preliminary work to develop a standard method for exosome quantification for this project.Once the standard is established, exosome samples conjugated with fluorescent tags will be applied to themicroarray spots. After washing, only the exosomes with the desired surface ligands will bind to the spotand be fluorometrically detected (Fig.1b). The relative fluorescence of each spot will be compared to astandard where only the exosome detecting antibodies, not the targeting molecule antibody, are present.This relative fluorescence describes the number of functionalized exosomes in the sample. These signalswill be compared to the cholesterol-based assay to obtain a quantitative readout of the number of engineeredexosomes and their relative protein loading. If fluorescent tags are not feasible, dyes, luminescentsubstrates, or other types of markers could be conjugated to the exosomes to create a measurable readout.The results of this aim will elucidate the ideal conditions for engineered exosome screening.Intellectual Merit: This work will generate a deeper understanding of protein microarrays as high-throughput screening tools and can be applied to development of new exosome or nanoparticle-basedtechnologies, which could be used in applications ranging from drug delivery to water treatment. It willexpand the foundational knowledge surrounding EVs and support future endeavors to optimize theproduction of different types of engineered exosomes, aiding in the discovery and development of EVtherapies. As a member of the Leonard Lab, which has expertise in exosome production and engineering, Iam well positioned to complete this project.Broader Impacts: This proposal integrates chemical engineering, bioengineering, and biochemistryprinciples to create an interdisciplinary project that advances dynamic drug delivery platforms throughhigh-throughput screening. Successful completion of this project will enable accurate exosomequantification, reducing labor and time investments. Rapid identification of improved processing conditionswill support efficient and sustainable production of therapeutic exosomes, increasing manufacturingfeasibility, and thus increasing their eventual accessibility on a global scale. I will leverage my connectionsat Codiak Biosciences to establish a collaboration to facilitate and support the project. I will disseminatethe knowledge gained from this research to the scientific community for feedback and further developmentthrough conferences and publications, such as the ISEV Annual Meeting. Providing students withopportunities to learn about STEM fields and to participate in projects directly will foster the nextgeneration of research scientists. I plan to direct my outreach toward programs encouragingunderrepresented students to consider graduate school, such as REUs and the Northwestern MorningMentors and Mentorship Opportunities for Research Engagement (MORE) programs, where I will mentorstudents and encourage their participation in STEM research.References: [1] Wang, J. et al. (2017). ACS Applied Materials & Interfaces, 9(33), 27441-27452. [2] Chia,B. S. et al. (2017). TrAC Trends in Analytical Chemistry, 86, 93-106. [3] Jørgensen, M. et al. (2013).Journal of Extracellular Vesicles, 2(1), 20920."
17.0,"Intellectual Merit How do you study something you cannot see? Dark matter (DM) is responsible forshaping the large-scale structure of the universe we see today, comprising 80% of all matter.Decadesofdirect and indirect searches for annihilation radiation have notyieldedanysignals. InordertostudyDMastrophysically, we must use the luminous parts of the universe — the galaxies and galaxy clusters thatreside inside DM halos — as tracers. The DM halo relationship is cleanest near the outskirts of thesestructures, where non-gravitational physics, such as AGN feedback, have the least effect. Whiledifficultto observe due to their low density, new and upcoming advancements in instrumentation are detectingobservational tracers in halo outskirts for the veryfirsttime.SubsequentmeasurementsofDMhalomassand dynamical quantities, such as accretion rate, will constrain not only large-scalestructurebutalsothenature of the DM particle itself.My projectexplorestheoutskirtsofbothindividualgalaxiesandgalaxyclusters:twostructuresatdifferent cosmological scales but subject to fundamentally similar dynamics. Starting on the scale ofgalaxies, the brightest cluster galaxies(orBCGs)haveextendedfaintstellarhalosthatarenowthoughttohave physically significant edges [1]. Moreover, in recent optical images from the Hyper Suprime-CamSubaru Strategic Program (HSC survey), it has been shown that the stellar mass in the outskirts(10-100kpcradii)oflow-redshiftBCGsisanexcellentproxyforDMhalomass[2].Theoutskirtsofthesemassive galaxies are dominated by stars accretedduringmergerswithprevioussatellitegalaxiesandthusprovide an estimate of “historical richness” for their DM halos. While promising for its potential ofmeasuring DM halo mass, this result leads to more questions: Why is the 10-100kpc region significant?Could an even tighter relationship to DM mass exist with stellar profiles past 100kpc?On a larger scale, the outskirts of galaxy clusters (>1Mpc) also provide a laboratory for theeffects of DM. At these distances, dark matter particles turn around at their apocenter, called thesplashback radius, the location of which depends on the halo’s mass accretion rate(MAR)[3,4].Recentsimulation work suggests this radius coincides with an analogous “stellar splashback” radius of thecluster’s stellar distribution (or intracluster light, ICL), which would also vary with MAR and revealintriguing DMhalodynamics[1].Thesmallsampleanduseofzoom-insimulationsinthisstudywarrantsafollowupinvestigationwithcosmologicalboxsimulationsandalargersample.HowobservablethisICLedge will be with future instruments is also unclear and requires further modeling.There are many other unexplored phenomena at theseclusteroutskirts,notonlyinDMbutinthehydrodynamics of gas. In particular, an accretion shock must beproducedwhencoldgasfallsintoahaloand experiences a drastic jump in temperature. According to the self-similar collapse model [5, 6], theradius at which this shock appears should be almost identical to the cluster’s splashback radius [7],making it another potential observational tracer of DM. However, the model has not held up insimulations, in which the shock radius has been found to be 20-100% larger than the splashback radius[8]. This disagreement is a fundamental theoretical gap that needs to be understood to interpret currenthigh-resolution observations of the Sunyaev-Zeldovich effect in clusters (from the South Pole Telescopeand Atacama Cosmology Telescope) as well as near-future radio observations of accretion shocks.Cosmological simulations offer the opportunity to understand the connections between baryonicphysics and underlying DM halos inordertobothinterpretobservationsandmakepredictionsouttohaloradii we cannot yet observe. While many processes in simulations are implemented via subgrid models,the processes in halo outskirts are mostly-first principle physics producible even with these limitedmodeling conditions. I will use cosmological simulations of dark matter and galaxies includingthelargevolumecosmologicalboxsimulationsuiteIllustris-TNG(TNG)[9].IproposetouseTNGtoinvestigatemultiple baryonic physics phenomena at theoutskirtsofgalaxiesandofgalaxyclustersaspotentialtracers of dark matter halo properties.My projectconsists of 3 scientific goals:1. Develop robust techniques to measure BCG light profiles out to large radii to find optimalestimators of DM halo mass2. Test the connection between ICL edges and splashback radius3. Analyze the relationship between the accretion shock radius and splashback radius1. Galaxy Stellar Outskirts andDMHaloMassTheHSCsurveyisamajorstepinobservers’abilitytooptically image BCG outskirts out to 100kpc given its high-quality seeing conditions and a depth 3-4magnitudes deeper than the SDSS. In collaboration with the HSCteam,Iwillusethesedatatodevelopanew technique for extrapolating stellar mass profiles of high-mass BCGs beyond their observable radiusby testing them against a sample of simulated, mock-observed TNG galaxies of similar mass.A crucial consideration in simulation-observation comparisons is how to recreate the conditionsused by observers. To achieve this science, we need to overcome technicalhurdles.Forexample,thefileordering of the TNG output data is by friends-of-friends groups, suchthatoverlappinggroupscouldleadto one group missing particles near its outskirts. Forgoingthisdataorganizationtoinsureallparticlesareaccounted for makes extracting complete profiles out to large radii in large simulations is a non-trivialtask. I recently implemented a function in a simulation-extraction software, Hydrotools, that overcomesthis challenge and allows users to extract all particles within a given radius. This function lays thefoundation for any project relying on large-scale radial profiles.2. ICL and Mass Accretion Rate Satellites fall into a halo with various velocities, orientations, andinternal energies, so it is not immediately clear that disrupted stars in the ICL are faithful tracers of theDM halo potential. I will use Hydrotools to extract complete stellar and DM profilesfromhalosinTNGto investigate this connection. The splashback radius is signified by a caustic in the DM density profilewhereparticlespileupaftertheirfirstorbit,sothe“stellarsplashbackradius”canbefoundanalogouslyinthestellardensityprofile.Iwillcalculatethedifferencebetweentheseradiiandtheirdifferentcorrelationswith MAR for a sample of various mass halos, predicting the use of the ICL as a DM halo tracer.3. Shock and Splashback Radii While TNG does not outputshocksurfacesspecifically,wecaninsteaddetect a sharp drop in gas entropy profiles to signify the accretion shock radius. I will analyze therelationship between the shock and splashback radii in massive halos over different stages of clustermerger events, using complete gas and DM profiles. These results will provide context to interpret therapidly growing amount of Sunyaev–Zeldovich, and soon radio, accretion shock observations.Future Directions The outskirts of galaxies and of galaxy clusters are a clear next place to look forpotential tracers of DM halos. Upcoming instruments and surveys will revolutionize our constraints onDM features such as the splashback radius. Moreover, the low surface brightness of BCG and ICLoutskirtsarealreadydetectablewiththeHSCsurveyandwillbeevenmoresowiththeupcomingVera.C.Rubin Observatory and the Nancy Grace Roman Space Telescope. In the radio regime, the SquareKilometer Array (SKA) will vastly increase the number and resolution of observed accretion shocks.However, to interpret any of these observations we need to improve our theoretical understanding. Myproject will build off of current observational work and provide the foundation for interpreting futuredata.Broader Impacts I will continue my work to limit barriers for underrepresented minorities (URM) inastronomy. Particularly, I will use the remainder of my term serving on the AAS SMGA (sexualorientation and gender minorities in astronomy) committee to develop a mentorship program forLGBTQ+ early career astronomers. This program will match graduate students and postdocs with moreexperienced mentors who share a LGBTQ+ identity. Mentors will guide mentees through navigating thefield, especially challenges specific to LBGTQ+ individuals in the workplace. I will also continue toco-lead the BANG! (Better Astronomy for the Next Generation) seminar series in my departmentwhichcovers alternate career paths and EDI issues in Astronomy. I will focus on planning seminar sessionscovering previously under addressed topics, such as accessible teaching strategies and equitableworkplace practices. Finally, I will continue to work with the GRADMAP (Graduate resources foradvancing diversity with Marylandastronomyandphysics)teamtoprovideexternalresearchexperiencesfor students at minority serving institutions by teaching workshops in career skills and serving as asummer research mentor.[1] Deasonetal(2020)[2]Huangetal(2021)[3]Diemer&Kravtsov(2014)[4]Adhikarietal(2014)[5]Bertshinger et al (1985) [6] Shi etal(2016a)[7]Shietal(2016b)[8]Aungetal(2021)[9]Pillepichetal(2018)"
18.0,"been political debated, although empirical work suggests that low-skill immigration has a small negativeeffect on average British wages. However, individual-level migration data suggests that Eastern Europeanmigrants tend to be highly educated and highly skilled [1], motivating my proposed investigation of theeffects of the emigration of high-human capital individuals from Eastern Europe following the collapse ofcommunism in the nineties. In particular, what are the macroeconomic impacts of a shock to thedistribution of human capital as a result of immigration?Empirical work suggests that there are large differences in output per worker across countries [2],and that differences in total factor productivity (TFP) account for the bulk of these differences in output[3]. The mass emigration of high human capital workers decreases aggregate productivity directly throughthe decrease in labor productivity. Research on the emigration of academic Jewish scientists in NaziGermany [4, 5] shows that there are persistent negative impacts on emigrants’ departments’ performancesbecause the replacements are of lower intellectual caliber and positive effects on receiving departments’patenting. This micro work validates macro-theoretical research on shocks to human capital.One aspect of Schumpeterian growth theory is that innovations are the result of firms’ investmentdecisions based on expectations of future profits. Previous work has made the connection betweennational knowledge stock and innovation at the scientific frontier. My work bridges the connectionbetween negative shocks to population and aggregate human capital with innovation in a technology-follower setting. I incorporate the firm’s trade-off between investment in R&D and production as afunction of the distributional shift in human capital, specifically firms’ decisions to invest in R&D as aresult of Eastern European emigration in the 1990s.Methods: I will construct a general equilibrium overlapping generations (OLG) model of a small openeconomy populated by heterogeneous agents that vary in their stock of human capital and age, and thenapply this framework to estimate the impact of the migration-induced productivity shock on Bulgaria’seconomic growth. Using the structural model, I am able to analyze the welfare effects on heterogeneousindividuals through equilibrium values of the model.Human capital accumulation is an endogenous process, meaning that agents choose their optimallevel of human capital. The agents allocate their time between labor, leisure, and human capitalaccumulation in each period. Firms split labor and capital inputs into production and research, where theresearch production function is governed by a Poisson process. Intuitively, investment in research yieldsinnovations or tangible improvements in technology at random and fairly rare points in time, and thisunderstanding of knowledge production closely fits within a Poisson process. The parameter that governsthis Poisson process is endogenously determined by the stock of human capital in the labor force availableto the firm and the existing stock of knowledge. In other words, within a discrete period of the model, thediscovery of one innovation does not have any bearing on the discovery of a second innovation(memoryless property of the Poisson distribution), but between periods the total innovations impact therate of knowledge production. The firm faces a tradeoff between production for profit in a given periodand investment in research for a potential payoff in a future period. This decision involves risk. Firms alsoconsider distortionary taxes and expectations about economic conditions in their decision.One metric of innovation is patent applications. Applications are a reasonable proxy forimmigration because patent applications are not dependent on a government agency’s determination ofthe worthiness of an innovation for being patented. In a revealed preference framework, applying for apatent indicates that the firm believes it has produced innovation worthy of patenting. This belief informstheir decision to invest in research and development. The preparation of a patent application is notwithout effort; therefore, applying for a patent represents the firm beliefs I am interested in capturing.I will calibrate my structural OLG model to Bulgarian data to conduct a policy experiment onemigration. Using individual-level data, the Mincerian earnings function for the returns to schooling andexperience can be calculated [6], which gives direct estimates of the parameters governing the humancapital accumulation decision by the agent. The weight of consumption in utility is adjusted to captureaggregate hours worked in the data (available from OECD), and this parameter characterizes the labor-leisure decision of the agents. The parameters governing the relationship between the rate of knowledgeproduction and human capital are estimated in the literature. These parameters combined with the first-order conditions of the structural model determine the firm’s behavior. Because I can fluently read andspeak Bulgarian and my personal experiences, I am uniquely able to obtain the necessary innovation datato calibrate the rest of model. Otherwise, standard data and computational resources are sufficient.Because the migration decision depends on a number of unobservable characteristics, it isimplausible to include this decision in a structural model. Information about the types of people whomigrate, include their ages, educational levels, and work experience are observable in individual-levelsurveys conducted in Bulgaria. Accordingly, emigration is captured by changes in the relative sizes ofhuman capital and age cohorts as well as level changes in population. Additionally, as a result ofbottlenecks related to work visas, documentation, and language barriers, this mass migration does nothappen immediately after the collapse of communism. This delay in the timing of the migration shockallows for a few years post-collapse to establish the baseline macroeconomic trends.Thus, there are two balanced growth paths of interest. One growth path is the case where nomigration occurs, and the model is calibrated to match the known pre-shock periods. The other growthpath includes the migration shock, and data on immigrants is used to adjust the measures of ages andhuman capital types. The comparison between the second balanced growth path and the data measures theperformance and predictive capacity of the model, while the comparison between the second growth pathand the first (the simulated counterfactual) represents the effect of the migration shock. A successfulmodel will replicate targeted moments of the data.Broader Impacts: Understanding the effects of high-skilled emigration is crucial to reconciling why theeconomies of Eastern and Western Europe have not converged since the 1990s and designing policies thatencourage talent to remain in Eastern Europe. The model I propose captures another dynamic ofmigration through shifts in the age distribution. Empirical work indicates that migrants tend to beyounger, and a large migration event such as in Eastern Europe following 1991 may shift the agedistribution upward. Previous work has analyzed the macroeconomic implications of an aging populationas well as changes to human capital separately, but the interaction between the two remains an openquestion. My model and associated calibration would partially fill this gap in the literature.Furthermore, the mass migration of young people negatively shocks the population growth rate.Because the growth rate of the population is determined by the proportion of young people, the one-period shock to the population growth rate propagates through R generations, where R is the cutoffbetween young and old. Combining this with the level decline in population as a result of the shock, mymodel also captures the absolute population declines observed in some Eastern European countries.Because population declines independent of wars, pandemics, and the like are rarely observed, there islittle empirical work on the macroeconomic implications of declining populations. My model andcomputational approach incorporates these effects and could isolate them via simulating an age-biased,human capital-neutral migration event, where migrants are young but equally skilled as the population.Several countries in Asia, Western Europe, and Latin America are expected to experience populationdecline in the near future, and the mass-migration events of the nineties started this process earlier inEastern Europe than the rest of the world. Accordingly, my findings on the effects of population declineare of significant interest and would contribute to an open and deeply relevant question.Moreover, the relationship between high-skilled emigration and innovation is not limited toEastern Europe. There are several US states, including my home state, Kansas, with net high school andcollege graduates leaving, resulting in a negative shock to human capital. During the Covid-19 pandemic,several Midwestern cities, including Topeka, Kansas, adopted policies that gave workers a lump-sumtransfer of money in exchange for moving and living in the city for at least a year. A natural extension ofmy work is to evaluate the prevalence and demographics of uptakers of such policies, and then analyzemy model with shocks to the human capital distribution as observed in the data.References: [1] IMF report “Emigration and its Economic Impact on Eastern Europe” [2] McGrattan andSchmitz, (1998) Federal Reserve Bank of Minneapolis [3] Hall and Jones (1999) QJE [4] Moesa et al(2014) American Economic Review [5] Waldinger (2016) Review of Economics and Statistics [6]Patrinos (2016) IZA World of Labor"
19.0,"free, first-principles theoretical treatment of core-to-core x-ray emission spectroscopy (ctc-XES). Successin this research program will have wide impact for refining analytical and fundamental study of the element-specific electronic structure in highly correlated materials, an extremely broad class with significantindustrial, technical, and environmental relevance. Furthermore, by having fully addressed the forwardproblem, i.e., prediction with no adjustable parameters of ctc-XES spectra from local structure, we will beable to use unsupervised and supervised machine learning (ML) methods to understand the informationcontent in core-to-core XES across systems already widely studied (e.g., 3d transition metals) and alsosystems that have seem comparatively little XES (e.g., materials with heavy d- and f-electron elements).This will likely lead to prediction of new diagnostic spectral signatures of magnetism in f-electron systems.Introduction and Background: X-ray emission spectroscopy (XES) is the very high-resolutionstudy of fluorescence given off by the radiative decay of a core-shell excited atom, inherently probing theoccupied electronic states. XES can carry information about the local chemical environment of thefluorescing atom, such as valence-level spin, oxidation state, ligand identity, local coordination geometryand bond covalency. While there are many truly first-principles theoretical tools for parameter-freecalculation of most other advanced x-ray spectroscopies (e.g., XAFS, RIXS, and valence-to-core XES), thesame is not true for ctc-XES, which is a deeply many-body problem where the treatment of highly correlatedmaterials with partially filled d- or f- shells is especially challenging [1]. DFT approaches fail to describethe local many-body correlation effects while more accurate configuration interaction (CI) methods arecomputationally expensive and often difficult to implement beyond simple systems [1, 2]. Multipletimplementations are therefore the preferred theoretical framework for ctc-XES with many theoretical codesand models being developed over the last 40 years [3]. Those multiplet models show adequate agreementwith experimental results after fits to screening and correlation parameters. Here, I will develop tools tocalculate those parameters, moving from a descriptive treatment to a predictive treatment of ctc-XES.Research Plan: My research plan has three main components: (1) A theoretical component thatbuilds off of my prior work (below) and the expertise available from my theory mentors, Profs. Rehr andKas; (2) Validation via measurement of ctc-XES across a wide range of materials, this capability is firmlyenabled by lab-based XES available in my Ph.D. advisor’s lab (Seidler group, UW); and (3) a MLcomponent that will build on emergent methods in the XAS community, such as recent Seidler group workon unsupervised ML [6]. Hence, I am strongly supported by local expertise and needed facilities.Beginning with theory, Figure 1 shows the distinction between common practice, the result of mywork over the past six months, and a large part of the proposed further improvements. First, the centralgreen column highlights the key-components that go into standard Multiplet Ligand Field Theory (MLFT).Note the need for many local environmental components such as the crystal field and charge transfer leadsto a large increase in free parameters, limiting predictive capability. Next, the leftmost column shows myprogress over the past 6 months building on work by Haverkort et al. [4] by applying a DFT + MLFTapproach to ctc-XES, using the full-potential local-orbital (FPLO) DFT code to determine many, but notall parameters needed by the multiplet engine (Quanty). Using ‘reasonable’ values for the remainingundetermined parameters, I find excellent agreement between my new calculations and experiment for theenvironmentally important speciation of Cr3+ with respect to the carcinogenic Cr6+, see Figure 2. Third, asshown in the right column of Figure 1, I will use the real-space Green’s function code FEFF to both replaceFPLO and also implement new calculation of the thus far undetermined parameters for the MLFT treatment[5]. The result will be the first truly parameter-free, first-principles MLFT treatment of ctc-XES.Moving to experimental validation: past, ongoing, and recently funded work in the Seidler groupincludes ctc-XES measurements of numerous elements in battery materials, oxygen evolution reactioncatalysis, cements used in long-term storage of toxic and radioactive wastes, and carcinogens occurring inconsumer products or industrial wastes (e.g., Cr toxicity, such as probed by Figure 2). This provides aplethora of testing grounds across numerous problems with high societal relevance. In this work, I will beable to collaborate with other students in the group to design reference standard studies, validate againstmy theory calculations, and then apply the resulting information to draw best inferences about the systemsof actual interest.Fig. 2. Agreement between current theory andexperiment for the K XES of Cr(III) and Cr(VI).Finally, the validated theoretical approachwill be distributed to the general x-ray spectroscopycommunity via the workflow management toolFig. 1. Theoretical MLFT workflow schema:Corvus and will also be used as the basis for MLstandard approach (center), current progressinvestigations of the information content of ctc-(left) and future plans (right).XES. This latter work will start with unsupervisedML, such as t-SNE, which the Seidler group recently introduced as an important way to determine thechemical information content in vtc-XES and XANES [6]. This will be the first ML study of this kind tobe applied to ctc-XES as traditional theory methods are either too inaccurate or too computationallyexpensive compared to the novel DFT+MLFT approach. This work will help determine which generalproblems are, or are not, well-encoded into ctc-XES across the periodic table and different chemical classes.Intellectual Merit: The interleaved characterization of local atomic and electronic structure posescentral challenges across numerous problems, including electrical energy storage, catalysis research, agingof construction materials, toxicity in consumer products, environmental consequences of industrial wastes,and low-diffusion matrices for long-term storage of toxic or radioactive wastes, all of which still have openquestions that require an MLFT approach to accurately describe. These questions come at a time of rapidgrowth in access to experimental ctc-XES capabilities via the development of lab-based instrumentationfor education and analytical study (a trend led by Seidler group), major upgrades of synchrotron facilitiesand specialized XES end-stations for applications in energy sciences, and the steadily increasing applicationof XES in ultrafast x-ray free element laser (XFEL) studies probing chemical and electronic dynamics.This project will have a uniquely outsized impact not only because of the importance of the socialand scientific problems being addressed but because of the synergy with the emerging experimentalaccess to core-to-core XES capabilities. Additionally, the open access model of the tools developed in thisresearch program will facilitate broad adoption within the x-ray community, bridging the gap betweenaccurate ab-initio theoretical methods and the experimental need for reliable first-principles theory.Broader Impacts: Much of my prior experience in outreach has centered around introducingpeople to a side of science which focuses on the curiosity and intrigue sparked by the natural world aroundus. I firmly believe that to accomplish this, access to intuitive introductory tools is a necessity. As addressedin my personal statement, I will continue to develop and refine x-ray specific educational material such asthe XAS-RW, addressing the acute need for qualitative and intuition based introductory material in mysubfield. I will compliment this with fun, science-based community engagement efforts through groupssuch as the UW Science Explorers and UW Stem Pals to bring hands-on physics directly into the classroom.This will provide the ideal environment to expand upon my Physics Field Day event, as I couple myorganizational experience with new community collaborations to deliver a unique, immersive program.Works Cited: [1]doi:10.1002/qua.24905;[2]doi:10.1002/cphc.201800038;[3]doi:10.1016/j.elspec.2021.147061;[4]doi:10.1103/PhysRevB.85.165113;[5]doi:10.1039/B926434E;[6]doi:10.1039/D1CP02903G"
20.0,"framework for a planet’s formation, evolution into its present state, and past and present geophysicalproperties such as magnetic fields and atmospheric conditions. In this era of prolific exoplanet discovery,the quest to investigate planetary interiors and surface conditions is more pressing than ever. With thegrowing number of exoplanets ranging in size from super-Earths to sub-Neptunes, and the omnipresentgoal of “finding a new Earth”, it is becoming evident we need to concentrate our studies on such planets.Currently, radial velocity and transit methods used to detect exoplanets give mass and radius data forexoplanets but offer no compositional information. Comparing the mass and radii of exoplanets with mass-radius relationships of pure materials such as iron, silicates, and ice, and stoichiometric mixture thereof,offer a glimpse into their plausible bulk compositions [2-4]. However, attempts to infer bulk compositionhave resulted in degeneracy with many interior composition combinations fitting mass and radius valuesfor a particular exoplanet. Many models assume planets are fully differentiated, yet previous works usingdensity functional molecular dynamics (DFT-MD) simulations at high pressures and temperatures havepredicted deviations from this model. For example, the miscibility of H O with H and He [5] and miscibility2of Fe and MgO [6]. Contrary to traditional models, we infer “fuzzy layering” if material is miscible atboundary conditions, which would result in the gradual mixing of heavier elements into the upper, lessdense layers. DFT-MD simulations are a powerful tool in predicting the equation of state (EOS) of a widevariety of planetary materials and mixtures at conditions that are difficult to achieve empirically.Hypothesis. Some super-Earth and sub-Neptune exoplanets, termed waterworlds, contain a significantamount of water (H O) ice overlaying a magnesium silicate interior [7,8]. The stability of such a stratified2internal structure depends on whether these simplified two-layer models reflect realistic water worldstructures. Instead of relying on static two-layered models, I am motivated to explore the dynamics ofmaterial mixing at the magnesium silicate-ice boundary layers under P-T conditions relevant to the interiorconditions of waterworlds. Understanding whether these two materials are miscible will help us betterresolve the internal composition and stratification of water worlds. I propose to study the miscibility of acommon high-pressure planetary magnesium silicate, enstatite (MgSiO ) [9], and high-pressure3water (H O) ice using DFT-MD. MgSiO will be referred to as rock and ice is assumed to be water ice for2 3the remainder of this proposal.Research Plan. (Research Goal 1: Building Rock-Ice Systems and running DFT Simulations) I will buildthe rock-ice systems and equilibrate each to a respective pressure in gigapascals (GPa) (Table 1).Table 1. Systems with MgSiO and H O crystal phases, space groups, and initial system pressure3 2System MgSiO phase Space group (MgSiO ) H O phase Space group (H O) P[GPa] x3 3 2 21 ppv Cmcm [63] ice X Pn-3m [224] 120 0.292 pv Pnma [62] ice X Pn-3m [224] 60 0.293 pv Pnma [62] ice VIII I41/amd [141] 30 0.26The crystal phases chosen for each material present at 0Kwere the most stable structures at each respective pressure (Table1.). I will run simulations on each system using a canonicalensemble (constant number of particles N, constant volume V,and constant temperature T) increasing the temperature of eachsystem from 500 K to 8000 K with the Nosé-Hoover thermostat[10]. I will perform simulations in 500 K increments in a “heat-until-mixes” approach, similar to the “heat-until-melts” method[11]. Although this approach is prone to overestimating meltingtemperatures, my goal is to calculate the upper bound P-Tconditions for rock-ice mixing which will be accomplished withmy MD. I describe each system by its ice to rock mass ratio[𝑚 /(𝑚 +𝑚 )], for example, System 1 has an ice to𝐻2𝑜 𝐻2𝑜 𝑀𝑔𝑆𝑖𝑂3rock mass ratio of 0.29. Then to investigate in which proportionsrock and ice will mix I will simulate additional systems with icemass ratios of 0.29 and 0.20. I will accomplish this by increasing the number of rock molecules whilekeeping the number of ice molecules constant. If the two materials spontaneously mix during thesimulations, I will know rock and ice are miscible at this temperature. Preliminary results from my MDsimulations of System 1, run at 8000 K (Fig 1.) show exciting, novel results of miscibility.(Research Goal 2: Determining Miscibility) An efficient way to detect mixing is to analyze howfar atomic species move from their original positions by calculating their mean squared displacement(MSD). When the diffusion coefficient for all species is above zero, I will consider the system fluid.However, I will not know based on MSD alone whether the atoms crossed the rock-ice interface. The systemcould contain molten rock and water which remain immiscible instead of forming a homogeneous mixture.Therefore, I will also visualize each trajectory and verify that diffusion occurs across the boundary. Myfinal method for confirming miscibility is to calculate the radial distribution functions (RDF) of magnesium(Mg) and silicon (Si) versus the oxygens (O) in MgSiO , termed rock oxygens, and oxygens associated3with ice, termed ice oxygens. My goal is to show that Mg and Si lose coordination with the rock oxygensand interact with the ice oxygens. For example, when I plot Mg−O and Mg−O , at the same temperature,rock iceif rock and ice are miscible, their radial distribution curves should overlap.Intellectual Merit. In addition to working with my Ph.D. advisor, Dr. Burkhard Militzer at U.C. Berkeley,I will collaborate with Dr. Sarah Stewart, a professor in the Earth and Planetary Science Department at U.C.Davis, to perform dynamic smoothed particle hydrodynamic (SPH) simulations of colliding planetarybodies. This will give insight into whether these large impact events produce the conditions necessary formaterial mixing. It is important to determine post impact conditions because giant impacts govern animportant stage of planet formation, mold their interiors, and drive geophysical properties [12].Multicomponent EOSs of material mixing will shift the planetary science community’s focus fromstatic planetary models, where fully differentiated layers are modeled, to dynamic ones which includechemistry deep within the planet. If we neglect the presence of “fuzzy layers” within planets, we may misskey planetary properties such as its thermal evolution and magnetic field generation, which influence otherproperties such as tectonics, outgassing, dynamics, and volcanism. I plan to continue investigating rock-icemiscibility by considering other rocky material, such as Mg SiO or MgO with H O, and exploring lower2 4 2pressure regimes [8]. Moreover, provided that the necessary conditions are reached, I will further myresearch to elucidate whether a homogeneously mixed rock-ice layer could persist over long periods of timeand even become stably stratified within water worlds. This will affect overall heat flow throughout theplanet which will help us better understand the evolution of water worlds.Broader Impacts. My proposal has applications in a diverse range of disciplines such as condensed matterphysics, high energy density physics, geochemistry, and geophysics. I will publish my work in journals(e.g. PNAS), present at conferences (e.g. AGU and APS), and most importantly continue outreach bypresenting my research at local, public seminars (e.g. BASIS, SLAM, and Compass Lectures). I spent myfirst summer as a graduate student volunteering at two workshops recruiting students to pursue graduateschool in planetary science. I also began tutoring environmental sciences at San Quentin Prison which helpskeep me informed on challenges facing our most at risk communities and how to aid in their success asaspiring geoscientists. After only one year in graduate school, I have already helped form the firstUnlearning Racism in the Geosciences (URGE) pod at Berkeley. We will present our pod’s work ofintegrating URGE deliverables into the Berkeley EPS department-level strategic plan for enhancingdiversity at AGU 2021. The NSF fellowship will allow me to produce and share my findings with my peersas well as a general audience, increase equity in my field, and recruit the next generation of geoscientists.References. [1] B. J. Fulton et al. The Astronomical Journal 154, 109 (2017). [2] A. Vazan et al. arXivpreprint arXiv:2011.00602 (2020). [3] O. Shah et al. Astronomy & Astrophysics 646, A162 (2021). [4] S.Seager et al. The Astrophysical Journal 669, 1279 (2007). [5] F. Soubiran et al. The Astrophysical Journal806, 228 (2015). [6] S.M. Wahl et al. Earth and Planetary Science Letters 410, 25 (2015). [7] M.S Marleyet al. Journal of Geophysical Research 100,348 (1995). [8] T. Kim et al. Nature Astronomy, 5, 815-821(2021). [9] T Duffy et al. Front. Earth Science 7, 23 (2019). [10] N. Shuichi Progress of Theoretical PhysicsSupplement 103, 1 (1991). [11] G. Robert et al. Physical Review B, 82, 104118 (2010). [12] P.J. Carter etal. Journal of Geophysical Research: Planets 125, 1 (2020)."
21.0,"Introduction: Externally actuated micro/nanorobots have generated considerable excitement over the lastdecade due to their potential to carry out controllable microbiological tasks.7 Specifically, microroboticswarms,containingtensofthousandstomillionsofindividualrobotsthesizeofbacteria,havethecapacityto perform diagnostics and directed drug transport within deep tissues and microvasculars hitherto inac­cessiblebyconventionalmeans.7 Unlikeindividualmicrorobots, swarmsleveragethecoupledinteractionsbetween constituents to form large­scale collective motions that far exceed the speed, strength, and func­tionalityofa singlemicrorobot. Because theseswarms areexternallyactuated bymagneticor opticfields,actuation schemes can be programmed to control a swarm’s collective motions and morphology. Specificexamplesincludeclustering,swirling, dispersion,orribbonformation, whichtogetherallowforhighenvi­ronmentaladaptivity.4 Unfortunately,experimentationaloneisinsufficienttoproperlydesignmicroroboticswarms for real­world applications; instead, efficient computational tools are needed to augment experi­ments by enabling rapid investigation into the effect of design parameters. However, modeling swarmingmicrorobotsisinherentlychallenging—owingtothetheoreticalandcomputationalcomplexityofresolvingthe many­body hydrodynamic effects and short­ranged collisions. No state­of­the­art method is currentlycapable of accurately simulating real­world microrobotic swarms. This issue is further exacerbated by thegenerallackoffundamentalunderstandingofhowtobestgenerateandcontrolaswarm’scollectivemotionsfor specific tasks, especially within confined microfluidic environments. I aim to overcome these chal­lengesby(1)creatingthefirsthigh­fidelity,scalablecomputationalframeworkabletosimulatedensesuspensions of complex­shaped, microrobots and (2) numerically investigating how key parameters,likerobotshape,actuationscheme,andgeometricconfinementaffectaswarm’scollectivemotions.IntellectualMerit: Accurate simulation of microrobotic swarms within real­world microfluidic environ­ments is essential if these systems are to be designed for practical biological applications. Previous worktoward modeling these systems has primarily focused on dilute suspensions, where the long­range hydro­dynamic interactions dominate the system dynamics, allowing the effect of near­body dynamics to be ap­proximatedbyrepresentingcomplex­shapedparticlesintermsofsimplegeometrieslikespheres,ellipsoids,or rods. However, as the number of particles per unit volume increases, near­body interactions becomeincreasinglyimportantcausingtheseapproximationstobreakdown. Withindensesuspensions,evenseem­ingly insignificant modifications to robot shape, like using spherical robots vs cubic robots, will result indrastically different close­to­contact dynamics, which directly impacts internal pattern formations. There­fore,fordensemicroroboticswarms,itisimperativethatthenear­bodydynamicsbetweencomplex­shapedparticlesbeaccuratelycapturedtocorrectlypredict/controltheircollectivemotions.Task1­Isogeometricanalysis: Toaddresstheseissues,Iproposetodevelopahighfidelitymodelcapableofaccuratelyresolvingthehydrodynamicinteractionsbetweencomplex­shapedmicrorobots. Guidedbythisgoal,IhavebeenworkingindirectcollaborationwithProf. B.Shanker(anelectromagnetsexpert)andProf.H.M.Aktulga(ahigh­performancecomputingexpert)todevelopanisogeometricboundaryintegralmodel,which I am implementing within Python. The fundamental principal of isogeometric analysis is to utilizesmoothbasisfunctionstorepresentparticlegeometriesandthephysicsontheirsurfaces,therebyprovidinghigherorderdescriptionoffieldsandenablingaccurateresolutionofnear­bodydynamics. Towardsthisend,Ireformulatedanexistingboundaryintegralsolver3 basedontheassumptionthatmicrorobotsaretypicallygenus­zeroshapes,allowingmetopullbacksurfacequantitiestotheunitsphereandthendiscretizeintermsof spherical and vector spherical harmonic basis functions. I then solve the governing boundary integralsthrough Galerkin’s method. One of the challenges when solving hydrodynamic boundary integrals is theevaluation of the nearly­singular integrals that arise when solving particle to self and particle to nearbyparticleinteraction. Toaddressthisdifficulty,Iderivedasingularity­freemethodforevaluatingparticleself­interaction through established techniques of singularity subtraction/isolation. My next step is to integrateadaptivequadraturetechniquestohandletheinteractionbetweenclose­to­contactparticles. Oncecomplete,Iwillresolvetheeffectofno­slipconfinementsbyaddedadditionalconstraintstomylinearsystembasedonwell­establishedmethods.6 Myfirstmilestonewillbetobenchmarkthismodelagainstanalyticalsolutionsfortheflowbetweensphericalparticlesbothwithandwithoutconfinement.Task 2 ­ High performance software development: High fidelity simulation of microrobot swarms iscomputationally intensive and requires fast, scalable numerical methods to make modeling real­world sys­temsfeasible. Thekeybottleneckistherapidcomputationofpairwisehydrodynamicinteractionsbetween𝑁 particles, which scales as 𝒪(𝑁2). To overcome this issue, I will integrate my hydrodynamic solver intotheparallelcomputingframeworkdevelopedbyProf. Shanker. ThisFORTRAN­basedframeworkcentersaroundtheAcceleratedCartesianExpansions(ACE)algorithm,whichreducesthecomputationalcomplexityofevaluatingthepairwiseinteractionsfrom𝒪(𝑁2)to𝒪(𝑁).1Toaccomplishthistask,IwillfirstconvertmycurrentPythonimplementationintoFORTRAN.IwillthendevelopsuitabledatastructuresfortheefficientcomputationandcommunicationofsphericalharmoniccoefficientsandcreatecustomMPIcommunicationschemes for the tonsorial kernels that arise in our calculations. These implementation details are vital forensuring that our framework remains computationally tractable and will be validated based on scalability.TheNSFGRFPwillsupplementourcomputationalresourcesbyprovidingaccesstoXSEDE,enablingmetofullyharnessthecapabilitiesofthishigh­performanceframework.Task 3 ­ Dense microrobotic swarms under rigid confinement: The simulation of dense microroboticswarms requires simultaneously resolving the hydrodynamic interactions and short­ranged collisions be­tween particles. Unfortunately, traditional collision resolution algorithms become numerically unstablewhen applied to dense assemblies. To overcome this limitation, my collaborator Dr. W. Yan (a compu­tationalbiologist)developedacollisionresolutionalgorithmusinggeometricallyconstrainedoptimization.5Throughthiscollaboration,IwillexpandDr. Yan’sexistingopen­sourcecode­basetoincludefastmethodsforevaluatingthedistancefunctionsandsurface­normalsbetweencollidingnon­convexparticlesbasedonadvances within the computer graphics community.2 I will then couple this code­base with the frameworkdeveloped in Task 2. Once complete, I intend to leverage the speed and flexibility of this computationaltool to analyze how key parameters like robot shape, robot actuation type, and confinement geometry af­fectaswarm’scollectivemotionsandpatternformations. Bysystematicallyperformingsimulationswithinthisexpansiveparameter­space,Iintendtoprovideexperimentalistswithacomprehensivepictureofhowtobestdesigntheirmicroroboticswarms. Toquantifytheeffectstheseparametershaveonaswarm’scollectivemotions,Iwillutilizemyexistingpost­processingtoolkit,whichIhaveappliedtoactivemattersystemsforextractingtheirlarge­scaletopologicalstructuresandensembleaveragedstatistics. Basedontheseresults,Iwilliterativelydesignloadingschemesandrobotshapestostreamlinethetransportandcapturingoflarge­scalecargowithinsimulatedmicrovascular­likeenvironments.BroaderImpacts:Controllablemicroroboticswarmshavethepotentialtoprofoundlyimprovepublichealthby facilitating novel treatment methods like the transport of chemotherapy drugs directly to cancer sites.7My work’s efficient computational framework will augment existing experimental techniques by enablingresearchers to virtually prototype their swarm designs within realistic environments. To facilitate the useof this framework by others, I will open­source and thoroughly document all software I develop. In doingso, Ihopetohaveafar­reachingimpactonthefieldsofsoftcondensedmatter, robotics, andmicrofabrica­tion, whichcouldbenefitsignificantlyfromamodelfordenseparticulatesuspensions. Furthermore, Iwilldisseminatethisresearchtonon­engineersbyparticipatingintheAlliancesforGraduateEducationandtheProfessoriate’sChalkTalks,whichseektodistillcomplexscientificworksforgeneralaudiences.References:[1]Baczewski,A.D.,etal. 2010,JournalofComputationalPhysics,229[2]Bender,J.,etal.2014,Comput. Graph. Forum,33,246–270[3]Corona,E.,etal. 2017,JournalofComputationalPhysics,332, 504 [4] Xie, H., et al. 2019, Science Robotics, 4, eaav8006 [5] Yan, W., et al. 2019, The Journal ofChemicalPhysics,150,064109[6]Zhao,H.,etal. 2010,JournalofComputationalPhysics,229,3726[7]Zhou,H.,etal. 2021,ChemicalReviews,121,4999"
22.0,"Background: Consistent individual differences in behavior – or “personalities” – are ubiquitous in animalsand have long captivated biologists1,2. Individual differences are a prerequisite for natural selection, andmany evolutionary biologists explore how variation in behavior predicts survival and reproduction.Meanwhile, neuroendocrinologists experimentally alter an animal’s internal state to change behavior. Onlyrecently have these disciplines been integrated to begin evaluating the mechanisms that maintain naturalindividual differences in adaptive behaviors in wild animals3. So far, this work has advanced ourunderstanding of the neural mechanisms of social behavior, but remarkably, has found few patterns linkingbrain gene expression to individual behavioral differences4,5. This suggests that top-down processes aremissing key determinants of individual variation in behavior. Certainly, behavior requires more thanmotivation; it also requires that both brain and body are properly fueled. Thus, I propose that peripheralmetabolic processes may be the fundamental force driving consistent individual differences in behavior.The liver is the primary driver of metabolism and is under high demands topower the brain and muscle to execute energetically expensive behaviors (Figure).In times of endurance, the liver undergoes ketogenesis to secrete ketone bodies intothe blood for organs to use as energy6. This metabolic pathway is associated withbehavioral variation: Migrating birds use ketogenesis to maintain energyhomeostasis7, and racehorses have higher ketone levels during long-distancecompared to short-distance races8. Given supplemental ketones, bees behave moreaggressively9, and human athletes improve exercise efficiency relative to controls10.These observations suggest that variation in ketogenesis is critical for performingenergetically expensive behaviors, but this has never been assessed at the individual level. Consequently,there is uncertainty about how natural selection maintains animal personalities. I hypothesize that naturalindividual differences in behavior stem from variation in the ability to mobilize energy.I will test my hypothesis with two specific aims, focusing on social aggression in free-living femalebirds. First, I will assess how natural differences in aggression correlate with: (a) hepatic HMGCS2, therate-limiting enzyme in ketogenesis, and (b) beta-hydroxybutyrate (BHB), the main ketone body produced6.Second, I will manipulate circulating BHB and test effects on individual aggressiveness in a repeated-measures design. Both aims build off preliminary data I generated in my first year as a PhD student.Study system: Tree swallows (Tachycineta bicolor; TRES) are obligate secondary cavity-nesters; theycannot excavate a nesting site and must fiercely compete for a pre-made cavity to reproduce. Femalesreadily take to artificial cavities (i.e. nestboxes), and they are more aggressive than males. Social aggressionrequires endurance, as females engage in extended aerial chases and intense physical attacks duringcompetition for nestboxes. High aggression individuals have better body condition11 and are more likely tobreed than low aggression females, showing that aggression is adaptive12. Such strong natural selectionshould erode this trait variation, and yet substantial individual differences in aggression persist.Preliminary data: Last spring, I conducted 5-minute simulated territorial intrusions (STIs) on free-livingfemale TRES. I measured aggression (e.g. time spent hovering, diving, pecking) towards a conspecificdecoy placed at the nestbox. Individual aggression was repeatable in consecutive STIs (R=0.90; p<0.001).2-7 days after the last STI, I collected 10 high and 10 low aggression females and conducted a genome-wide analysis of their brains (i.e. RNAseq in hypothalamus and amygdala). Despite a well-powered design,I found very few differentially expressed genes between high and low aggression birds, indicating thatsubstantial behavioral variation cannot be explained by differences in baseline neural gene activity. Theseresults further support my hypothesis that behavioral differences emerge beyond the brain.AIM 1: To what degree do individual differences reflect variation in ketogenesis? From these samehigh and low aggression birds, I will extract RNA from the liver, where I confirmed HMGCS2 is highlyexpressed based on TRES transcriptomic data13. Using established lab protocols, I will design HMGCS2primers and perform qPCR to measure HMGCS2 gene expression, running samples in triplicate forHMGCS2 plus two endogenous control genes. I will also quantify BHB concentration in 10μl of bloodfrom these individuals, using test strips read by a handheld ketone meter that is already validated in wildbirds14. I will employ linear models to examine the degree to which natural variation in aggression ispredicted by HMGCS2 expression, BHB concentration, or a combination of the two.AIM 2: How does experimentally manipulating BHB alter individual aggressiveness? I will exposeincubating females to a commercially available BHB cream (BPI Keto Cream) applied to a fake egg in thenest for 12 hours. As the female incubates overnight, BHB will be absorbed via the brood patch, afeatherless area of vascularized skin on the belly. Control females will receive a fake egg with a vehiclecream. Past work has used this noninvasive approach to manipulate hormones in TRES15. Here, it will allowmanipulation of ketone levels independent of handling-induced stress. In a within-subjects design, I willuse 30-minute (prolonged) STIs to measure intensity and duration of aggression the morning before andafter BHB (or control) treatment, analyzing results with a repeated-measures ANOVA. Blood BHB will bequantified in both groups after the second STI using the ketone meter described in Aim 1. I will alsoseparately validate that BHB treatment elevates BHB blood concentration in a subset of birds.Predictions, Alternatives, & Next Steps: I predict that individual variation in aggression will positivelycorrelate with both HMGCS2 and BHB, with greater levels in high vs. low aggression individuals (Aim 1).Likewise, I predict that individuals will increase aggressiveness in response to supplemental BHB (Aim 2).Support for my hypothesis in Aim 1, but not Aim 2, would suggest that birds must engage in prolongedcompetition to promote ketogenesis, considering that females in Aim 1 were unprovoked at the time ofcollection. In this case, a future step would be to assess ketogenesis during sustained competition bymanipulating nestbox availability, which is shown to increase aggression and metabolically challenge thebrain16. I am also well-positioned to explore additional tissues from these same birds, such as the pectoralmuscle where BHB is converted into usable fuel6. Nearly all TRES fighting occurs in flight, suggesting thepectoral muscle is a promising tissue to connect energetic constraints to social behavior (Figure).Intellectual Merit: Individual differences serve as the raw material for evolutionary change, leading to thediversity of behaviors seen in nature. However, we have limited insight into the origin of this variation. Mywork explores the potentially critical role of peripheral energetics in shaping natural individual differencesin the wild. Recent work reveals other routes by which the periphery influences brain and behavior (e.g.gut-brain axis, microbiome), a view that my research extends. In the long-term, my proposal will not onlybuild the foundation of my dissertation, but it will also serve as a springboard for applying energeticperspectives more broadly, to understand how metabolism accounts for diverse behavioral differenceswithin and among species. Ultimately, my work will examine how both evolutionary and proximatemechanisms work together to build an aggressive female, an overlooked perspective in a field that, sinceDarwin, often assumes that females do not compete or that their aggression is just like that of males.Broader Impacts: As a first-generation, biracial graduate student, I strive to diversify STEM by helpinghistorically underrepresented undergraduates overcome institutionalized barriers, thereby demystifyingacademia’s hidden curriculum. My efforts include the creation of a “how to” guide for applying to graduateschool, which I disseminated to local and national groups. As a co-facilitator of an anti-racism group atIndiana University (IU), I developed action plans to hire and support diverse undergraduate researchers inmy lab. These efforts set the foundation for my goals as a graduate student and future faculty member toimprove recruitment and retention in STEM. Mentorship is central to this plan. I honed these skills withmentorship training while working with an undergraduate mentee in IU’s Center for the Integrative Studyof Animal Behavior NSF REU summer program. Moving forward, I will work with the Jim HollandSummer Enrichment Program, which provides research experience for high-achieving minority high schoolstudents and helps them transition into an IU STEM major, extending my efforts to broaden inclusion.References: 1Koolhaas et al. Front Neuroendocrinol (2010). 2Sih et al. TREE (2004). 3Hofmann et al. TREE(2014). 4Bell et al. Behaviour (2016). 5Benowitz et al. Behav Ecol (2019). 6Grabacka et al. IJMS (2016).7Frias-Soler et al. Biol Lett (2021). 8Volek et al. Metabolism (2016). 9Rittschof et al. J Exp Biol (2018).10Dearlove et al. Med Sci Sports Exerc (2021). 11Rosvall. J Avian Bio (2011). 12Rosvall. An Behav (2008).13Bentz et al. Sci Rep (2019). 14Sommers et al. J Field Ornithol (2017). 15Vitousek et al. Proc B (2018).16Bentz et al. PNAS (2021)."
23.0,"Aunderstand how neural circuits, assembled through geneticprograms, can give rise to complex behavior. Throughevolution, species display a wide range of behaviors, someof which have been mapped to specific genetic variations1.Genes that mediate complex behavior must act via neuralcircuits, yet little is known about these intermediate changes.In this proposal, I will bridge this knowledge-gap byinvestigating neural circuit differences that determineBvocal communication behaviors in two closely-relatedrodent species.Background and Rationale: Using sounds to communicateis widespread in nature — from croaking frogs, duettingbirds, to us, humans, engaged in conversation. Our lab hasrecently discovered a rodent species (Alston’s singing mice)FIG. 1: (A) Phenotypic variation inthat engages in similar fast vocal interactions. Singing micevocalizations of the lab mouse and Alston’sbreed in captivity, can be maintained in a colony, and showsinging mouse. (Spectrograms from thestereotyped vocal behaviors even in laboratory settings. Phelps lab, U.T. Austin) (B) Divergence andAdditionally, we have already established the use of viral tools duplication model as observed in cerebellarfor mapping, manipulating, and measuring neural circuits2. nuclei8.Singing mice (Scotinomys teguina) and lab mice (Mus musculus) are separated by a few millionyears of evolution (Steve Phelps lab, unpublished), are roughly the same size, and brain slices are largelyindistinguishable between the species. Yet, there are key differences in their vocal repertoires; Lab miceproduce only short, variable ultrasonic vocalizations (USVs), while S. teguina produce both USVs andhuman-audible ‘songs’ (Figure 1A). Crucially, unlike singing mice, lab mice do not participate in vocalturn-taking. Thus, we ask: What are the neural circuit differences underlying this behavioral distinction?Though traditionally thought to be unique to the primate lineage, our lab recently demonstratedrobust motor cortical control of vocal behavior in the singing mice. Using four complementary lines ofevidence (intracortical micro-stimulation, stimulation induced vocal arrest, focal cooling andpharmacological silencing), we defined a region of orofacial motor cortex (OMC) that mediates flexiblevocal behaviors in the singing mice2. In contrast, lab mice born without the entire cortex (including OMC)can still produce USVs3. Therefore, we predict that differences in the motor cortical circuitry between thelab mice and singing mice underlie differences in their vocal behaviors. We hypothesize that motorcortical control over vocalization in the singing mice evolved from the ancestral orofacial control neuralcircuits via a duplication of OMC followed by cell-type divergence (Figure 1B). This duplication-divergence model predicts the existence of a dedicated group of song-specific neurons in the singing mouseOMC with specific projection patterns to downstream vocal pattern generators in the midbrain and thebrainstem. Using novel spatial transcriptomics and barcoded projection mapping methods developed inTony Zador’s (my co-advisor) lab, I will determine the diversity of cell-types in the motor cortex and theirdownstream projection patterns in both the singing mice and the lab mice.Aim 1: Do motor cortical cell types differ between lab mice and singing mice? The duplication anddivergence model suggests that neural cell types in the OMC of singing mice evolved in a spatiallysegregated manner. First, to determine differences in cell types, I will perform single cell RNA sequencing(scRNAseq) in the OMC of lab and singing mice. Analysis of scRNAseq data requires aligning sequencedreads to a genome, publicly available for the lab mouse and recently generated by our collaborators for thesinging mouse (unpublished, Steve Phelps). Cell types will be identified using known marker genes foundin the literature. We will identify potentially novel cell types as those which have no assigned identitiesbased on canonical marker genes.While scRNAseq will allow us to quantify differences in neural cell types through in-depthtranscriptomics, we lose spatial information. To determine spatial location of neuronal cell types, we willuse a spatial transcriptomic method, BARseq, developed in the Zador lab4. This technique uses hybridizedprobes and in situ sequencing to determine spatially resolved expression data for hundreds of genes inparallel4. I am confident that I can perform this experiment as the Zador lab has a dedicated pipeline tocomplete this experiment and regularly performs spatial transcriptomic experiments.Aim 2: Do projection patterns of motorcortical neurons differ between lab andsinging mice? To determine OMCprojection patterns, I will first perform viraltracing experiments. I will inject AAV vectorthat expresses GFP into the OMC of bothspecies and image the brains using confocal FIG. 2: MAPseq protocol involves injecting barcodes into targetmicroscopy. While viral tracing can detect area and sequencing barcodes expressed in neural projections inbulk anatomical differences, this methoddownstream areas5.lacks accurate quantification of projections and cannot distinguish changes that occur on the single celllevel. To address these inadequacies, we will also be performing MAPseq, a method for single cell tracingdeveloped by the Zador lab. MAPseq is a method that uses virus to infect neurons with a DNA barcode thatis expressed in the cell body and axon of the neuron5,6. Through dissection and sequencing, we can recoverthe projection patterns of thousands of individual cells (Figure 2). I am confident that I can perform theseexperiments as I have already generated preliminary results for the lab mouse OMC. Furthermore, we cancombine MAPseq with our spatial transcriptomic method to correlate projection patterns and cell types4,7.Anticipated results: If the duplication-divergence model of the singing mouse OMC holds true, I wouldexpect to observe the following results: (1) novel cell types in the OMC of singing mouse (2) the spatiallocation of these novel cell types to be located in a spatially distinct area, and (3) novel projection patterns,perhaps to brainstem pattern generators, correlated with these novel cell types. In summary, theduplication-divergence model predicts correlated changes in cell transcriptomes and their projectionpatterns. Of course, another possibility is that cell type and projection pattern differences occurindependently. Even so, I will be able to distinguish independent changes due to the resolution of theoutlined experimental design. Thus, we have designed experiments that will produce results whether ornot our expected model (duplication and divergence) is true.Intellectual Merit: I anticipate three major contributions to neurobiological methods, as well as ourunderstanding of the evolution of neural circuits. First, this study can identify distinct neural populationsbased on projection patterns and/or genetic markers. Identifying neural populations in this manner allowsscientists to target these neural population for further functional validation and experimentation. Second,our results could identify genes underlying neural circuits in vocal communication, findings which couldcontribute to the development of better molecular tools for manipulating vocal circuits. Lastly, this studywould provide insight into the evolutionary underpinnings and biological basis of vocal communication.Broader Impact: I plan to make code and data available on open-source websites including GitHub.During my time at NIH, I created a RNAseq tutorial and shared resources on my GitHub page in additionto uploading code I wrote for analyzing RNAseq data9. I plan to maintain my GitHub page and upload codedeveloped for analyzing data collected through this project for other scientists to consult and use. Inaddition, I plan to create an online tutorial geared toward high school and/or college students that have littlecoding experience or exposure to bioinformatics. I also plan to publish our results in open access journalsincluding uploading early drafts of the manuscript to bioRxiv to facilitate timely advancement of scientificknowledge.References: [1] Metz et al. 2017. Current Biology. [2] Okobi, Banerjee et al. 2019. Science. [3]Hammerschmidt et al., 2015. Scientific Reports. [4] Chen et al., 2019. Cell. [5] Kebschull et al. 2016.Neuron. [6] Han, Kebschull, Campbell et al., 2018. Nature. [7] Sun, Chen et al., 2021. Nature Neuroscience.[8] Kebschull et al. 2020. Science. [9] https://github.com/eisko/RNAseq/"
24.0,"Background: With the growing implementation of inquiry-based labs in physics, students are nolonger following rote procedures and are expected to utilize complex experimental skills likemeasurement uncertainty, experimental modeling, and computation, which require students toengage in sensemaking [1]. We view sensemaking as “a dynamic process of building or revisingan explanation in order to ‘figure something out’—to ascertain the mechanism underlying aphenomenon in order to resolve a gap or inconsistency in one’s understanding” [2]. Given thatexisting research on sensemaking has focused on textbook problem solving, research is needed tounderstand how sensemaking appears in inquiry-based labs, given their increasing prevalence[3]. Physics is often viewed by students as a confusing, unapproachable subject; understandingstudent sensemaking is an important step in developing labs that are more accessible to a rangeof students, beyond physics majors.Preliminary Results: In response to the call for inquiry-based physics labs, as well as labs thatserve as better preparation for pre-medical and other life science students, the PER group at theUniversity of Utah has implemented Introductory Physics for Life Sciences (IPLS) labs, in whichstudents investigate physical mechanisms in the context of biological systems. In my preliminarywork with the group, I explored student sensemaking in IPLS labs, and I found that the instancesof sensemaking led to students having a deeper understanding about the relationship betweentheir data and the relevant physical systems. Furthermore, this initial analysis was instrumental indetermining an appropriate theoretical framework for the proposed research. First, I noticed thatstudents didn’t often fully articulate their thinking and thus my data was limited. To amelioratethis problem, I aim to use a think-aloud protocol in which students are encouraged to share alltheir thoughts during the lab investigations, which will provide a more complete data set.However, a limitation of interviews is that they are not as authentic, so I find it is important totriangulate interview data with the lab observation data. Second, I observed that students werefrequently comparing their model that was generated as a result of collecting and analyzing datato their existing mental model of the relevant system.Theoretical Framework and Research Plan: For my research plan, I draw on twocomplementary theoretical frameworks. First, I will use the modeling framework forexperimental physics, which was first developed for upper-division physics labs and functions ona recursive interaction between a student’s physical system model and their measurement model[4]. Given that measurement models are less common in introductory physics, I focus on a data-based model, which captures the focus of these labs where students are predominately analyzingdata; this is a similar adjustment to that which has been implemented elsewhere [5]. Second, Iwill utilize epistemic games, which are defined as the rules and strategies that guide inquiry; inPER, this framework has been used to study structured problem solving and knowledgedevelopment tasks [6-8]. Defining an epistemic game includes specifying the target epistemicform, constraints, entry conditions, moves within the game, and transfers to other games [9].Based on my initial analysis, student sensemaking in labs has characteristics that parallel theform of an epistemic game, e.g., making moves toward an end goal of resolving inconsistencies.These two frameworks are complementary as the recursive elements of modeling translate tomoves in a game. Each framework on its own has certain limits, but together they are morecomprehensive and powerful; they will allow for a rigorous analysis of student sensemaking ininquiry-based labs. The steps of my research plan are as follows:Step 1: I will identify all instances of sensemaking in the existing lab observation data, focusingon the classroom environment factors that contribute to the sensemaking.Step 2: Based on identified classroom environment factors from Step 1, I will write a task-basedinterview protocol intended to prompt sensemaking, and I will conduct these interviews with adifferent population of undergraduate life-science students.Step 3: I will first identify instances of sensemaking in the interview data. Then, using instancesof sensemaking from both the observational data and interview data, I will code my data using acoding scheme developed for the different parts of the modeling process, based on the modelingframework (e.g., revision of the data-based model, comparison between models).Step 4: With the modeling framework analysis done in Step 3, I will define sensemakingepistemic games that occur in the inquiry-based lab environment by coding the data with keyfeatures of epistemic games. Depending on the prior analysis, I will either define one epistemicgame that describes general sensemaking or a number of games that each describe a differentform of sensemaking.The merger of these two datasets, as well as the combination of the modeling framework and theepistemic games framework will allow for an in-depth understanding of student sensemaking ininquiry-based physics labs.Intellectual Merit: The inquiry-based physics labs are designed to better replicate genuineresearch environments, as well as encourage students’ agency and scientific inquiry; as such,they are increasingly prevalent in undergraduate curricula. But yet, there is limited research onsensemaking in these labs. To address this hole in the literature, I will take a novel approach ofcombining two disparate theoretical frameworks, epistemic games and modeling, and twocomplementary data sets, to gain a holistic understanding of sensemaking in inquiry-based labs.Results will be new knowledge about sensemaking in these increasingly prevalent labs that canserve as a foundation for future lab research, along with an example of how to effectivelycombine disparate theoretical frameworks that can serve as a model for other scholars in thefield.Broader Impact: Understanding student sensemaking in inquiry-based labs through theepistemic game framework will have direct instructional implications. For instance, we canimprove training so that TAs and instructors can recognize sensemaking epistemic games in labsand utilize them in instruction, asking questions that prompt sensemaking, rather thanrecollection of facts. Such instructional changes will improve undergraduate physics education,and specifically better prepare pre-medical students for medical school and other life sciencestudents for postgraduate studies and careers. Life science students often view physics as aforeign subject; supporting pre-medical students in productive sensemaking in these labs mayencourage more students to continue in these labs and be successful in long term careers in themedical field [10]. While typically unintentional, physics can be a “weed-out” course for thesestudents, so these changes intended to increase retention have the potential to improve equity andcontribute toward diversifying the medical field. Beyond the effect on pre-medical students,encouraging sensemaking is a step toward teaching students that they have relevant experiencethat can be used in a physics setting, making physics a more accessible subject for all.References: [1] Holmes, N. G. et al. Proc. Natl. Acad. Sci. (2015). [2] Odden, T. O. B. and Russ,R. S. Sci. Ed. (2018). [3] Odden, T. O. B. and Russ, R. S. Phys. Rev. Phys. Educ. Res. (2019). [4]Zwickl, B. M. et al. Phys. Rev. Phys. Educ. Res. (2015). [5] Vonk, M. et al. Phys. Rev. Phys.Educ. Res. (2017). [6] Tuminaro, J. and Redish, E. F. Phys. Rev. Phys. Educ. Res. (2007). [7] Hu,D. et al. Phys. Rev. Phys. Educ. Res. (2019). [8] Chen, Y. et al. Phys. Rev. Phys. Educ. Res.(2013). [9] Collins, A. and Ferguson, W. Edu. Psych. (1993). [10] Moore, K. et al. Am. J. Phys.(2014)."
25.0,"Introduction: Applications that demand large cooling capacities, such as high-powerelectronics, rely on the elevated thermal energy density that is associated with the latent heat ofvaporization. Flow boiling of a liquid in a channel is one of the most effective approaches forensuring high heat transfer efficiencies. For example, single-phase convection can remove heatwith a rate up to 20 kW/m²K, whereas flow boiling easily reaches 100 kW/m²K.1 Flow boilingwithin microchannels increases the heat transfer potential even further, due to the enhancedsurface-to-volume ratio. Many electronics and microelectromechanical systems (MEMS) withhigh power densities thus rely on microchannel flow boiling as their primary cooling strategy.Consequently, an efficient and reliable operation and control of this chaotic multi-phaseflow process is hence indispensable. In both macro- and microchannels, the two-phase mixturecan be characterized by different flow regimes, which are defined by the relative amounts andconfiguration of the liquid and vapor phases, and ranges from bubbly flow (few vapor bubbles inthe center) to slug flow, annular flow, and eventually mist flow (few liquid droplets in thecenter).Despite the great promise that two-phase flow boiling poses, it presents many challenges.For example, dry-out, or the critical heat flux (CHF), occurs at the onset of mist flow and leadsto a drastic rise in wall superheat that can induce material thermal fatigue and ultimately failure.Unfortunately, its occurrence and location there-of is difficult to predict, leading to theimplementation of large safety margins during the initial design of the thermal managementsystem. A different flow instability arises from the rapid expansion of bubbles, which causespressure oscillations that can ultimately jeopardize the structural integrity of the channel andeven initiate flow reversal.2 These instabilities have presented major challenges toward flowboiling applications and serve as a focal point for recent studies. To overcome the existinglimitations, I propose to use machine learning (ML) to detect and ultimately control theonset and nature of these flow instabilities. Autonomous detection and self-stabilization of flowboiling instabilities would significantly enhance the reliability of two-phase cooling systems,while reducing costs and greenhouse emissions.Intellectual Merit: The use of ML in thermal management is a novel method for predicting heattransfer properties. A recent publication by Ravichandran et al.3 has shown that neural networkmodels can predict the margin to the boiling crisis in a pool setting. I propose that in flowboiling, the onset detection and solution to mitigating flow instabilities can similarly beaccomplished through the implementation of a deep learning algorithm.Aim 1: Collect images and videos of various flow instabilities for different flow conditions.ML requires the collection of large amounts of data to train an algorithm. I will construct anapparatus for recording various instabilities. Korniliou et al.4 describes a method formicrochannel fabrication onto a polydimethylsiloxane (PDMS) substrate with an infraredtransparent tin indium oxide back wall. I will implement IR imaging to record wall surfacetemperatures while simultaneously recording high speed optical imagery at identical frame rates.The setup will include a pressure transducer mounted at both ends of the channel to monitordifferential oscillations. A micropump will serve to circulate the fluid after it passes through avacuum degasser. The ratio of heat flux to mass flux has been used to quantify microscaleinstabilities by defining their oscillation periods.5 I plan to induce various instabilities within themicrochannel by adjusting flow rate and heat generation while recording the resultant effects ontemperature and pressure. Each instability will be categorized into an appropriate set of resultantconditions. In addition to recording my own footage, I will also use data available in openliterature and contact authors of recent publications to share their data.Aim 2: Train a machine learning algorithm to predict each type of instability based on pre-defined conditions. I propose to train an artificial neural network (ANN) model by inputtingmeasurements of pressure oscillations, nucleation site density, surface temperature changes, andbubble movement into each instability category. A feature ranking algorithm will beimplemented to define the key measurement parameters. I will incorporate Google’s machinelearning library TensorFlow to accomplish these tasks. The data will be split appropriatelyamong sets for training, validating, and testing the model. Model evaluation will be conductedthrough 10-fold cross validation to ensure proper fitting. I will utilize the model’s mean absolutepercentage error as the primary evaluation metric. The results of the model will be used todetermine the corresponding flow, thermal, and differential pressure conditions associated withspecific instability types.Broader Impacts: This project serves as a vital proof-of-concept for validating the use ofmachine learning to detect flow instabilities. Time permitting, I plan to program the model into aclosed-loop control algorithm. Upon the detection of a specific instability, the algorithm wouldcontain and implement a pre-programmed solution, such as the adjustment of the flow rate orpulsation of ultrasonic waves. This solution will serve as a pioneering step toward theimplementation of machine learning in thermal management and demonstrates a potentialmethod for revolutionizing the peak performance and safety of electronics coolingapplications. The development of a working control algorithm would allow for systemoptimization and self-stabilization, which would answer direct needs of the thermal fluidscommunity.During our STEM club sessions for EduMate NYC, as introduced in my personalstatement, we received strong positive feedback from the students during the computer sciencepresentation. I therefore intend to use this project to initiate an Introduction to ArtificialIntelligence virtual workshop for high school and middle school students in the St. Louisarea. The St. Louis metro region is one of the most segregated cities in the United States, and itslong history of racial disparity contributes to educational inequity to this day. I will discuss thefundamentals of artificial intelligence, including machine learning, natural language processing,and computer vision in weekly sessions throughout 5 weeks in the summer months. Anadditional 5 weeks will be spent discussing the applications of artificial intelligence, such asrobotics, transportation, and my proposed project. The goal behind these events is to create afoundational understanding of artificial intelligence while inspiring students to pursue thesetopics in their future studies and careers. Allowing young innovators to develop skills in oneof the most important technologies today is valuable for contributing to their futuresuccess. I will collaborate with the St. Louis Academy of Science to host these events andprovide outreach assistance.References: [1] Bergman, et al. (2011) Fundamentals of Heat and Mass Transfer [2] O’Neill, et al.(2020) International Journal of Heat and Mass Transfer [3] Ravichandran, et al. (2021) Appl. Phys. Lett.[4] Korniliou, et al. (2017) Applied Thermal Engineering [5] Prajapati, et al. (2017) ExperimentalThermal and Fluid Science"
26.0,"Hypothesis: The compositional evolution of crustal material (both felsic and mafic) following impactevents can be simulated by heating and partially vaporizing such materials at high temperatures incontainerless experiments. Varying the temperature (T), time (t), and oxygen fugacity (fO ) in the2experiments enables the creation of synthetic impact glass analogues. Comparing the textures andcompositions of these analogues to those of natural glasses will inform how these materials evolve duringthe tektite formation process. Incorporating the results of partial vaporization experiments into mixingmodels of tektite formation will result in more realistic predictions of tektite parent materials and potentiallyexplain why tektites do not form from mafic protoliths on Earth.Background: There are currently 190 confirmed craters on Earth’s surface1, only four of which are inbasaltic targets. Lonar crater, which formed in Deccan Trap basalt, is the only well-known and fullyaccessible of these. During impact events, shocked and melted material may be ejected from the site ofimpact. Material that is thrown more than 2.5 crater diameters away from the impact location is known asdistal ejecta2. Glassy, chemically homogenous, and aerodynamically shaped distal ejecta are known astektites. Only four of the 190 terrestrial craters have resulted in tektite distribution over wide geographicregions known as strewn fields, and all known tektites originate from target rock that is felsic,approximating rhyolitic compositions. This research will investigate why tektites have never formed frommafic (basaltic) target rock during a terrestrial impact event, and to seek to better understand the nature andevolution of the starting materials that formed tektites from the four major strewn fields. Existing mixingmodels3–6 assume compositions of tektites represent idealized end-member mixtures of the melted targetmaterial, and most attempts to identify the parent materials involve general comparison among chemicalcomponents of tektites and predicted parent materials5. These models are overly simplistic as they do notaccount for the loss of chemical constituents to volatilization at high temperatures in the impact plume.Research Plan: (Research Goal 1: Tektite experiments) I will synthesize glasses that replicate thegeochemistry and textures of tektites and Lonar crater impact glass in an aerodynamic levitation laserfurnace7 (ALLF). Melting/vaporization experiments will vary T, t, and fO to identify conditions that form2Lonar glass analogues (Table 1).Table 1. Experimental conditions based on previous experiments estimating tektite thermal histories7Series 1 2 3 4 5 6 7 8 9T(°C) 1800 1800 1800 2000 2000 2000 2200 2200 2200t (s) 10-120 10-120 10-120 10-120 10-120 10-120 10-120 10-120 10-120fO Ar O CO+CO Ar O CO+CO Ar O CO+CO2 2 2 2 2 2 2Starting materials are Deccan Trap basalt, USGS basalt (BCR-2), and USGS rhyolite (RGM-2).Experimental methods will follow previous ALLF tektite experiments7. Approximately 10 mg of thestarting material is heated with a CO laser at low power to fuse the sample and form spheres suitable for2levitation. The fused spheres are then levitated on a flow of gas (Ar, O , or CO+CO ) while being heated2 2with the laser for seconds to minutes. After heating to the desired T-t, laser power is cut, and the meltspheres cool quickly to form glass. The chemical, mineralogical, and textural characterization ofsynthesized and natural glasses will be completed via scanning electron microscopy with energy dispersivex-ray spectrometry (SEM/EDS) at Indiana University–Purdue University Indianapolis (IUPUI) and electronprobe microanalysis (EPMA) at Washington University in St. Louis (WUSTL). These analyses will becompared to electron microprobe analyses of Lonar glass8, and previous work on felsic material7.Exploratory experiments using the starting materials and methods described above resulted in darkcolored, glassy spheres with little to no vesicles or mineral growth. SEM/EDS analyses of these preliminaryexperiments show preferential loss of Na and K from all melt compositions relative to non-alkalicomponents. Further, heating basalts in an oxygen-rich environment results in more rapid and completeloss of K O (undetectable after 10 s at 2000 °C).2(Research Goal 2: Mixing model calculations) Tektites are not produced from a single, homogeneoussource rock – thus, any explanation of tektite generation must involve a multi-component mixing modelinvolving likely upper crustal target rocks (sediments) as the major components9. Previous studies haveestimated the contributions of possible target lithologies to final tektite geochemistry using mixing models.However, the assumptions and limitations of existing models may hinder their ability to realisticallyrepresent tektite formation. Previous mixing models assume that end-member compositions of likelyprotoliths are unchanged during tektite formation, i.e., they do not take into account the effects ofevaporative fractionation3 on the target materials as they are heated in the impact plume. I will address thisby executing computationally intensive mixing models that properly account for fractionation due tovaporization and assess the extent of agreement between assumed target lithologies and tektitegeochemistry. I will incorporate my experimentally derived volatilization rates into dynamic multi-component mixing calculations by modifying the GeoChemical Data toolkit (GCDkit) software to create amore realistic representation of the processes attending tektite formation, and to determine the relativecontributions of each protolith to different tektite compositions. I will also compare my experimentallyderived volatilization rates, and the results of my mixing models with predictions of compositionalevolution of tektite melts from MAGMA code.My ongoing research uses the R programming language to perform multivariate analyses andimplement machine learning algorithms to investigate tektite compositional trends. I am creating an open-source web-based application to classify unknown tektites into their strewn fields and subgroups withinstrewn fields. This NSF Graduate Research Fellowship will afford me the opportunity to expand myprogramming and modeling portfolio to more computationally intensive applications.Intellectual Merit: The modification of planetary surfaces through impact cratering is the most importantsurface modifying process on most rocky bodies in the Solar System10, yet it remains underrepresented asa field of study. My research will improve both the understanding of the evolution of Earth’s crust and themodeling of impact events. My mixing model calculations will be the first to properly account for thechemical modifications that occur in the impact plume. These calculations will produce a useful tool forthe scientific community to analyze (or reanalyze) terrestrial impact products and target lithologies. Myexperimental data will also provide valuable insight into the volatilization behavior of felsic and maficmelts at conditions relevant to impact plumes. The results may shed light on the absence of mafic tektites.Broader Impacts: The results of my research will have applications in a diverse set of fields such as high-temperature geochemistry, computational modeling of geochemical processes, and impact processes. I willdisseminate the results in journals (e.g., Computers & Geosciences), at conferences (e.g., AGU, GSA), andto GK-12 students and the general public at outreach events (e.g., Pacers STEM Fest, Celebrate ScienceIndiana). As an NSF Graduate Fellow, I will continue working towards a more equitable and inclusiveculture. Already as a new graduate student I became a founding member of IUPUI’s Geology COmmunityfor Racial Equity (GeoCORE). I also came up with the idea for the Mineral Eponym CrowdsourcingInitiative (MECI), an effort to facilitate an examination, analysis, and synthesis of the origins of mineralnames, and the messages this historic naming system has created. This initiative is currently being led bymembers of the Mineralogical Society of America (MSA) Diversity Task Force (my advisor is a member)to seek funding for its execution. Most recently, I have been invited to participate in a project to create newcurricular materials for the IUPUI Earth Sciences Department focusing on issues at the intersection of Earthsciences, ethics, and equity. My role in this project will be to analyze, quantitatively and qualitatively, theassessment results of teaching material effectiveness. The analytical and computational skills I will learnas an NSF Fellow will allow me to perform analyses that will directly impact the inclusivity, diversity,engagement, and retention of underrepresented groups within the geosciences.References: [1] Earth Impact Database, PASSC [2] Glass, B. P. et al. Elements 8, 43–48 (2012) [3]Ackerman, L. et al. Geochim et Cosmochim Ac 276, 135–150 (2020) [4] Ferrière, L. et al. Chem Geol 275,254–261 (2010) [5] Love, K. M. et al. 52, 2085–2090 (1988) [6] Meisel, T. et al. Meteorit Planet Sci 32,493–502 (1997) [7] Macris, C. A. et al. Geochim et Cosmochim Ac 241, 69–94 (2018) [8] Ray, D. et al.Earth Moon Planets 114, 59–86 (2014) [9] Koeberl, C. Tectonophysics 171, 405–422 (1990) [10] Koeberl,C. in Treatise on Geochemistry 73–118 (Elsevier, 2014)"
27.0,"Stress in the city: investigating the effect of urbanization on coyote oxidative stress and dietBackground: As the world urbanizes, animals are adapting to novel environmental disturbances in human-dominated landscapes. The type and magnitude of these stressors vary considerably with human activity,culture, and socioeconomic status (SES), and each can influence the amount of biodiversity within a city1,2.Wealthier neighborhoods (higher SES areas) generally exhibit higher biodiversity and greater foodavailability, collectively known as the luxury effect1,2. Paradoxically, some low SES areas exhibit highbiodiversity by providing greater refugia (e.g., abandoned buildings) for prey2. Overall, the luxury effecthas repeatedly been shown to affect ecological dynamics at the community level, principally shapingspecies assemblages and interactions, which ultimately affect population and organismal ecology1,2. Fewstudies, however, have investigated how the luxury effect and urban stressors (e.g., light pollution)interact to affect the ecology and physiology of urban wildlife.Wildlife in urban and low SES environments face distinctenvironmental pressures relative to their conspecifics in rural and highSES areas1. However, how within-city differences in disturbance (e.g.,noise pollution) affect stress levels and fitness outcomes is largelyunexplored. Given that stressors in low SES neighborhoods aremagnified1, organisms in these areas may experience greater oxidativestress, an imbalance between free radicals and antioxidants in the body4,5.Biological responses to oxidative stress can vary with environment,genotype, and activity levels5. Further, antioxidants gained through foodcan provide a defense against oxidative stress6. Anthropogenic food,however, is often protein-poor and low in antioxidants5. Hence, wildlifethat exploits such resources are likely to develop health risks7 (e.g.,hyperglycemia, which is correlated with low immunity8) and are at higherrisk of the deleterious effects of free radicals4, including apoptosis5.Because these effects can reduce fitness4, it is imperative to uncoverhow human-driven impacts on habitat and diet shape an individual’sability to cope metabolically with anthropogenic stressors (Fig. 1).My research will investigate the effects of within-city and among-city variation on the physiology of coyotes (Canis latrans). Specifically,I will test how oxidative stress and diet vary along an urban-socioeconomic gradient. Urban coyotesare well-suited model organisms to address the phenotypic consequences of variation in human disturbanceswithin urban systems. Coyotes are ubiquitous across North America and have assumed the apex predatorrole in urban areas following the local extirpation of tertiary carnivores (e.g., wolves, Canis lupus)3.Moreover, coyotes often consume anthropogenic food9, but exhibit variation in diet9,10. As apex predators,stressors that affect coyote behavior or physiology will have top-down effects in urban ecosystems3.I predict low SES areas will represent poor habitat and diet quality via a reduction in prey diversity1.Therefore, coyotes will supplement their diets with a greater proportion of anthropogenic food subsidiesrelative to conspecifics in rural and high SES areas. I will trap coyotes (n=60) at 15 predetermined locationsalong an urban-socioeconomic gradient based on land cover, household density, and median householdincome11 across the Seattle-Tacoma, WA metropolitan region over three years during winter and summer.Coyotes show more restricted home ranges in urbanized areas and are unlikely to forage in non-adjacentterritories12. I will collect blood and hair samples from captured animals and scat samples from within andaround trapping sites. I will deploy GPS collars and use spatial data to determine the mean habitat type andSES area used by each individual, and relate these habitat measures to physiological data.Aim 1: Quantify oxidative stress variation in coyotes along an urban-socioeconomic gradient.H1: Coyotes in low SES areas are exposed to more stressors, leading to greater oxidative damage andhyperglycemia relative to rural and high SES coyotes. Alternatively, coyotes may cope with urban stressvia access to higher prey diversity in low SES areas, where refugia for prey is more common. To quantifyoxidative damage, I will analyze lipid erythrocyte proteins from blood samples for peroxidation4.Additionally, I will test for hyperglycemia by examining glycated serum protein levels8.1Cesar O. Estien Research StatementAim 2: Determine the effect of urbanization on coyote diet composition and how dietinfluences their ability to mitigate oxidative stress. H2.1: Urban coyotes consume less natural food andmore anthropogenic food than rural coyotes. Urban coyote fecal and hair samples will have lower nitrogen(δ15N) signatures, demonstrating a protein-poor diet, and higher carbon (δ13C) signatures, reflectinganthropogenic food consumption13. H2.2: Urban coyotes increase their antioxidant capacity by up-regulating antioxidant enzymes to cope with urban stress. To evaluate how coyotes mitigate stress, I willevaluate their (a) total antioxidant capacity, (b) activity of antioxidant enzymes4, and (c) diet composition.To evaluate (a), I will use the ferric reducing ability of plasma assay to describe the global antioxidantbalance4; (b), I will measure glutathione peroxidase and superoxide dismutase activity4; (c), I will performstable isotope analysis (using δ13C and δ15N)11 on hair and scat samples to determine diet composition (i.e.,anthropogenic vs. non-anthropogenic food sources). Using a linear mixed-effects model framework withAIC model selection, I will analyze the effect of site characteristics (rural/low SES/high SES), sex, andreproductive status on oxidative stress and the effects of urbanization on diet and oxidative stress.Feasibility: My research project will bring a new avenue of research to an established system, the Grit CityCarnivore Project (Dr. Christopher Schell, University of Washington). I will collaborate with the UrbanWildlife Information Network to effectively identify coyotes near trapping locations through existingcamera trap data. Field sites and permits have already been approved. My field experience(trapping/sampling) and computational skills (database management/R), along with access to cutting-edgeequipment and collaborators, will lead to the success of this project.Intellectual Merits: Understanding the consequences of urban systems on wildlife physiology and stressis essential to developing effective wildlife conservation plans. My proposed research will fill knowledgegaps by exploring the luxury effect in coyotes and identifying links between urbanization, SES, andoxidative stress. These results will bring a novel perspective to an emerging field investigating theinfluence of urbanization on the life-history of urban wildlife. This study will form a foundation forfuture studies on fitness outcomes and adaptation to oxidative damage and could establish coyotes asbioindicators that reflect the health of urban environments (e.g., high oxidative stress may reflect exposureto pollutants14). Further, this project will advance our knowledge of the biological processes within cities.Broader Impacts: (1) Community Engagement and Education: In addition to disseminating my resultsthroughout the scientific community, I will also present these findings locally (e.g., Tacoma News Tribune,high schools). I will also engage directly with residents and students near urban trapping sites to observecoyotes closely and showcase the vibrancy of the urban biome. I will partner with Environmentalists ofColor and The Nature Conservancy to create community engagement opportunities and accessibleeducation materials in urban ecology, focusing on Black and Brown communities in the Seattle-Tacoma metropolitan area. I will work with Treehouse, an organization aiming to close the education gapbetween underrepresented foster youth and their peers, to develop engaging interdisciplinary assignmentswith real data that links math, science, and urban history. (2) Management Implications: I will leverageexisting connections to work with Point Defiance Zoo and Aquarium and Woodland Park Zoo to developworkshops about urban wildlife natural history and conservation. My research will reveal how wildlifeare modifying their behavior in urban areas and how wealth disparities in humans influence wildlifestress, which will help managers develop natural areas for urban wildlife. Through my collaborations,I will be able to interact directly with Seattle and Tacoma city officials to help develop environmentaljustice and urban conservation policies.References: [1] Schell et al. (2020) Science. [2] Kuras et al. (2020) Landscape Urban Plan. [3] Prugh etal. (2009) BioSci. [4] Herrera-Dueñas et al. (2017) Front. Ecol. & Evol. [5] Isaksson (2015) Funct. Ecol.[6] Arnold et al. (2010) Biol. J. Linn. Soc. [7] Strandin et al. (2018) Phil. Trans. R. Soc. B Biol. Sci. [8]Schulte et al. (2018) Cons. Physio. [9] Morey et al. (2007) Am. Midl. Nat. [10] Newsome et al. (2015)Oecologica. [11] Magle et al. (2015) Anim. Conserv. [12] Gehrt (2007) Proc. 12th Wildl. Damage Mgmt.Conf. [13] Windberg et al. (1991) J. Wildl. Dis. [15] Pérez-Coyotl et al. (2019) Env. Poll.2"
28.0,"Background: Martian ice likely holds the key to interpreting Mars’ past climate, but much is stillunknown regarding the distribution and properties of Mars’ icedeposits. It is well known that Mars has extensive polar ice capsthe size of Greenland. Included in these large polar caps are thenorth and south polar layered deposits (NPLD and SPLD,respectively), that are comprised of kilometers-thick deposits ofwater ice. In addition, surveys by Conway et al. (2012) and Soriet al. (2019) have identified craters in the surrounding terrainswhich contain “outlying” deposits of ice (Figure 1), which mayor may not have formed at the same time as the deposition ofthe polar caps. These, as well as other efforts to identify andcharacterize ice, have used radargrams from the SHARAD(SHAllow RADar) sounding radar onboard NASA’s MarsReconnaissance Orbiter (MRO) to analyze the subsurface inthese icy areas, as radar images can essentially act as large-scaleice cores. However, additional data such as roughness andFigure 1. From Sori et al. (2019)dielectric constant of the shallow (<5 m) subsurface can beLocations of icy crater deposits nearextracted from these radargrams by analyzing the reflectivity ofthe southern polar cap. All threethe surface echo (Campbell et al., 2013; Castaldo et al., 2017;colors of points indicate outlyingGrima et al., 2012).crater deposits that will be consideredResearch Objectives and Motivation: I propose toin this work.leverage this technique to analyze the physical properties ofnorthern and southern outlying polar ice deposits. From my analyses, I will be able to draw conclusionsabout the purity, composition, and surface roughness of these ice deposits. Comparing similarities anddifferences between the ice deposits in the two hemispheres, as well as how the outlier deposits compare totheir corresponding nearby polar ice caps, will allow me to assess how localized or global the climateprocesses were which led to the formation of polar ice deposits. In addition, I will analyze the subsurfaceradar echoes of the southern icy outliers and search for the existence of any buried CO deposits that may2have been sequestered from the atmosphere in past climate events (Figure 2).The main objective of this project is to identify differences in physical properties between southernand northern icy outlier deposits. Conway et al. (2012) found evidence that supports similarities incomposition between the NPLD and outlying ice deposits located in northern craters. While the NPLD hasbeen found to be made up of pure water ice (Grima et al., 2009), large deposits of CO ice have been found2sequestered in the SPLD (Phillips et al., 2011). Given the similarity in composition between the NPLD andnorthern outlying ice deposits, it stands to reason that such a similarity may exist between the SPLD andcorresponding southern outlying ice deposits. This motivates my search for sequestered deposits of CO ice2within the southern outlying ice deposits. If such CO deposits are found, it would highlight a major2difference between the northern and southern outlier ice deposits, and would also place new constraints onthe thickness of the atmosphere in Mars’ past. CO sequestered in the ice would have once been in the2atmosphere, which would have a significant impact on the Martian atmosphere and climate system. Forexample, the amount of CO that has been found in the SPLD alone is enough to have doubled the2atmospheric pressure on Mars pre-sequestration (Phillips et al., 2011). Even if sequestered CO deposits2are not found in these southern outliers, other differences in composition, purity, and/or surface roughnesscould provide exciting insights on the icy processes at work in each hemisphere.Methods: To determine if a difference in physical properties of ice in the northern and southernoutlying crater deposits exits, I will examine the ice at two different spatial and temporal scales. First, I willuse the reflectivity of the primary surface echo to infer the roughness and dielectric constant of the youngersurface ice. Similar techniques have been used to make global maps of SHARAD parameters (Campbell etal., 2013; Castaldo et al., 2017; Grima et al., 2012), but have not been used to study these outlying icy craterdeposits. This will allow me to compare the present-day conditions of ice in the northern and southernhemispheres of Mars. I will also leverage the subsurface capabilities of SHARAD to analyze older layersof ice below the surface in these outliers, with the additional goal of determining the existence ofsequestered CO similar to that which Phillips et al. (2011) found within the SPLD. By analyzing the2properties of both subsurface and surface reflectors, I will be able to make comparisons of physicalproperties of northern and southern icy outliers as well as the climate conditions that could have formedthem.Figure 2. Example SHARAD radargramfrom Phillips et al. (2011). Reflection-free subsurface zones (“RFZ”) werefound to be pure CO2 deposits.Intellectual Merit: Such a study of the outlying ice deposits has not yet been done. The Martianice acts as a record of the climate in which it formed, so understanding the ice in both hemispheres isnecessary in order to be able to answer the questions of what conditions were present in Mars’ past. I expectthat this study will provide new insights on the similarities and differences in composition, purity, andsurface conditions of ice in the northern and southern hemispheres. Analyzing these properties can tell ushow the ice was deposited; for example, very pure ice would be indicative of a deposition via snowfall,while low ice contents generally imply formation due to condensation of atmospheric water vapor withinpore spaces of the regolith. Finding layers of ice with different properties would also provide strongevidence for changes in the climate, which could be linked to orbital/rotational variations analogous toMilankovitch cycles on Earth. This work may also confirm the presence or absence of sequestered CO2deposits in the southern outlying ice deposits, which if found would place new constraints on the thicknessof Mars’ atmosphere pre-sequestration of the CO .2Purdue University is an ideal institution at which to carry out this research. Here, I am advised byProf. Ali Bramson, who has extensive experience working with SHARAD observations of Martian ice (e.g.,Bramson et al., 2015) and is a Co-I on the NASA-funded Subsurface Water Ice Mapping (SWIM) project,which uses multiple types of observations (including radar) to map subsurface ice through the mid-latitudesof Mars. I will also be working with Prof. Mike Sori (also at Purdue University), using his database ofsouthern outlying ice deposits (Sori et al., 2019) as the set of southern deposits I will be characterizing.Broader Impacts: Indiana is home to the newest of our national parks: Indiana Dunes NationalPark (INDU). Using my experience as an Astronomy Ranger at Bryce Canyon National Park, I will workwith the chief rangers of interpretation and education and INDU, Bruce Rowe and Kim Swift, to develop anight sky educational program that connects what we see in the sky to geology here on Earth. Though INDUis near the light pollution of Chicago, major planetary bodies are still visible. This night sky program willbe held outdoors on the park’s West Beach weekly during the main summer season (April–November) andfocus on water and sand dunes throughout the solar system that are also present in the park. This park isuniquely located near major metropolitan areas, and as such these programs will serve communities thatare traditionally underserved by science outreach. More details on this planned project can be found in myPersonal Statement.References:Bramson, A. M., Byrne, S., Putzig, N. E., et al. (2015). Geophys. Res. Lett., 42(16), 6566–6574.Campbell, B. A., Putzig, N. E., Carter, L. M., et al. (2013). JGR: Planets, 118, 436–450.Castaldo, L., Mège, D., Gurgurewicz, J., Orosei, R., & Alberti, G. (2017). EPSL, 462, 55–65.Conway, S. J., Hovius, N., Barnie, T., et al. (2012). Icarus, 220(1), 174–193.Grima, C., Kofman, W., Mouginot, J., et al. (2009). Geophys. Res. Lett., 36(3), 2–5.Grima, C., Kofman, W., Herique, A., et al. (2012). Icarus, 220(1), 84–99.Phillips, R. J., Davis, B. J., Tanaka, K. L., et al. (2011). Science, 332, 838–841.Sori, M. M., Bapst, J., Becerra, P., & Byrne, S. (2019). JGR: Planets, 1–21."
29.0,"The sparse and heterogeneous distribution of water in savanna landscapes largely determines herbivoredistributions. Thousands of animals gather at watering holes and riverbanks, which become foci for bothcompetition and predation. Species with relatively low water needs can take advantage of large, naturallyoccurring gaps (“refugia”) between persistent water sources to avoid competition and predation; in fact,these refugia can be critical to maintaining their populations1. Kruger National Park (“Kruger”), SouthAfrica, offers a unique long-term experiment of the effects of surface water augmentation on herbivoredistributions. Kruger was fenced in the early 1960s, obstructing historic migrations of grazers to dry-season water sources. In response, management installed hundreds of watering holes (“boreholes”), butthese fragmented the dry refugia, allowing the ranges of drought-intolerant species (i.e. Equus quagga,Connochaetes taurinus) to expand into those of drought-tolerant, locally rare antelope1,2 (RA) (i.e.Taurotragus oryx, Hippotragus equinus, H. niger). This attracted predator attention to refugia and createdmore competition for forage during the severe droughts of 1981, 1985, and 19923. Surface water alsoattracts elephants, which can drastically alter the surrounding ecosystem and impact forage biodiversity4.This increased predation, competition, and ecosystem engineering all contributed to the alarmingpopulation declines in RA in the 1980s3. Realizing this, in 1997 Kruger’s management scheme was re-examined, and two-thirds of boreholes were closed4. The current conditions for Kruger’s RA are stillfraught, however. Borehole closures have not returned refugia to their original extents4; many remainopen for their touristic value (e.g. guaranteed presence of diverse species). In addition, climate modelsproject that southern Africa will experience more frequent and intense droughts5, especially threateningKruger’s drier northern areas, where most of the park’s RA refugia are located6.Motivation: Water access drives complex savanna dynamics. Lingering hydro-homogeneity inKruger, along with projections indicating more frequent and intense droughts, make it imperative tounderstand how this community is structured, how species interactions shape responses to climate change,and how these might change in the future. I will determine (1) how surface water sources and resultinginterspecific interactions affect how large herbivores respond to climate variables, and (2) how thischanging community structure impacts resilience to extreme environmental events. I will also create atool for Kruger park managers to infuse sharper knowledge of ecosystem structure into management aims.Methods: I will analyze herbivores’ interactions and responses using GJAMtime, a Bayesian time-series ‘generalized joint attribute model’ developed by Dr. Jim Clark7. GJAMtime models speciesdistributions through environmental and interspecies interactions, improving upon traditional staticspecies distribution models that fail to address interactions between species and temporal dependence onprevious conditions. GJAMtime builds species migration, density-independent (DI) growth, and density-dependent (DD) interaction terms into a familiar Lotka-Volterra model and generates a species-interactioncoefficient matrix (“a-matrix”), enabling dynamic community structure analysis8. In preparation, I havedivided a map of the park into 710 30km2 grid squares, to which I either aggregated (borehole locations,fires, geology, climate variables) or interpolated (rainfall, grass abundance) annual environmentalcovariates. I determined Bayesian priors for species interactions and responses to covariates throughreview of savanna literature and personal communication with established savanna scientists. Aerialannual census data are rich; from 1977-98, park rangers counted all animals in parkwide airplane census;from 1998 onwards, 800-m wide transects replaced the expensive full-park census (providing 15-28%coverage instead)9. For transects, data on individual animals’ distance-from-aircraft were also collected.With knowledge of each species’ detection rate (a factor of coloring, preferred habitat, and size), I willderive species detection functions using the R package ‘DSim’ to estimate true herbivore abundances.Research Plan: This project extends my exploratory analyses, detailed in my personal statement, toinclude borehole and fire data, larger temporal extents, narrower hypotheses, and novel statistical tools.(1) How does surface water affect community structure, and how can this in turn limit RA populationdensity? Hypothesis: If greater hydro-homogenization permits species invasion of refugia, then negativeimpacts on RA will be seen through (1) decreased populations and (2) negative a-matrix speciesinteraction coefficients. Equilibrium population sizes are a function of migration, DI, and DD growth; Iwill compare equilibrium abundances and a-matrix coefficients from greater and lesser boreholeconcentration years to determine whether these boreholes negatively affect RA populations. I willcompare pre-1997 data (high borehole density) to post-1997 data, the latter proxying a time with fewboreholes. I will extract how much of each species’ climate responses are coming from migration, DI, andDD growth using GJAMtime estimates. If results do not support my hypothesis (negative effect ofboreholes on RA population density), then this indicates the influence of other sources on RA populationdecline, including an increase in elephant disturbance after culling was ended in 1992; anthrax outbreaksin roan antelope in the early 1980s; or changes in fire management, extent, and intensity over time.(2) How does changing community structure affect the savanna ecosystem’s resilience to extremeevents? Hypothesis: If these changing community structures reduce ecosystem resilience, then increasinghydro-homogeneity will (1) increase drought recovery time, (2) increase fire recovery time, and (3)increased community instability. Major droughts occurred in Kruger in 1981-82, 1985-86, 1991-93, 2014-16, and 2018-20. These droughts straddle the borehole closures of the 1990s. Natural and prescribed fires,with varying intensities and times between burns, also occur regularly across the savanna. For intenselocal fires and parkwide drought events, I will compare each species’ population the year before the eventto its population in subsequent years to determine population recovery time. I will compare these trends toa stability analysis of the a-matrix (with negative eigenvalues indicating stability) for these periods to seeif community structure and species interactions are impairing ecosystem recovery after extreme events. Ifwe do not see evidence for this, then the influence of management decisions (e.g. removal of fencing, endof elephant culling) or climatic interactions (e.g. fires during drought years) played a larger role thanspecies interactions, setting the groundwork for future studies in community stability and resilience.Resources: The Kruger GIS Lab provided all data, and South Africa National Parks registered myproject this fall. In March 2021, I will share my research at Kruger’s Savanna Science Network Meeting,discussing my assumptions and findings with other savanna scientists. I will also travel to Kruger in 2021and 2022 to participate in dry season censuses and attend courses on savanna ecosystems. My mathdegree and two years’ coding experience at IBM prepared me well for the analysis of the complex modelsproposed in my study. I am advised by statistical and climate-change ecology expert Dr. Jim Clark andKruger grassland ecologists Dr. Steve Higgins (University of Bayreuth) and Dr. Carla Staver (Yale).Intellectual Merit: This analysis is crucial to maintaining one of the world’s last Pleistocenemegafauna savanna ecosystems. My novel statistical analysis will illuminate the relationship betweenspecies interactions and community environmental responses, a connection understudied in modernecological literature. I also propose to determine how a changing community structure affects anecosystem’s resilience to climate change, a pressing issue to today’s ecologists. Finally, my analysis ofKruger’s extensive, long-term datasets with GJAMtime’s Bayesian Gibbs-sampling techniques certainlymeet the 2020 GRFP solicitation goal of supporting “computationally intensive research”.Broader Impacts: Adaptive park management requires use of near real-time animal census andclimate data. I will provide park managers with a data workflow to feed each year’s new census data intomy GJAMtime model. I will (1) convert GJAMtime’s outputs to be readable by non-statisticians (2) writechange detection functions to highlight how herbivore responses vary from previous years, (3) convert thecode from steps 1 and 2 into an open-source user interface in RShiny to allow park managers to run codewithout prior programming skills, (4) solicit regular feedback from park management, and (5) provideiterative, ongoing support and tool improvement through GitHub. These five steps provide a link betweenthe environment-species interactions model and a more user-friendly interface for management decision-making. Additionally, as described in my personal statement, I will use my African savanna conservationresearch to develop open-source RShiny modules, based on Kruger herbivore and environmental data, toengage high schoolers in Durham Public Schools to boost their skills and confidence in math and coding.[1] CC Grant et al. 2002. Koedoe 45. [2] IPJ Smit 2011. Ecog. 34. [3] MP Veldhuis et al 2019. Ecol. Lett.22. [4] IPJ Smit 2013. Pachyderm 15. [5] Working Group II, Fifth Assessment Report of the Inter-governmental Panel on Climate Change, 2014. In: Impacts, Adaptation, and Vulnerability, Part B:Regional Aspects. [6] JO Ogutu & N Owen-Smith 2003. Ecol. Lett. 6. [7] JS Clark et al. 2017. Ecol.Monogr. 87. [8] JS Clark, et al. 2020. PNAS, 117. [9] JM Kruger et al 2008. Wildl. Res. 35."
30.0,"I propose to develop and implement a new approach to quantum-light spectroscopy. I will benchmark thenew approach against established classical-light techniques, namely nonlinear coherent spectroscopy, anduse classical- and quantum-light spectroscopies to investigate the mechanism of circularly polarizedphotoluminescence from chiral perovskite thin films.Introduction: Quantum light has been the subject of research in many physics subdisciplines, but untilrecently has not been considered as a tool for molecular spectroscopy by physical chemists. Much of thecurrent research on spectroscopy using quantum light has focused on using entangled photon pairs (EPPs)for nonlinear spectroscopies involving two-photon absorption1, effectively using quantum light as an analogfor classical light in nonlinear applications. I propose to use an established technique in the field of quantumphotonics – quantum-state tomography – in a spectroscopic application that treats both the quantumlight and the light-matter interaction fully quantum mechanically.The advantage of the proposed quantum-light spectroscopy over known nonlinear ultrafastspectroscopy techniques is the ability to directly investigate the quantum mechanical nature of a materialsystem and its dynamics. By measuring changes in the state of quantum light due to light-matterinteractions, we can learn about phenomena such as entanglement of correlated species in matter and spin-orbit coupling. Chiral perovskite thin films are an exciting and important material system to investigatewith this spectroscopy. Recent studies have shown that chiral perovskites act as sources for circularlypolarized photoluminescence (CPL), a highly sought-after feature applicable to bioresponse imaging, 3D-LED displays, quantum computing, spintronics, and more.2 An investigation of chiral perovskite thin filmsby Di Nuzzo, et al. has shown that the unknown mechanism of CPL in Ruddlesden-Popper perovskite thinfilms does not agree with the model of Rashba spin-orbit coupling,3 the primary model used to describespin-orbit coupling in 2D-semiconductors. I propose to use quantum-light spectroscopy, as well as two-dimensional photoluminescence (2DPL) and photo-induced absorption (2DPIA) spectroscopies, to explorethe claim that the CPL of chiral perovskite thin films is due to the charge of photoexcited Wannierexcitons and study the chiral symmetry transfer from optically inactive cations to excitons.Background: Quantum-state tomography is a technique used to completely characterize a quantum stateby measuring its density matrix. Photonic-state tomography involves the measurement of an ensemble ofpolarization-entangled photon pairs to determine the full two-photon density matrix4. I propose to use thespectroscopic setup in Figure 1, in which EPPs aregenerated in a polarization basis via spontaneousparametric down conversion (SPDC) using a pairof BiBO crystals. The two photons, the signal andthe idler, are spatially separated along the edgesof the SPDC emission cone and sent down distinctoptical paths. The idler photon is sent directly to a Figure 1. Proposed quantum-light spectroscopy setuppolarimeter composed of a quarter wave plate (QWP), a half wave plate (HWP), and a polarizing beamsplitter. The signal photon interacts with a sample before being sent to an identical polarimeter. Thepolarimeters project both photons onto a polarization basis defined by horizontal (H), vertical (V), diagonal(D), and right (R) polarizations. Finally, the photons are detected by single photon detectors that drive acoincidence counter. By determining the change in the full density matrix of the biphoton state, we canidentify the transformation matrix associated with the light-matter interaction in the polarization basis.Previous Work: The experimental set-up in Figure 1 has been realized in the Silva lab and validated bytaking tomographic measurements of several prepared biphoton states of the form andHH VVc |HH〉+c |VV〉with a quarter waveplate (QWP) in the place of a sample. In the defined polarization basis, a QWP performsa unitary transformation defined by a 90° rotation of the Poincaré sphere about an axis dependent on thewaveplate angle. Measurements taken with our experimental setup of a QWP at 0°, 22.5°, and 45° indicatesuch a transformation, corresponding to a rotation without loss of purity in the biphoton state.The proposed experimental set up is also easily combined with other spectroscopic techniquesfamiliar to the Silva lab, such as pump-probe spectroscopy. Preliminary data taken with a similarexperimental set up in which the sample is excited by a pump laser has shown that the quantum state of theprobe biphoton pair is altered by scattering off of a triplet-triplet intermediate state involved in singletfission. Through experimental measurements of bis(triisopropylsilylethynyl)tetracene (TIPS-tetracene)samples obtained through collaboration with Prof. John Anthony at the University of Kentucky andtheoretical development done in collaboration with Prof. Eric Bittner at the University of Houston, we havestudied the nature of the long-lived correlated triplet pair of TIPS-tetracene, which has been assumed to beentangled in the spin basis without experimental evidence.5 The experimental data, along with simulationsof the TIPS-tetracene system and the many-body scattering theory of the biexciton probe have allcontributed to a manuscript to be submitted to the Journal of Physical Chemistry C.Aim I – Theoretical comparison of quantum-light and 2D spectroscopies: The implementation ofquantum-light spectroscopy is nontrivial; working in the photon counting regime and with ensemblemeasurements requires precise environmental control and careful error analysis. It is necessary to show theproposed quantum-light spectroscopy will yield information that is inaccessible with known spectroscopictechniques and worth the challenge. I intend to do this theoretically using Lindbladian models to predictthe data that can (and cannot) be obtained for chiral perovskite systems comparatively with 2D andquantum-light spectroscopies as shown in our paper published on ArXiv6 for TIPS-tetracene.Aim II – Experimental investigation of CPL of chiral perovskite thin films: In concert with theproposed theoretical development, I intend to interrogate the mechanism by which chiral Ruddlesden-Popper perovskite thin films impart circular polarization on unpolarized incident light using 2DPL, 2DPIA,as well as the proposed quantum-light spectroscopy. I plan to synthesize the thin films with the help ofEsteban Rojas-Gatjens, a groupmate co-advised by Prof. Seth Marder. To my knowledge, these thin filmshave not been characterized with any 2D-spectroscopy which could probe their exciton dynamics.Intellectual Merit: I am ideally positioned to do this research. As part of the Silva group, I have access toa full toolbox of 2D- and ultrafast spectroscopic techniques which are regularly used by our group toinvestigate perovskites. Moreover, the project will benefit from continued collaboration with Prof. EricBittner and future collaboration with Andrei Piryatinski at the Center for Nonlinear Studies at Los AlamosNational Laboratory. The proposed research has potential to establish the experimental and theoretical basisfor a new form of quantum-light spectroscopy while also learning about the fundamental mechanism ofCPL from chiral perovskites, which could improve understanding of spin-orbit coupling in chiral materials.Broader Impacts: Understanding the chiroptical properties of chiral perovskite thin films wouldcontribute to many possible applications, as cited above. However, chiral perovskite thin films are justone of many interesting material systems that the proposed quantum-light spectroscopy can be used tostudy. Development of a new quantum-light spectroscopy would expand the capacity of spectroscopists tostudy fundamental quantum mechanical phenomena. It could be used to characterize gates used inquantum computation, singlet fission materials, spin-based memory devices, and so on.[1] S. Mukamel, et al. J. Phys. B., 53, 072002 (2020). [2] G. Long, et al. Nat. Rev. Mat., 5, 423-439(2020). [3] D. Di Nuzzo, et al. ACS Nano, 14, 7610-7616, (2020). [4] J. Altepeter, et al. Adv. Atom. Mol.Opt. Phys, 52, 105-159 (2005). [5] C. Yong, et al. Nat. Comm., 8, 15953 (2017). [6] arXiv:1909.12869"
31.0,"conserved protein belonging to the ribonuclear binding protein family.[1]It is involved in diverse, essentialcellular functions including RNA transport and alternative splicing. TDP-43 is also the primary componentof cytoplasmic aggregates that are the hallmark of amyotrophic lateral sclerosis (ALS), aneurodegenerative disease with very limited treatments and an average survival-after-diagnosis of 2-3years.[2]Some of these aggregates are amyloid—aggregatescharacterized by a fibrillar morphology andβ-sheet-rich structure as well as a prion-like ability to propagate the amyloid structure.[3]Amyloid proteinsare closely linked tohuman disease, including many neurodegenerative diseases like Alzheimer’s and Parkinson’s. One roleTDP-43 performs in the cytoplasm is protecting RNA during cellular stress by forming membranelessorganelles known as stress granules (SGs).[4]SGsare concentrated droplets of RNA and RNA-bindingproteins that are formedvialiquid-liquid phase-separation(LLPS), the spontaneous de mixing of asolution into a metastable concentrated droplet phase and a dilute phase driven by transient, multivalentinteractions. Phase-separated membraneless organelles have recently been discovered to play critical rolesthroughout the cell, but the complete composition and internal protein conformations of these droplets arenot fully understood.[5]Long-lived SGs (the resultof prolonged cellular stress) have also been shown tolose fluidity and become proteinaceous aggregates, suggesting a connection between protein aggregationand phase-separation.[4]A link between LLPS and amyloid aggregation is likely, as many amyloidogenicproteins can phase-separate without the need of other proteins or RNA.[6]In fact, it has been shown thatLLPS droplets made from the C-terminal domain (CTD) of TDP-43 act as an intermediate for amyloidaggregation in some conditions (Figure 1).[7]The study of protein conformation inside any LLPSdroplet has been very limited. Better understanding of thebasic composition of droplets (i.e. water content) as well asthe secondary structure of protein in LLPS droplets will helpFigure characterize how it may serve as an aggregation1. intermediate. Investigating whether either of theseTDP-43factors change with droplet age will add further tostates. the story. For example, is droplet aging andTDP-43 in (a) soluble (b) phase-separated, and accompanying loss of droplet fluidity due toCTD(c) aggregated states as viewed by brightfield changes in protein conformation, waterconfocal microscopy. Scale bars are 10 µm.exclusion,oranotherfactor?Doessecondarystructureofconstituentproteinschangeasdropletsage,ordoproteins remain disordered throughout droplet lifetime? Do aggregates formed via a phase-separationintermediate differ substantially from those formed in non-phase-separating conditions? Being able toaddress these questions will help 1) better understand LLPS and how itcarriesoutitsmanycellularroles,and 2) identify possible drug targets if TDP-43 LLPS proves to be linked to pathological amyloidaggregation. This work aims to understand secondarystructureofTDP-43inphase-separateddropletsandtrack changes that may occur in droplet hydration and protein conformation during the transition fromLLPS to aggregate.Methods and Experimental Design. I propose to utilize Ramanmicro-spectroscopy—asensitivetypeofvibrational spectroscopy which utilizes Raman scattering—coupled to a microscope, which allows forspatial resolution (Figure 2a).[8] Water scatters strongly in the 3000–3600 cm−1 range, allowing for anapproximation of hydration in droplets based on the intensity of the water bands versus a standard. TheRaman fingerprint region (1000–2000 cm−1) informsonthesecondarystructureoftheprotein(Figure2b).Specifically, the formation of β-sheet-rich structures upon amyloid aggregation results in a characteristicpeak at ~1665 cm−1.[9]Sidechain packing can be analyzedviaC-H deformation modes at 1300-1500cm−1.[9]One of the strengths of Raman spectroscopyis that a single droplet can be observed over time withRaman spectra taken at multiple time points. Raman data from Murthyet al.of another phase-separatedamyloid protein similar to TDP-43 suggests that protein within the droplets resembles soluble protein atearly time points, but it is unknown if this structure is sustainable or if it naturally proceeds to a moreamyloid-like secondary structure.[10]By followingthe lifetime of TDP-43 droplets, I can determinechanges in hydration and protein structure as the droplets age and lose fluidity, filling the gaps left byMurthyet al.and expanding the work to a proteinmore relevant to ALS pathology.Aim One: Collect Raman spectra inside of LLPS can act as a mechanistic intermediate duringTDP-43 LLPS droplets TDP-43 amyloid formation.TDP-43 will be used to prototype the experiment Aim Two: Characterize Differences betweenCTDbecause it reliably forms β-sheet-rich amyloid, and I Aggregateshave previously characterized its aggregation Figure 2. Raman spectroscopykinetics in a variety of conditions. TDP 43 canCTDphase-separate on its own and has been reported todrive aggregation of the full-length protein.[11]Afterproof-of-concept, full-length TDP-43 will beexpressed and purified. The protein will be placed inphase-separating solution conditions (high salt,neutral pH), and phase-separation will be confirmedviabrightfieldmicroscopy (Figure 1b). I will create a catalog ofRaman data from each time point giving a detailedview of the structural changes during dropletsolidification. I hypothesize that: 1) the conformationof TDP-43 will differ between its soluble, LLPS, andaggregated forms, 2) water content in droplets will(a) Diagramdecrease as droplets age and water becomes excludedillustrating the set-up of a Raman microscope,from the stacked β-sheets formed by proteins in theadapted from [12] (b) Representative Ramanamyloid conformation, and 3) as the phase-separatedspectra of TDP-43 fibrils with evident C-Hdroplet ages, the secondary structure band around CTDdeformations an amide I band reporting on β-sheet1600-1700 cm-1will narrow and sharpen, indicatingacontent.transition to β-sheet that mimics amyloid aggregates.Taken together, this data would demonstrate thatTDP-43 can aggregate even when phase-separation is not present. I will use Raman spectroscopy toanalyze the secondary structure of aggregates formed with and without the phase-separation. This willreveal any polymorphism in structure as Raman spectra are sensitive to not just secondary structure, butalso side chain packing as seen in the C-H deformation bands. I will also use Raman to examine samplespropagated from the brains of ALS patients (patient samples are used to ‘seed’ recombinant protein and,due to the prion-like nature of TDP-43, structure is preserved). By comparing the Raman spectrum of thein vitrophase-separated and non-phase-separated aggregatesto the spectra of the patient-propagatedsamples, insight into whether disease-related aggregation stems from a phase-separated intermediate willbe gained.Resources and Suitability.I have significantexperience using Raman micro-spectroscopy inDr. Jennifer Lee’s lab at the NIH. Paired with my prior work with TDP-43 and strong record ofindependence and publication, this makes me uniquely well-suited to pursue this project. The work will beconducted utilizingthe Raman micro-spectrometer at the University of Wisconsin Centers for Nanoscale Technology.Intellectual Merit.By characterizing the generalhydration and composition of LLPS droplets, this projectwill provide foundational information on LLPS, a process of interest to fields ranging from polymerchemistry to cell biology. Additionally, if LLPS are shown to be intermediates in amyloid aggregation, thisopens new doorways for drug development targeting the proteins in droplets.Broader Impacts. This project illustrates the value of an interdisciplinary approach in studying humanhealth and disease processes. Specifically, it demonstrates how physical chemistry methods—the mostmicro scale—can offer foundational, useful information on emergent processes in complex biologicalsystems. I hope that demonstrating the utility of physical chemistry, which can often feel hopelessly farremoved and theoretical for students, will pique the interest of the next generation of chemists as I workwith them as a teaching assistant and research mentor.References. [1] Y. Sun, Biochemistry 2017. [2] M. Neumann, Science 2006. [3] J. L. Robinson, ActaNeuropathol 2013. [4] C. M. Dewey, Brain Res 2012. [5] S. Boeynaems, Trends Cell Biol 2018. [6] S.Elbaum-Garfinkle, J BiolChem2019.[7]W.M.Babinchak,JBiolChem2019.[8]R.R.Jones,NanoscaleRes Lett2019. [9] Z. Movasaghi,Appl Spectrosc Rev2007. [10] A. C. Murthy, Nat Struct Mol Biol2019.[11] A. E. Conicella, Structure2016. [12] S. Lohumi,Appl Sc.2018."
32.0,"(sRNA-seq) technologies have fueled the discovery of many new classes of biologically relevantnon-coding sRNAs. Accumulating evidence suggests that sRNAs are critical contributors to thepathogenesis of various diseases and play an essential role in regulating gene expression levels1.RNA-seq analysis has revealed diverse classes of sRNAs circulating on various lipid and proteincarriers, including high-density lipoproteins (HDL) 1. The most well characterized sRNAs aremicroRNAs (miRNA) and the sRNA-seq analysis tools currently available are designed to focusmostly on miRNA quantification. Due to the limitations of previous analysis tools, our labdeveloped a novel sRNA analysis pipeline (i.e. TIGER) which profiles many classes of host (e.g.mouse, human) and non-host (e.g. bacteria, archaea, fungal) sRNAs present on lipoproteins2.Using our new TIGER pipeline, we discovered that the overwhelming majority of circulatingsRNAs on HDL are classified as host and non-host ribosomal RNA-derived fragments (rDF)2.Motivation: Although the functional role(s) of rDFs are poorly understood, mountingevidence suggests that rDFs are not products of random degradation, but regulated by specificendonucleolytic cleavage processes, similar to that of transfer RNA-derived fragments (tDFs)3.Indeed, various stressors were shown to induce transfer RNA cleavage events, producing stabletDRs3. Angiogenin is an RNase A-family enzyme that is thought to be primarily responsible forstress-induced tRNA fragmentation within mammalian cells4. Angiogenin has also been shownto induce rRNA fragmentation, although to a lesser extent4 Interestingly, the cleavage of tRNAs.and rRNAs are inherently linked to their chemical modifications (i.e. m1A and m5C)5. BothtRNAs and rRNAs represent the most abundant sRNAs, and the two most heavily modifiedRNAs in the eukaryotic genome. Although the identification of chemical modifications on tDFshas been actively pursued, few studies address the modifications found on rDFs. However,preliminary data I have generated using 2D-thin layer chromatography (2D-TLC) identifiedabundant base modifications (e.g. m5C, m6A) on sRNAs isolated from human HDL samples.A major limitation when exploring the sRNA world is that many base modifications candisrupt Watson/Crick base pairing and impede first-strand synthesis by reverse transcriptase(RT) 4. These chemical modifications therefore affect the detection and quantification of sRNAs,limiting the power of discovery. Although recent improvements to our TIGER pipeline havegreatly enhanced our ability to assess sRNA content on HDL, base modifications wouldsignificantly impair efficient detection of these modified sRNAs. To circumvent these issues, arelatively new method was developed called AlkB-facilitated RNA methylation sequencing(ARM-seq) which exploits the RT roadblocks created by chemical base modifications (i.e. m1A,m3C and m1G) in tRNAs6. The E. coli AlkB homologs (ALKBH1 and ALKBH2) act as “eraser”proteins, catalyzing the demethylation of specific chemical base modifications6. This methodrepresents a large step forward in the quantification of tRNAs, however a very limited number ofstudies have used ARM-seq for rDFs. Similar to tDFs and miRNAs, which were once readilydiscarded from RNA-seq datasets, rDFs may play important roles in the regulation of geneexpression. As such, accurately quantifying rDFs and their modification status on HDL is key togaining a more complete understanding of the biological functions of the epitranscriptome.Based on our previous studies and preliminary results I hypothesize that: (1) Improved sRNA-seq methods will increase the inclusion and identification of rDRs in HDL-sRNA datasets. (2)Stress factors induce parent rRNA fragmentation leading to an increase in circulating rDRs. Iwill address these hypotheses through two central aims.Aim 1: Enhance HDL-sRNA identification by characterizing the landscape of chemicalbase modifications found on sRNAs. To achieve this goal, we must capture and identify all hostand non-host rDRs. This will include a.) Expanding bioinformatic analyses for rDRs, b.)Improving the identification of modified rDRs, and c.) Removing modifications on sRNAs forenhanced rDF inclusion in sequencing analyses. To address this aim I will first collect bloodfrom healthy individuals and isolate their sRNAs found circulating on HDL using fast proteinliquid chromatography. I will then pretreat HDL-sRNAs with the purified AlkB enzymes prior tocDNA synthesis (RT step) and library preparation. By comparing AlkB-treated and untreatedsamples, I will reveal the positional modification profile of HDL-sRNAs, including rDFs. TheTIGER pipeline will be used to identify the diverse classes of sRNAs on HDL particles. Thepower of ARM-seq will be maximized by taking advantage of RNA modification databases, suchas Modomics and RMBase. I expect ARM-seq to efficiently reveal chemical base modificationsin the sRNA samples and increase the repertoire of rDFs.Aim 2: Characterize changes in parent rRNA fragmentation and cellular rDF export toHDL in response to environmental stress. Overwhelming evidence supports the role for specificenvironmental stressors to induce tRNA cleavage; however, very few studies have looked atrRNA fragmentation during environmental stress7. To determine whether oxidative stress, heatand cold stress, or γ-irradiation promote rRNA cleavage events, and the export of rDFs to HDL, Iwill treat human hepatic and non-hepatic cell lines with various environmental stressors(hydrogen peroxide, cold or heat shock, or irradiation with UV). Afterwards, the cells will befractionated into nuclear and cytoplasmic extracts, and HDL will be isolated using a FPLC. Toexamine stress-induced rRNA fragments within these cellular fractions, I will use improvedsRNA-seq approaches and confirm candidate rDFs using northern blot techniques. Moreover, wewill quantify the export of hepatic rDFs to HDL in response to stresses to using HDL-sRNAexport assays. I fully expect that exposure of specific environmental stressors will induce distinctparent rRNA fragmentation patterns and alter hepatic rDF export to HDLBroader Impact: Circulating sRNAs have been shown to be differentially altered inseveral diseases and hold great potential for the discovery of novel biomarkers and highlypromising therapeutics. Given the value of potential biomarkers, the field of sRNA has led tocutting edge research. However, there are still gaps in our understanding of sRNA diversity oncirculating HDL. My proposal helps to address this gap and may lead to the identification of yetunknown RNAs. With novel classes or sRNAs being discovered, and the validation of modifiedsRNAs, it is paramount that RNA-modification and sRNA databases are updated. I willdisseminate my findings to web portals and servers dedicated to compiling databases for RNAmodifications.Intellectual Merit: It was not very long ago that many sRNAs were considered “junk”and often removed from RNA-sequencing data analysis. However, we now know that sRNAscan regulate several aspects of gene expression. The novel pipeline generated by ourbioinformatics team allows us to discern several classes of small RNAs found in both eukaryotesand prokaryotes. This interdisciplinary proposal applies techniques from bioinformatics,transcriptomics, microbiology, and biochemistry, and represents the first study aimed atidentifying modified small RNAs on HDL. Successful completion of this proposal will not onlyexpand the repertoire of sRNAs and rDRs but will also show how rDRs are important biologicalmolecules.References: [1] Vickers et al. 2011. Nature Cell Biology. [2] Allen et al. 2018. Journal of ExtracellularVesicles. [3] Lambert et al. 2018. Non-coding RNA Investigation. [4] Su et. Al. 2019. J Biol Chem. [5]Rashad et al. 2020. Neural Regeneration Research. [6] Cozen et al. 2015. Nature Methods. [7] Thompsonet al. 2009. Cell."
33.0,"Title:Investigating Maine’s Indigenous Fire Prehistoryto Inform Forest Management Under GlobalChangeWith climate change amplifying underlying environmental issues, modern wildfires have becomeenormous devastating forces, costing lives, our natural resources, and billions of dollars. Early US ForestService practices focused on fire suppression as a management tool, which increased the presence ofunderbrush, snags, and flammable material in forests1.Though these practices have changed, those initialmanagement plans coupled with drought, eco-tourism, and rising temperatures have led to the large-scale,uncontrollable, high-intensity fires in the West that, as of October 1, 2020, have burned nearly 7.7 millionacres this year2.In contrast, indigenous fire management has played an important role in the ecology of many NorthAmerican landscapes for thousands of years. Native peoples used fire to clear the land for cultivation,promote healthy and diverse food-rich forests, and facilitate diverse wildlife habitat3. These practiceshave largely been excluded in modern forest management plans. By the 1970’s the Forest Service beganutilizing indigenous knowledge to set controlled burns in the West, Southwest, and Southeast, but not inthe mixed hardwood forests of the Northeast1, wherefire is not widely considered to be an importantprocess4. However, there have been large-scale destructivefires in the last century, like the Great Fire of1947 in Maine. This drought-intensified fire consumed 17,188 acres, destroyed 240 buildings, and costover $23 million in property damages5. As climate change is causing warmer temperatures and droughtsin the Northeast6, there remains a critical need tounderstand the long-term history of fire (both naturaland anthropogenic) in this region.Most of our academic knowledge about indigenous fire use in New England is largely based on journalsand other written accounts by European settlers. However, those records lack the perspectives ofindigenous people, and only explain fire use post-contact7.Historical observations and Wabanaki oralknowledge indicate that, within the last 500 years, Native peoples used fire to clear land for agriculture,and to improve hunting grounds south of the Kennebec River in Maine. Penobscot place names describeareas that experienced regular burning. For example, Schoodic (skudek) Peninsula, a part of AcadiaNational Park, means “burnt-land”8.Long-term fire records from lake sediment cores and tree rings have provided another valuable source ofinformation about the relationships between fire, climate, vegetation, and people in the American West,Midwest, and Southeast, but are still lacking for the Northeast, including New England. A recent studysynthesizing charcoal patterns across New England found no evidence of pre-European anthropogenic fireuse, but this reflected a regional fire record that would not highlight the more localized scale at whichindigenous peoples would have been burning4. Charcoalrecords in the Northeast have primarily beentaken from large bodies of water9, which are biasedtowards large regional fires, instead of local, lowintensity fires, which would have been the types of fires Native peoples used for land management4.Therefore, while previous paleoecological studies have been important for understanding the large-scalefire prehistory of New England and its relationship to climate, they are poorly suited to the study ofanthropogenic fires. And, by failing to partner with Native scholars and incorporating oral knowledge ofpast land use, such studies mask indigenous peoples’ expertise and contributions to the health of thelandscape10.Intellectual MeritMy research goal is to reconstruct localized fire records in Maine to better understand fire as a prehistoricland management tool in New England. I will take a multi-pronged approach to this work: 1.) I willconduct an actualistic study to identify the signals of localized understory burns and small patch clearingsin the charcoal and pollen records of forest hollows and small ponds. 2.) In collaboration with members ofthe Penobscot Tribe, I will collect sediment cores from small ponds and forest hollows near settlementsand prehistoric hunting grounds to examine whether small-hollow cores can identify local, small-scaleburning. 3.) I will then synthesize these findings with existing geoarchaeological, climate, and pollenrecords to assess the relationships between population and cultural shifts, climate, vegetation, and firehistories across scales. All of the necessary equipment and facilities to carry out this project are availableat the University of Maine Climate Change Institute, and Dr. Gill is building tribal partnerships viacollaborations with Penobscot faculty at UMaine: Dr. Darren Ranco, director of the WaYS program, andDr. Bonnie Newsom, archaeologist. Partnership opportunities are also available at Acadia National Parkthrough the National Park Service.Many fire-use studies focus on written accounts, the charcoal record, and tree scaring to reconstruct pastfire regimes, but researchers have historically excluded indigenous communities when studying pasthuman land use. My project will contribute to a more accurate historical record of prehistoric land use bybetter matching the tools to the questions to characterize anthropogenic fire histories and impacts. Thisproject will also add to our understanding of charcoal records taken from small hollows. In contrast withthe pollen record, hollow-based fire records are lacking, which limits our ability to interpret stand-scalefire impacts11.Broader ImpactsThough fire is not considered to be an important process in the Northeast, with climate changeexacerbating existing environmental issues, it is becoming an increasingly dangerous threat. This pastsummer, drought conditions and increased eco-tourism due to COVID-19 resulted in a summer of over900 high-intensity, destructive fires in Maine6. Maine’seconomy depends on logging and tourism12anddrought-induced fires put both of those industries at great risk. This study seeks to understand lowintensity fires and will inform conservation and management practices. Such fires clear underbrush andsnags, reducing the fuel load for uncontrolled fires. This would make Maine’s forests safer while alsoreducing tick populations by burning shrub species that foster these disease vectors13. Cleared underbrushwould improve forest health by reducing canopy competition and eliminating weaker diseased trees. Allof these benefits could increase timber quality and forest health, boosting two of the state’s majorindustries during a time of economic uncertainty.The Wabanaki Confederacy is a collection of Eastern Algonquin tribes including the Penobscot,Passamaquoddy, Mi'kmaq, and Maliseet people. I plan to use my research to contribute to the NativeAmerican Graves Protection and Repatriation Act (NAGPRA) by providing supporting evidence of longterm tribal habitation. This project will contribute to a long-term collaborative relationship with localtribes and will provide critically needed information in support indigenous sovereignty claims. I alsointend to collaborate with the NSF-funded Wabanaki Youth in Science (WaYS) program at UMaine.WaYS trains Wabanaki youth in both tribal knowledge and scientific approaches through summer campsand internships. I intend to include Wabanaki students in my project by bringing groups of students outinto the field and mentoring students in the lab to learn sediment coring and paleoecological techniques.References.[1]Forest History Society.US Forest Service FireSuppression. [2]Congressional Research Service.2020. 43. [3]Ryan K.C. 2013.Frontiers in Ecology and the Environment.[4]Oswald, W.W. 2020.Nature3,241–246. [5]National Park Service, Acadia. 2020. [6]The Maine Monitor. 2020.Bangor Daily News.[7]Ruffner, C. M. 2005.USDA: Proceedings 16th CentralHardwood Forest Conference.[8]Francis, J.E.2008.Farms, Forest, and Fire44(1): 4-18.[9]Patterson.1988.Holocene Human Ecology in NortheasternNorth America.[10]Kimmerer, R.W. and Lake, F. 2001.Journal of Forestry99(11):36-41. [11]HigueraP.E. 2005.The Holocene15(2): 238-251.[12]US Newsand World Report. 2020.Best States: Maine.[13]Gleim E.R. 2019.Nature."
34.0,"Introduction and Preliminary Results: Discovered at Drexel University in 2011, MXenes are a novelclass of 2D materials that comprise metal carbides and nitrides. Due to their excellent electronic, optical,thermal, and mechanical properties, MXenes have great promise for applications in several technologiesincluding additives in solar cells and electronic contacts for semiconductors [1]. Compared to other 2Dmaterials, MXenes offer an optimal combination of high electronic conductivity, low cost, and facilesynthesis methods. Furthermore, their tunable optoelectronic properties, such as work function and opticalabsorption, enable MXenes to improve emerging photovoltaic materials such as perovskites and inorganicsemiconductors. To realize the full potential of MXene photodetectors, an improved fundamentalunderstanding of their electronic and optical properties is needed.During my master’s thesis, I refined methodsfor photodetection analysis of MXene thin films. Whileit laid the groundwork for the optoelectronic study ofMXenes, the underlying factors that drive MXeneresponse to light (photoresponse), such as the impactsof the electrode and substrate type, are not well-understood. While MXenes have proven successful asadditives and electrodes, I aimed to bring them to themainstream as active materials. My work focused on thephotoactive capabilities of Ti C , which has already3 2succeeded as a transparent photodetector electrode [2].Although Ti C is the most commonly studied MXene,3 2its response to chopped illumination with visible lightFigure 1: Ti C films exhibit consistent negativehad not yet been reported. 3 2photoconductivity when deposited on patternedFigure 1 compares the average change influorine-doped tin oxide (FTO) substrates withoutresistance (R) upon illumination for films withthe use of silver paste contacts (black). However,different initial resistance values (corresponding tothin films with high R switch from negative tothickness) and with different contact methods. Here, 0positive photoconductivity upon illumination withthe application of silver paste as an electrical contactthe application of metal contacts (red) andcauses Ti C to deviate from innate behavior upon3 2experience suppressed photoresponse whenillumination, while a change to a thinner substratedeposited on glass slides (green). Schematic(glass slides) suppresses the magnitude of theof MXenes shown in inset [2].photoresponse. Ti C is a well-known metallic and3 2photothermal material with innate negative photoconductivity, leading to an expected increase in R uponillumination or heating; these observations that contradict expected behavior call into question the role ofsilver-MXene interactions, carrier dynamics, and heat transfer in determining the material’s photoresponse.I hypothesize that the photovoltaic (PVE) and the photothermoelectric (PTE) effect each play into thephotocurrent generated by MXenes, giving them the power to serve multiple applications, from thermalimaging to photovoltaic electrodes.Research Plan: I aim to both experimentally and computationally study heat and charge transport inMXene photodetectors to guide their design in imaging and energy generation applications. I will beginmy examination with Mo-based MXenes, a lesser-studied subset of MXenes with potential as a photoactivematerial. Previous empirical studies question computational results showing Mo TiC has semiconductor-2 2like properties [3]. This work will seek to confirm these analyses by isolating contributions to light-matterinteractions for Mo-based MXenes. Furthermore, over 30 different MXenes have been reported to date [1].This proposal outlines just the beginning of our exploration into MXene photodetection capabilities inresponse to visible light, as the methods listed can be applied to other photoactive MXenes as well.Objective 1 – Understand the impacts of device architecture: In varying the deposited film thickness,contact geometry, and substrate type, I will evaluate their individual influences on photodetector properties(responsivity, noise, stability) in response to chopped illumination with visible light. Using thermallyconductive substrates, such as sapphire, the impact of thermal effects can be mitigated. I expect stronglyabsorbing films, non-metal electrical contacts, and thin, thermally conductive substrates to produce thestrongest photoresponse for Mo-based MXenes. Upon gaining this phenomenological data, I will then studycharge carrier dynamics to understand the light-matter interactions for each MXene device. Under theguidance and expertise of Prof. R.J. Holmes, I will probe exciton diffusion at the interface of thephotoabsorbing MXene and the electrical contact via an external quantum efficiency measurement methodcurated in his group [4]. This broadly applicable method provides additional understanding of carrierdynamics upon photoexcitation and will guide selection of device architecture for improved performance.Objective 2 – Model optical and thermal transport kinetics: Through computational efforts to modelcontributions from the PTE and the PVE, I will confirm the dominant effect that determines thephotoresponse. Should combined contributions dictate the photoresponse, I aim to create a secondary modelsystem specific to MXenes. By compiling a model from literature for both heat and carrier transport, I willdetermine optimal film thicknesses, contact geometry, and substrate types for devices that rely on either thePVE or the PTE, creating two reliable device architectures with improved responsivity. Moreover,simulating the photodetector architectures created in Objective 1 using COMSOL will push them to theirthermal and electronic limits, granting insight into widespread implementation of MXene photodetectors.Objective 3 – Create devices and optimize performance: Equipped with the knowledge of optimal devicearchitecture and film deposition, I will build Mo-based photodetectors and investigate industrially relevantissues, such as stability, lifetime, and performance of larger area devices. Given the inevitable obstacles inscaling up a device, I must tailor the device parameters found in Objective 1 to suit applications that wouldbenefit from either the PVE or the PTE, such as energy generation or thermal imaging, respectively. Ienvision my contributions will spur the development of MXene-based photodetectors that suit multiplepurposes simply by changing the device architecture.Intellectual Merit: My well-rounded background in chemical engineering and materials science andengineering allows me to understand not only why MXenes behave the way they do, but also how we canimplement these materials in devices. I will utilize the wealth of knowledge from multiple energy transportexperts, including Prof. Holmes, as well as state-of-the-art facilities for nanotechnology research at UMNto ensure the success of this project. The proposed research will provide an improved fundamentalunderstanding of the factors that influence MXene photodetection, an emerging field of interest with limitedliterature available. Upon gaining this understanding, we can continue to use MXenes in optoelectronicapplications, reducing the cost to produce photodetectors and allowing for widespread implementation ofmore conductive, easily synthesized materials.Broader Impacts: My work aims to inspire other researchers to consider implementing MXenes in theirdevices, bringing the field closer to a reliable, reproducible method for renewable energy generation.Through my research on nanomaterials in energy applications, I aspire to make clean energy commonplace,expanding on my dreams of a sustainable future arising from wanting to develop accessible biodegradableplastics in high school. I also aim to continue my impactful record of mentorship and community outreach.Leaning on my extensive outreach experience described in the accompanying personal statement, I plan tocreate an interactive lesson on current and novel photodetectors and sensors through Science for All, astudent-run group created to support and promote STEM fields to local, underserved middle schools in theurban Twin Cities. Prof. Holmes also has the laboratory facilities to package photodetectors, allowing meto bring samples to the classroom. Lastly, through the Undergraduate Research Mentorship Program(UROP), I will seek and recruit undergraduate students from underrepresented groups for this project,serving as a research and personal mentor to guide them through their technical careers and encourage themto continue their STEM education.References: [1] L. Zhao, et al. Tungsten, 2 (2020): 176 – 193 [2] K. Montazeri, et al. Adv. Mater., 31.43(2019): 1 – 9. [3] G. Li, et al. Proc. SPIE 11279, 112791U (2020): 66 – 84. [4] T. Zhang, et al. Nat.Commun., 10.1 (2019): 3489 – 3495."
35.0,"wetlands (UPOWs), are a practical, cost-effective, and highly scalable approach to managing environmentalwater quality.1 UPOWs utilize microbial growth in the benthic region within a photosynthetic biomat,hosting a stratified population in aerobic, anaerobic, and anoxic zones. Biomat microbe ecosystems havedemonstrated treatment of influent water for nutrients, trace organic compounds, and other contaminants atrates that match—and in many cases exceed—those of traditional vegetated or subsurface wetlands.1 Thesemicrobial populations develop independently over multiple months, using algae and other detritus as carbonand electron sources.The low implementation and maintenance costs of these systems have drawn attention to their usefor increasing water availability and decreasing risk in otherwise water-poor or unprotected communities,such as the Arequipa region in Peru. These communities utilize surface water from local rivers such as theTambo, which contains concentrations of arsenic (As) exceeding Autoridad Nacional de Agua regulationsfor both domestic and agricultural use.2 Elevated concentrations are likely a result of high background levelsof As in local geology and introduction from mining operations in the area. The surrounding communitycan no longer safely consume or export important commercial products such as rice or river shrimp becauseof this threat. The long-term effects of these economic limitations and human health impacts cannot beunderstated and will continue to persist so long as the region suffers from degraded surface water quality.Dr. Josh Sharp, professor of Civil and Environmental Engineering at the Colorado School of Mines,is currently working with the Universidad de San Augustín de Arequipa (UNSA) in Peru to study thepotential for UPOWs to treat surface waters for metal and metalloid contaminants. UPOWs with thecapability to remove these hazards would provide communities with a first step toward improvingenvironmental water quality.Challenges of degraded water quality do not adhere to national or state boundaries. Communitiesall over the world, including here in the United States, contend with a lack of access to safe water sources.My goal is to apply research on UPOWs to ensure no one has to suffer from contaminated water. I willbuild upon Dr. Sharp’s research on UPOWs by determining their capacity for arsenic removal.Hypothesis: UPOWs are able to remove trace organics and nutrients from surface waters and are potentiallycapable of immobilizing metal and metalloid contaminants.1 Arsenic (V) is the most prevalent form of Asin surface water, and poses a hazard to human and environmental health.3 I hypothesize that UPOWsincorporating sulfate-reducing bacteria have the capability to remove As (V) from surface water viaprecipitation with sulfide in a variety of geographic settings.Research Plan: Objective 1: Analyze the potential for As (V) precipitation as As S in the presence of2 3sulfate-reducing bacteria in UPOWs.Arsenic (V) removal by precipitation relies on the transformation of As (V) to As (III), as biologicalsystems have previously been observed to utilize sulfate-reducing bacteria to precipitate As (III) withsulfide.3 H AsO , the naturally occurring form of As (III), reacts with sulfide to produce As S (Equation3 3 2 31) which is insoluble in typical surface water conditions.42𝐻 𝐴𝑠𝑂 +3𝐻 𝑆 ⇌ 𝐴𝑆 𝑆 +6𝐻 𝑂 Equation 1! ! "" "" ! ""Some sulfate-reducing bacteria hold the potential to reduce As (V) to As (III).5 The presence ofthese bacteria could allow for the precipitation of As (V), proceeding as in Equation 1. Sulfate-reducingbacteria colonize and function well in biomat ecosystems,4 but they have yet to be tested for specificremoval of As.Objective 2: Evaluate As removal efficiency of UPOWs across largely differing geographical areas.The formation and function of biomats in UPOWs rely on both biotic and abiotic constituents ofsurface water. Successful arsenic removal depends on the colonization and function of sulfate reducingbacteria, algae, and other diatoms, all of which could differ by region. I will observe whether biomatecosystems will support microbe composition necessary to perform key contaminant removal functionsregardless of UPOW location.Differing water chemistry and abiotic constituents could alter the As removal pathway or block Asprecipitation altogether. In some cases, As may complex with other constituents to produce undesiredbyproducts, such as Thioarsenic.6 A particularly interesting factor in the success of As removal may alsobe sulfate concentration, though determining direct influence is outside the scope of this project.Approach/Methods: Testing will occur at both the bench and field scales. After the effectiveness of themesocosm-sized UPOW biomat has been determined, the biomat composition and design will be tested atthe field scale at the Prado Wetlands in California and then at the UNSA in Peru.Objective 1: Bench scale biomats will be harvested from existing UPOWs in the Prado Wetlands anddeployed in the lab at the Colorado School of Mines to be tested with spiked influent water. Test water willconsist of local Colorado water samples spiked with known levels of arsenic. Sulfate will be held constantin a similar concentration to that of the Tambo. Removal efficiency will be calculated using a mass balanceon As, with a known influent concentration, precipitation concentration determined using a modifiedTessier extraction of the biomat,7 and effluent concentration determined using ICP-MS chromatography.Selective inhibitors for sulfate reducing bacteria, such as molybdenum8, will be used to evaluate arsenicprecipitation in response to sulfate reducing capacity.Testing will move to the field scale as a validation step in large-scale performance after bench-scale testing has been completed. Field testing will first take place at the Prado Wetlands, where a colonizedUPOW will be allowed to run for an extended period of time. As concentrations will be measured using thesame methods as at the bench scale.The continual rise of precipitated arsenic in the biomat could lead to concern after long periods oftime in field operating conditions. To mitigate potential release of highly concentrated arsenic from abiomat, I recommend an operating system in which sections of biomat could be harvested prior to theaccumulation of dangerous levels of As or other harmful constituents. These sections could go on to beused as fertilizer to utilize their elevated levels of nitrogen, resulting from abundant nitrifying bacteria.Objective 2: Successful function of a UPOW system in Peru will first be estimated at the bench-scale usingreplicated Tambo River water at the Colorado School of Mines. Biomat colonization and As removal willbe monitored over the course of several months using these waters, with an emphasis on the perception ofsulfate reducing bacteria presence.Field-scale testing will occur at the UNSA and will mirror procedures in the United States, nowusing unmodified water from the Tambo River. Biomats will colonize and undergo testing in mesocosmand field-scale UPOWs and arsenic concentrations will be determined using a mass balance approach.Intellectual Merit: Metal and metalloid removal has not yet been tested in UPOW systems, but thesuccessful performance of sulfate-reducing bacteria in previous UPOWs could lead to an innovation in Asremoval methods. This study would quantify the effectiveness of this mechanism for arsenic removal fromsurface water via UPOWs.UPOWs have been tested in the United States but have not been observed abroad. This study willdemonstrate the effects of differing surface water characteristics of different regions on arsenicprecipitation. Additional application of UPOWs, including biomat harvesting, could have basis for furtherinvestigation to increase utility of these already compelling systems.Broader Impacts: The development of this system, and other natural treatment systems, would makeprogress on the priorities set forth by the UN Sustainable Development Goals and the Grand Challenges ofthe National Academy of Engineering. My work would directly contribute to these efforts aimed atincreasing global sustainability and standards of living. More immediately, an UPOW system has thepotential to mitigate the threat of arsenic for the Arequipa community and others like it. Depending onsequestered metal concentrations, the periodic harvesting of UPOW biomats, for fertilizer or otherwise,could also prove UPOW potential to serve a purpose beyond water treatment. Further research on naturaltreatment systems will continue to drive down cost, increase understanding, and foster education incommunities using natural water treatment.References: 1Jasper, et al. (2013). Environ. Eng. Sci. 30(8), 421-436. 2Autoridad Nacional de Agua. (2020)Ministerio de Agricultura y Riego. 3Lizama, et al. (2011). Chemosphere. 84(8), 1032-1043. 4Jones, et al.(2017). Appl. Environ. Microb. 83:e00782-17. 5Macy, et al. (2000). Arch. Microbiol. 179, 49-57. 6Stucker,et al. (2014) Environ. Sci. Technol. 48(22), 13367-13375. 7Tessier, et al. (1979). Anal. Chem. 51(7), 844-851. 8Blum, et al. (1998). Arch. Microbiol. 171, 19-30."
36.0,"Introduction:Glass-Ceramics (GC’s) are critically relevant materials for industry and scientific research, primarily dueto their outstanding mechanical, thermal, and optical properties. High-grade GC’s such as lithium-aluminosilicate (LAS) are commonly used as insulation materials for high-performance aircrafts andmissiles, optical bodies of precision optics, and biomaterials for medical equipment[1]. Although thematerial properties of GC’s are very attractive in many engineering fields, the cost of manufacturingcomplex geometries can be prohibitive, primarily due to the high cost of tooling and limited machiningcapabilities of present manufacturing methods. Therefore, it is the goal of the proposed work to implementa novel method of manufacturing GC’s with predictable, tailorable, and optimized material properties.GC’s are classified as two-phase materials; one being the glass matrix, the other being small volumefractions of nanocrystal inclusions. Typically, GC’s are manufactured through casting or forming methodsbased on glass-making techniques. In these methods, the glass matrix is heated to high temperatures usinga two-step process. In the first step, known as nucleation, the GC is heated just past its devitrificationtemperature to create a high density of nuclei throughout the interior of the glass. The second step involvesre-heating the GC to a highly controllable temperature which directly impacts the growth rate, crystal size,and region of crystallization[2].Vat Photopolymerization (VP) is an Additive Manufacturing (AM) process which utilizes UV light toselectively cure a polymer-based resin in a layer-by-layer fashion. VP can offer unparalleled resolution,complex internal and external features, and high-solid loadings of GC’s to further enhance theirapplications. Digital Light Processing (DLP) is a sub-category of VP which uses a UV projector instead ofa laser to expose cross-sections of the design geometry onto a resin vat. Therefore, the curing characteristicsof the polymer resin are controlled by the light intensity and the effective pixel size from the projector.Additionally, by carefully tailoring the monomer, oligomer, and photo-initiator concentrations in the resin,high solid-loading of GC’s within the resin could be achieved[3]. The polymer matrix is finally burnt offthrough a debinding step before the sintering process, resulting in a highly pure and fully dense GC part.To further improve the mechanical, thermal, and optical properties of the GC’s, an Ion-Exchange (IX)process will be implemented after the sintering step. During this process, cations of small atomic size fromwithin the glass matrix surface are replaced by larger cations from the molten salt bath through a diffusionmechanism driven by temperature difference, resulting in a permanent compressive force in the surface ofthe part, which suppresses the growth of surface flaws and reduces crack propagation within the glass[4].Proposed Research Activities:Objective 1: Understanding primary and secondary parameter influence on material properties ofGlass-Ceramics. From my previous and ongoing research, it has been noted that the concentrations ofmonomer, cross-linker, and photo-initiator in respect to the solid-loading of the matrix material greatlyimpact the printability and final properties of the GC. Therefore, it would be highly beneficial to understandthe primary and secondary parameters during the printing, debinding, and sintering processes and theirimpact on the final material properties.Primary parameters from the printing step could include UV exposure times, light intensity, and layerthickness; secondary printing parameters could include layer waiting time, lifting speed, and vattemperature. Degree of Conversion (DoC) is a common measurement tool that utilizes Fourier-TransformInfrared (FTIR) characterization data to rapidly quantify the progress of the photopolymerization reaction.Primary and secondary printing parameters will therefore be directly quantified and compared through DoCby use of FTIR. For debinding, primary parameters could include ramping rates and holding temperatures;secondary parameters could include crucible materials and furnace atmosphere. Initially,Thermogravimetric analysis (TGA) will be performed on printed samples to determine ideal holdingThe University of Texas at El Paso 1Sebastian Vargas NSF GRFP Research Statementtemperatures in efforts to ensure complete removal of organic compounds. Additionally, Energy DispersiveSpectroscopy (EDS) will be used as an elemental analysis tool to compare anticipated composition of theGC’s to actual results. In terms of sintering, primary parameters could include final sintering temperaturesand furnace atmosphere; secondary parameters could include ramping rates and cooling rates. X-RayDiffraction (XRD) analysis will be performed on sintered samples to broadly determine the degree ofcrystallization by comparing results to literature and standards. Finally, by identifying the relationships(linear or non-linear) between parameters and material properties, a novel, reliable, and well-understoodmanufacturing method for GC’s based on the DLP process could be achieved.Objective 2: Inclusion of alkali modifiers for chemical strengthening through Ion Exchange (IX).Based on the recent work of Gy, R.[4] and Macrelli, et al.[5], lithium, potassium, and sodium ion modifierswill be added to the GC resin formulation in preparation for chemical strengthening through the IX process,which will be carried out directly after Objective 1. The depth of penetration of the cationic exchange layer,also known as case depth, is a direct metric of the effectiveness of the IX process and will be evaluated atvarious depths using a refractometer. As mentioned before, the strengthening process intrinsically developsa residual compressive stress at the surface of the GC. Therefore, the effect of cation modifier concentrationon the final mechanical properties will be assessed by compressive, flexural, and hardness testing based onASTM standards and will be performed with equipment available at the Keck Center and SMP lab.Extended Objective: Supporting the development of a machine-learning-based model to predictmaterial properties of glasses from compositional data. Based on the recent work by Ward. et al[6], aframework capable of extracting predictive models from existing materials data is being developed by theKansas City National Security Campus (KCNSC). My research will serve to provide the model withcharacterization and testing data obtained from Objectives 1 and 2 in order to effectively populate themodel. More detailed information may not be suitable for public release at this time.Intellectual Merit:The proposed work represents a novel method for manufacturing two of the most relevant materials tosociety: ceramics and glasses. My research would directly advance the limited understanding of the intricaterelationships between input parameters and material properties at different steps of the DLP manufacturingprocess. This critical understanding could potentially overcome a common barrier towards furtherdevelopment and implementation of DLP-based AM as a prevalent manufacturing method.Broader Impact:The development of DLP-based AM could enable previously unachievable part geometry of GC’s andtherefore, become a highly tailored process to impact many industries including aerospace, defense, andmedical. Additionally, this work could drive further research in STEM, including fields such as AdditiveManufacturing, Machine Learning, and materials science. Finally, the proposed work would directlysupport ongoing research efforts at the KCSNC, and thereby, the National Nuclear Security Administration.References:[1] Elan Industries. https://www.elantechnology.com/glass/glass-materials/las-glass-ceramics/[2] Rawlings, R. D., J. P. Wu, and A. R. Boccaccini. ""Glass-ceramics: their production from wastes—areview."" Journal of Materials Science 41.3 (2006): 733-761. [3] Kotz, F, et al. ""Three-dimensional printingof transparent fused silica glass."" Nature 544.7650 (2017): 337-339. [4] Gy, René. ""Ion exchange for glassstrengthening."" Materials Science and Engineering: B 149.2 (2008): 159-165. [5] Macrelli, Guglielmo,Arun K. Varshneya, and John C. Mauro. ""Ion Exchange in Silicate Glasses: Physics of Ion Concentration,Residual Stress, and Refractive Index Profiles."" arXiv preprint arXiv:2002.08016 (2020). [6] Ward, Logan,et al. ""A general-purpose machine learning framework for predicting properties of inorganicmaterials."" Nature: npj Computational Materials 2.1 (2016): 1-7.The University of Texas at El Paso 2"
37.0,"Center reported a total of 19,105 new cases of spinal cordinjuries with some amount of paralysis in 2019. Brainmachine interfaces (BMIs) are a burgeoning technologicalsolution to restore quality of life to these people throughconnecting brain signals to prosthetics. Current brainmachine technology collects and transmits neural signalsfrom implantable electrode arrays to be decoded usingalgorithms which are implemented on cumbersome andpower inefficient computers. These systems also requiredaily calibrations by scientists and clinicians to maintainFigure 1: Proposed Brain Machine Interfacetheir usability. Herein lies an approach to address theseArchitecture.problems through implementing specially designedalgorithms that are memory and computationally efficient onto a low power application specific integratedcircuit (ASIC) to decode patient intent using a fully implantable device. The goal is to engineer hardwareto implement intelligent decoding algorithms that will increase the reliability of neural decodingsystems and decrease the physical size and power requirements by orders of magnitude throughremoving the need for transmission of unprocessed neural data. I am working with professor AzitaEmami at the Caltech Mixed-mode Integrated Circuits and Systems (MICS) laboratory to begin my workas an ASIC and algorithmic designer implementing these systems.Previous Work: The promise of this project to produce reliable power efficient BMIs relies on thedevelopment of power efficient algorithms. The MICS lab has developed efficient algorithms that utilizedeep multistate dynamic recurrent neural networks [1], as well as done an assay on decoding algorithms[2]. Furthermore, if energy efficient algorithms do not provide the power performance required, in memoryprocessing architectures could be utilized to reduce power lost from transporting weights between memorybanks and processing units [3].Intellectual Merit: Current BMI technology largely utilizes hardware implementations which transmitdigitized neural signals back to a compute station. There are few BMI ASICs that decode patient intentdirectly without off-the-shelf hardware implementations. Custom machine learning ASICs provide anopportunity to optimize for power and area efficient systems. BMI systems have unique signal processingconstraints due to relevant information being mixed across time, frequency, and space in highlydimensional, redundant datasets. These constraints often require complex computational algorithms withhigh internal state complexity, that generally decreases power efficiency [2]. This poses a particularlydifficult engineering dilemma which requires a uniquely multidisciplinary approach to leverageknowledge of neuroscience with engineering expertise in ASIC design. This dilemma is to fit therequired computationally complex task of decoding patient intent from neural signals into a power and areaefficient package.Hypothesis: BMI ASICs implementing computationally, and memory efficient algorithms will be able toefficaciously ascertain patient intent while maintaining robust performance whilst still meeting power andarea constraints requisite of fully implantable systems.Research Plan: Several crucial prerequisite steps for this proposal are already underway in Azita Emami’slab including the evaluation of neural features measured from patient data for stability over time.Aforementioned specialized algorithms have been developed and evaluated for performance. While theseprerequisite steps are crucial to the outcome of this project, the scope of this proposal is constrained to theimplementation of these algorithms in hardware, optimizing for low power. Therefore, this proposal willonly discuss the development, implementation, and testing of the algorithms into CMOS fabric. Stage I-Algorithm CAD Design and Testing: Digital and analog hardware will be described and laid out intoVirtuoso Computer Assisted Design (CAD) program. The circuits will be fabricated with general poweroptimization techniques in mind such as clock and power gating portions of the circuit when they are notin use. Other techniques include using intentional specificity of transistor thresholds throughout the designso that leakage current is minimized, as well as a minimization of supply voltage levels. Furthermore,specific tradeoffs will be made between the bit precision of the algorithms and the resources required to runat those precisions. Significant energy is also lost by moving the algorithm’s weights from memory to theprocessing hardware, so a layout will be designed such that the algorithm weights are physically closer towhere computations are done. While designing the circuits, each component will be characterized at a unitlevel so that the performance of the entire circuit can be ensured. Stage II-CAD Simulation and FPGATesting: After designing the circuit in Virtuoso, the entirety of the circuit will be tested with patient neuraldata collected over several weeks. The circuit simulation will give significant insight into the performanceof the decoder system once fabricated. The simulation will also allow for design bugs to be caught andcorrected before resources are spent fabrication of the design into silicon. The digital components of thecircuit will also be implemented on a commercially available Field Programable Gate Array (FPGA) whichwill not only give physical proof that the logic and algorithms designed will work, but will give an upperbound on the power and area usage for the ASIC implementation. Stage III-Hardware Fabrication: Severaltest chips will be fabricated to investigate the performance of the decoding algorithms. This allows forverification and debugging of the major components of the algorithm, with the final system chip producedafter all components are aptly constructed and verified. The circuits will be implemented into standard celllibraries for 65 nm CMOS technology using Design Vision. Stage IIII-Hardware Testing: The fabricatedchip will be designed for testability using techniques such as built in scan chains to give access to theinternal states of the circuit. Custom test systems will be built to feed neural signals to the device under testand validate the performance of the hardware. Stage IV-Going Forward: Once designed, fabricated, andverified, the integrated circuits could be tested in vivo using the same experimental therapy program fromwhich the neural data was harvested.Pitfalls and Alternatives: Due to variation in fabrication processes, the fabricated chips may exhibitcharacteristics and behavior that were not accounted for during simulation. If experienced, the test hardwaredesigned into the chip will be utilized to identify and debug the flaw.Timeline and Collaboration: The duration of the proposed project is three years and will be conductedunder the supervision of Azita Emami. Azita Emami’s MICS lab works in direct collaboration with RichardAnderson’s neuroscience lab. This is a collaboration between two leading scientists in their respectivefields. The MICS and Anderson lab collaboration has significant skill and expertise to confidently producethe anticipated results of this proposal. Emami’s lab has adequate facilities and resources to fund thesignificant capital required to design and develop custom ASIC hardware. This project also has direct accessto neural recordings of patients with implanted UTAH neural arrays which provides essential data fortraining the decoder algorithms.Anticipated Results: Using specially designed decoding algorithms, significant reductions in power andarea will be observed in the resultant neuro decoding system. It is important to note this project aims tomaintain decoding accuracy and stability, despite using orders of magnitude less power and area.Broader Impacts: Fully implantable neural intent decoders will not only greatly improve the quality of lifeof patients with paralysis, but also provide the basis for fully implantable ASIC chips designed for directstudy of neural activity without the need to be linked to heavy, memory and power inefficient recordingsystems. The miniaturization of hardware and computational effort can further be generalized to many IOTor wearable systems which requires robust signal processing algorithms with limited power and arearequirements. This will enable a variety of wearable devices to decode bio signals without the need toupload the signal data to an off-chip server, greatly improving security, power, and speed performance.References: (1) B. Haghi, S. Kellis, M. Ashok, S. Shah, L. Bashford, D. Kramer, B. Lee, C. Liu, R.Andersen, A. Emami, “ Deep multi-state dynamic recurrent neural networks for robust brain-machine interfaces”, Program No. 406.04. 2019 Neuroscience Meeting Planner. Chicago, IL: Society forNeuroscience, 2019. Online. (2) Mahsa Shoaran, Benyamin A. Haghi, Milad Taghavi, Masoud Farivar,Azita Emami, “Energy-Efficient Classification for Resource-Constrained BiomedicalApplications” IEEE Journal on Emerging and Selected Topics in Circuits and Systems (JETCAS), 2018.(3) T.-J. Yang, V. Sze, “Design Considerations for Efficient Deep Neural Networks on Processing-in-Memory Accelerators,” IEEE International Electron Devices Meeting (IEDM), Invited Paper, December2019."
38.0,"extraordinarily challenging by the extreme starlight suppression required toimage faint planets around brilliant stars. The noise-limited performance ofcurrent high-contrast imaging instruments can resolve planets up to 10million times dimmer than their host star. In order to access Earth-likeplanets – the highest-priority planetary targets named by the Astronomy andAstrophysics Decadal Survey [1] – sensitivity must be expanded to planets10 billion times fainter than their star. The primary limitation on increasingcontrast is speckle noise, which is scattering of the stellar point spreadFig. 1: Raw image of thefunction (PSF) that can mimic or obscure planet signals [2]. As observationplanetary system HR8799.time increases, the total noise contributions of read noise and photon noiseFour Jupiter-size planetsattenuate, but speckle noise does not, establishing a high noise floor thatare obscured by quasi-cannot be reduced without removing the speckles themselves. I propose tostatic speckles. Image: Dr.develop a computational method of speckle subtraction for data takenC. Maroiswith the Gemini Planet Imager (GPI), which will improve the precisionof existing data and will enable future higher-contrast observations of exoplanets. In addition toimproving the sensitivity of legacy data, the proposed work will provide timely support for the fundedGPI upgrade beginning in 2020 and returning to science operations with commissioning of GPI 2.0 in2023.Study Design: Speckle noise is created as starlight passes through non-uniform atmosphere and optics,producing a stellar PSF that varies with time. Atmospheric speckles can only be corrected by improvedadaptive optics hardware. This leaves “quasi-static” speckles caused by non-common path aberrationswithin the instrument optics. Quasi-static speckles change slowly over timescales of minutes to hours [3],resulting in an effect that varies both chromatically and temporally.This project aims to model, and subsequently remove, these quasi-static speckles using thenon-parametric technique of principal component analysis (PCA). PCA identifies “principalcomponents” as linear combinations of input parameters, producing a dimensionally reduced result whichidentifies the strongest predictors of the features of that data. These results can be used to subtract thequasi-static speckles directly. Previous applications of PCA to high-contrast imaging (e.g. [4, 5]) havefocused on subtracting the entire stellar PSF, both atmospheric and quasi-static speckles, which is usefulfor recovering target signal but results in improvement for only the dataset it’s applied to. The techniqueof applying PCA to isolated quasi-static speckle noise has never been successfully applied toexoplanet high-contrast imaging, but will result in a more flexible, broad correction for this type ofnoise. By characterizing quasi-static speckle behavior and evolution over given epochs and wavelengths,corresponding corrections can be applied not only to the training data, but any data of matchinginstrument, epoch, and wavelength. This method may also reveal stable speckle behavior which is presentat all times and wavelengths, and can be universally subtracted. Once applied, the precision of legacy datais expected to improve by one order of magnitude, and this speckle subtraction will allow future GPIobservations to achieve greater contrast by approximately two orders of magnitude [6], making importantsteps towards accessing Earth-like planets. The phases of this project are outlined below.Phase I: First, I will build a training dataset of GPI science images containing isolated speckle noise,which can be achieved by subtracting a noiseless model of the stellar PSF from all training data. This willleave only unexplained noise behind, the primary component of which is quasi-static speckle noise.Phase II: Grouping the training dataset over discrete time increments and wavelength intervals, I willapply PCA to the training data. The results of this analysis can be used to subtract an estimate of thestable components of quasi-static speckle noise from the data. Phases I and II will take place during years1 and 2 of graduate school, which is well-timed to inform the concurrent GPI upgrade.Phase III: Then, I will quantify the effectiveness of this correction procedure by measuring theimprovement of the intrinsic noise present in each subtracted image, as well as by performing injection-recovery tests with simulated planet signals.Phase IV: Finally, once these results have been verified, I will develop and release an open-sourcecodebase for quasi-static speckle subtraction, intended for use by scientists working with GPI data. PhasesIII and IV will take place during years 3 and 4 of graduate school, which will align with thecommissioning of GPI2.0 allow for my results to be folded into its data reduction pipeline.One anticipated challenge associated with Phases I and II is that speckle noise is difficult toisolate in legacy GPI data, either because accurate reference PSFs cannot be generated, or because thedata contains systematics which may confuse the subsequent analysis. In this case, since GPI will bepresent at Notre Dame for upgrades, I will be able to collect data directly from the instrument using thetelescope simulator operated by the Chilcote group. By allowing more control over observing conditionsand precise knowledge of the input PSF, data taken using the telescope simulator will enable a cleanerfirst-step analysis, allowing more robust treatment of the legacy data when it is later re-introduced.Another anticipated problem is that GPI2.0 goes on-sky before Phase IV concludes. However,modifications to the processing pipeline can still be made after science operations commence since post-processing can be retroactively applied. Additionally, even if completion of Phase IV lags, the robustnessand impact of this technique will be well understood from Phase III, and observations can be planned inanticipation of the correction tools of Phase IV being completed in the future.Intellectual Merit: The importance of increased contrast for high-contrast imaging campaigns is crucialeven beyond exoplanets, with implications for the direct imaging of all astrophysical objects at smallangular separations from a comparatively bright source — including circumstellar disks, stellar winds, orjets emitted from neutron stars, pulsars, or black holes. This project is a high-impact, far-reaching, andlow-cost avenue to increasing the science yield of existing direct imaging instruments, increasing thesensitivity of extant and future data without the need for the expensive and prolonged development ofnew instrumentation. Additionally, while the proposed solution will be built specifically for GPI, it can beadapted to interface with other ground-based high-contrast imaging instruments, including SPHERE onVLT and CHARIS on the Subaru Telescope. A software-based speckle subtraction method also hasstrong implications for the development of space-based direct imaging missions, such as the Nancy GraceRoman Space Telescope (formerly WFIRST), as speckle noise is similarly dominant in space-based directimaging [7]. The open-source release of my work will facilitate broad advancement andcollaboration across astrophysics subdisciplines and different instrument teams.Years of previous research experience, including publishing papers, presenting at conferences,giving talks, and directing analysis, have prepared me to effectively execute the proposed work. I haveyears of experience with data analysis and visualization with Python, and as part of my work with CERNand GPI have worked with large datasets and distributed computing. I currently work on GPI withProfessor Jeffrey Chilcote at the University of Notre Dame, so I am familiar with the instrument and amprepared to hit the ground running. I will also benefit from the technical expertise and support of theinternational GPI collaboration as I develop this project. Given the large volume of legacy data which willbe analyzed during this project, as well as the computationally demanding nature of PCA, I will requireaccess to high-performance computing facilities such as the Notre Dame Center for Research Computing.Broader impact: The NSF GRFP will support me to pursue high-impact research alongsidecommunity engagement. Alongside this speckle suppression project, I will establish a peer mentorshipprogram at my graduate institution, as well as develop curricula and workshops to engage publicelementary students in space science, both of which I detail in my personal statement. I will integratethese engagement efforts with the GPI Outreach team to create science communication materialsconveying the excitement of squinting through stellar glare to find new worlds orbiting underneath.[1] National Research Council 2010, New Worlds, New Horizons in Astronomy and Astrophysics[2] Marois, C., Doyon, R., Nadeau, D. et al. 2003, EAS Publications Series, 8, 233-243[3] Hinkley, S., Oppenheimer, B., Soummer, R. et al. 2007, ApJ, 654, 1, 633-640[4] Wang, J., Ruffio, J.-B., De Rosa, R., et al. 2015, Astrophysics Source Code Library, ascl:1506.001[5] Soummer, R., Pueyo, L., Larkin, J. 2012, ApJL, 755, 2[6] Soummer, R., Ferrari, A., Aime, C. et al 2007, ApJ, 669, 1, 642-656[7] Brown R., Burrows C. 1990, Icarus, 87, 2, 484-497"
39.0,"Motivation: Since the mid-1970s, global natural gas production has steadily risen to its current all-timehigh, and is projected to continue until at least 2040.1 Although natural gas is a cleaner burning fuel thangasoline, its implementation in the transportation sector has been stymied by its significantly lowervolumetric energy density.2 Densification strategies, including liquefaction or high-pressure storage, haveinherent safety and cost issues that are widely viewed as prohibitive for passenger vehicles.3Introduction: Adsorbed natural gas systems that employ porous materials, such as metal-organicframeworks (MOFs) and covalent organic frameworks (COFs), have received considerable attention aspotential alternatives to higher pressure and/or cryogenic storage methods.4,5 In these systems, favorableinteractions between the gas and the porous solid increase the amount of gas that can be stored at a giventemperature and pressure as compared to an empty tank.4 However, the non-molecular nature of theseextended structures makes solubility non-existent, reducing compatibility with post-syntheticfunctionalization and modification that can be leveraged to increase gas adsorption capacity and bulkmaterial properties, such as density and thermal conductivity.Hybrid metal-organic or all-organic molecular analogs of these porous materials, coined porouscoordination cages (PCCs) and porous organic cages (POCs), respectively, directly address this issue whileretaining the highly sought after permanent porosity and tunability of their expanded, 3-D counterparts.6,7PCCs often contain open metal sites that provide favorable interactions for increased gas storage ascompared to all-organic structures.6 However, these molecules tend to display surface areas that pale incomparison to MOFs and POCs. On the other hand, POCs display surfaceareas that are on par with many MOFs, but lack the tunable metal cation-gas molecule interactions seen in hybrid metal-organic systems.8 Toaddress these issues, I propose the design, synthesis, and application ofnovel porous organic cages with integrated metal sites toward the selectiveadsorption and/or storage of small molecules.Preliminary Results: Although porous organic cages have been heavilyinvestigated over the past decade, the study of the high-pressure storage ofgases in these materials is still well in its infancy.7 As a result, relativelylittle is known about their utility as gas storage materials. Similarly, post-synthetic metalation of these systems to introduce sites with catalyticFigure 1: Known POCactivity or selective gas adsorption has been unexplored. The standardtargeted for preliminary workmetric for porous materials, gravimetric surface area, is a simplisticrepresentation of a material’s ability to store a gas. While the high surface areas that POCs have displayedprovide a basis for using such materials as gas storage media, investigations into these materials for thespecific task of gas storage is surprisingly limited. Incorporation of metal chelating sites within molecularcages will allow for the precise insertion of a specific metal post-synthetically. Metal cations can play animportant role in tuning metal-gas interactions, which is necessary for creating a material for selective gasadsorption or high-pressure storage. I targeted a known POC based on triformylphenol and 1,2-diaminocyclohexane, where a half-salen unit is formed when the cage is constructed (Figure 1).9 Confirmedvia SEM-EDX and XPS, initial results show coordination of a Ni2+ center into the cage’s structure, whileretaining permanent porosity (Figure 2). Further gas adsorption studies to better understand the selectivityof the metal-integrated POC are currently underway.Aim 1: Create a library of ligands and cage topologies that are conducive to metal integration. Inspirationfor this approach can be drawn from recent literature on the reported topologies of cages, where the moststraightforward methods involve imine or boronic ester formation to create the covalently linked cage.Although specific angles must be considered within the ligands in order to access these desired topologies,functional groups and sizes of the ligands are typically tunable. Understanding this, cages will befunctionalized and built around traditional multi-dentate ligands, such assalen, catechol, and 2,2’-bipyridine to form metal complexes after cageisolation.Aim 2: Isolate porous organic cages and introduce metals to theirchelating sites. Typically, solution-based syntheses produce cages. Thepurity of isolated cages can be confirmed through several techniques dueto their molecular nature, most readily being high-resolution massspectrometry, NMR, and IR spectroscopy. For more complex cages, suchas cages containing chiral centers, additional efforts will be put forth toobtain diffraction quality single crystals, utilizing techniques such asvapor diffusion and liquid/liquid diffusion, to further confirm cage Figure 2: Model representingformation. After successful isolation, the porous organic cages will then the integration of Ni2+be introduced to metal salts to obtain their metalated counterparts via solvothermal methods and solid-statemetalations. A plethora of techniques are available at the University of Delaware for the characterizationof the metalated POCs, including SEM-EDX, XPS, EPR, and the previously mentioned techniques.Aim 3: Perform gas adsorption studies and identify the roles that both cages and metal-sites play inselective gas uptake and storage. Gas adsorption studies will be performed on both the base cage and themetalated cage to decipher the interplay of porosity and selective gas uptake. Surface area analyses will beperformed in the Bloch Lab, using both CO and N as probe molecules, along with systematic high-2 2pressure gas storage studies (hydrocarbons, H , etc.) and enthalpy of adsorption calculations.2Intellectual Merit: While small molecule storage has been heavily studied in extended frameworks likeMOFs and COFs, much less is known for porous molecular materials. These materials retain the soughtafter permanent porosity of expanded frameworks, as well as impart solubility that can lead to advantageouspost-synthetic modification. This project will elucidate how POCs can be utilized as gas storage media anddevelop the novel field of metalated POCs, including their design, synthesis, and utilization as adsorbednatural gas materials.Broader Impacts: My proposed project has opportunities for collaborations that I will pursue heavily tobetter understand these systems. Collaboration with computational groups will help predict gas storagecapacities and suggest more favorable interactions based on metals and ligands, and work with catalysis-focused groups can utilize my metalated cages as a homogenous setting for catalytic reactions. Just asimportantly, I will continue to mentor undergraduate researchers and first year graduate students to teachthem essential and advanced laboratory skills. I will share my findings at local, national, and internationalmeetings when they are deemed safe, and until then, I will present my work virtually and continue to publishresults.References1. EIA, ""World Energy Outlook 2019"", 2019, https://www.iea.org/reports/world-energy-outlook-2019/gas2. EIA, “How much carbon dioxide is produced when different fuels are burned?”, 2019,https://www.eia.gov/tools/faqs/faq.php?id=73&t=113. DOE, “Natural Gas Fuel Safety”, https://afdc.energy.gov/vehicles/natural_gas_safety.html4. Mason, J. A.; Veenstra, M.; Long, J. R. Chem. Sci. 2014, 5, 32-51.5. Das, S.; Heasman, P.; Ben, T.; Qiu, S. Chem. Rev. 2017, 117, 1515–1563.6. Gosselin, A. J.; Rowland, C. A.; Bloch, E. D. Chem. Rev. 2020, 120, 8987–9014.7. Hasell, T.; Cooper, A. I. Nat. Rev. Mater. 2016, 1, 16053.8. Zhang, G.; Presly, O.; White, F.; Oppel, I. M.; Mastalerz, M. Angew. Chem. Int. Ed. 2014, 53, 1516-1520.9. Petryk, M.; Szymkowiak, J.; Gierczyk, B.; Spólnik, G.; Popenda, Ł. Janiak, A.; Kwit, M. Org.Biomol. Chem. 2016, 14, 7495-7499."
40.0,"Introduction: Over the past 130 million years, flowering plants have evolved a variety of visual andchemical cues that mediate species’ interactions. The diversity of color phenotypes in flowers has been thesubject of many ecological studies and the biosynthesis and regulation of the main compounds responsiblefor pigmentation is well understood1,2. These compounds are well-known for their role in pollinatorattraction and additionally have many important biological functions that have been described (e.g.,allelopathy, lignification, protection from UV radiation)3. However, despite the significance ofpigmentation in plant growth, development, and reproduction, the role of pollen color remains unclear.About 75% of flowering plant species have yellow or white colored pollen, though pollen may alsobe pigmented red, blue, purple, or black4,5. The composition of specialized metabolites that occur in pollenacross several taxa (e.g., phenolic compounds, alkaloids, terpenoids) have also been described6. Several ofthese compounds are known to be important for pollen development, pollen germination, pollen tubegrowth, and protection from abiotic stress (i.e., temperature, UV)7.ARecent work from Dr. Shu-Mei Chang’s lab at theUniversity of Georgia, Athens (UGA), has discovered pollen colorpolymorphism in wild geranium, Geranium maculatum. Fieldobservations along the Appalachian Mountain region show thatB C Dpurple and yellow pollen color morphs persist in different ratiosalong an elevational cline8. Though pollen color polymorphismConfocal LC-MS/MShas been observed in other plant species, the ecological functionFigure 1. Experimental Design. (A) Purple &and adaptive value of this trait is still unknown9-12. Therefore, Iyellow pollen color morphs. (B) iNaturalistpropose to examine the geographic distribution patterns of pollen distribution data by community scientists. (C)Confocal microscopy & LC-MS/MScolor morphs, characterize their phenotypes, and evaluate thecharacterization of pollen phenotypes. (D)functional role of this trait in an ecological context (Fig. 1). Reproductive trait evaluation under abiotic stress.Aim 1: Determine the distribution of pollen color by integrating field surveys and community scienceIn native G. maculatum populations, dark pollen color morphs have been observed at higherelevations8; a trend that has not been observed in other plant species9-12. iNaturalist is an online platformand smartphone application that allows anyone to record observations in nature. To date, there are over13,000 records of G. maculatum and over 1,600 individuals that have made observations across the US. Todetermine if there is a correlation between elevation and pollen color, I will use this data to analyze theoccurrence of purple and yellow pollen color morphs in a logistic generalized linear model with latitudeand elevation predictors, as described by Austen et al12. I expect to see a positive correlation betweenelevation and pollen color intensity along an elevation gradient based on previous field observations.Furthermore, I will geo-reference 20 populations of G. maculatum along an elevation gradient toserve as collection sites for my study. To supplement my own collection material, I will advertise this studyon the Ecological Society of America listserv and on social media pages of native plant societies to recruitcommunity scientists. I will then create collection kits with an overview of the project and a guide topropagule collection to mail to each individual, who will harvest from their respective site and mail theircompleted kits to UGA. Clear instructions will be provided to each collector on how to image the populationand gather one representative specimen to allow confirmation.Aim 2: Characterize reproductive traits and pollen phenotypes of G. maculatum populationsPollen features that vary among pollen color morphs can have a significant impact on male fitnessof a plant13. Thus, I will examine the morphological and biochemical characteristics associated with pollencolor. I will propagate G. maculatum from rhizomes from Aim 1 in the greenhouse at UGA and generatean F2 population that segregates in pollen color. Upon flowering, reproductive traits (e.g., flower number,flower size, flower color, pollen color, seed set) for each plant will be described. I will collect and imagepollen by confocal microscopy at the UGA Biomedical Microscopy Core (BMC) for characterization ofpollen features (e.g., size, surface ornamentation). Then, I will utilize the Proteomics and MassSpectrometry facility at UGA to quantify specialized metabolite accumulation in anther tissue and pollenby liquid chromatography tandem mass spectrometry (LC-MS/MS). Specialized metabolites havepreviously been characterized for G. maculatum pollen and it was found that the metabolite profile differedsignificantly among four collection sites6. I will further characterize the correlation between pollen colorintensity and metabolite profile to identify compounds that are important for pollen performance in Aim 3.Aim 3: Evaluate trait-correlated tolerance to abiotic stressTo evaluate the pollen performance of the F2 individuals, I will measure pollen viability,germination, and siring success under different conditions. I will expose different colored pollen to agradient of temperature and light intensity treatments (mimicking field conditions), and assay for pollenviability and germination in vitro, where pollen germination rates and pollen tube length will be recorded.Additionally, I will observe the siring success of each pollen color morph in vivo.I will then conduct common garden experiments to evaluate fitness in field conditions. ReplicateF2 populations that contain identical genotypes (by splitting rhizomes) will be planted in common gardenplots at the Highlands Biological Station in North Carolina (high elevation) and the UGA State BotanicalGarden (low elevation). Floral/reproductive traits (as described in Aim 2) and transplant survival will berecorded for each population over the span of 2 years. I hypothesize that dark pollen individuals will havegreater reproductive success in high elevation due to specialized metabolites that confer abiotic stresstolerance. I expect that light pollen individuals will have decreased transplant survival but compensate tosome extent by producing more flowers with higher seed set; a maternal reproductive strategy described byKoski et al. in Campanula americana13. I will also collect the same subset of individuals from each gardenfor metabolite analysis (as described in Aim 2) to determine whether there is a genetic-by-environment(GxE) effect on their profiles.Intellectual Merit: My previous research experience in floral development, pollen biology, biochemistry,and molecular biology makes me uniquely positioned to lead this interdisciplinary and community-sciencesupported endeavor. Under the guidance of Dr. Chang, an expert in plant ecology and plant mating systems,I will expand our limited understanding of the role of pollen color polymorphism as a strategy forreproductive success. Additionally, previous graduate students in the Chang group have led community-science research endeavors using iNaturalist, making this an ideal environment to build upon thisinfrastructure. In taking advantage of the biological research stations available to graduate students at UGA,this study will be the first of its kind to evaluate pollen color morph-dependent fitness in an ecologicalcontext. Moreover, coupling biochemistry and ecology approaches, I will generate a comprehensiveunderstanding of the role that specialized metabolites play in pollen germination and reproductive success– information that has implications in both agricultural production and native plant conservation.Broader impacts: I foresee my graduate research as a vehicle for mobilizing community scientists,providing educational opportunities to underserved communities, and improving diversity in academia. Iwill work closely with K-12 instructors to develop plant biology lessons with field work and familyengagement components to create community awareness of these relevant topics. Students and theirfamilies will be given demos on how to use the iNaturalist platform to encourage outdoor activity andparticipation in community science. In collaboration with Max Barnhart, a graduate student in the IntegratedPlant Sciences program who is the lead PI on an American Society of Plant Biology (ASPB) sciencecommunication grant, I will create and distribute a zine to provide an overview of my work to the generalpublic and the community scientists involved. I will also share my experience with the scientific communityby developing a workshop entitled “Incorporating Community Science Into Your Research Program” forthe annual ASPB conference. During this workshop, I will discuss the various platforms available forbuilding community science projects, demonstrate how to navigate and utilize these platforms, and lead anexercise on brainstorming ways to engage community scientists in your research.References: 1Rausher MD. Int. J. Plant Sci. 2008. 2Grotewold E. Annu. Rev. Plant Biol. 2006. 3Jiang et al.Plants. 2016. 4Lunau K. Plant Syst. Evol. 1995. 5 Miller et al. Optics & Laser Tech. 2011. 6Palmer-Younget al. Ecol. Monogr. 2018. 7Muhlemann et al. PNAS. 2018. 8Udell-Perez R. Field Obs. 9Jorgensen &Andersson. New Phytol. 2005. 10 Koski & Galloway. New Phytol. 2018. 11Wang et al. Evolution. 2018.12Austen et al. Ecology. 2019. 13Koski et al. J Evol. Biol. 2020."
41.0,"Novice programmers who are writing code encounter frequent challenges, which they often attempt toaddress by searching online to learn new concepts or debug their code [3]. However, novice programmersrarely receive explicit instruction on how to effectively resolve programming challenges with onlinesearch. Seeking help through online search is a critical self-regulatory skill for students, both in class andafter graduation, but professional programmers agree that it can be difficult to learn [8]. Some prior workhas investigated the challenges that professional developers face when searching and how to supportthem. However, there is little research about how programmers learn to use online search, how to teachsearch effectively, or how adaptive tools can support this process. Further, prior work has been limited tocollecting user search queries and developer surveys, without using the programmer's code and errors tounderstand their context and the reason for their search.My research goal is to 1) understand the strategies that undergraduate novice programmersuse to search for help online when writing and debugging code, and 2) explore how to design adaptivelearning environments that support students in learning effective online search strategies.Building on Prior Work: Collecting data from novices’ programming environments has become popularin Computer Science (CS) Education due to their ability to provide granular views into the programmingprocess via incremental code snapshots. These code snapshots have been leveraged to extract featuressuch as compiler error encounter rate and error resolution time, which are used to understand novicedebugging behaviors. In addition, code snapshots can be used in the design of interventions thatdynamically provide feedback during the programming process based on current and past code contexts.It has been shown that intelligent tutoring systems (such as augmented programming environments) thatprovide timely automatic feedback can positively affect learning [5]. Work has been done on augmentinglearning environments with tools such as web browsers that filter search results to be moreunderstandable by novices [2,7]. However, many of these tools focus on improving search results: notools have been developed with a focus on improving code search behavior and impartinggeneralizable long-term search skills.RQ1: What barriers do students face and what strategies do they employ when using web-based searchsystems to write and debug code? In Year 1, I will conduct exploratory lab and classroom studies toidentify common barriers that novices encounter and strategies that they use for online search duringprogramming problems. My goal is to discover what unique problems novices encounter when usingonline search, inform pedagogy on how online search should be taught, and learn what features toconsider when designing a tool to support better search behavior. In small scale lab studies during thefirst semester, novice programming students will be asked to solve programming problems appropriate totheir skill level while having access to online search. I will collect think-aloud protocols as students work,pre- and post-surveys, logs of students' search behavior, and fine-grained code snapshot logs. Classroomstudies of NCSU’s introductory computing (CS1) course during the second semester utilize augmentedprogramming environments and provide a large volume of search and code snapshot data, which willallow us to test if the findings from the lab studies are generalizable to the classroom. Using this data, wecan evaluate how search behavior from beginner programmers may differ from or align with prior workon professional developer behavior, such as in query style, query reformulation rate, and search sessionlength. Building on prior work on using code snapshots to track compiler error resolution [1], we willexplore how to track students’ success in using online search to resolve errors. This will allow us toidentify which students are struggling, where they are struggling, and what search strategies are effective.RQ2: How can we give students accurate and timely feedback on how to improve the effectiveness oftheir search queries? In Year 2, I will perform design-based research of a learning environment thatwill provide automated support to students to improve their search skills. While the ultimate designof the system will be shaped by student and teacher needs identified in Year 1, the system will supportdeveloping students’ skills in the key phases of the search process. The key phases of search are derivedfrom theories of help-seeking (e.g. [4]): recognizing the need for help, gathering relevant information,formulating an effective query, identifying an effective source of help, and integrating the help into code.For example, consider a student who is stuck on an error and whose previous search attempts were notsuccessful. The system could then suggest an effective help-seeking strategy that was identified in RQ1,such as query reformulation. The system will offer adaptive help, responding to a student’s current codeand error message. I will achieve this by building on foundational work by the HINTS lab at NCSU onusing program code to create adaptive feedback systems [6]. My current membership in the HINTSlab puts me in a unique position to design this system.RQ3: What effect does timely automated feedback on search queries have on novice programmingbehaviors and their ability to use web-based search to resolve future problems? After multiple rounds ofdevelopment in Year 2, in Year 3, I will deploy the system and perform classroom studies to measurethe impact this tool has on novices’ search and programming behavior. These classroom studies willinitially take place over the course of a semester in NCSU’s CS1 course. The effectiveness of theintervention will be measured by the change in student programming performance and retention of help-seeking behaviors over time (as evidenced by features of successful help-seeking identified in RQ1, suchas query styles and error resolution rate). In addition to quantitative metrics, qualitative feedback bystudents at the end of the semester will also inform the system’s overall impact.Intellectual Merit: This project will provide novel insight on the strategies that undergraduate noviceprogrammers use to search for help online. By extending prior work on programmer search behaviorsthrough the novel methods of observing program and error state, we can gain granular information aboutthe contexts in which novice programmers seek help. In exploring effective search strategies (RQ1), wecan inform the design of better pedagogy for teaching online search. The feedback methods designed inRQ2 and evaluated in RQ3 will inform future designs of intelligent tutors for help-seeking. This projectwill provide a base for future work on understanding programming help-seeking behavior, and themethods discovered could be extended to learner populations beyond novices.Broader Impact: In many CS programs, searching for code help online is a skill that is not explicitlytaught, yet is expected of students in upper-division courses and after graduation. Explicit pedagogyaround web search will normalize help-seeking behavior and reduce impostor syndrome. Automatedfeedback systems allow for the refinement of these skills even if an instructor is unavailable. This projectwill inform future online search pedagogy and the design of learning environments that reinforce theseskills. By addressing these two issues, this project will help make CS more accessible.[1] Jadud. “Methods and Tools for Exploring Novice Compilation Behaviour” ICER‘06 [2] Lu et al. “ ”Information Retrieval Journal ‘17 [3] Muller, et al. Exploring Novice Programmers' HomeworkPractices: Initial Observations of Information Seeking Behaviors SIGCSE ‘20 [4] Nelson-LeGall. “Help-Seeking: An Understudied Problem-Solving Skill in Children” Developmental Review ‘81 [5] Nesbit, etal. “Intelligent Tutoring Systems and Learning Outcomes: A Meta-Analysis” Journal of EducationalPsychology ‘14 [6] Price, et al. “iSnap: Towards Intelligent Tutoring in Novice ProgrammingEnvironments” SIGCSE ’17 [7] Venigalla et al. “StackDoc - A Stack Overflow Plug-in for NoviceProgrammers that Integrates Q&A with API Examples” ICALT’19 [8] Xia, et al “What do developerssearch for on the web?” Empir Software Eng ‘17"
42.0,"Introduction: Traditional stair construction, in which stair flights are rigidly connected to thestructure at both ends (“fixed-fixed” connections), has been shown to cause damage to stairs andsurrounding structural members during earthquakes due to stairs being stretched and compressed dueto the relative displacement between a building’s floors1. (See Figure 1.) In response to this, alternativedesigns (“fixed-free” connections) have been developed2 that permit stairs to accommodate the relativedeformation between stories by detaching the stair at one of the floors. Recent tests2 have confirmedthat fixed-free connections have the potential to eliminate damage due to seismic forces beingdistributed to stairs, but further testing is needed to understand these novel designs. Scissor stairs, acommon configuration in which the stair turns back on itself at a mid-story landing, have not yet beentested in conjunction with fixed-free connections.Stairs have been shown to affect a structure’s seismicresponse3, so it is essential to investigate scissor stairs withfixed-free connections not only in isolation but also interactingdynamically with a building. One concern is that releasingdegrees of freedom for fixed-free connections may cause awhiplash effect due to the stair’s mass being less constrained,damaging nearby building components. Additionally, thiswhiplash effect may cause undesirable torsion in the building.Therefore, a key challenge in designing fixed-free stairs is toremove enough restraints to permit some movement whilepreventing completely free oscillation.I propose to observe and quantify the dynamiccharacteristics fixed-free scissor stairs and their effect on thelateral response of buildings. Three variations of fixed-freeconnections will be considered: 1) removing all connectionsfrom the lower end of the stairs so that it may slide freely on itslanding, 2) use slotted connections to allow some movementwhile restraining most movement, and 3) using a sliding hangerconnection to allow translation in all three dimensions withoutleaving the stair completely unattached.Hypothesis: Fixed-free stairs will prevent damage that traditionally constructed stairs would otherwisesuffer by allowing relative movement between stairs and floors and dissipating energy through friction.Research Goal 1: Develop Models for Stairs with Fixed and Free ConnectionsI will model four scissor stair configurations: three with fixed-free connections and a control casewith traditional, rigid connections. Because building prototypes and performing dynamic testing istypically cost-prohibitive, I will develop finite element models of the stairs and their connections usingthe finite element program LS-DYNA. An essential feature of LS-DYNA is its ability to model frictionand the interaction between components that come into contact with one another4. The models will besubjected to cyclic and dynamic loading protocols to identify the force-deformation behavior of thestair system under earthquake loading.Research Goal 2: Model Scissor Stairs in StructuresUsing the methodology described by Wang et al. (2015)5, I will represent fixed-free stairs instructures by developing a system of nonlinear springs using the force-deformation relationships foundin Goal 1, which will be then integrated into full-building structural models to observe the effect offixed-free stairs on the seismic response of buildings. For this task, I will use the structural finiteelement framework OpenSeesPy, which is more appropriate for modelling an entire building. In orderto evaluate the effects of fixed-free stair connections, I will subject the models to dynamic loadingusing a variety of ground motions, then compare member forces and nodal displacements betweenmodels without stairs, with traditional stair connections, and with fixed-free stair connections.Research Goal 3: Improve Full-Building Models by Comparing to Shake Table TestWorking under Professor Keri Ryan at the University of Nevada, Reno, I will participate in theshake table testing of a full-size, 10-story timber building at the NSF’s National Hazards EngineeringResearch Infrastructure (NHERI) facility at UC San Diego in 20216. Because this structure will includescissor stairs with various types of fixed-free connections, this will be an unprecedented opportunityto gather physical data showing the effects of stair-structure interaction. Using this data, I will developa model of the building including the stairs using OpenSeesPy, which I will validate and calibrate withdata from the shake table test. Discoveries from this test will allow me to improve the stair-structuremodels developed for Goal 2.Intellectual Merit: Although prior research efforts have investigated the performance of fixed-freeconnections2 and the interaction between scissor stairs and structural systems5, no study has yetaddressed coupling the two. Previous tests have demonstrated the potential of fixed-free connectionsto mitigate damage in stairs2 sufficiently to warrant further investigation. Accurately characterizing thenonlinear force-deformation relationship of scissor stairs with fixed-free connections will facilitatefuture research into the seismic response of buildings. Furthermore, developing a nonlinear springmodel in Goal 2 will be an important step in helping practicing engineers integrate the results of thisresearch into design practice.This research will also advance the quality of computational analysis in structural engineering. Tomy knowledge, I will be the first student at the UNR to extensively use OpenSeesPy, an adaptation ofthe finite element framework OpenSees for Python. Python has many data science libraries that willimprove analysis of data from shake table tests and computational models. Linking Python andOpenSees will improve the quality of structural research by facilitating pre- and post-processing ofdata from tests and simulations.Broader Impacts: Failure to account for differential movement between floors has led to stairscollapsing in the recent Wenchuan and Christchurch earthquakes2. Fixed-free connections can preventsimilar collapses in the future, but first their effects on building response need to be considered beforethis life-saving technology can be fully implemented. Since stairs are the primary means of egress froma building during a catastrophic event, protecting stairs from collapse during seismic events is anessential task for preventing loss of life. Furthermore, better modelling of stair-structure interactionwill ensure safer design and reduce damage, which will in turn facilitate rapid recovery after disastersby reducing building downtime and preventing economic losses.In order to promote the use of safer stair systems, I will disseminate my findings throughpublications in structural engineering journals, the NHERI TallWood outreach webpage, and throughseminars hosted by UNR’s Earthquake Engineering Research Institute chapter. The NHERI TallWoodproject will give me opportunities to work closely with industry collaborators to further develop andpromote fixed-free connections. I will also present a simplified version of my research to K-12classrooms to foster youth interest in earthquake research.References:[1] D. Bull, (2011). Canterbury Earthquakes Royal Commission.[2] C. Black, et al., (2020). 17th World Conference on Earthquake Engineering.[3] J. Zhu, et al., (2011). Applied Mechanics and Materials.[4] https://www.lstc.com/products/ls-dyna[5] X. Wang, et al., (2015). Earthquake Engineering & Structural Dynamics.[6] K. Ryan, et al., (2020). Colorado School of Mines."
43.0,"which humans can run experiments and the enormous size of the search space.1 Recently, the materials-design loop has been accelerated through several different mechanisms, including robotic high-throughputexperimentation (HTE), atomistic simulations, and machine learning (ML).1 While each of these techniqueshas independently shown promise for accelerating discovery, an approach that applies all threeharmoniously would revolutionize chemical research with wide-ranging implications, enabling faster andcheaper discovery of new pharmaceuticals, catalysts, and photovoltaic devices. I aim to advance this effortin my own research by coordinating the interplay between these three methods for the discovery and designof new dye molecules. Dyes are a suitable class of molecules for testing an autonomous, integrated designplatform because they have several readily measurable properties that must be optimized simultaneouslyfor use cases ranging from solar cells to medical imaging. Specifically, I am focusing on the followingobjectives: (1) developing ML models to predict UV-Vis absorption and emission spectra accuratelygiven a dye molecule and solvent pair, (2) creating a generalizable, automated active machinelearning framework to improve the prediction models, and (3) utilizing this framework to design anovel near-infrared (NIR) dye for biomedical sensing and diagnostics.Objective 1 - Model Development for UV-Vis Spectra Predictions: Accurate prediction of UV-Visoptical properties is essential to dye design for any application. Previous work toward predicting UV-Visspectra with ML has mostly consisted of the simpler task of predicting two scalars, the wavelengths of thepeaks of maximum absorption and emission (𝜆 and 𝜆 )2, and has been limited by data sparsity. Sinceabs emstarting my work with Prof. Rafael Gómez-Bombarelli in January, I have addressed this limitation bycollecting all openly accessible UV-Vis data from seven online repositories (29,811 measurements in total)and standardizing it into a consistent format. I then used a combination of a directed message-passing neuralnetwork (DMPNN)3 and a feed-forward neural network to predict a value for 𝜆 given an input molecule-abssolvent pair and an analog of 𝜆 computed with time-dependent density functional theory (TD-DFT).absUsing this method, my model has achieved a test-set mean absolute error (MAE) of 8.68 nm (a 17%reduction in error over the previous best model) on the largest dataset for which ML predictions havebeen published.2 My first step toward extending this method to predict full spectra will be to train mymodel to predict the peak widths and intensities for each 𝜆 using the data I assembled. I foresee the limitedabsquantity of available data presenting a challenge for predicting full spectra since the majority of openlyaccessible data contains only 𝜆 values for each molecule-solvent pair. I will address this issue with aabspretraining strategy in which I train my model with lower-fidelity data and use the resulting neural networkweights as the initial weights when training my final model (as opposed to a random initialization). I willthen estimate the epistemic and aleatoric uncertainty in my model’s predictions using a deep ensemblingapproach.4 Finally, I will replicate the previous steps for predicting emission spectra. My accurate modelsfor predicting absorption and emission spectra will aid experimentalists in choosing which moleculesto test, even before I further automate this process in the following objective.Objective 2 - Active Learning: My models’ abilities to make predictions with corresponding uncertaintieswill fulfill an important prerequisite for implementing active learning (AL), which improves models byfocusing the sampling of new data on molecules with high uncertainties in their predictions. The additionalcomponents needed for active learning are (1) a set of new molecules from which to sample, and (2) amethod of measurement for each sample. My experimental collaborators in Prof. Klavs Jensen’s group havecreated (1) by extracting a list of 7 million purchasable compounds from chemical vendor websites. Further,they have created a method for (2) by building an HTE apparatus for measuring 96 UV-Vis spectrasimultaneously. Since TD-DFT calculations are faster and cheaper than experiments, I propose using theseto augment the strategy for (2) by reducing the number of necessary experiments. I will design acomputational framework to automatically deploy calculations for molecules with a high epistemicuncertainty and retrain my models using this new data. From molecules that still have high uncertainty afterthe calculations, my system will use the uncertainty values along with molecular similarity to choose 96molecules to recommend for measurement in the HTE apparatus. My models will automatically receivedata from the experiments and repeat the previous steps iteratively until their predictive performances reachasymptotes of aleatoric uncertainty. The proposed AL framework integrates TD-DFT and HTE in anautomatic fashion, which will enable significant time and cost savings and will be readilygeneralizable to many areas of chemistry and materials science research.Objective 3 - Design of a Novel Dye for Biomedical Imaging: Once I am able to demonstrate that myML models are sufficiently accurate over a large region of chemical space, I will adapt my AL frameworkto design novel molecules with optimized properties for biomedical imaging. Specifically, it is favorablefor dyes to have absorption and emission peaks in the NIR-II range (1000-1700 nm) because this range hasdeeper tissue penetration compared to visible or shorter-wavelength NIR-I light.5 High Stokes shift (𝜆 -em𝜆 ) and high quantum yield are also desirable.5 Additionally, I will leverage the ongoing work of myabscollaborators in Prof. Bill Green’s group who are predicting solubility, toxicity, and photodegradation, asthese are also important properties for this application.5 I will employ the generative models of Jin et al.6 tocreate new molecules out of substructures that are likely responsible for desired properties of interest inknown molecules. Next, I will make predictions on these new molecules with my ML models. I will thenmodify my AL framework to explore the new chemistries proposed by the generative models; it will deployTD-DFT calculations as necessary for molecules with uncertain predictions and ultimately recommendnovel molecules with predicted properties in the target ranges to my experimental collaborators in theJensen group. They will use automatic retrosynthesis methods7 to synthesize the novel compounds and willthen use their HTE apparatus to test which proposed molecules indeed have the desired properties. Finally,I will propose the best-performing molecules to Prof. Angela Belcher’s group for further study and in vivotesting. If successful, this strategy could serve as a blueprint for combining experiments, theory, andML for multi-objective molecular design across the field of chemistry.Intellectual Merit: Design problems in chemistry and materials science often suffer from a combinatorialexplosion of configurations to explore, which makes solution of these problems intractable by brute force,or with HTE, physics-based calculations, or ML alone. By using all three methods simultaneously andautomating the interactions between them, my work will be an advancement toward a “closed-loop” systemthat can explore massive chemical spaces with minimal need for human intervention beyond thespecification of design objectives. Conducting my work at MIT gives me the opportunity to collaboratewith experts who have proven records of integrating chemistry and computer science methods, and it givesme access to computing resources to run atomistic calculations and train ML models. An NSF fellowshipwould supplement my current computing resources with access to XSEDE and would ensure thenecessary funding for my completion of this project.Broader Impacts: I will design a novel dye that could be applied to guide surgery or to detect cancer atearlier stages. My work’s flexible multi-objective optimization will also be able to design new dyes foradditional applications such as dye-sensitized solar cells. Furthermore, the AL framework I develop couldbe widely adopted to design other types of molecules and materials, such as those in batteries and catalysts.I plan to make all code and datasets I develop openly available online with detailed documentation, whichwill enable other researchers to replicate and build upon my work more easily. Additionally, I will host aworkshop to demonstrate my framework, with the goal that even experimentalists with littlecomputational experience would learn to utilize the AL component of my framework to accelerate theirprogress in molecular or materials design. My work ultimately aims to encourage greater collaborationbetween experimental, theoretical, and computational researchers by automating the connections betweentheir work in pursuit of design challenges that would otherwise be intractable.References: [1] Angew. Chemie Int. Ed., 2019, doi:10.1002/anie.201909987. [2] ChemRxiv, 2020,doi:10.26434/chemrxiv.12111060.v1. [3] J. Chem. Inf. Model., 2019, 59 (8), 3370–3388. [4] J. Chem. Inf.Model., 2020, 60 (6), 2697–2717. [5] J. Mater. Sci., 2020, 55 (23), 9918–9947. [6] ICLR, 2020, arXiv:2002.03244. [7] Science, 2019, 365 (6453), eaax1566."
44.0,"Introduction/Intellectual Merit: Advanced metabolic engineering allows scientists to use geneticengineering techniques in lower organisms, such as Escherichia coli and Saccharomyces cerevisiae, toproduce molecules of interest through recombinant pathways. Metabolic pathways are groups of genes thatencode enzymes that work together to produce the molecule of interest. Scientists have identified the mostefficient genetic modification methodologies to create optimal production strains, including promoterlibraries. A promoter library consists of a variation in the DNA sequence which varies the transcriptioninitiation rate of the associated gene. This variation can come from promoters in the native organism or innon-native organisms, which are identified using RNAseq data. These libraries have been extensivelydeveloped for model organisms such as E. coli and S. cerevisiae. However, these tools are currently limitedfor non-conventional organisms. Leaders in the field of biochemical engineering have identified thedevelopment of genetic tools for use with non-conventional organisms as a foremost goal because modelorganisms lack the complexity that non-conventional ones can provide1. Leveraging unique properties ofnon-conventional organisms allows scientists to build upon promising results that push the boundaries ofthe pharmaceutical, environmental, and cosmetic industries.Using the knowledge that I’ve gained from working in two metabolic engineering labs over the lastthree years, I intend to further explore the non-conventional oleaginous yeast, Yarrowia lipolytica. Thisyeast is particularly interesting because of its ability to naturally prevent bacterial contamination3, itsutilization of various hydrophobic and hydrophilic carbon sources4, and its ability to efficiently producelarge amounts of lipid-based products5. Y. lipolytica was originally identified in environments containinghydrophobic substrates and studied for its ability to biosynthetically produce enzymes and citric acids2.Recently, metabolic engineers have become more interested in this yeast as they explore non-conventionalorganisms for production of high-value compounds.Research Plan: Although genetic engineers have made significant strides in the toolkits available for Y.lipolytica, they currently lack the diversity necessary to fully exploit its potential. One of the newest toolkitswas developed by a group in France and is called the Golden Gate toolkit for Y. lipolytica6. The GoldenGate toolkit allows researchers to efficiently transform and integrate heterologous pathways in theorganism. This toolkit includes a validated promoter library and has been successfully used to express afunctional xylose utilization pathway. A major goal of my research plan is utilizing this toolkit and othersto integrate several metabolic pathways into the organism. Additionally, scientists have discovered morepromoters and have begun to look into computational models for the organism. These promoters includeTATA box promoters7 and one repressible and one bidirectional promoter2. Repressible promoters providenegative feedback to down regulate transcription pathways, which is useful for products that are inhibitoryto growth. A bidirectional promoter can be initiated in both directions for transcription; this becomesimportant for efficient gene co-expression. However, in order to further enable the metabolic engineeringgoals for this non-conventional yeast, more native and non-native promoters need to be identified so thatresearchers can better optimize the genetic conditions forefficient pathway expression.One way I plan to find new native promoters isthrough the use of RNAseq, described in Figure 1. RNAseq isa technique that can identify transcriptionally active regions ofthe genome and provide data on the expression levels of genesunder various growth conditions or metabolic states. Thisleads to the identification of relevant promoter regions anddata that can then be compared between specified growthconditions and normal growth conditions in which thepromoter region should not be active. This technique will alsobe applied to other organisms in order to create non-nativepromoters, allowing for the identification of exciting newFigure 1. Simplified steps of RNAseq promoters that behave differently than native ones in the hostprocess for identification of promoters. organism. The identified promoter sequences will then beobtained for both sets of promoters and will be expressed recombinantly and characterized in the hostorganism. The identification of both native and non-native promoters will allow for a more robust toolkitthan what is currently available.These new promoters will then be applied to pathways of high interest in the scientific community.One such pathway is the pathway for production of plant oils. Jojoba oil was identified as a leadingingredient for anti-aging formulas for skincare in the 2000s and is still widely used today with increasingdemand8. Harnessing the ability of Y. lipolytica’s high metabolic flux towards fatty acids enables a newroute of production for the long chain fatty acids that comprise Jojoba oil. The enzymes in this pathwayhave been identified9 and can be recombinantly expressed to produce Jojoba oil. This pathway will be atesting ground and motivator for identifying and characterizing novel promoters. After successfulintegration of the recombinant pathway, scale-up production studies can begin.The experiments for genetic optimization will take place in small volumes within 48-well plates(2mL). After creating multiple genetic libraries through use of promoters discovered and discussedpreviously, fermentation growth conditions can be studied in shake flasks (250mL). Studying the organismin shake flasks informs decisions about growth conditions in large scale studies, such as those done in abioreactor. After determining high quality growth characteristics, studies will be moved into a bioreactor(typically 1.5L+) to study the industrial feasibility of the process. Few studies have been done using Y.lipolytica in bioreactors, so this process will require permutations of multiple parameters to determine thebest operating conditions for growth and oil production. This objective will be assessed by the ability of thebioreactor process to be scaled and replicated and for Y. lipolytica to produce high oil titers at scale underthe optimal conditions.Throughout the completion of genetic cloning and scale-up studies, enhancement of currentcomputational models will be occurring in parallel. Genome-scale-metabolic models (GEMs) have beencreated for Y. lipolytica. GEMs provide a kinetic model of cellular metabolism, meaning that a GEM canpredict the metabolic activity of an organism based on user-defined parameters. The Y. lipolytica modelsneed to be improved so that a wider range of researchers can use them. The best models achieve around80% accuracy to experimental findings, however for people outside the field of metabolic engineering, themodels are hard to understand and use7. In order to enhance the model, experimental data will be collectedon new promoters, new growth conditions, and scale-up studies. Confirmation of already existing geneediting tools will also be collected. Utilizing GEMs is radically different than metabolic engineering’srandomized approach for identification of optimal conditions. The GEMs allow researchers activelyworking with Y. lipolytica to first test their hypotheses in silico so that they do not spend excess time andresources attempting to screen every genetic and/or fermentation parameter.Broader Impacts: Currently, Jojoba oil is produced via extraction of the oil from the seeds of the Jojobaplant. This time-intensive and costly process could be made easier through the creation of a heterologousproduction host. An efficient recombinant host organism allows for scientists to produce the same qualityoil with a significant decrease in the environmental stresses associated with harvesting from the naturalJojoba plant. Metabolic engineering enables Y. lipolytica to sustainably convert widely available carbonsources into high-value natural products. However, until further promoters are developed, and scale-upstudies are done on the organism, its full potential cannot be harnessed. Furthermore, the in silico model ofY. lipolytica will allow a large community of scientists to work together to better understand the growthand production capabilities of the organism. Taken together, the work proposed above leads to a continuedadvancement of metabolic engineering technologies to benefit society through development of advancedmethodologies for sustainable chemical production.References:1. Whitehead, T. et al. Biotechnol. Bioeng. (2020). Journal (2014).2. Hussain, M. TigerPrints (2017). 6. Larroude, M. et al. Microb. Biotechnol. (2019).3. Michely, S. et al. PLoS One (2013). 7. Ma, J., et al. J. Ind. Microbiol. Biotechnol. (2020)4. Ledesma, R. et al. Trends Biotechnol. (2016). 8. Ahmad, A. et al. Biomed. Dermatology (2020).5. Gonçalves, F. et al. The Scientific World 9. Miklaszewska, M. et al. Plant Sci. (2016)."
45.0,"Introduction: Understanding exactly how femalesmake matechoices,andhow thesemapontomale fitness and quality, has important ramifications for understanding trait evolution, and forconservation in species where female choice plays a large role in male success. Leks, wheremany males display at once hoping to attract a mate make an ideal model because femaledecision-making pathways should depend only on male display or other on-lek factors, and noton extrinsic factors such as territory quality or parental care. I propose to apply eye-trackingtechnology to female Greater Sage-Grouse (Centrocercus urophasianus) to determine how theyacquire information from visual displays produced by males when selecting mates. Eyemovements can be used to understand cognitive processes as animals must focusonaparticularsubject to process the information given by it. Limitations on sensory processing determine theamount of information a female can take in about a male and thus limits what she considerswhen choosing a mate.1 I hypothesize that female choice is drivenby integrationof multiplesignal elements.Aim 1: I will track female eye movements to determine which parts of the display femalesconsider as they focus on one element at a time before moving on to another. Femalescannot take in the whole of the display at once and should reduce their focus to only what theyperceive to be the most important signal elements.Aim 2:Once females’preferredtraits areknown, Iwill assessthe differencesbetween successfuland unsuccessful males to determine if there is likely selection pressure onthose traits. Findingthose differences will demonstrate that females are intaking sensory information,processing it, and using it to make decisions about mating.Methods: I will travel to lek sites across Montana to conduct this research. Using cameras andGPS units2 placed on males, I will track general positions of males on the lek and estimateterritory sizes for each male. I will also track mating success for each male by counting thenumber of matings attempted and presumably successful matings. For assessing females’preferred traits, I will use eye-tracking technology3 to determine how females are acquiringinformation about important traits. Analysis of eye movements will show the specific featuresfemales target and use as criteria for mate choice. Using data from eye-tracking, I will measurethe male ornaments females focused on, comparing between males with many matings, malesthat received some female attention butfewmatings, andmalesthat didnotreceive anymatings.I will analyze the differences between each group for each trait to assess whether the trait isunder significant selection pressure driven by female choice.1Dukas R. 2002. Behavioural and ecological consequences of limited attention. Philos. Trans. R. Soc. B Biol. Sci.357, 1539-1547.2Wann, GT, Coates, PS, Prochazka, BG, Severson, JP,Monroe, AP, Aldridge, CL. Assessing lek attendance of malegreater sage‐grouse using fine‐resolution GPS data: Implications for population monitoring of lek mating grouse.Popul. Ecol. 2019; 61: 183– 197.3Yorzinski JL, Patricelli GL, Babcock JS, Pearson JM, and Platt ML. 2013. Through their eyes: selective attentionin peahens during courtship.J. Exp. Biol 216:3035-3046Intellectual Merit: Eye-tracking is currently an under-utilized4 but insightful method inunderstanding visual cognition, especially in sexual selection. My research contributes toexpanding use of this technology to understand how sight can affect trait evolution in anorganism where visual traits are dramatic and emphasized. It provides other scientists with theunderstanding that these types of studies are feasible. It can be translated to see how cognitionvaries across the animal kingdom and increaseknowledgeabout visualcognition’sroleinsexualselection. Further, my research addresses the NSF Big Idea “Understanding the Rules of Life”because the process of decision making in sexual selection and female choice is still notclearlydefined. Not only will I address the intraspecific interactions between males and females in apopulation, but I will assess cognition on an organismal level, to figure out how females intakeinformation and perform a highly complex behavior, choosing a mate, in response.My experience working with autonomous recording units and GPS mapping with myundergraduate advisor and in my honors thesis has prepared me to work with various types oftechnology in the field. I am comfortable handling and managing equipment and data collectedfrom the units. I am able to translate these experiences to this project to create an efficientworkflow tohandle massamounts ofdata. I alsohave experienceanalyzinghighvolumesof datafrom audio recordings, which is easily transferable to processing video.Broader Impacts: With my proposed research, I will create opportunities for undergraduateresearch and citizen science. I will have undergraduate research assistants help me withcapture, measurements, and placement of GPS receivers. These students will gain valuabletraining in fieldwork techniques andexperimental design,preparing them toalso goontoexpandscientific knowledgein ecology, animalbehavior, andorganismal biology.Asadisabled andfirstgeneration student, I will reach out to increase research participation for underrepresentedstudents alongside my plans to expand access to research opportunities for underservedstudents. I will also recruit citizens from the surrounding areatohelp collectdata about thelek,thereby allowing more citizens to appreciate the habitat and gain an appreciation of science.Special effort will be made to extend this opportunity to local high school students who maynot otherwise have the opportunity to conduct research with scientists. Leks areparticularlycharismatic and tend to engage a wideaudienceof citizensof all agesinterested inbirds,whichgives me the opportunity to teach them about behavior andhow tomake scientificobservations.At the same time as citizen outreach, I will also educate thepublic about thesagebrush habitat,Sage Grouse, and emphasize the importance of conservation science inmaintaining ahealthyenvironment. I also plan to collaborate with the U.S. Fish and Wildlife Service, localconservation organizations and Native American tribes to preserve habitat and reduce theamount of frackingin thearea,leadingtoimproved environmentalconditions, preservationofculturally important land, and more greenspaces, improvingmentaland physicalwellbeingfor those living around sagebrush. Increased contact between the groups will also facilitatebetter working relationships and improve society for people who use these lands.4Billington J, Webster RJ, Sherratt TN, Wilkie RM, and Hassall C. 2020. The (Under)Use of Eye-Tracking inEvolutionary Ecology. Trends in Ecology & Evolution.Trends Ecol. Evol."
46.0,"mate. The majority of research regarding the signal function of visual traits has concerned color or patchesof color. This focus on charismatic coloration has left unexplored the potential signaling function ofachromatic patterns. Some patterns, such as the white check patch of great tits (Parus major) or the blackfacial spots of female paper wasps (Polistes dominula), have been suggested to function as assessmentsignals1. Yet, there is little empirical evidence that females consider patterns when selecting a mate. In thesongbird family Estrildidae, patterns or certain features of patterns may be dimorphic, which suggests thatthese may be sexually selected traits. This idea is only beginning to be explored, with some studies linkingestrildid patterns to individual quality2,3. Little is known, however, about how females perceive thesesignals, including the extent to which features that stand out to human observers draw the attention of thebirds themselves.The zebra finch (Taeniopygia guttata) is an ideal species in which to study the role of achromaticpatterns in estrildids. This species exhibits four notable sexually dichromatic traits, two being related tocolor and two being related to pattern. These include red beak color, which is more pronounced in malesthan females, and an orange cheek patch, barred bib, and white flank spots that are only exhibited by males.Although the function of male beak color has been well studied, little attention has been paid to the otherthree dimorphisms, aside from one study showing that female zebra finches prefer males with moresymmetrical barred bibs5. There also is little known about how these dichromatic patterns have evolved,and to what extent these patterns vary in wild populations. Furthermore, zebra finches come from thesubfamily Poephilinae6, which exhibit a wide range of chromatic and achromatic patterns, allowing for atractable phylogenetic comparison of perceptual abilities. I hypothesize that dimorphic achromaticpatterns function as signals of quality independent of color, and that species with these patterns areable to perceive and assess variation in this signal better than those without.Aim 1a: Quantify the range of natural variation of zebra finch patterns. Using museum specimensfrom the University of Michigan’s ornithology collection, I propose to measure the degree of variation ofplumage patterns within zebra finches. After photographing the ventral and lateral sides of specimens, Iwill use ImageJ software to determine the degree of variation in male bar and spot pattern. This is animportant analysis because in order for sexual selection to operate, there must be existing variation for it toact upon. After determining the range of this variation, I will categorize the types of plumage variation thatmay exist among males. Likely, these will include differences in regularity, contrast level, and density ofpatterns, though other features may also differ. Finally, I will test if certain aspects of these patterns covarywith body size, beak color, or other indicators of individual quality.Aim 1b: Determine the extent to which females can discriminate natural pattern variation. Usingmethods developed to test for categorical color perception in this species (i.e. training birds to flip discs ofdifferent colors for a food reward)7-9, I propose to ask how female zebra finches perceive variation inpatterns of bars and spots. To do this, I will make discs using paper printed with images of male chest orflank plumage as determined in Aim 1a. I will place these discs on wells in which a food reward is foundand train birds to select the pattern that varies the most from the others. Using the range of variationdetermined in Aim 1a, I will test for the extent to which two varied patterns are indistinguishable to zebrafinches. Given that zebra finches court at close range, this approach matches how close females would beto these patterns when assessing males. Additionally, I will test for sex differences in contrast perceptionto ask whether dichromatic bar/spot patterns could function in female choice, male competition, or both. Ifdichromatic patterns serve as signals of quality, I predict that female zebra finches will have thevisual acuity necessary to discern variation in this signal.Aim 2: Test female preference for pattern quality. I will test for female preference of male patternvariants using digitally manipulated images of male conspecifics. Using a television screen separated by apartition (hereafter “Bird TV”), I will observe how long females spend near one of two videos of male zebrafinches as evidence of their mate preference. I will first record videos of male zebra finches and thendigitally alter certain aspects of their achromatic patterning that have been positively correlated with bodycondition and dominance hierarchy in other estrildids: regularity of barred plumage2 and number of whitespots10, respectively. Bird TV, a novel method for mate choice experiments, is currently being developedby my advisor, Dr. Steve Nowicki, to test female preference for male beak color, which is a well-supportedpreference. After this approach is validated, Bird TV will be used in my proposed experiment. I predictthat females will prefer the aforementioned pattern variants that have been previously suggested toserve as signals of quality (regularity of barred plumage and large spot size), but have not beenexplicitly tested.Aim 3: Compare the perceptual abilities of closely related estrildids: The zebra finch is a uniqueestrildid in that it simultaneously exhibits dimorphic carotenoid coloration, barred plumage, and spottedplumage. As a result, it is possible that zebra finches are adept at both color and contrast perception. Otherclosely related species, such as the long-tailed finch (Poephila acuticauda) or double-barred finch(Taeniopygia bichenovii), exhibit fewer dimorphic traits. Therefore, I will compare the visual abilities ofzebra finches to its closest relatives to see if there are trade-offs associated with color and contrastperception. For example, the double-barred finch does not exhibit carotenoid coloration, but both males andfemales have bars and spots, and so may have been selected to specialize in perceiving patterns. In contrast,the long-tailed finch exhibits carotenoid coloration in both male and female beaks, but lacks bars or spots,suggesting that it may have been selected to specialize in color perception. I hypothesize that there is atrade-off between color and contrast perception—specifically, that exclusively colorful birds arebetter at color perception, and that exclusively patterned birds are better at contrast perception. Ipropose to test the color and contrast perception of the long-tailed finch and double-barred finch using themethods from Aim 1, then test female choice using methods from Aim 2, and compare these results to thoseof the zebra finch. An inconspicuously colored and more distant relative of the zebra finch, the Bengalesefinch (Lonchura striata domestica), was recently shown to discriminate colors differently than zebrafinches11. My work will follow up on this investigation to test the effect of phylogenetic relatedness oncolor and pattern perceptive abilities in Estrildids.Intellectual Merit: In studying the potential signaling function of certain visual traits, it is criticallyimportant to first understand how these signals are perceived. If such signals are not being perceived ordifferentiated at all, then we need to re-evaluate what other function they could possibly serve apart fromintraspecific communication. While patterned plumage has been previously proposed to function inintraspecific signaling, no study has actually examined how adept animals are at perceiving variation inthese patterns. Therefore, my work will be a necessary first step in determining if patterned plumage shouldcontinue to be explored as a signal of quality.Broader Impacts: As an NSF fellow, I will ensure that my research, at every stage, contributes to mypersonal goal of retaining as many students as possible in the sciences. At Duke, I will invite undergraduatesto not only assist in collecting data, but also in contributing intellectually so that they may share authorshipon future publications. During the summer, I will train undergraduates through Duke’s paid BiologicalSciences Undergraduate Research Fellowship. This program not only introduces students to biologicalresearch, but also provides professional development opportunities and a campus-wide showcase to presenttheir research. I benefited greatly from summer research programs like this, particularly the NSF REU, soI know firsthand the impact they can have. I want to help Duke undergraduates feel comfortable in aresearch environment through close mentorship and reassurance that questions and mistakes are part of thelearning process. Beyond Duke, I plan to share my research with scientists and science enthusiasts in thebroader “Triangle” (Durham. Raleigh, and Cary, NC) area. The North Carolina Museum of NaturalSciences in nearby Raleigh hosts opportunities for science communication and outreach that I plan to fullyengage in. For one, they host the Scientific Research and Education Network (SciREN) Networking Event,which gives an opportunity for scientists to adapt their research into K-12 lesson plans. They also host aDarwin Day event, in which people of all ages are invited to learn about Darwin and his legacy. I will sharemy findings at these events, and adapt them so that they are appropriate and accessible to all ages andbackgrounds. Finally, I will participate in Skype-a-Scientist to connect with students globally.1Pérez-Rodríguez et al. 2017. Proc. Royal Soc. B. 2Marques et al. 2016. Roy. Soc. Open Sci. 3Soma &Garamszegi 2018. Behav. Ecol. 5Swaddle & Cuthill 1994. Proc. R. Soc. Lond. B. 6Olsson & Alström 2020.Mol. Phylogenet. Evol. 7Caves et al. 2018. Nature 8Zipple et al. 2019. Proc. Royal Soc. B. 9Caves et al.2020. Behav. Ecol. Sociobiol. 10Crowhurst et al. 2012. Ethology 11Caves et al. (in press) Am. Nat."
47.0,"Introduction: Recent advancements in technology have enabled new ways of constructing metamaterialsthat possess desirable mechanical properties. Materials that have high elastic stiffness and low density areconsidered some of the strongest, stiffest, lightest materials available today [1]. By controlling theirmicrostructures, we can tune mechanical properties of metamaterials that endure extreme conditions.A trait of a metamaterial microstructure that is much ignored to date is randomness (aperiodicity),owing to the limitation of current design approaches based on unit cells. Aperiodic structures are likely toresult from natural self-assembly and self-organization processes and may be more robust againstuncertainty. Examples of robust microstructures can be seen in natural formations such as wood andnacre, or in parts of the human body such as bone [2]. Materials that are robust against uncertaintyperform well under various forces and stresses they may encounter.Currently, state-of-the-art approaches for designing metamaterial microstructures for desirableproperties can be categorized either as parameterized design or topology optimization methods. Bothapproaches build their foundation on the assumption that material microstructure consists of periodicallyrepeated motifs (or unit cells). Parametrized design is a simpler design method to design structures likelattices; it allows for a few design parameters to map directly to specific properties, but it needs an ad-hocdesign to start with. Since the design space is quite narrow, there is a narrow range of achievable materialproperty ranges. Meanwhile, topology optimization is a design method that allows for freeform design ofa structure with almost any geometry; it is mathematically well defined, but computationally expensive,leading to unpredictable geometries that are hard to manufacture [3]. Both approaches are difficult to useas tools to efficiently and effectively explore the vast design space of material microstructures.By combining optimal features of each method, this research aims to expand the microstructuredesign space to maintain local parametric behavior while enabling global freeform design. Throughnumerical approaches, one can program aperiodic material microstructures towards desirable propertiesusing a “growth”-like process that is encoded by “DNA”-like pairwise combination rules. With this“growth” process, a method for physical self-assembly is desired as it allows for rapid production ofprogrammable metamaterials. The mechanical self-assembly process has been explored in severalapplications across different scales [4, 5], but none have been able to achieve mechanical self-assembly ofan aperiodic microstructure. This design approach allows us to efficiently generate new random yetordered microstructures. It enables effective exploration of the material design space and pushes theboundaries of applying new stronger materials to applications such as shock absorption and acoustics.Research Plan: I aim to develop self-assembly methods to investigate how the shape and design ofcellular automata base cells affect mechanical properties of programmable metamaterials. I willthen develop specific tunable metamaterials for applications that desire the particular properties.Numerical, experimental (Fig. 1), and application phases can be achieved with FEA software, 3Dprinting, and mechanical testing equipment commonly used in any mechanical engineering lab. Myprevious research experience doing this with square-shaped tiles demonstrates my technical capability.Specific Aim I. Develop Baseline Samples: I will first develop a wave function collapse algorithm [6] forvarious polygons, such as pentagons and hexagons. The versatile algorithms will be developed in Pythonfor both 2D and 3D self-assembly with flexibility for varying polygons. To do this, I will use a so-calledwave function collapse algorithm, which performs a “growth” process similar to cellular automata. Wedefine fundamental building blocks and connectivity rules over a cellular space. Once the first cell is set,connectivityrules areenforced todeterminesurroundingcell states;this processthen repeatsinpropagating cycles. This will generate 2D and 3D samples for multiple shapes to be transformed into 3Dobjects in Rhino with Grasshopper C# that will be tested using FEA software. This forms a baselinemapping of the programmable microstructure design space as a success assessment.Specific Aim II. Perform Physical Experiments: From my numerical analysis of these structures, I will3D print specific samples generated by the algorithms and physically perform the same mechanical testsas in the numerical phase using mechanical testing equipment, such as an Instron machine. The results ofthese tests can be compared to the numerical results to evaluate their degree of error.Physical 2D and 3D self-assembly methods for multiple shapes will be developed to gain furtherinsight into this self-assembly method. Inspired by the mechanics of DNA self-assembly processes [7], Iwill design tiles for each shape with their respective channel types dictated by the polygon’s interiorangle. This tile design and experimental setup must ensure some randomness and adhere to the algorithm-determined connectivity rules. The self-assembled 3D printed tiles will be used as a carrier casting moldin which to pour a plastic material to generate the metamaterials to be tested. Using the same mechanicaltesting methods as the previous samples, I will then compile and analyze data for information about thedesign space and microstructure properties with a focus on how base cell shape and correspondinginterior angles affect mechanical properties of the metamaterial microstructures. At this point, a newphysical method for developing aperiodic programmable metamaterials will have been created. Thedesign space can be studied by constructing a material database. If the physical self-assembly method isnot experimentally reliable, the initial algorithm-based numerical study and mechanical tests still providea wealth of data to be used in the applications phase.Specific Aim III. Develop Metamaterials for Applications: Based on my findings from the studiesperformed in the previous phases, I will then study special properties of certain metamaterials that thisself-assembly method yielded, such as shock absorbency and acoustic capacity. My experimental resultswill yield a desired mechanical property by tuning the specific base cell shape and quantity of channeltype. With these settings, the physical self-assembly method can be used to create an array of samplesused for additional testing for specific properties, such as impact testing in the shock absorbency case.These studies will demonstrate how the metamaterials yielded from the developed self-assembly methodcan be applied as lighter, stronger, and more flexible alternatives to materials currently used in aerospaceand medicine.Intellectual Merit: This project will develop a mechanical self-assembly method of aperiodicprogrammable metamaterials, contributing new 2D and 3D self-assembly methods to metamaterials andmechanics research; this will improve the fundamental understanding of material microstructures andtheir properties. This project will also enhance understanding of the mechanics of self-assembly such asattractive forces and interlocking as seen in DNA self-assembly [7]. Working on this project at a researchinstitution with a strong mechanical engineering program will provide the proper resources to researchand publicize my findings related to metamaterials, bio-inspired processes, and their applications tomedical and aerospace fields.Broader Impacts: This project will contribute new 2D and 3D self-assembly methods to metamaterialsand mechanics research while developing new aperiodic programmable metamaterials with large degreesof tunability. Scale-independent metamaterials will be created that can be applied to aerospace materials,soft materials, and medical devices for its capabilities of enhanced shock absorbency, acoustic properties,elasticity, and strength. Additionally, through its biologically linked process of self-assembly, themicrostructures developed have the potential to be applied to sustainable, environmentally friendlystructures and devices. This project also has a parallel educational impact to introduce high school andundergraduate students to numerical and experimental methods in mechanical engineering and STEM. Iplan to mentor students in researching metamaterials.[1] J. B. Berger et al., “Mechanical metamaterials,” pp. 533–537. [2] H. Wagner et al., “Bonemicrostructure,” pp. 1311–1320. [3] O. Sigmund et. al, “Topology optimization,” pp. 1031–1055. [4] E.Klavins, “Programmable Self-Assembly,” pp. 43–56. [5] G. M. Whitesides, “Self-Assembly,” pp. 2418–2421. [6] Heaton, R. (2018). Wavefunction Collapse Algorithm. [7] S.-S. Jester et al., “DNAnanostructures,” pp. 1700–1709."
48.0,"Americans spend approximately 90% of their time indoors1, and by 2050 over two-thirds of theglobal population will live in urban environments2. Studies have shown that human exposure to pollutantsindoors is orders of magnitude higher than the exposure experienced outdoors3. Focusing air qualityresearch on the places occupied by the most people and where pollutant exposure is highest is importantin preventing negative health outcomes. It is paramount to understand the chemical, physical, and societalprocesses of the interface between urban and indoor air quality.Volatile organic compounds (VOCs) are emitted into the atmosphere from both anthropogenicand biogenic sources, including industrial and transportation activity, biomass burning, and vegetation.Indoor VOCs accumulate both from outdoor sources permeating into indoor spaces and from indooractivities such as cooking, cleaning, and off-gassing of furniture. Besides these gaseous VOCs, othersemi-volatile organic compounds (SVOCs) exist both in the gaseous and condensed phase due to theirlower vapor pressure and higher boiling points. When VOCs and SVOCs react with sunlight and oxidantssuch as ozone and nitrogen oxides (NO ), secondary organic aerosols (SOA) are produced, particles withxknown hazards to human health.While there have been mobile, real-time measurements of air pollutants such as PM 4 (particles2.5less than 2.5 microns in diameter), there have been limitations to similar VOC measurement campaigns:the measurement’s location was stationary5, the hour-long sampling time made it difficult to locatepollution “hot spots”6, or the instruments used could not measure compounds made possible by currenttechnology7,8. Prior to recent advances in VOC mass spectrometry, it had been difficult to measure VOCsand SVOCs at (a) sensitivities that allow identification of compounds and measurement of accurateconcentrations and (b) mobile, real-time temporal scales to link concentrations to specific sources.Recent technological advances have made it possible to overcome such limitations. The newestgeneration proton transfer reaction time-of-flight mass spectrometer, the Vocus 2R PTR-ToF-MS fromAerodyne, Inc., has world-leading real-time mass resolution and sensitivity. The new mass spectrometermeasures concentrations of more than 1600 chemical compounds every second, including many high-molecular-weight molecules considered semi-volatile. It can detect concentrations at part per trillionlevels with 1-second measurements and even part per quadrillion scales at 1-minute averaging for certaincompounds, allowing us to explore the frontier of trace – and very toxic – air pollutants. Using the mostadvanced mass spectrometer for this project will lead to the reporting of both SVOC molecules and traceVOCs that past mass spectrometers did not have the sensitivity to detect. The new Vocus Inlet forAerosol (VIA, Aerodyne, Inc.) gives us the novel ability to measure the time-resolved chemicalcomposition of SOA and other particles found indoors and outdoors, which is important for quantifyinghuman exposures.Research ObjectiveAs the first study to investigate the interface in VOC and SOA concentration between urbanoutdoor and indoor environments using world-leading measurement capabilities, this project aims to:(1) Quantify concentrations and human exposure to air pollutants that have been previouslyunidentifiable due to technological limitations.(2) Identify and apportion the major sources of VOCs and SOA found indoors and in urban areas.Task 1: In controlled experiments, we will characterize indoor concentrations of VOCs and SVOCs suchas benzenoids, siloxanes, and hydrocarbons. In UT-Austin’s environmental chambers and UTest House –a full-scale house on UT-Austin’s research campus outfitted with an array of sensors – experiments willsimulate common household events such as cooking and cleaning; VOC, SVOC, and particleconcentrations will be measured. To supplement our work, we will also use past datasets of theHOMEChem measurement campaign, which used the UTest House to characterize typical householdactivities9. Due to the increased sensitivity and precision of our novel mass spectrometer, we hypothesizethat we will make novel characterizations of SVOCs that previous instruments were insensitive to andthat past research campaigns did not report.Task 2: Using citizen science pathways already established from past research campaigns10, we willrecruit 20 volunteer homes of diverse economic and geographical locations around Austin, Texas to take2 air samples of ambient air twice per day for 2 weeks, one inside their home and one directly outside ofit. The air samples will be taken off-site for evaluation by our Vocus mass spectrometer to find VOC andSVOC concentrations across both temporal and spatial scales in urban and suburban environments. Weexpect that VOC concentrations will vary widely from home to home due to individual differences inventilation, personal care product usage, and cooking routines; however, we hypothesize that homeswithin a neighborhood will have similarities due to proximity to vehicle and industrial emissions.Task 3: Concurrently with the citizen science measurement, we will drive the Vocus mass spectrometeraround Austin to measure VOC concentrations found on Austin’s roads at 1 Hz time scales. Pairing theVOC data with GPS data will be vital in finding point sources and pollution “hotspots”. Every other daywe will measure with and without the VIA aerosol inlet, collecting data on both the gaseousconcentrations and chemical composition of particles. We hypothesize that many pollution “hotspots”will be from sources usually overlooked as key polluters. Due to the complex chemical and physicalprocesses that impact air quality, it is important to measure other air pollutants, not just VOCs andSVOCs. We will also measure mobile concentrations of ozone, NO , and PM – all interdependent onx 2.5the presence of VOCs – as well as meteorological data such as wind speed, temperature, and humidity. Toadd to our data set, we will use the Texas Commission on Environmental Quality’s (TCEQ) 6 Austin-areamonitoring stations as supporting data for wind speed, temperature, PM , ozone, NO , and sulfur oxides.2.5 xTask 4: Combining the mobile air pollutant data with citizen science air samples and environmentalparameters will produce a rich dataset across temporal and spatial scales. Using source apportionment andmultivariate analysis methods – for example, positive matrix factorization (PMF) and principalcomponent analysis (PCA) – we will identify major sources of urban and indoor VOCs. We hypothesizethat our analysis will reveal unknown, as well as verify known emissions from indoor sources – suchas cleaning or cooking – but will also quantify indoor exposure to pollutants penetrated from outdoors.Broader ImpactDue to the breadth of samples we will collect during Tasks 2 and 3, I will recruit at least 2undergraduate students from both UT-Austin and Huston-Tillotson University (an H.B.C.U. located inEast Austin) to help with the collection of the citizen air samples. To introduce them to air qualityresearch, I will train them in off-line VOC analysis and data processing.By conducting this campaign in actual homes and roads in addition to a laboratory setting, ourfindings can be used quickly for recommendations in homes and residential developments in Austin andother cities. By utilizing citizen science, this research will increase public awareness of the pollutantsthat residents are inhaling. The papers published from this campaign will be used as recommendations forurban planners, environmental regulators, and, perhaps most importantly, the general public. Bymeasuring around Austin, we will also report on the accuracy of the TCEQ stations and how eachstation’s neighborhood-scale measurements differ from precise ground-level measurements.Intellectual MeritWhile several studies have measured air quality across urban areas, this will be the first study todo so by measuring a wide range of VOCs (with atomic mass units from 30 to 500) in real-time usingnew mass spectrometry technology. It will also be the first campaign to use such a wide-ranging dataset –the controlled studies in the UTest House, the citizen science household air samples, TCEQ stationmeasurements, and the mobile dataset – to better understand the urban and indoor air quality system. Byfocusing on air pollutants that are not well-understood due to past technological limitations, we will alsoreport on exposures that have been overlooked.Works Cited[1] Klepeis et al. (2001), J Expo Anal Environ Epidem., 11(3), 231-252; [2] UN World Urban. Proj.: The2018 Revision (2018), pg. 10; [3] Nazaroff (2008), Build. and Env., 43(3), 269-277; [4] Apte et al. (2017)Environ. Sci. Tech., 51(12), 6999–7008; [5] Deng et al. (2018), Aero. Air Qual. Research, 18, 3025-3034;[6] Zheng et al. (2020), Sci. Total Environ, 703, #135505; [7] Maji, Beig and Yadav (2020), Environ.Pollution, 258, #113651; [8] Crippa et al. (2013), Atmos. Chem. Phys., 13, 8411–8426; [9] Farmer et al.(2019) Environ. Sci: Proc. Imp., 21, 1280-1300; [10] Bi et al. (2018), Environ. Inter., 121(1), 916-930"
49.0,"Tour Orbiter to the Ice Giant PlanetsIntroduction and BackgroundThe ice giant planets, Uranus and Neptune, have only been observed directly during flybys of the Voyager2 probe in 1986 and 1989. As it stands, the ice giants are two of the most under explored objects in oursolar system, and raise many of the most important questions about planetary and solar system evolution.In order to complete a thorough survey of the outer planets, the Ice Giants Pre-Decadal Survey (IGPDS)decided on two areas of interest to pursue in the first flagship missions: the atmospheric composition ofthe ice giants, including the tropospheric 3-D flow, heat balance, and meteorology, and the composition,structure, and evolution of the ice giant satellites1. To accomplish both objectives, a flagship missiontoeither system would require a complex trajectory that takes into account both an atmospheric entry probeand a satellite tour of the system. Due to the lengthy flight time involved in such a mission, it would bebeneficial to consider a pair of twin atmospheric entry probes in the interest of ensuring that the scientificobjectives are met. Two atmospheric probes would allow for a greater spatial resolution as well as asecond sampling of the atmosphere, which decreases the chances of the atmospheric probe landing in anunrepresentative region, as the Jovian Galileo atmospheric entry probe experienced in 19952. A flagshipmission with twin atmospheric entry probes and a satellite tour brings forth a complex trajectory designproblem when factoring in the vehicle weights, atmospheric entry locations, and launch windows of eachplanet.ProposalTo further investigate the feasibility of a flagship mission to either Uranus or Neptune including twoatmospheric entry probes and a satellite tour, I propose using two NASA trajectory design andoptimization softwares, the Copernicus Trajectory Design and Optimization System and the Program toOptimize Simulated Trajectories II (POST2), in order to systematically test combinations of spacecraftweights, atmospheric probe weights, and separate atmospheric probe latitudinal/longitudinal entrancesalongside traditional ballistic (chemical) trajectories and solar electric propulsion (SEP) trajectories.MethodsIn order to design and evaluate the various mission combinations with end-to-end optimization, I willutilize POST2 alongside the Copernicus software. Copernicus serves as the primary trajectoryoptimization tool for mission design at NASA, and as such, has many degrees of customizability in termsof low and high thrust trajectories.3This will allowfor the testing of various combinations of SEP in theinner solar system flight with a later transition to chemical propulsion. POST2 gives the ability tointroduce multiple vehicles at any point in the simulation- these “child” vehicles inherit the state of their“parent” vehicle, and will be vital in further analyzing the trajectories of the two atmospheric entry probesonce they begin separation from the parent spacecraft.4I plan to utilize the Copernicus API in order torapidly test various configurations for the launch stage up to the entry probe separation stage of themission, including the transition from SEP to chemical propulsion. I will then push this output into thePOST2 software, which will complete the trajectory design by simulating the separation of theatmospheric entry probes, the atmospheric entrances, and the satellite tour of the remaining orbiter. I plan1Ice Giants Pre-Decadal Survey Mission Study Report.,2017. (JPLD-100520) https://www.lpi.usra.edu/icegiants/mission_study/2Irwin, P. G. J.,2009. Giant Planets of Our Solar System. Giant Planets of Our Solar System: Atmospheres, Composition, andStructure, Springer Praxis Books. ISBN 978-3-540-85157-8. Springer Berlin Heidelberg, 2009.3Williams, J. et al. “Overview and Software Architecture of the Copernicus Trajectory Design and Optimization System.”(2010).4NASA Langley Research Center, “Overview of the Program to Optimize Simulated Trajectories II (POST2)”,https://post2.larc.nasa.gov/overview/to write the data interchange software in either Python or Julia, a new programming software used fortrajectory design, depending on the requirements of the two trajectory design softwares.The outputs of these combinations can then be compared in terms of the fastest route, the mostcost-efficient route, and the lightest route. The combinations explored will be constrained by thefollowing scientific considerations outlined in the IGPDS report5.UranusThe flight length and severe axial tilt of the Uranus brings forth many constraints to the mission:A combination of SEP and chemical trajectory could deliver a basic probe and orbiter combination toUranus in ~11 years of interplanetary time, when considering an average vehicle, such as the Atlas V 551.Due to the axial tilt, the planet’s seasons last ~21 years. In order to observe a different season than that ofVoyager 2’s observations, we must launch before the end of the 2030 decadal window so that the missionis completed before the 2049 equinox. Due to the alignment of the planets during this window, a gas giantflyby and/or gravity assist can only be considered with Jupiter. As such, the best gravity-assist sequencefor this window is Venus-Earth-Earth-Jupiter (VEEJ).NeptuneThe flight length of a Neptune flagship mission would require covering a much largerinter-planetary distance than that of a Uranus flagship mission, and would in turn require a strongerlaunch vehicle. The Delta-IV Heavy or the SLS Block 1-B would lend itself better to a Neptunian systemmission than the Atlas V 551, and would allow the spacecraft to complete only an Earth-Jupiter (EJ)gravity assist in order to reach Neptune. Neptune’s largest satellite, Triton, raises many questions aboutsatellite evolution due to its retrograde orbit, and thus it may also be beneficial to explore multiple flybysof this moon during the satellite tour.Intellectual MeritThough the Uranian and Neptunian systems were brieflyanalyzed in the Voyager 2 flybys, therehave been no further missions to these systems. Furthermore, the only scientific data regarding thesesystems are from remote telescopic observations and the limited Voyager 2 observations.6As the IGPDSreport stressed the importance of a flagship mission with an optimal launch window in the 2030 decade,we must prepare a mission as soon as possible. Due to the extreme inter-planetary distances, we mustoptimize the mission to ensure that all scientific goals are met in both a timely and efficient manner. Theinclusion of twin atmospheric entry probes would ensure that the in-situ atmospheric readings are preciseand representative of the planet, while the satellite tour would allow for further exploration of the systemand its evolutionary path. This proposed study will explore the trajectory design and optimization of amission with twin atmospheric entry probes and a satellite tour, ensuring that the decades of preparationand execution involved in an ice giants mission will be as fruitful as possible.Broader ImpactsA flagship mission to the ice giants would constitute a new age in space exploration, particularlyif the mission included a set of twin atmospheric entry probes. As a twin probe setup has never beenexecuted, this would revolutionize the future of in-situ atmospheric measurements, while also providingprecise results for a relatively unknown part of our solar system. The trajectory considerations of asatellite tour could also result in the discovery of new satellites, as well as previously unknown chemicalsignatures and geographical landscapes. This study would allow for the exploration of a brand-newspacecraft and probe configuration as well as the potential for a flagship mission to one of the mostunder-explored areas of our solar system, allowing for technological and scientific research for decades tocome.5Ice Giants Pre-Decadal Survey Mission Study Report.,2017. (JPLD-100520)https://www.lpi.usra.edu/icegiants/mission_study/6Irwin, P. G. J.,2009. Giant Planets of Our SolarSystem. Giant Planets of Our Solar System: Atmospheres, Composition, andStructure, Springer Praxis Books. ISBN 978-3-540-85157-8. Springer Berlin Heidelberg, 2009."
50.0,"BACKGROUNDRNA modifications, also known as epitranscriptomics, are emerging as a novel layer of dynamicgene regulation [1]. RNA modifications alter existing RNAs’ structure and function to influence variouscellular pathways via RNA processes such as transcription and translation [2, 3]. Pseudouridine (Ψ) wasthe first RNA modification discovered [1]. Despite being the most abundant and widespread RNAmodification in living organisms, little is known about its function. In this proposal, I will establish anapproach to systematically investigate the biological roles of pseudouridine by focusing on theunique activities that this modification imparts to RNA.The isomerization of uridine to pseudouridine by pseudouridine synthases (PUS enzymes)structurally stabilizes RNAs via the formation of an extra hydrogen bond donor [3]. Ψ was previouslythought to primarily stabilize tRNA and rRNA; however, new developments in modern-sequencingtechniques reveal the more interesting downstream effects of pseudouridylation. For example, there isevidence that H/ACA RNPs, RNA-dependent PUS enzymes convert stop codons into sense codons inyeast [2]. Interestingly, PUS7-mediated pseudouridylation has been found to regulate stem cell growthand fate determination partly through tRNA modification, which activates tRNA-derived fragments toinhibit protein synthesis [3]. This provides evidence that Ψ modifications may be critical in cell lineagecommitment.Specifically, mutations associated with several pseudouridylating enzymes, namely PUS1, PUS3,and PUS7, are associated with neuronal disorders and intellectual disability [4]. PUS1 mutations areassociated with cognitive impairment [5]. Additionally, PUS1 acts on the steroid RNA activator, a co-activator of the nuclear estrogen receptor α regulating neuronal survival [5]. Truncated PUS3 and reducedlevels of ψ U39 in tRNA were detected in patients with intellectual disability [5]. Lastly, mutations inPUS7 can cause intellectual disability and microcephaly in humans [4]. These studies suggest that Ψ cansubstantially impact neuronal differentiation and function; however, the mechanisms regardingpseudouridylation in neurogenesis are poorly understood. My results will contribute to ourunderstanding of the importance of pseudouridylation in neurogenesis and neuron function.PROPOSED RESEARCHMy overarching goal is to elucidate the molecular and functional roles of Ψ in neuronal cells. Based onthe reported links to human brain function, I hypothesize that Ψ is a critical modification for neuronaldifferentiation and function. I further propose that the Ψ landscape between stem cells and neuronsis unique and specific. I will test the above hypotheses with the following aims:Aim 1—To identify pseudouridylating enzymes for investigation. There are 13 known PUS enzymesin human cells; however, only a few predicted human PUS enzymes have been studied to date. In additionto PUS1, PUS3, and PUS7, I will predict other PUS enzymes associated with neuron function by firstperforming weighted gene co-expression network analysis (WGCNA). This analysis will reveal sets, ormodules, of highly correlated genes. To perform WGCNA, I will use multiple human tissue RNAsequencing datasets from the GTEx project. I expect PUS1, PUS3, and PUS7 to appear in one modulebecause these genes share connections to neuronal function. Other PUS enzymes that are expected tocorrelate with neuronal genes will fall in this module. I will then conduct gene ontology enrichmentanalysis to verify that the PUS candidates in that module are associated with neuron processes. Theseexperiments will predict key pseudouridylating enzymes in addition to PUS1, PUS3, and PUS7 that willbe investigated in neurons.Aim 2—To investigate the effects of PUS enzymes on neurogenesis. To define the impact of PUSenzymes on early neurogenesis, I will use CRISPR/Cas9 to knock out each candidate gene identified inaim 1 in iNGN cells. iNGN cells are a human induced pluripotent stem cell line which has beenengineered to be readily induced into neurons within four days by doxycycline [6]. I will design a gRNAthat targets the N-terminal coding exon of each gene to induce nonsense-mediated mRNA decay andvalidate that the enzyme is no longer expressed via Western Blot.I will explore two different methods of inducing edited-iNGN cells into neurons to gather morecomprehensive results. For the first method, I will supplement cell media with doxycycline to induce theformation of neurons. Since this procedure only takes four days, it will allow for efficient generation ofeasily reproducible data. However, the rapid induction of robust neuronal morphology by doxycyclinemay limit the resolution of detectable phenotypic changes in these cells. Thus, the second, slowermethod enables me to mark differences at each stage during differentiation. I will differentiatesuccessfully edited colonies of iNGN cells using a slow differentiation method following a previouslypublished protocol [7]. I will use an inducible Cas9 system to knock out the PUS enzyme at different timepoints to determine the most critical points of pseudouridylation during neurogenesis [8]. To detectpotential morphological alterations, I will use a neurite outgrowth assay and monitor the expression ofneuronal markers via immunofluorescence. Rescue of the phenotypes by ectopic expression of the wild-type protein will control for the specificity of the effects. I will select the cell lines with the strongestphenotypes for additional study in aim 3. These studies will reveal how PUS enzymes impact neuronalmaturation.Aim 3—To determine neuron-specific RNA targeting by PUS enzymes. To determine the positions ofRNA binding by PUS enzymes at single-nucleotide resolution, I will perform UV cross-linking andimmunoprecipitation, followed by high-throughput sequencing (iCLIP-seq) in iNGN-derived neuronsexpressing Flag-tagged PUS enzymes. I will corroborate these results by using specific antibodies to pulldown endogenous PUS complexes. Mock-infected cells will be used as a control to exclude non-specificRNA binding. I will complement these results with Ψ-seq to confirm that the PUS-bound sites arecatalyzed. A comparison of the sites bound in stem cells and neurons will reveal neuron-specific Ψ sites.Because PUS enzymes may have multiple substrates, it may be unclear how to assign mutant phenotypesto loss of modification in specific RNA species. I will control for this variable via rescue experiments bytransfecting specific synthetic pseudouridylated RNA substrates identified by Ψ-seq experiments. Theseexperiments will reveal the Ψ landscape in neurons and identify RNA targets for future study.Summary: Successful completion of these aims will shed new light on the poorly understood but criticalroles that pseudouridylation plays in neuronal development. A potential follow-up study to investigate thefunction of Ψ in the identified RNA targets is an RNA pull-down assay. To determine the role of Ψ on thecomplex composition of RNA species, Ψ and non-Ψ RNA probes tagged with biotin can be pulled down,and the interactome can be analyzed by mass spectrometry. Future research into the biological roles ofRNA modifications will reveal novel causes of neurological disorders.Intellectual Merit: In Dr. Murn’s lab, I’ve gained the necessary training in molecular biology techniquesand RNA biochemistry to carry out this project. I am currently optimizing pseudouridine-seq and will usemy experience in this technique for this proposal. I will receive the bioinformatic training necessary tocarry out my proposal through future mentoring from Dr. Chaolin Zhang. Dr. Zhang’s lab at ColumbiaUniversity is an ideal fit because of his focus on RNA-protein interactions, RNA regulatory networks inneural development, and expertise in high-throughput transcriptomic data analysis.Broader Impacts: As a graduate student and later as a professor, I will mentor undergraduate women ofcolor and encourage them to pursue research careers. I will continue to empower young high schoolwomen by establishing additional chapters of Queens of STEAM. The support of the NSF GRFP willenable me to carry out my research while continuing STEM outreach.[1] I. A. Roundtree, M. E. Evans, T. Pan, and C. He, “Dynamic RNA Modifications in Gene ExpressionRegulation,” Cell. 2017. [2] J. Karijolich and Y. T. Yu, “Converting nonsense codons into sense codonsby targeted pseudouridylation,” Nature, 2011. [3] N. Guzzi et al., “Pseudouridylation of tRNA-DerivedFragments Steers Translational Control in Stem Cells,” Cell, 2018. [4] H. Darvish et al., “A novel PUS7mutation causes intellectual disability with autistic and aggressive behaviors,” Neurology: Genetics. 2019.[5] M. T. Angelova et al., “The emerging field of epitranscriptomics in neurodevelopmental and neuronaldisorders,” Frontiers in Bioengineering and Biotechnology. 201. [6] V. Busskamp et al., “Rapidneurogenesis through transcriptional activation in human stem cells.,” Mol. Syst. Biol., Nov. 2014. [7] Y.Shi, P. Kirwan, and F. J. Livesey, “Directed differentiation of human pluripotent stem cells to cerebralcortex neurons and neural networks,” Nat. Protoc., Oct. 2012. [8] K. I. Liu et al., “A chemical-inducibleCRISPR-Cas9 system for rapid control of genome editing,” Nat. Chem. Biol., 2016."
51.0,"topologically relevant materials. Successful execution of this approach will lead to new materials discoveryand generate new methods for electronic band structure engineering.Introduction: Linking desired physical properties to structural motifs is a fundamental goal in solid-statechemistry. As we will see, topological semimetals are exemplars to this goal: ultrahigh mobility electronsarising from linear band crossings can be derived from specific structural motifs, further predicted frombasic electron counting rules1. Previous work regarding topological materials has largely focused onsystematically scanning the thermodynamic stability of compositions in particular space groups, followedby selected synthesis of the most promising candidates. More recently, scientists have explored how slightperturbations of topological systems can induce charge density waves through structural modulationsrationalized via electronic considerations.2 That is, seemingly simple chemical substitutions used as n- orp-type dopants, aimed to adjust the Fermi energy to lie in a precise electron state.Changing the composition of a structure may induce a structural change, such as a Peierls distortion,which would open a up bandgap at the Fermi energy. Further, exactly how a given structural transitionnavigates its potential energy surface to form such specific distortions is largely unexplored in the literature.Finally, even if such chemical substitution does not significantly alter a structure, development of predictivestrategies for diversifying the possibilities of elemental substitution should be developed. Exploringsynthetic control over such distortions in topological materials can provide one such prescription to theseissues. Thus, understanding how such distortions lead to thermodynamic favorability, paired with how suchdistortions alter physical properties, may then open a playbook for “band engineering” where finely tuningcomposition can gap out unwanted bands from the Fermi surface.Background: Topological materials can be well understood through the Zintl-Klemm concept: an electroncounting method where transfer of electrons is assumed from the most electropositive element to the mostelectronegative element in a crystal structure. The remaining atoms then form covalent networks to reducethe total thermodynamic energy of the system. In Figure 1a, a Walsh diagram shows the thermodynamicstability of a Te chain as a function of bond angle. The linear geometry is found to be stabilized at 223electrons, the third level, due to less overlap of anti-bonding interactions. In extended solids, it would thenbe predicted that linear chains form when there are 7 electrons per chain atom. Such is the case in UTe ,2seen in Figure 1b, a promising candidate host for the sought-after Majorana quasi-particle.1 Each uraniumis found to be in the 3+ oxidation state and transfers two electrons to the nearest tellurium sites, formingwhat can be thought of as [UTe]+ slabs and a linear Te- chain. As a result, the geometry enforces a linearcrossing at the Fermi energy, shown in Figure 1c. Doubling of the unit cell, when considering 2 atoms perunit cell, folds the band structure back on itself creating a linear band crossing located at the Fermi energy.Figure 1. a) A Walsh diagram of a Te molecular unit. b) The unit cell of UTe , a topological3 2superconductor containing linear chains. c) The resulting band structure for an isolated linear chain of Te-ions. A linear crossing at the Fermi energy occurs halfway between the Γ and Ζ points. d) A folded bandstructure, arrived at by doubling the unit cell, forming a Dirac node at the Fermi energy.Proposal: Derivation from ideal electron counts in such covalent networks can lead to a structuraldistortion. In the classical example of a linear chain of atomic orbitals, a half-filled band will favordimerization, leading to differing bond lengths, opening a band gap at the Fermi energy. However, recentinvestigations have found, counterintuitively, that such distortions can lead to improved topological bandstructures or high-mobility electrons. Despite a structural modulation in the square-net layer, which can beviewed as a two-dimensional linear chain, NdTe exhibits ultra-high mobility electrons and anomalous3quantum oscillation behavior1. Moreover, the distorted square nets in GdSb Te was recently shown to0.46 1.48gap out trivial band crossings, “cleaning” the band structure by retaining the screw axis associated withits structural distortion.2For my analysis of similar systems, I will utilize recent adaptations of Density Functional Theory (DFT)outputs that establish direct links between local features in solid state compounds and their contribution toelectronic and steric favorability. Specifically, the reversed applied Molecular Orbital (raMO) analysis aimsto fit tight-binding parameters from DFT band structure calculations. As a result, DFT-calibrated molecularorbital diagrams are visualized to explain formation of closed-shell configurations (see Figures 1a) and c)).Parallel with this, DFT-Chemical Pressure (DFT-CP) resolves local packing frustrations that can arisewithin dense atomic packings, from which the role of atomic size can be assessed. Utilization of both thesecomputational analyses can explain why a structure may obey or derivate from predictive bonding schemessuch as the Zintl–Klemm concept.3 Both raMO and DFT-CP software packages are freely available via theGNU Public License and will be used in this work. I will also synthesize and structurally as well aselectronically characterize the targeted compounds.Therefore, I will employ an iterative approach of experiment and theory to implement a frame ofunderstanding structural distortions in topological motifs, targeting the following research objectives:1. Determination of topological systems in which unexpected electron counts or steric packingfrustrations may favor charge density wave formation.2. Synthesis of candidates, as well as detailed structural and physical characterization of materials.3. Demonstration of band engineering through the tuning of new superstructures guided bytheoretical analysis.Intellectual Merit: Princeton University offers many unique multidisciplinary approaches needed to studytopological materials. In the Schoop laboratory, I have access to core instruments needed for thisinvestigation, including furnaces for solid-state synthesis, a single-crystal X-ray diffractometer formaterials characterization, a magnetic properties measurement system, and a physical propertymeasurement system with a dilution fridge. Through NSF supported opportunities, such as the PrincetonCenter for Complex Materials (PCCM), frequent collaborations will be drawn through an interdisciplinaryresearch group focusing on topological quantum matter. Specifically, the Department of Physics offersmany avenues for collaborative work in physical properties characterization with Dr. Nai Phuan Ong, Dr.Ali Yazdani, and Dr. Sanfeng Wu. There are also many opportunities through the NSF-funded Imaging andAnalysis Center which provides access to instruments such as the scanning electron microscope.Frequent collaborations outside of Princeton University will also be utilized. So far, single-crystaldiffraction data obtained for a linear chain system indicate missed satellite peaks with a modulation vectorq = 0.06a*, indicating a massive 50/3 supercell periodicity. Despite prediction of such a distortion ruiningthe metallicity of the structure, electrical transport data suggests that the system remains metallic. To thisend, a proposal has been written and sent to Dr. Yusheng Chen at Argonne National Laboratory, hopefullyto be accepted for next cycle in March of 2022. Additionally, the Schoop laboratory frequently collaborateswith scientists at Helmholtz-Zentrum Berlin such as Dr. Andrei Varykhalov at the BESSY II beamline forangle-resolved photoemission spectroscopy. Looking ahead, probing the band structure of a crystal relatedto this project may significantly improve the impact of my investigations.Broader Impacts: The predictive framework I develop will open paths to tailoring band structure throughcomposition, allowing for more control of physical properties used in technological applications. In thefuture I will expand to other structural motifs such as the square- and Kagome-nets. Finally, visualizationtools, like raMO, have chemical education implications for use in NSF-funded operations, such as PCCM’sPrinceton University Materials Academy.References:1. J.F. Khoury and L.M. Schoop. 10.1016/j.trechm.2021.04.011 Trends in Chemistry, (2021).2. Lei S.; Theicher, S.M.L.; Topp, A. et al. 10.1002/adma.202101591 Adv. Mater. (2021).3. Warden H.E.M.; Lee S.B.; Fredrickson D.C. 10.1021/acs.inorgchem.0c01347 Inorg. Chem. (2020)."
52.0,"fluorescence from satellitesAcross the globe, the terrestrial biosphere is responding to growing climate extremes, including morefrequent heatwaves, droughts, and high-impact weather events1. For North American forests, this meansincreasing physiological stress on one of the continent’s most important carbon sinks, along with the vastquantity of biodiversity that these ecosystems support. A fundamental way to understand and potentiallymitigate the ecological impacts of extreme heat and drought events is by tracking carbon uptake throughphotosynthesis (i.e., gross primary productivity, GPP), across seasons at the forest-scale2. However, large-scale monitoring of GPP is challenging when considering the highly dynamic and remote nature ofmountain biomes, which make up a substantial portion of North American biomass3. Montane landscapesexhibit vast gaps in spatial coverage of surface-level GPP measurements, along with complex topographythat makes land surface models and atmospheric tracer approaches prone to significant uncertainty4. Thus,remotely-sensed data from space present a promising tool to fill in these spatial gaps to better understandforests’ response to stress and the implications for the terrestrial carbon cycle.Traditionally, forest-level GPP has been derived from satellites using reflectance-based indices thatquantify the “greenness” of a land surface. However, the temperate and boreal forests that comprise manyNorth American mountain biomes consist mainly of evergreen conifer trees which retain their needles, andtherefore, greenness, even in photosynthetically dormant seasons (e.g., drought or winter). Thus, studiesthat use reflectance-based indices as metrics of conifer GPP face significant challenges in capturingseasonal to decadal changes of photosynthetic activity5,6. In contrast, solar-induced chlorophyllfluorescence (SIF), which is emitted by chlorophyll pigments as a byproduct of the photosynthetic processand can be measured via satellite instruments, has been shown to closely follow the seasonal cycle ofphotosynthetic production in evergreen forests7. The combination of newly available remotely-sensed high-resolution SIF data, in conjunction with measures of complex terrain characteristics (e.g., slope angle,aspect and elevation), represents a uniqueopportunity for understanding GPP overmountain biomes. In my proposed work, I willanalyze GPP derived over the Sierra Nevadamountain range in California using ground-based flux tower data, biogeochemical models,and remotely-sensed SIF and reflectance-baseddata in order to test the hypotheses describedbelow and in Figure 1.Hypothesis 1 (H1) - SIF is an improved wayto measure GPP over montane coniferecosystems compared to traditionalreflectance-based remote sensing indices.High-resolution SIF from satellites providesextensive spatial data coverage, but satellite- Fig. 1: Satellite-based SIF will be analyzed againstbased SIF has yet to be analyzed for fine-scale reflectance-based indices and modeled GPP in mountainsspatial and elevation gradients in complex to assess drought-induced stress.terrain. To test H1, I will analyze SIF data fromthe TROPOMI and OCO-2/3 satellite instruments over the Sierra Nevada range, comparing to GPPmeasured at eddy-covariance flux towers from the NSF-funded National Ecological Observatory Network(NEON) and Southern Sierra Critical Zone Observatory sites in the Sierra Nevada range. I will thencompare SIF and traditional reflectance-based indices (NDVI, EVI, CCI) to quantify differences in theirability to predict seasonal and interannual GPP as a function of elevation and terrain characteristics.Hypothesis 2 (H2) - Characterization of mountain conifer forests response to drought can be improvedwith the aid of remotely-sensed SIF. The Sierra Nevada range has consistently experienced extreme droughtconditions over the past decade; these forests’ productivity in response to drought can be estimated usingbiogeochemical models, but does the spatial resolution of a model limit its ability to resolve such dynamicprocesses over complex terrain? Based on insights from H1 and using SIF as a means of constrainingmodeled GPP, I will test H2 by comparing remotely-sensed SIF to GPP modeled using the CommunityLand Model version 5 (CLM5) over the Sierra Nevada region for timeframes with available high-resolutionSIF data, detecting mismatch between satellite- and model-derived GPP over seasonal and interannualcycles during observed drought periods.Hypothesis 3 (H3) - SIF can provide information towards early warning capabilities for forest health inresponse to drought conditions. Assuming a direct linkage between forest productivity and physiologicalstress, remotely-sensed measures of GPP could act as highly localized indicators of forest health in drought-stricken regions. Using information gleaned from H1 and H2, I will analyze high-resolution SIF data withrecent records of forest drought disturbances to quantify trends in SIF as they are correlated with droughtevents. Through this analysis I will uncover statistical relationships between SIF and drought stress in thecontext of variables such as elevation, aspect, and snow cover to determine the extent to which SIF can actas an early warning system for forest health over land-use management scales.Collaborations and Computing Resources: To complete this work, I will build on an existing NSF-funded collaboration between the University of Utah and researchers at California Institute of Technology(led by Prof. Christian Frankenberg) to access high-resolution, pre-processed topography-corrected SIFdata products over the Sierra Nevada range. I will also work with the University of California–IrvineInnovation Center for Advancing Ecosystem Climate Solutions to engage regional Sierra Nevadastakeholders in scientific discussion. To accommodate the computational needs associated with my work,I will utilize dedicated group-access nodes (purchased by advisor Prof. John Lin) on two supercomputersmaintained by the University of Utah’s Center for High-Performance Computing.Intellectual Merit – Global Carbon Budget: Remotely-sensed SIF has the potential to track forestproductivity over global scales and is a promising tool for rectifying uncertainties in the carbon budget ofmountains. My work will be among the first to examine high resolution SIF over complex terrain in orderto address uncertainties in forest drought response. As heat and drought stress grow increasingly prevalentdue to climate change, understanding the highly dynamic response of montane carbon stocks will be criticalfor improving terrestrial biosphere models that inform global climate policy. Forest Management: Highresolution SIF can help diagnose features of forest wellbeing and tree mortality at scales meaningful to landuse management. Through assessment of H3, I will examine how SIF can be used to provide early warningcapabilities for near-term forest disturbances and allow land managers to adapt to rapid changes in foresthealth from critical stress events. These capabilities ultimately aid in emergency preparedness capabilitiesto mitigate damage from wildfires and bark beetle die-off.Broader Impacts – Stakeholder Engagement: The U.S.D.A. Forest Service Region 5 and SierraNevada Conservancy have a vested interest in central California’s forest health and wildfire management,motivated by public protection, forest resource care, and conservation advocacy. In addition, the CaliforniaAir Resources Board is seeking accurate methods to estimate forest carbon stocks for implementation ofcarbon accounting policies. Through collaboration with UC–Irvine (see above), I will engage stakeholderrepresentatives from these institutions through ongoing virtual correspondence and regularly heldstakeholder meetings to disseminate my findings on forest drought response and early warning capabilities.Code Sharing: As I have already done in my previous publications, I plan to provide open access to R andpython scripts to the entire research community produced through my personal Github webpage(github.com/lkunik).References: [1] IPCC 6th Assessment Report, (2021) [2] E. Tomppo, et al. (2021) Remote Sens. 13, 597.[3] D. Schimel, et al. (2002) Eos Trans. AGU. 83(40), 445–449. [4] M. Rotach, et al. (2014) Bull. Amer.Meteor. 95(7), 1021-1028. [5] K. Springer, et al. (2017) Remote Sens. 9, 1–18. [6] D. Sims, et al. (2006) J.Geophys. Res. 111, G04015. [7] T. Magney, et al. (2019) Proc. Natl. Acad. Sci. 116(24), 11640-11645."
53.0,"Background: The Bushveld Complex is located in South Africa and was emplaced approximately 2.056Ga. It is the largest layered mafic intrusion in the world, covering an area of 65,000 km2 with a thicknessranging from 7-9 km1. The Bushveld is an important resource for the world, hosting major quantities ofplatinum and platinum group elements (PGE), titanium, iron, vanadium, tin, and chromium2. The mafic toultramafic cumulate sequence of the complex is called the Rustenburg Layered Suite (RLS) and is dividedinto five zones: Marginal, Lower, Critical, Main, Upper, and Roof Zones. The Upper and Upper MainZones (UUMZ) are genetically related to each other and are separated from the lower zones by a layerknown as the Pyroxenite Marker (PM)3. The UUMZ hosts the most significant Fe, V, Ti, and P deposits2.The UUMZ is dominated by gabbro, anorthosite, and Fe-Ti-oxide rich rocks, which includemagnetitite (magnetite and ilmenite) and nelsonite (magnetite, ilmenite, and apatite) mineral assemblages.Fe-Ti-oxide rich rocks make up the smallest proportion in the UUMZ but host the majority of economicallysignificant minerals. The Fe-Ti-rich rocks are typified in 26 magnetite and 6 nelsonite layers documentedin the western limb4; the same number of magnetite layers have also been mapped in the eastern limb3.The gabbro layers in the UUMZ are thought to have been formed by cooling and differentiation ofthe residual magma that produced the Pyroxenite Marker. However, the evolution and relationship betweenthe anorthosite and magnetite/nelsonite layers is still poorly understood. Several models have beenproposed to explain the genesis of these layers, including: immiscibility, fractional crystallization/mineralaccumulation, disequilibrium crystallization, chamber rejuvenation and magma mixing, and hydrothermalenrichment2-6, 9. However, no consensus has been reached as to which model may most accurately describesthe petrogenesis of the Fe-Ti-oxide rich layers because each authors’ interpretation of the data has in turnbeen challenged by other workers.Objective: To apply new techniques and ideas developing in magma chamber research to the magnetitelayers in the Upper Zone of the Bushveld Complex and use the new datasets to test models for developmentand differentiation of UUMZ layers. The results will be applied to magnetite pipes that have similar mineralassemblages to the magnetite layers, but have contested origins.Hypothesis: Testing different previously proposed models for the origin of Fe-Ti-oxide rich magnetite andnelsonite layers in the Bushveld Complex will result in a new model that combines certain aspects of theseend-member processes to more accurately define the petrogenesis of the oxide-rich layers.Methods: The western limb will be studied via samples from the Bierkraal cores and the magnetite layersin the eastern limb will be sampled during field-mapping. Bulk rock geochemistry analyzed with x-rayfluorescence (major elements) and LA-ICPMS (trace elements). Mineral compositions will be analyzed byEPMA and LA-ICPMS; the data will be integrated with photomicrographs collected using optical andscanning electron microscopy.Testing models: Immiscibility. Silicate liquid immiscibility occurs when a homogenous silicate meltseparates into two compositionally distinct liquids with identical mineralogy but in differing proportions.In mafic layered intrusions, this process begins after considerable crystal fractionation, resulting in a crystalmush. If the permeability of the crystal mush is high, liquid may separate by gravity, producing nearlymonomineralic layers5,6. The presence of Fe-rich silicate inclusions in minerals such as plagioclase andapatite is evidence for liquid immiscibility. If the Fe-Ti-oxide rich layers formed through immiscibleprocesses, then the crystallized Fe-rich melt inclusions will have major and trace element content similarto the magnetite layers. Additionally, the host mineral that crystallized from the Si-rich melt will have lowerREE, HFSE, P, Ti, and FeO contents than the conjugate Fe-rich inclusions7.Fractional crystallization/mineral accumulation. Fractional crystallization of magma will lead to adense residual magma that will begin to crystallize magnetite and accumulate into magnetite-rich layers.The resulting magma after magnetite crystallization will have a lower density and rise buoyantly continuingthis process. If fractional crystallization occurred, a fractionation trend will be recorded in minerals withincreasing height in the section. Consequently, stratigraphically higher magnetite and anorthosite layerswill have increased iron enrichment, lower plagioclase An%, lower Mg# in pyroxene and olivine, lower Vcontent in magnetite, and higher whole rock SiO wt%4. Additionally, in a closed system with continuous2fractionation, incompatible elements become more enriched and compatible elements depleted withincreasing stratigraphic height. In magnetite, this will be recorded as decreased Ti, V, and Cr (compatibleelements) and increased Si and Ca (highly incompatible)8.Disequilibrium crystallization. Another idea proposed for the genesis of magnetite-rich layers israpid crystallization in disequilibrium conditions in response to increased oxygen fugacity (ƒO ) towards2the base of a magma chamber. As magnetite crystallization progresses, ƒO is lowered. Vanadium (V)2partitioning between magnetite (mt) and clinopyroxene (cpx) can be used as a proxy for oxygen fugacity,as it is sensitive to changes in ƒO . If V /V increases, this corresponds to decreasing ƒO 2. Additionally,2 mt cpx 2if the Fe-Ti-oxide layers crystallized instantaneously in high ƒO , Mg, Al, and Si contents will be relatively2enriched in magnetite from these layers compared to disseminated magnetite in anorthosite/gabbro layers9.Chamber rejuvenation and magma mixing. If new magma was injected periodically during theemplacement of the UUMZ to form the distinct Fe-Ti-oxide rich layers, step-like changes in mineralcomposition through a vertical unit, rather than a smooth fractionation trend, will be observed. Also, if thenew magma is more primitive than the final fractionation stages of the previous injection then compositionalreversals will be observed moving up-section. Compositional reversals in magnetite will be seen as higherCr and V contents followed by an abrupt change to lower content4.Hydrothermal enrichment. This model is particularly applicable to the magnetite pipes that have avertical structure. If the Fe-Ti-oxide rich layers formed by hydrothermal enrichment rather than having amagmatic origin, magnetite will be depleted in Ti, Al, and HFSE, as hydrothermal fluids have generallylow concentrations of these minerals due to their relatively low solubility. In contrast, magmatic magnetitewill be relatively enriched in compatible elements. Silicon and Ca are two elements that are highlyincompatible with magnetite, so if these are enriched in the samples, it suggests hydrothermal activity.Another characteristic of magnetite that is indicative of hydrothermal enrichment is if the Ni/Cr ratio is >1(in silicate magmas this ratio is always less than one)9. In addition, photomicrographs of magmaticmagnetite commonly show concentric compositional zoning in contrast to patchy textures common ofhydrothermal minerals9.Intellectual Merit: The UUMZ contains world class deposits of important strategic elements includingvanadium, iron, and titanium. There are limited global resources of these minerals and global demand isgrowing exponentially2. Understanding how these ore deposits form is critical both globally and to U.S.interests, as the country is dependent on foreign sources for many of these important commodities. Thereis still much debate about the formation of magnetite layers in the Bushveld Complex, even though theyhave been identified and studied for many years. Results from this research may be applied to other partsof the extensive Bushveld Complex, as well as to other layered mafic intrusions around the world.Broader Impacts: Impacts of this research of magnetite layers of the Bushveld Complex extend beyondEarth. One of the most exciting endeavors of the last century, sending humans to outer space, has propelledscientific curiosity perhaps more dramatically than any other scientific activity. As interest in deep-spaceexploration and establishing a human presence on Mars and other planets increases, so has the need tounderstand the processes of ore-deposit formation and exploitation. Lessons learned about thedifferentiation of magnetite layers in the Bushveld Complex may provide insight and strategies for sourcingiron and titanium (and other metals) that are crucial to permanent infrastructures, but are not cost effectiveto send from Earth.Results from my research will be shared with colleagues through publications and presentations atconferences, including the national GSA and AGU conferences. Additionally, one of my long-term goalsis to provide educators with resources they can implement in their classrooms to encourage curiosity intheir students and create lifelong learners who can contribute to scientific advancement. Applying ore-forming processes to ideas of colonization on other planets offers the potential for stimulating STEMactivities that can be leveraged into K-12 educations to increase engagement in science. Potential projectstopics could include what would be required to mine resources on another planet, requiring students toengage strategy and research, and in the process hopefully garner a lifetime of scientific curiosity.[1] Zeh et al. (2015) Earth Planet Sci Lett, v. 418, p. 103-114 [2] Fischer (2018) PhD Dissert., 129 p.[3] Scoon and Mitchell (2012) S Afr J Geol, v. 115.4, p. 515-534 [4] Tegner et al. (2006) J Petrol, v. 47, p.2257-2279 [5] Cawthorn (2015) in Layered Intrusions, p. 515-587 [6] VanTongeren and Mathez (2012)Geology, v. 40, p. 491-494 [7] Veksler et al. (2006) Contrib Mineral Petrol, v. 152, p. 685-702[8] Dare et al. (2014) Miner Depos, v. 49, p. 785-796 [9] Klemm et al. (1985) Econ Geol, v. 80, p. 1075-1088"
54.0,"the environment, our previous knowledge, and our underlying motivation in order to makegoal-directed choices. Several brain regions are recruited in this decision-making process. Themediodorsal thalamus (MD) has been shown to be necessary for cognitive tasks like workingmemory and goal-directed decision-making1. The mediodorsal thalamus (MD) takes higher order​​feedback and sensory information and relays it to the orbitofrontal cortex (OFC) and basalganglia (BG). The orbitofrontal cortex (OFC) is necessary for value-based decision-making andinferring2. The OFC sends projections to the striatum, the input nucleus of the basal ganglia,​​which is needed for action performance3.​​While there is evidence that both OFC and MD project to dorsal striatum 4, how and what​​information is being sent or modulated through these paths is less clear. I plan to use transgenesand recombinase technologies to limit the expression of a fluorophore or a calcium indicator in acell-type and projection-specific manner to measure the interactions between these regionsduring a decision-making task. I hypothesize that distinct sensory and valuation information​processing is occuring in OFC and MD. These aims address how information in cortico-basal​ganglia-thalamic (CBGT) loops is being passed on and selectively used to controldecision-making.Aim 1: Characterize the cortico-thalamic-basal ganglia circuit using anatomical tracing.​Previous research has focused on individual streams ofinformation from the thalamus to prefrontal cortex5. However,​​there have been no studies examining overlapping OFC andMD collaterals in striatum. I seek to address how OFC andMD projections are overlapping. In order to understand howinformation is flowing through this particular CBGT loop, Iwill first conduct an anatomical study. I will performstereotactic surgery in mice, which I have previously done inthe Gremel lab6. I will inject two adeno-associated viruses​​ ​into the mice: a retrograde Cre-GFP in DS and aCre-dependent mCherry in MD. After waiting for adequate​viral expression, I will visualize the neurons usingfluorescence microscopy. The presence of mCherry labeledMD terminals in OFC would indicate that those MD neuronsproject to both OFC and DS. The same strategy will be usedto look for OFC neurons that synapse onto both MD and DS.This anatomical information (Figure 1) will inform how to​ ​proceed with functional investigations; if the same neuronsare synapsing in OFC and DS (or MD and DS), there may bean interesting mechanism controlling behavior. An undetermined portion of thalamostriatalneurons synapse onto inhibitory interneurons, so there is a possibility that they function as aclamp to perform gain control on the information coming from OFC. If I do not see overlap ofcollaterals in the microcircuitry of striatum, I intend to investigate how MD is contributing toholding information in a decision-making task.Aim 2: Examine the activity of MD and OFC neurons synapsing in striatum during a​ ​self-initiated decision-making task.To examine how MD and OFC are synapsingin striatum, I will use genetically encoded calciumindicators (GCaMP and RCaMP) as a proxy forsynaptic activity in behaving mice. I will performfiber photometry to measure calcium activity in twogroups of mice, one group with MD and DS, andanother with OFC and DS. I will use anaxon-targeting GCaMP in the MD and OFC andRCaMP in the DS so I can simultaneously recordfrom both populations (Figure 2). To look at specific​ ​cell types, I will restrict RCaMP expression in DS toeither indirect or direct pathway medium spiny neurons (iMSNs or dMSNs). These methods willallow me to look at how the activity in the MD or OFC is related to the two striatal outputpathways. Mice will be trained to hold down a lever for a specific duration in order to earn afood reward. I hypothesize that information may be accruing actively over the period of holding​down the lever, and this information may be maintained through the MD. Calcium transients will​be examined around lever press initiation/stop and reward delivery. I will compare the transientsover time (days of learning) and between MD, OFC, and DS to examine decision-makingcomputations that may be supporting behavior. We will use regression analyses to quantify thedependency between the activity of MD and DS and OFC and DS when the animal is deciding tolet go of the lever. I expect that there is more correlation in MD-DS when the animal holds downthe lever long enough to earn a reward.Intellectual MeritThis work will provide insight on circuitry underlying decision-making. The findings willalso inform how neurons integrate information and use that integrated information to generateactions. Results may provide insight into circuit motifs like gain control that allow for rapidproblem-solving, potentially applicable to other neural circuits and artificial intelligence.Broader ImpactsFindings may inform the development of treatment for disorders where appropriate actionselection is disrupted- OCD, mood disorders, schizophrenia, and addiction, hopefully improvingwell-being. Treatment for these diseases may mitigate the cost of disability in the US and helpour economy grow by including more people in the workforce. Moreover, funding this projectdirectly ensures the full participation of myself, a woman with a disability, in STEM.Results will be shared in peer-reviewed publications and at conferences, and will also beshared with the general community by writing blog posts for NeuWriteSD7. I will also share my​​research and general scientific topics through demonstrations at K-12 schools and at communityevents with all ages. I am excited to have matched with a ""pre-scientist"" 6th grade pen pal, andwe are exchanging letters about going to college, overcoming obstacles, and scientific careers.All of this outreach generates curiosity and better scientific literacy in the general public.References1 ​ Hallassa & Kastner, Nat Neuro (2017). 2 ​Gremel et al., Nat Comm (2013). 3 ​Yin, Neuroscientist (2017). 4 ​Hunnicutt​ ​ ​ ​ ​ ​ ​ ​ ​et al., eLife (2016). 5 ​Parnaudeau et al., Biol. Psychiatry (2018). 6 ​Baltz et al., eLife (2018). 7 ​neuwritesd.org​ ​ ​ ​ ​ ​ ​ ​"
55.0,"Intellectual Merit: Inspired by the adaptability of biological organisms, soft robots haveemerged to address some of the technical limitations of conventional rigid robots. Although rigidrobots are remarkably capable at high-precision and load-bearing tasks, their stiff materialproperties, with a Young’s modulus in the range of 109 – 1012 Pa, inherently limit their ability tophysically interact with their environment. In contrast, soft robots are composed from gels,fluids, and elastomers with a Young’s modulus of 106 – 109 Pa. These soft materials mimic themechanical properties of biological tissues and can bend, stretch, and compress.This ability to conform is key for applications in human-robot interaction, biomedicaldevices, and space-restricted environments. For example, a rigid wearable accessory has limitedplacement locations that are both comfortable for the user and informative for the device. Incomparison, a soft wearable device, that can compress and stretch, greatly increases compatiblelocations and therefore potential applications, such as biometric monitoring or activity tracking.These advantages have also been shown to enable successful applications in medicine, such asorgan-assist sleeves, drug delivery, prostheses, and surgical tools [1].However, soft robot applications still face prevalent barriers to improved functionalityover rigid robot solutions. The same material properties that give soft robots their versatility alsocreate challenges in actuation, control, sensing, and modelling. In contrast to rigid systems with asmall number of joints, soft robots possess many more degrees of freedom due to theircontinuous elastic bodies. In order to fully understand their environment, soft robots requireeffective sensing tools in a stretchable format. However, soft and stretchable sensing solutionshave only been recently developed for strain and pressure sensing. The lack of sensoryinformation has resulted in the absence of sensor-based control and higher-level decision makingthat would be customary for a rigid robot [2].The Soft Machines Lab at Carnegie Mellon University led by Professor Carmel Majidimade a breakthrough in soft robotic sensing capabilities by demonstrating a hybrid soft sensorskin with orientation, pressure, temperature, and proximity sensing processed on-board [3].Finally armed with multimodal sensing to determine the soft robot’s environmental and internalstate, a unique opportunity has arisen for the development of sensor-based control for soft robots.Proposal: As part of the team that developed the soft sensor skin in [3], Iwill build on our previous work and implement sensor-based control of arobotic arm and gripper using the sensor skin. This will serve as the firstdemonstration of the feasibility of sensor-based feedback control on thissoft robot system. The approach can then be extended to a wider range ofsoft robotic systems, which I will further explore in my graduate research.I. Physical System: The sensor-based control system will be implementedon a robotic arm and elastic sensor skin adhered to a two-finger softFig. 1: Hybrid soft sensorgripper. The sensor skin will have two soft strain sensors made of liquidskin described in [3].metal traces, a time-of-flight (TOF) sensor to measure distance, an IMU, and an on-boardmicroprocessor to process sensor data. The strain sensors will be located on each of the innerfingertips to detect the presence of the object. The TOF sensor will be placed on the palm of thegripper, parallel to the scanning surface. The IMU will be placed next to the on-board processor,which will be located at the top of the gripper, to sense the gripper’s orientation. The sensor skinwill be connected to a computer hosting a finite state machine to sequence behaviors. Thecomputer will be connected to the robotic arm, so that the finite state machine can generate itsmovement.1II. Control System: The sensor-based control system will consist of two main components.i. TOF data processing: The gripper will scan the table in uniform rows, collecting TOF data tocreate a 2D array of distance measurements. This 2D array can then be analyzed as an imageusing OpenCV to identify the size, orientation, and location of each object on the table. Thedevelopment of this TOF algorithm is crucial to the development of soft robot feedback controlby allowing for rudimentary image processing when camera sensors are inaccessible.ii. Finite state machine: The robot arm and gripper will be controlled by a finite state machine(FSM) that uses sensor input to govern the state. The size, orientation, and location of the objectwill be determined by the TOF algorithm in the first state. After the object has been identified,the strain, IMU, and TOF sensor data will be used to sense the presence of the object in the graspof the gripper. The presence or absence of the object would inform the system of a successfulgrasp, lift, transport, or release of the object. This information will be used to traverse the statesof the system. The FSM will demonstrate basic autonomy with feedback control of a soft system.III. Testing: The performance of the sensor-based control of the robotic arm and gripper will betested against an open-loop robotic arm and gripper in a grasping and placement task. Objects ofvarying size will be placed on a flat surface in front of the gripper. The gripper and robot armwill be programmed to have four potential actions: grasp, lift, move, and release. The open-loopsystem will use provided object locations and complete each of the actions strictly in sequence.The sensor-based control system will not have prior information about object locations; instead,it will use sensor data to determine the object locations after scanning the workspace. Thesensor-based control system will also have the opportunity to decide whether to move onto thenext action or repeat previous actions based on sensor data. The success rate of grasping, lifting,placing, and overall task completion for each system will be compared over multiple trials.One potential challenge with this system is noise from ambient light conditions affectingthe accuracy of the TOF data. Because the system relies on the TOF data to locate and interactwith the object, the accuracy of this data is crucial. A potential solution would be calibrating theTOF sensor to the specific environment that it will be operating in.Broader Impacts: This proposal addresses a key challenge in the control of soft robot systemsby demonstrating a novel implementation of sensor-based control using a multimodal sensingskin. A successful demonstration will further push the boundaries of control and autonomy in thefield of soft robotics, as well as provide a platform for more complex control architectures in thefuture. These advancements are necessary for ubiquitous soft robots in everyday life; forexample, soft robot applications in the care and improved quality-of-life for the elderly.One practical application for this specific soft robot system consisting of a sensing skin,soft gripper, and robot arm would be to sort and grasp food objects in a food processing facility.The soft gripper would be better-suited to handling delicate food objects than a rigid gripper,which would reduce the amount of damaged food from handling errors. The sensor-based controlsystem would allow for unsupervised operation, as expected in a modern facility.In addition, this project could be demonstrated in STEM outreach to inspire interest inSTEM from K-12 students. Because the differences in performance of this system could beeasily seen and understood with little technical background, and the task of grasping and placingis familiar, this demonstration would be particularly well-suited to a young audience.[1] M. Cianchetti, et al.,""Biomedical Applications of Soft Robotics."" Nature Reviews. Materials 3.6 (2018): 143-53.[2] T. Thuruthel, et al.,“Control Strategies for Soft Robotic Manipulators: A Survey,” Soft Robotics, Vol. 5, No. 2(2018).[3] T. Hellebrekers, K. B. Ozutemiz, J. Yin and C. Majidi, ""Liquid Metal-Microelectronics Integration for aSensorized Soft Robot Skin,"" 2018 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS).2"
56.0,"Title: Energy-information trade-off in vocal developmentBackground: Vocal development is the result of interactions among several biomechanical andphysiological processes, all of which are constrained by energy. Our attempts to understand howall these mechanistic pieces are coordinated over postnatal life is thus a formidable challenge.While the importance of energetic costs in development is obvious, we must also consider thatthese costs must be traded-off with information transmission: human infants and other animalsuse vocalizations (e.g., cries, contact calls) to solicit care from conspecifics. How these costs aretraded-off during development has not been considered, yet it could provide a common, high-level framework across species within which low-level mechanistic findings may be interpreted.I propose to investigate whether a model that considers energy and information trade-offs bestpredicts the shape of vocal developmental trajectories in mammals; I will then test the model’spredictions with empirical data.Three different models could potentiallyexplain the trajectory of vocal development, andeach can be characterized mathematically using acost function. The first model is through a constantand progressive change (Fig. 1a,d). The secondmodel relies on a strong initial change followed byslow adaptation (Fig 1b,e). Both models can ac-count for associative learning. The second modelcan also account for bodily growth in at least 60species3. The third model considers development Figure 1. Model schematics. (a) First model: linearas stepwise (Fig 1c,f). Using data from three dif- shift of the cost. (b) Second model: cost modeledferent mammalian species—marmoset monkeys1,2, through recurrence equation4. (c) Third model: twobats5 and humans6,7, all of which exhibit vocal fixed costs balance each other. (d) Linear change.learning—I extracted four standard acoustic fea- (e) Gradual change. (f) Stepwise change.tures (call duration, dominant frequency, amplitude modulation frequency, and Wiener entropy)and calculated their principal component to generate one single acoustic measure. Using thatmeasure, I found that the best model is the stepwise model. The adjusted R2 for the linear, gradu-al and stepwise model are shown in Fig. 2. The stepwise model is also the only one able to accu-rately predict the day of transition between immature and mature-sounding vocalizations. It willtherefore serve as the model for investigating the constraints that shape vocal development.Hypothesis: The stepwise transition of vocal output is predicted to be shaped by physiological(energetic) and social (informational) con-straints. These can be manipulated inde-pendently to determine how each mightinfluence development. Aim 1: Testwhether energy changes the transition tim-ing in marmoset monkeys. One factor in-fluencing the energy required to vocalize isrespiratory power, thus lighter air shouldreduce its energetic cost. I will fit the Figure 2. Model fitting. (a) Marmoset monkey. (b) Egyptianstepwise model with vocal data collected fruit bat. (c) Human.while infants were in a helium-oxygen (lighter air) during brief daily sessions over 2 months andcompare it to data outside the helium-oxygen chamber (regular air). Aim 2: Test whether the in-formation transmission changes the transition timing in marmoset monkeys. Efficient infor-mation transmission is characterized by how well the infant’s vocalization can be used to predictthe parent’s vocalizations. I will fit the stepwise model with infant vocal data recorded in ses-sions with high versus low levels of parental feedback over 2 months2.Methods: To achieve aim 1, I will study energetic manipulations using vocalizations recorded ina heliox chamber8. Heliox (20% O and 80% He) has a lighter mass than regular air, so the ener-2gy required to pump the air out of the lungs is lower. Marmoset infants are placed for 20 min in achamber that holds 45 L of air, and their vocalizations are recorded. To achieve aim 2, I will usevocalizations from infants placed in a 20-min playback condition, in which infants receive audi-tory feedback from a closed-loop playback sys-tem11. The infants receive either the father’s orthe mother’s mature calls. With the closed-loop system, we can control the amount ofcontingent playback they will receive, thusmanipulating the rate at which infants canchange the informational content of their vo-calizations. Figure 3. Schematics of energy cost manipulation. (a)Results Evaluation: I can use the stepwise Higher and (b) lower cost. (c) Simulation using costsmodel to predict the change in the transition from (a) and (b).day when either the energy or information cost is manipulated (Fig. 3). That change will be com-pared with the change obtained in the experiments. In aim 1, by decreasing the energy cost in theheliox chamber, the transition day should happen later. By decreasing the information cost in aim2, the transition should happen sooner. If the predictions do not hold, then either the constraintsof the model are not energy and information, or the way they constrain development is not theone proposed by the model. In the first case, I can investigate other possible constraints, for ex-ample, how differences in the environment affect development. In the second case, I can check ifvariations of the model (such as a different cost shape) can better explain the data.Intellectual Merit: The project has the potential to explain how vocal learning can happen inmarmoset monkeys and likely other species, including humans and other vocal learners. It incor-porates different factors important for vocal development into one framework, highlighting theimportance of the body and the environment into behavior. The stepwise model is also general-izable to other behavioral systems (e.g., locomotion), and thus potentially useful to describe thetransitions we see when categorizing any behavior into different stages.Broader Impacts: Low socioeconomic status populations have a higher incidence of speech-language impairments, such as reduced vocabulary and phonological awareness9. A better under-standing of vocal development can meaningfully inform intervention programs. For example, itcan be used to measure how diet (energy) versus social interaction (information) lead to healthyvocal development. The computational nature of my project allows me to involve undergraduatestudents early on in my research. This will be facilitated by the ReMatch program at Princeton,that encourages first and second-year undergraduates to do research. The subject is engaging dueto the natural curiosity around how humans and other animals communicate. Moreover, I willdisseminate my findings in scientific meetings as well as in forums accessible to the public (in-cluding video lectures).References: 1Takahashi et al., 2015. 2Takahashi et al., 2017. 3Renner-Martin et al., 2018. 4Fehér et al., 2009. 5Prat etal., 2017. 6Cruz-Ferreira, 2003. 7Brent et al., 2001. 8Zhang and Ghazanfar, 2018. 9Perkins et al., 2013."
57.0,"between a treatment and control group – has come to be understood as the gold standard for scientificsettings where the end goal is intervening in some process to achieve a desired end, as in geneticengineering, clinical trials or public policy design. This is for good reason: causal inference is a techniquefor identifying the precise impact of a given intervention on the target outcome, which is essentiallyimpossible otherwise due to issues of confounding. Nonetheless a number of issues still plague causalinference as a method of inquiry. Perhaps the most important is failure to generalize. We see thiseverywhere from MPRA estimated gene expression not predicting measured expression in cells [1] to thenumerous nudges that work well in laboratories and fail when scaled [2]. Often these issues ofgeneralization are related to a shift in the underlying population tested in the lab and the actual populationintervened on. This means there is a deep connection between understanding when we should expecttreatments to translate to results and out-of-distribution prediction problems in the machinelearning literature. The second major problem with causal inference it is not integrative: informationfrom one experiment rarely if ever informs our understanding of another experiment on a similarpopulation. A clear consequence is that causal inference has produced a fractured landscape of treatmenteffects without real theoretical connections, especially in the social sciences. Using latentrepresentations of experimental units would allow for multitask learning which would effectivelyshare information on treatment responses across treated units.Related Work Machine Learning and causal inference is an emerging intersection with tremendouspromise. Most work in the literature is focused on understanding treatment heterogeneity within a givenstudy. Usually this is done by building a model to predict the outcome for treated and control units, thenusing that model to predict counterfactual treatment or control outcomes for each unit and taking thedifference. The distribution of these differences captures the degree of treatment heterogeneity, which isoften of interest especially in medical contexts where it is important to know if treatment effects aredriven by broad effects or much higher than average effectiveness in some sub-group. Within thisliterature the closest work to my proposal is [3], which attempts to learn representations to improve thequality of these counterfactual predictions but does not focus either on out-of-distribution predictions forunderstanding generalization or learning representations for multiple experimental treatments.Proposal Toward extending the literature on machine learning and causal inference to address thegeneralizability of treatments and allow sharing of information across treatment effects I propose to uselearned representations of experimental units to allow for out-of-distribution prediction with calibrateduncertainty estimates and multi-task learning. Calibrated uncertainty in individual predictions shouldallow extrapolating from the experimental setting to the population of interest and looking at theconfidence intervals to understand the expected range of outcomes. Multi-task learning, and in particularusing a shared latent representation across experiments should enforce information sharing acrossdifferent experimental settings, formally allowing the results of treatment in one experiment to inform theanalysis of other experiments.Research Plan Much of my work up to this point has been on representation learning of regulatory DNAand of political beliefs. In the political context I have found that even without tuning, representations canprovide more robust out-of-distribution prediction. Along similar lines I have found that multi-tasklearning of latent representations also improves the out-of-distribution predictions. In the genetics contextmy work has shown that Gaussian processes offer well calibrated uncertainty estimation on samples farfrom the training distribution.Aim I: Before digging deeper into method development I want to confirm these insights hold across othercontexts. Does multi-task learning improve the quality of latent representations for out-of-distributionprediction in genomics as well as politics? Do Gaussian processes still provide well calibrated uncertaintyif treated units are companies instead of basepairs? More generally I plan to build simulations to explorethe dimensions of when and why these ideas hold up and hopefully to develop supporting theory.Aim II: After confirming the results from my pastwork I want to extend these insights to develop aframework for embedding causal inference in deeplearning. To build the learned representations I planto explore Variational Auto-encoders, Auto-Encoding Generative Adversarial Networks, andcomparing to a baseline using multitask learningdirectly and taking the last shared layer as the latentrepresentation. The core idea is to use these latentrepresentations to predict the outcomes for eachunit in the control and treated conditions. Becauseof their high-quality uncertainty estimation, I planto use Gaussian processes to make thesepredictions. Of course, if the learning of the latentrepresentations is completely independent of outcome prediction there will be no information sharingacross tasks. So, I am going to leverage another property of Gaussian processes: their differentiability. Iplan to split training into two phases. The first unsupervised phase will just focus on training the auto-encoder for learning representations. The second phase will optimize the latent space for the predictingthe outputs for all experimental settings simultaneously, updating the auto-encoder by back-propagatingthrough the Gaussian processes (in the figure these are the yellow arrows pointing to outcomes).Aim III: This framework is only useful if it actually works in practice. I want to conduct replications ofseveral randomized trials that were first tested in the lab and then scaled. In particular I want to examinedeworming studies from development economics [4], fixed/growth mindset work from the educationliterature [5], and α-1 adrenergic receptor antagonists for COVID-19 treatments [6].The first of these failed to scale, and the second succeeded with limited effectiveness, and the third is anexample where the experiment only involves older men but the target population for intervention is thegeneral public. If my method correctly recovers the average treatment for these experiments, it wouldconfirm the value in robustly extrapolating before taking the costly step of scaling treatments.Intellectual Merit Should my approach to out-of-distribution confidence intervals prove successful itwould have significant implications for the machine learning literature. Similarly, if integratinginformation across experiments proves useful for estimating treatment effects that will be very significantfor work in causal inference, transforming the way we think about randomized trials. Instead of one-offexperiments we could engineer large models that integrate as many effects as possible to mutuallyimprove our understanding. Even if my main approach does not work as expected, in the process ofcompleting this research, I will certainly be able to contribute to our understanding of when out-of-distribution prediction is easy and when it is hard, and to the literature on learning representations.Broader Impacts Understanding when and how treatments effects will generalize when scaled upsignificantly is a crucial question in clinical settings and in public policy. If I am able to establish aframework that allows for more precise estimation of treatments when scaled it could greatly improve ourunderstanding of who drugs are effective at treating, allowing greater patient understanding of expectedoutcomes and uncertainty. It would also improve the design of government programs, and the cost ofdesigning government programs if extrapolation could substitute for running full scale experiments.References [1] de Boer, Carl G., et al. ""Deciphering eukaryotic gene-regulatory logic with 100 millionrandom promoters."" Nature biotechnology 38.1 (2020): 56-65. [2] Rai, Tage S. ""Honesty “nudge” fails toreplicate."" Science 368.6488 (2020): 279-280. [3] Johansson, Fredrik, Uri Shalit, and David Sontag.""Learning representations for counterfactual inference."" International conference on machine learning.2016. [4] Miguel, Edward, and Michael Kremer. ""Worms: identifying impacts on education and health inthe presence of treatment externalities."" Econometrica 72.1 (2004): 159-217. [5] Yeager, David S., et al.""A national experiment reveals where a growth mindset improves achievement."" Nature 573.7774 (2019):364-369. [6] Konig, Maximilian F., et al. ""Preventing cytokine storm syndrome in COVID-19 using α-1adrenergic receptor antagonists."" The Journal of Clinical Investigation 130.7 (2020)."
58.0,"for the Multiple Mirror TelescopeThere are planets where it rains rubies. Specifically, some planets orbiting alien suns showevidence of clouds made of corundum, which is the basis on earth for rubies and sapphires(Wakeford, 2016). This is a romantic discovery from observing exoplanet atmospheres, but morepractical research looks for possible signs of life on other planets, be it bacteria or dog in an aliensuit, in the form of combinations of molecules that indicate non-equilibrium chemistry (e.g.water, oxygen, methane, ozone). In ground based observatories, research of this nature is onlymade possible with adaptive optics (a system that corrects observations in real time by usingwavefront sensors to observe the shape of incoming light). Infrared (IR) observatories, like theMultiple Mirror Telescope (MMT) have the potential to observe these signs of life, but at presentlack the instrument sensitivity or wavelength range to achieve these goals. In collaboration withthe NSF funded project MAPS (the MMT Adaptive optics exoPlanet characterization System) Iwill test, model, integrate, and perform on sky commissioning with two IR and visiblepyramid wavefront sensors on the Multiple Mirror Telescope. This proposed upgrade to theMultiple Mirror Telescope provides observations of fainter targets yet to be observed, increaseswavelength range, and tests new wavefront sensing techniques that inform the next generation oftelescopes.Intellectual Merit :In the field of exoplanet astronomy, ground-based observations are limited by the Earth'sturbulent atmosphere, which causes incoming light to a telescope to spread irregularly over alarger area. When the object is a faint point-like source, better adaptive optics systems enableobservations of star-planet-systems that we could not have seen before. With adaptive optics(AO), observations are corrected in real time by applying a correction (calculated by wavefrontsensors) with mirrors that deform to correct the atmospheric perturbation. Figure 1 demonstratesan example of how light appears after corrections by adaptive optics at Lick Observatory, as wellas the predicted improvement to the AO system at MMT with the MAPS upgrade.Figure 1. Left : Lick Observatory image with and without applied correction to the wavefront. (Max, 2019) Right :Using Strehl (the ratio of peak intensity for an image with and without aberrations) as a metric, we can see thepredicted performance upgrade due to AO on MAPS through J and H bands (the IR regime) (Morzinski, 2018).My proposal is unique because I plan to incorporate the two wavefront sensors in asingle system with a dynamic choice of IR or visible wavefront sensing, drastically improvingimage quality for the final IR science images. The observer will choose which wavefront sensorwill provide better correction for their observation; for a source that is significantly brighter inthe IR or visible, collecting more photons means faster and more accurate corrections, which isespecially vital when the atmosphere is moving in real time. To that end, the switch to pyramidwavefront sensors will provide an additional improvement to photon collection over the presentShack-Hartman wavefront sensor installed on MMT. Additionally, two new detectors will beused for the wavefront sensors: a CCID-75 visible detector (which is new to astronomyapplications), and a SAPHIRA IR avalanche photo diode detector; both have reduced readnoiseover the current detector used for wavefront sensing with MMT (Morzinski, 2018). As shown inFigure 1, the proposed improvements to the AO system will provide a 40-50% improvementin the observed intensity in the IR as compared to the existing MMT system.Plan of Work :(1) Run an initial analysis to select our exact infrared regime. Specifically I will predictif the J band (1.1-1.4 microns), H band (1.5 – 1.8 microns), or an overlap, will be better for ourproposed targets. This will be informed by my work with the Exoplanet Characterization ToolKit, with an emphasis on the atmospheric retrieval tools contributed by Mike Line (Fowler,2018.) I will evaluate to what extent water, carbon monoxide, and carbon dioxide (the moleculeswe expect to find in our initial round of Jupiter-like targets) are observable in these proposedbands given varying host stars shining through varying planetary atmospheres. (2) Performinitial experiments to setup and test the two wavefront sensors in the optics lab facilities atthe University of Arizona. Specifically I will integrate the two wavefront sensors in the Arizonalab facilities and find ways to programmatically take images and control hardware on the testbed.This work will be streamlined by my work on GLARE (the Generalized Lab Architecture forRestructured optical Experiments), a Python suite of automated experiment software and testbed-agnostic controllers for hardware common in optical testbeds (Fowler, 2020). (3) Performfurther testing to reduce and correct for alternate noise factors including dark current,readnoise, optical ghosts, etc. Specifically, I will generate multiple images, isolate signs of thesealternate noise factors, and test alternative hardware configurations and modes and/or calibrationsoftware to optimize final image quality. My work on the Wide Field Camera 3 Quicklookproject (a codebase including a dark current and readnoise monitor) will inform the detection andremoval of noise from these experiments. (4) Integrate the wavefront sensors into MMTalongside on-sky commissioning of the full adaptive optics system.Unique Resources :Many of the investigators of MAPS are at the University of Arizona, including Dr. KatieMorzinski (the principal investigator and an Assistant Astronomer) who will advise me for thisproject. The University of Arizona has two lab spaces that will support this project, as well as avibrant instrumentation group to support and facilitate this work. The University of Arizona hasunfettered access to MMT as well as 50% of its telescope time for calibration observations andexperiments, and as it is local to the university at Mount Hopkins, we can actively iterate withMMT and the lab to test and improve new components.Broader Impact :The original NSF MAPS proposal includes a Winter School, a brief winter workshopaimed at graduate students, postdocs, and professionals to teach the science of exoplanetinstrumentation. The Winter School is based on previous NSF Professional DevelopmentProgram funded programs like Adaptive Optics Summer School led by the Center for AdaptiveOptics. As part of this work, I will design a lab demonstration exploring the distinction betweenan IR and visible wavefront sensor. My experience as a teaching assistant and SoftwareCarpentry instructor will facilitate creating and leading a lab for my colleagues, under theadvisement of Dr. Morzinski who is leading the Winter School.Fowler, J. et al. “G.L.A.R.E..”, AAS Meeting #235, 2020 --- Fowler, J. et al. “ExoCTK”, AAS Meeting #231,2018 --- M., Claire “Introduction to AO and the CfAO.” AO Summer School. 2019. --- Morzinksi, K. “MAPS:The MMT AO ExoPlanet Characterization System .” Cf AAO Retreat. 2018. --- Wakeford, H. R. et al. “High-Temperature Condensate Clouds in Super-Hot Jupiter Atmospheres.” MNRAS, (2016)"
59.0,"The continued reliance on agricultural and petrochemical-based methods of production for manyhigh-value compounds threatens future generations with shortages of essential manufacturingmaterials, organic solvents, biofuels, and pharmaceuticals. The application of synthetic biologyto metabolic engineering has worked to address this growing concern by transferring requisiteenzymatic pathways from native organisms to standardized chasses and manipulating them toboth decrease dependence on non-renewable inputs and increase overall production yield.Despite continued efforts to improve the tunability and consistency of reaction progress withinlarge-scale bioreactors, traditional controller-based methods of optimization remain stymied byexcessive variability characteristic of biological systems.Intellectual Merit: Recent developments in the application of optogenetic tools to metabolicpathways have demonstrated potential in addressing the lack of tunability and irreversibility oftraditional chemical-inducer based control schemes. Leveraging the implicit reversibility ofoptogenetic induction, Milias-Argeitis et al. (2016) developed an automated transcriptionalcontrol system to maintain a constant concentration of fluorescent protein as a proof of concept.While the proposed systems can be used to rapidly increase protein production, the tunability ofthe system is limited by the slow rate at which the proteins degrade. In the context of metabolicapplications this delay could contribute to the non-optimal accumulation of toxic intermediatesand decrease the applicability of feedback structures, reducing overall fermentation yield. Thedevelopment of a reversible post-transcriptional control mechanism presents a novel,generalizable solution to this meaningful challenge.Hypothesis: A reversible, post-translational system for the control of selective proteindegradation can be created using existing optogenetic toolkits to rapidly and precisely decreaseprotein concentration.Approach: A selective protein degradation tag is conjugated to the coding sequence of a targetprotein. The tag marks the target protein for degradation via ClpXP, a selective proteasecomprised of ClpX and ClpP subunits2. The reconstitution of these subunits is facilitated throughheterodimerization of the cryptochrome Cry2 to the protein CIB13. Sufficiently orthogonal to thegreen light (535nm) and red light (672nm) utilized for transcriptional control, instances of Cry2and CIB1 reconstitute in the presence of blue light (470nm) and spontaneously disassociate in itsabsence4.A BFig. 1 Genetic circuit for proposed selective degradation scheme. (A) Representation of “slowresponse” transcriptional control used in Milias-Argeitis et al. (2016) updated with a proteindegradation tag. (B) Representation of “fast response” post-transcriptional control featuring thereconstitution of the ClpXP protease in the presence of blue light to degrade tagged proteins.1Research Statement Kevin FitzgeraldAim 1: Ensure conjugation of CIB1 tag to ClpX subunits has negligible impact on hexamerformation.The ClpX subunit is itself composed of six ClpX subunits. In the context of this project, eachaClpX subunit would be conjugated to a CIB1 dimerization domain and constitutively produced.aAlthough a small protein, it is critical to ensure that the conjugation of CIB1 to ClpX does notainterfere with the formation of hexameric ClpX. To achieve this aim, a library of mutant ClpXasubunits with CIB1 conjugated at different locations will be generated via rational design andscreened for their ability to recombine via western blot. Utilizing a non-conjugated ClpP subunit,the functionality of structurally-promising CIB1-ClpX mutants will then be evaluated by theiraenzymatic capacity to degrade tagged fluorescent proteins.Aim 2: Ensure ClpX/ClpP fusion is negligible in the absence of blue light and reversiblefollowing exposure to blue light.Wild type ClpX and ClpP subunits independently recombine via the formation of hydrogenbonds between key looping peptides on their exteriors. For the system to selectively degradetagged proteins of interest, it is necessary to minimize any spontaneous recombination andsubsequent functionality of conjugated ClpXP in the absence of blue light. Simultaneously,the utility of this light-based system is contingent on the reversible nature of the optogeneticreactions. Once background ClpXP functionality is minimized, it is also possible that the ClpXPcomplex formed upon initial Cry2/CIB1-mediated binding interactions will remain cohesive andfunctional despite the dissociation of conjugated light domains. It is therefore necessary torationally generate and screen mutations within the ClpX/ClpP binding domains capable of bothminimizing subunit binding affinities and maintaining enzyme functionality in the presence ofblue light.Broader Impacts and Future Directions: Properly tuned to compatibly function withexisting transcriptional control systems, a rapid, light-controlled protein degradation systemwould serve as a valuable tool in improving the sensitivity of optogenetic feedback systems inindustrial fermentation processes. By effectively decreasing system lag, target concentrations ofpotentially toxic enzymes can be maintained more consistently despite excessive backgroundnoise. In the context of metabolic engineering this increase in control has the potential toimprove both the speed and yield of fermentations. For those individuals relying onfermentation-based pharmaceuticals for the treatment of disease or fermentation-based biofuelsfor energy, even minor improvements in fermentation yield could decrease costs and improveaccessibility to such essential compounds. In the future, the implementation of optogeneticprotein controllers at each step in a metabolic process could serve to drastically improve thetunability and engineering capacity of large-scale fermentation processes.References: 1. Milias-Argeitis, A., Rullan, M., Aoki, S., Buchmann, P., & Khammash, M. (2016). Automatedoptogenetic feedback control for precise and robust regulation of gene expression and cell growth. NatureCommunications, 7(1). doi: 10.1038/ncomms12546 2. Baker, T., & Sauer, R. (2012). ClpXP, an ATP-poweredunfolding and protein-degradation machine. Biochimica Et Biophysica Acta (BBA) - Molecular CellResearch, 1823(1), 15-28. doi: 10.1016/j.bbamcr.2011.06.007 3. Park, H., Kim, N., Lee, S., Kim, N., Kim, J., &Heo, W. (2017). Optogenetic protein clustering through fluorescent protein tagging and extension of CRY2. NatureCommunications, 8(1). doi: 10.1038/s41467-017-00060 4. Kennedy, M., Hughes, R., Peteya, L., Schwartz, J.,Ehlers, M., & Tucker, C. (2010). Rapid blue-light–mediated induction of protein interactions in living cells. NatureMethods, 7(12), 973-975. doi: 10.1038/nmeth.15242"
60.0,"projects, and written reports, as well as quizzes and exams. In large enrollment courses,instructors often use multiple-choice questions as an assessment method because of the ease andperceived objectivity in grading.1 Although multiple-choice exams are useful for providing fastfeedback about student performance, the multiple-choice item format has been criticized forprimarily assessing low levels of cognition.2 Biology assessments that fail to target higher-orderthinking can be detrimental to the student learning process because these low-level assessmentslimit the development of critical reasoning and problem-solving skills, do not promote the long-term retention of course material,3 negatively affect study habits,4 and hinder scientific inquiry.5Bloom’s taxonomy is widely used in biology education researchas a tool for evaluating student performance and guiding thedevelopment of instructional strategies.6,7 Bloom’s taxonomyconsists of a hierarchy of cognitive skills: remember, understand,apply, analyze, evaluate, and create.8,9 This framework can beused to categorize the cognitive levels assessed by multiple-choice and constructed-response items on biology exams.The division of biology courses into introductory andadvanced courses implies that the higher-level coursesprovide opportunities for students to gain a greater depth ofconceptual knowledge and to practice the higher-ordercognitive skills that are necessary for STEM careers. Although previous research has identifiedthat introductory biology courses primarily assess the two lowest levels of Bloom’s taxonomy,10there are few studies that analyze if assessments in 300- and 400-level courses target the higher-order thinking that is presumed in advanced biology courses.The advantages and disadvantages of multiple-choice and constructed-response items arewell-studied,1 but there is little research on the extent to which the different item formats areused when assessing content knowledge and cognitive skills in introductory and upper-levelbiology courses. Multiple-choice items are traditionally associated with assessing the lowestlevels of Bloom’s taxonomy and constructed-response items are often thought to target higher-level thinking, but there has not been extensive research in biology courses to determine if thereis evidence to support these stereotypes about item format.There is a gap in the literature regarding the frequency with which multiple-choice andconstructed response items are used in introductory and upper-level biology courses to assesshigher-order cognitive skills. My research will fill this gap, highlight strengths of the currentmethods of biology assessment, and identify the areas where assessment can be improved tobetter reflect the knowledge and skills that are required for success in STEM careers.Research Questions 1) Is there a difference in the cognitive levels assessed in introductory andupper-level biology courses? 2) What is the relationship between item format and cognitive levelassessed on undergraduate biology exams? 3) What decisions, processes, and methods areinstructors using to design undergraduate biology exams?Methods To answer these research questions, I will survey exams from biology instructors at arange of undergraduate institutions. Biology instructors will be recruited for participation in theresearch through professional networks such as the Ecological Research as Education Networkand the Society for Advancement of Biology Education Research. The collected examdocuments will be reviewed using a directed qualitative content analysis, a process in which eachquestion on the exam will be categorized by a Bloom’s cognitive level as well as by item type.I will mentor undergraduate research assistants and teach them how to use Bloom’staxonomy to review exam items. I will use a Cohen’s kappa analysis to determine interraterreliability for consensus of the classifications of Bloom’s level and item type between thereviewers. To determine which factors predict the Bloom’s level of exam items, I will runordinal regressions with item type and course level as predictor variables and instructor as arandom effect. In the analysis of Bloom’s levels on individual exams, I will calculate a weightedaverage because items designed to assess higher-order thinking may tend to have a higher pointvalue than items assessing lower-level cognitive skills.I will conduct semi-structured interviews with instructors to clarify the decisions, processesand methods used to design biology exams. The interview protocol will consist of three sections:1) questions about possible constraints, such as large class size, that might limit the type ofassessments administered in their courses, 2) participant familiarity with Bloom’s taxonomy orother frameworks for assessing cognitive skills, and 3) goals for exam design.This research focuses on exams because this form of assessment tends to reflect the types ofknowledge and skills that students are expected to master in a course, but I acknowledge thatthere are assessment methods other than exams. There are some limitations to Bloom’staxonomy as a framework because of its design for broadscale application in education research.These limitations will be addressed by using the Blooming Biology Tool, which is amodification of the Bloom’s framework tailored for the analysis of questions on biology topics.7Intellectual Merit My experiences as a high school science teacher and as an AssessmentSpecialist at the Educational Testing Service provided the skillset that I will use to conduct theproposed research. Previous studies have identified that introductory biology courses primarilyconsist of items assessing low-level cognitive skills,10 but there are few studies that haveexamined either the assessment methods in upper-level biology courses or the relationshipbetween item type and cognitive level assessed on biology exams.Broader Impacts One goal for this research is to strengthen the quality of the undergraduatebiology education experience through identifying areas of assessment that can be improved.Students who are administered high-level items throughout their science courses are more likelyto acquire deep conceptual understanding of the course material,2 so determining whereassessments can be modified to target higher levels of Bloom’s taxonomy is a step in the processof promoting intellectual development in biology students. This research also addresses thedisparity between the cognitive skills assessed on introductory biology exams and the cognitiveskills required for solving real-world scientific problems. Although this research will beconducted primarily on assessments from American undergraduate institutions, biology examsare not unique to the United States, and the implications of this research will have internationalreach. A second goal of this research is to promote the advancement of biology educationresearch, which will be accomplished through training undergraduate students in educationresearch methodology, involving students in the process of qualitative and quantitative dataanalysis, and collaborating with students to present the research at science conferences.(1) Stanger-Hall, K. F. CBE Life Sci. Educ. 2012, 11(3), 294-306. (2) Martinez, M .E. Educational Psychologist.1999, 34(4), 207-218. (3) Jensen, J. L. et al. Educ. Psychol. Rev. 2014, 26(2), 307-329. (4) Entwistle, A.; Entwistle,N. 1992, 2(1), 1-22. (5) Momsen, J. et al. CBE Life Sci. Educ.2013, 12(2), 239-249. (6) Bissell, A. N.; Lemons, P. P.BioScience. 2006, 56(1), 66-72. (7) Crowe, A. et al. CBE Life Sci. Educ.2008, 7(4), 368-381. (8) Bloom, B. S. et al.McKay: New York, NY, 1964. (9) Anderson, L. W.; Krathwohl, D. R. Allyn & Bacon: Boston, 2001. (10) Momsen,J. et al. CBE Life Sci. Educ. 2010, 9(4), 435-440."
61.0,"LeeAnnM.SagerMazziottiGroup,DepartmentofChemistry,TheUniversityofChicagoGoal: Iaimtodevelopamethodologytoexplorethedegreeofexcitoncondensationonaquan-tumcomputer,determinethepreparation(s)thatobtainmaximumexcitoncondensationforagivennumberofqubits,andprobethepropertiesofsaidexcitoncondensatestates.Introduction: Condensation phenomena has been an active area of research since 1924 whenEinsteinandBosefirstintroducedtheirideal“Bose-Einstein”gas.1Theidenticalparticlescompris-ingthisgas(bosons)wereproposedtobeabletoaggregateintoasinglequantumgroundstatewhensufficiently cooled.1 Later, London and Tisza attributed Bose-Einstein condensation (BEC) to bethesourceofsuperfluidity—thefrictionlessflowofzero-viscosityfluids—thathadbeenobservedin low-temperature liquid helium.2 In 1940, Pauli established the relationship between spin andstatistics, demonstrating that particles with integral spin values obey Bose-Einstein statistics—arebosons—and hence may form a condensate.2 Extrapolating further, pairs of fermions—particleswith half-integer spins—may interact such that the overall two-particle system has integral spinand is hence bosonic. In fact, recent experimental and theoretical investigation has particularlycenteredaroundthecondensationsofonesuchclassofbosons: excitoncondensates.3 Excitoncon-densation is defined by the condensation of particle-hole pairs (excitons) into a single quantumstate to create a superfluid. The superfluidity of electron-hole pairs involves the non-dissipativetransferofenergy,whichhasapplicationsinenergytransportandelectronics.3Motivation: While excitons form spontaneously in semiconductors and insulators and whilethe binding energy of the excitons can greatly exceed their thermal energy at room temperature,theyrecombinetooquicklytoallowforformationofacondensateinasimplemanner. Tocombatrecombination,thecouplingofexcitonstopolaritons,whichrequiresthecontinuousinputoflight,4andthephysicalseparationofelectronsandholesintobilayers,whichinvolvesimpracticallyhighmagneticfieldsand/orlowtemperatures,5areemployed. Thus,anew,more-practicalavenueforthecreationandstudyofexcitoncondensationisdesired;quantumcomputingofferssuchanavenue.A qubit is the basic unit of quantum computing (analogous to the classical bit); the qubit itselfis a quantum system whose most-general state is a linear combination of its two basis states ( 0| ⟩and 1 ,theclassicalbitstates)withanappropriatephasefactor(eiφ)givenby6| ⟩θ θ cos θΨ = cos 0 +eiφsin 1 = 2 .| ⟩ 2 | ⟩ 2 | ⟩ eiφsin θ! "" ! "" ! # $2 ""Ifaqubitisconsideredtobeaone-fermion,two-levelsysteminwhichth#er$eisaprobabilitypofthefermionbeinginthelower-levelstate( 0 )andaprobability1 pofthefermionbeingintheupper-| ⟩ −level state ( 1 ) where p = cos θ 2, then a single qubit can represent two particle-hole paired| ⟩ | 2 |orbitals. Assuch,asystemofN qubitscanbeviewedasN fermionsinanN-folddegenerate,two-# $level, particle-hole paired system. As explored in Ref. 7, such a model can demonstrate excitoncondensationinsystemswithasfewas3fermionsin6orbitals(i.e.,athreequbitsystem).Resources: InthisworktheIBMQuantumExperiencedevices—whichareavailableonline—willbeused. Qiskitopen-sourcequantumcomputingsoftwarewillbeemployedforanalysis.Aim-1, Probe the Extent of Exciton Condensation of an Arbitrary Qubit State: In or-der to computationally probe the presence and extent of condensation behavior, I aim to mea-sure the largest eigenvalue of the 2G˜ matrix—a calculable, characteristic property of excitoncondensation—on the quantum computer.8 The elements of the 2G˜ matrix are given by 2G˜i,j =k˜,˜lLeeAnnM.Sager Page1⟨Ψ |ψˆ i†ψˆ jψˆ ˜l†ψˆk˜|Ψ⟩ −⟨Ψ |ψˆ i†ψˆj|Ψ ⟩⟨Ψ |ψˆ k˜†ψˆ ˜l|Ψ⟩where |Ψ⟩is the N-fermion wavefunction; i,j,˜ l,k˜representspinorbitals;andψˆ andψˆarethecreationandannihilationoperators. Duetotheparticle-†hole pairing of each qubit, the spin orbitals denoted by i and j and the spin orbitals denoted by k˜and˜ l must correspond to the same qubit to be non-zero, simplifying the matrix. In order to obtainthe 2G˜ matrix on a quantum computer, these elements must be translated into the basis of Paulimatrices. The expectation values of the Pauli matrices can be obtained through direct measure-mentfromaquantumcomputer,andthematrixelementscanthenbecalculatedthroughuseoftheappropriateconversion. Thelargesteigenvaluecanbecomputedfromthematrixobtained.Aim-2, Determine Preparation(s) for State(s) with Maximum Exciton Condensation: Aquantum state of qubits can be prepared on a quantum computer by the application of a unitarytransformation,Uˆ ,suchthat Ψ (1,2,...,N) = Uˆ Ψ (1,2,...,N) describesthepreparationofi i i 0| ⟩ | ⟩anN-qubitstatefromtheinitialstate Ψ = 00 0 . Iaimtodeterminetheappropriateunitary0| ⟩ | ··· ⟩transformation for a given number of qubits that corresponds with the maximum condensationof excitons—the largest eigenvalue. One particular N-qubit state that may be of interest on thissearchistheGHZstate—thestateinwhichallqubitsareinthe 0 stateorthe 1 statewithequal| ⟩ | ⟩probability (i.e., Ψ = 1 0 N + 1 N );6 this state is highly entangled and is hence an| GHZ ⟩ √2 | ⟩⊗ | ⟩⊗idealcandidateforexcitoncondensation.# $Aim-3, Probe Properties of Exciton Condensates: Any physical, measurable property of asystem corresponds to a Hermitian matrix (Aˆ) such that the eigenvalues of Aˆare the possible out-comes of measurement of said property. The elements of these Hermitian matrices can be writtenintermsoftheexpectationvaluesofPaulimatricesandcanthereforebeobtainedforagivenqubitpreparation. Fromthismatrix,theprobabilityofagivenmeasurement( Ψ a )andtheexpectationi n⟨ | ⟩valueofthatproperty( Ψ Aˆ Ψ )canbeobtainedwhere a istheeigenstatecorrespondingtoai i n⟨ | | ⟩ | ⟩givenmeasurementa and Ψ isanN-qubitstatepreparedbytheunitarymatrixUˆ . Forexample,n i i| ⟩the energetics of a prepared qubit state can be probed by obtaining the eigenvalues/eigenstates ofthetwo-fermionreducedHamiltonianmatrixgivenby2K = 1 1 2 Zj + 1 1 .N −1 −2∇1 − j r1j 2r12Intellectual Merit: This project aims to expand our understa%nding of exciton’condensation&phenomena. Shouldtheseapproachesprovesuccessful,areliableandfacilepreparationforexcitoncondensatestateswillbeachieved,andpropertiesofsuchcondensateswillbeabletobeprobedinastraightforwardmanner.Broader Impacts: The superfluidity of excitons in a condensate allows for the frictionlesstransportoftheexcitationenergy,releaseduponrecombinationoftheparticleandhole. Addition-ally, such superfluidity in a bilayer—with electrons in one layer and holes in another—allows forthe frictionless transfer of charge as long as current is directed in opposite directions in the twolayers—a phenomenon known as counterflow superconductivity.3 Understanding and exploitingthe superfluid properties of exciton condensates may hence be instrumental in the effort to designwiresandelectronicdeviceswithminimallossofenergy,decreasingoverallenergyconsumption.1 Einstein,A.KöniglichePreußischeAkademiederWissenschaften1924,261––267.2 Vilchynskyy,S.I.;Yakimenko,A.I.;Isaieva,K.O.;Chumachenko,A.V.LowTemp.Phys.2013,39,724–740.3 Fil,D.V.;Shevchenko,S.I.LowTemp.Phys.2018,44,867–909.4 Fuhrer,M.S.;Hamilton,A.R.Physics2016,9.5 Kellogg,M.;Eisenstein,J.P.;Pfeiffer,L.N.;West,K.W.Phys.Rev.Lett.2004,93,036801.6 Kaye,P.;Laflamme,R.;Mosca,M.Anintroductiontoquantumcomputing;OxfordUniversityPress,2010.7 Lipkin,H.J.;Meshkov,N.;Glick,A.J.Nucl.Phys.A1965,62,188–198.8 Garrod,C.;Rosina,M.J.Math.Phys.1969,10,1855–1861.LeeAnnM.Sager Page2"
62.0,"Introduction: Grain growth is a critical process to both metals and ceramics processing, as grainsize plays a major role in bulk material properties, such as fracture toughness. Abnormal graingrowth (AGG) is a process by which the growth of a small fraction of grains is incentivized andthey grow faster than their neighbors, resulting in a bimodal grain size distribution andheterogeneous bulk properties. Though work has been conducted in this field for decades1, thecause and mechanism behind AGG are still poorly understood.The process is particularly import to ceramic materials, as the superior thermal resistanceof ceramics lends itself to extreme environment applications. At these elevated temperatureskinetics are accelerated, expediting grain growth and AGG – this is a particular challenge inalumina, which is very susceptible to AGG2. Processing of these materials also raises concern, ashigh sintering temperatures can have the same deleterious effect. As such, it is vital to understandhow to control grain growth in ceramics processing and applications.Textured microstructures with enhanced mechanical properties in materials can bedesigned by controlling their crystallographic orientation during processing. One technique thathas been explored is the application of a magnetic field during processing3,4. This project willinvestigate how texturing by applied magnetic field inalumina ceramics impacts grain growth through the useof electron and synchrotron X-ray based techniques, whichallow us to track individual grains and grain boundaries. Ihypothesize that a strong applied magnetic field duringprocessing will reduce grain growth and mitigate AGGdue the formation of low-angle and, thus, low-energygrain boundaries that have a low driving force to move.This will be validated by 3D microstructuralcharacterization, allowing the measurement of grainboundary orientation and character for textured samples.These results will be relevant to industrial applications ofalumina – including the manufacture of automotive partsand ballistic armor – as microstructure engineering can Figure 1. Preferential crystallographic orientation(ratio of 006 signal intensity to total signal intensity)improve the mechanical properties of ceramic materialsas a function of applied magnetic field strength inand improve stability and lifetime. alumina with different slip solid loading4.Objective 1: Preparation of textured Al O samples by thermomagnetic slip-casting process:2 3Alumina samples for this experiment will be prepared via slip casting with high-purity α-Al O2 3powder. Alumina is chosen as a test material due to its impressive mechanical properties andapplicability as a structural ceramic, as well as its susceptibility to texturing by magneticfield. A dispersant will be added to the slip to prevent the agglomeration of particles. The sampleswill be subjected to an applied magnetic field during casting – this texturing technique has beenshown to induce the growth of preferentially oriented grains during annealing3,4. Figure 1illustrates this effect in alumina. Samples will be cast under applied magnetic fields of 0-8 T with0 T being a control sample. Once cast, alumina green bodies will be sintered to near theoreticaldensity and annealed at temperatures above 1400 ºC for various times.Objective 2: Electron microscopy characterization of grain growth: From the bulk samples,centimeter-sized sections will be cut and polished for observation under a scanning electronmicroscope (SEM) to determine the initial average grain size by image analysis softwareemploying the linear intercept method5. The samples will then be further annealed under identicaltime and temperature conditions, and the same method will be repeated to determine the graingrowth in each sample. These results will provide a quantitative measure of grain growth asa function of applied magnetic field during processing and annealing time.Objective 3: 3D characterization of crystallinity and grain size distribution: The novelty ofthis work lies in the use of high-energy X-ray diffraction microscopy (HEDM) to characterize thesamples. In this technique, a sample is placed in the path of anincident X-ray beam and rotated while diffraction patterns arecollected. In post-processing, these can be indexed to generate acrystallographic map of the measured volume. From the bulk,millimeter-sized samples will be prepared. From 3Dcrystallographic maps measured by HEDM, true grain sizes (at aresolution of 1 µm) can be determined and a grain size distributioncreated. The non-destructive nature of this technique is extremelyadvantageous, as it will allow tracking of individual grains andboundaries across heat treatments. Thus, the slower movement ofindividual textured low-angle grain boundaries can be observedand quantified. Via 3D characterization of individual grains andboundaries, these results will verify a) the character andFigure 2. Set-up for HEDM synchrotronmotion of the boundaries as a function of applied magneticmeasurements, beamline 1-ID atAdvanced Photon Source, Argonne field, and b) whether observed low-angle grain boundariesNational Lab. Incident X-ray beaminduced by texturing reduce AGG.travels along positive z-direction.Research Plan: The timeline for this project is one year. Slip casting will be done at Oak RidgeNational Lab, which houses a commercially available thermomagnetic system offering up to 8 Tmagnetic field. The timeline for this step is one week, accounting for travel time, as slip casting isa well-known process that can be modified as needed. SEM will be conducted at the University ofFlorida, whose Research Service Centers house a TESCAN SEM. The polishing, samplepreparation, and data analysis will take 9-10 months. Lastly, HEDM experiments will be run at theNSF-sponsored CHESS synchrotron’s Structural Materials beamline, at which HEDM will beavailable beginning in December 2019. The experimental design considers that each HEDMmeasurement takes hours, and beamtime slots are limited. As such, high-priority samplesexhibiting strongly textured microstructure will be selected for synchrotron measurement.Broader Impacts: Beyond structural materials, microstructure engineering is essential tofunctional materials like oxide fuel cells and laser materials. The results of this project will offerquantitative insight into the use of an applied magnetic field to texture alumina ceramics – thisfundamental study will serve as a bridge for future industry-specific studies. As such, I wouldenjoy sharing these results at conferences and with industrial collaborators directly.1. Journal of the American Ceramic Society, 80(5), 1149–1156. 2. Scientific Reports, 6(37946),2–11. 3. Scripta Materialia, 54(6), 977–981. 4. Science and Technology of Advanced Materials,7(4), 356–364. 5. Journal of the American Ceramic Society, 91(7), 2304–2313."
63.0,"Background and Rationale: Cerebral Arteriovenous Malformations (cAVMs) are congenitalvascular lesions that affect 0.01-0.50% of the population. The annual risk of hemorrhage in thecAVM nidus is on average 3%, but the risk can be as low as 1% to as high as 33% depending onpatient-specific anatomies. Since the cAVM nidus has low resistance, it allows blood to shuntdirectly from arterial feeders (AFs) to draining veins (DVs) at high flow rates. As a result, if thehemodynamic stresses exceed the elastic modulus of the vessel wall, then a rupture may form andcause a hemorrhage. Embolization – the intravascular injection of embolic materials to AFs, is oneof the most common interventional therapies to prevent hemorrhages by diverting blood flow awayfrom the nidus. However, current methods to visualize blood flow patterns for embolizationtreatment planning are limited. Using the standard-of-care – 2D superselective angiogramsequences (2D+τ) and 3D rotational angiography (3DRA) – is challenging because the contrastagent reaches multiple regions of the nidus simultaneously, which prevents the identification ofcAVM compartments and fistulae. Therefore, there is an urgent need to elucidate blood flowpatterns in the cAVM to improve on treatment planning for embolization.One method to address this problem involves computational fluid dynamics (CFD) to simulatecAVM hemodynamics on patient-derived models. However, the length-scale of the nidus preventsCFD from being applied because the spatial resolution of 0.6mm in 3DRA is insufficient to capturethe 0.1mm or smaller diameters of intranidal vessels. As an alternative, some studies have resortedto using electric network models, but these models are typically not based on clinical data. Insteadof modeling every intranidal vessel in the nidus, I could model all the intranidal vessels collectivelythrough a porous volume [1], which has been shown to be a good approximation of the nidus [2].Simulating the density of intranidal vessels beyond the spatial resolution limitations of 3DRAis possible because voxel intensity is proportional to the amount of contrast agent in a vessel [1],which provides information on the internal geometry of the nidus. Based on Darcy’s law and massconservation, there are seven parameters that characterize blood flow through the porous volume:porosity, permeability, fluid viscosity, fluid density, quadratic drag factor, and the velocity andpressure boundary conditions [1]. These parameters can be inferred from 3DRA images. However,existing models [1], [3] lack validation with other paradigms, such as in vitro testing, and themodels are limited to Types IIa, IIb, and IV in the Yakes classification of cAVMs, which are notrepresentative of the population since there are a total of six types. My research objective is toinvestigate cAVM hemodynamics for embolization planning through generalized patient-specificCFD models for each angioarchitecture type in the Yakes classification, with a porous volumerepresenting the nidus, and validate in silico results using an in vitro flow loop.Specific Aim 1: Develop simplified cAVM digital phantoms for validation with varying spatialporosity distributions. I will design digital phantoms on SolidWorks (Dassault Systèmes, Vélizy-Villacoublay, FR) with one tubular AF and DV connected to a rectangular porous volume. Thephantom will be meshed using a triangular grid of approximately 104-105 elements for a celldensity of around 16 cells per voxel [1] using Gambit (Ansys, Canonsburg, PA). The velocityboundary condition at the AF inlet will be set according to phase-contrast magnetic resonanceangiography (PC-MRA) images, while a zero-pressure boundary condition will be used at the DVoutlet. Blood viscosity will be set to 4.00cP, density to 1060 kg/m3, and Re to 265. Fluent (Ansys,Canonsburg, PA) will be used to run the CFD simulation. To validate, I will confirm that the fluidbehaves according to expectations where flow paths will mostly circulate in nonporous regionsand that flow through porous regions will obey theoretical expectations from Darcy’s law.Specific Aim 2: Construct generalized patient-specific cAVM models. I will construct theboundaries of the cAVM and the AFs and DVs from 3DRA images. This will be done throughsegmentation (3D Slicer, Boston, MA), and I will obtain morphometric measurements usingAnalyze 12.0 (AnalyzeDirect, Overland Park, KS). Based on the segmented anatomies and patient-specific measurements, I will create generalized models for each cAVM angioarchitecture type onSolidWorks. Afterwards, I will mesh the models using a tetrahedral grid on Gambit. The porousvolume parameters will be inferred from 3DRA images and then averaged. As before, I will setthe fluid properties of blood based on nominal values. I will validate mesh convergence througha mesh independence study on Fluent by comparing coarse vs. medium, medium vs. fine, andcoarse vs. fine meshes. Moreover, I will compare porosity distributions through CFD between thegeneralized models and five different patient-specific anatomies for each angioarchitecture type.Specific Aim 3: Develop a flow loop for in vitro validation. I plan to modify an existing flowloop in Prof. Ajit Yoganathan’s lab to simulate cAVM hemodynamics. For example, the flowloop has two pressure measurement probes, which is insufficient for cAVM simulation. I will makemodifications to incorporate more probes to accommodate for all the AFs and DVs. From themodels used in the in silico study, I will manufacture transparent rigid physical phantoms using anMR-compatible resin (Watershed 11122, DSM Somos, Elgin, IL). I will then implement the sameinflow conditions from the computational study to the flow loop and compare flow field datathrough PC-MRA and digital particle image velocimetry for validation. Furthermore, I will alsomanufacture the five patient-specific anatomies for each angioarchitecture type in the Yakesclassification from Specific Aim 2 and compare in vitro flow field results to in silico results.Timeline and proposed laboratory: I would like to work with Prof. Ajit Yoganathan(Georgia Tech) because of the close alignment of research interests. I anticipate that this study willtake five years: one for Specific Aim 1, and two each for Specific Aim 2 and Specific Aim 3.Intellectual Merit: Currently, only Orlowski et al. [1], [3] have used a porous volume tosimulate the cAVM nidus. My project expands on this model, in that there have been nopublished papers that uses a generalized CFD model based on patient-averaged data, an invitro flow loop to validate and compare with in silico findings, and a porous model to simulatethe cAVM nidus. As post-embolization complications are a major concern, my computationalmodel can serve as the first step to a surgical planning software that meets this need.Broader Impact: With further exploration, the computational model proposed can beexpanded to a two-fluid model for simulating the propagation and solidification of embolictherapies, which can provide pre-operative outcome prediction, potential increase in embolizationsession efficiency, and optimize interventional strategies. My project may also be scaled-up forinterventional planning in other AVMs situated in the lung, muscle or bone, prognosis evaluation,and optimization of therapies. Finally, I will collaborate with clinicians at Emory University andUniversity College London to ensure clinical utility and present my work at conferences.Feasibility: From my master’s thesis, I will be supported by University College London,University College Hospital, and Kings College London to obtain 3DRA and PC-MRA patientdata. I will seek Institutional Review Board approval under Prof. Yoganathan’s support.[1] P. Orlowski, F. Al-Senani, P. Summers, J. Byrne, J. A. Noble, and Y. Ventikos, “Towards Treatment Planning forthe Embolization of Arteriovenous Malformations of the Brain: Intranidal Hemodynamics Modeling,” IEEE Trans.Biomed. Eng., vol. 58, no. 7, pp. 1994–2001, Jul. 2011. [2] C. W. Kerber, S. T. Hecht, and K. Knox, “Arteriovenousmalformation model for training and research,” AJNR Am. J. Neuroradiol., vol. 18, no. 7, pp. 1229–1232, Aug. 1997.[3] P. Orlowski, P. Summers, J. A. Noble, J. Byrne, and Y. Ventikos, “Computational modelling for the embolizationof brain arteriovenous malformations,” Med. Eng. Phys., vol. 34, no. 7, pp. 873–881, Sep. 2012."
64.0,"IntroductionOligodendrocyte precursor cells (OPCs) are the progenitor cells responsible for formingmature, myelinating oligodendrocytes (OLs) in the central nervous system during development.While the majority of OPCs differentiate early in life, there is a small pool that generate OLs overthe life span and can differentiate into OLs following white matter injury (WMI). Previous workhas shown that this differentiation is impaired in aging, reducing the ability to recover from WMI.1Significant upregulation of senescence markers in old vs young OPCs suggests senescence, a stressinduced state in which cells no longer proliferate, contributes to the impaired ability of OPCs todifferentiate2. Studies of senescence in other cell types has shown that it leads to reduced functionalcapacity and mediates the physiological consequences of aging. Thus, better characterizing OPCsenescence and the mechanisms involved would greatly improve our understanding of the role ofOPCs in brain aging.Although studies have identified some canonical senescence genes in OPCs, OPCsenescence genes have not been completely characterized, making accurate identification ofsenescent OPCs more difficult. Furthermore, due to our lack of understanding of OPC senescencemechanisms, there is a need to identify novel regulators of senescence in OPCs. Understandingthese mechanisms would greatly enhance both our understanding of OPC development, and ourability to promote CNS myelination in injury. Given this, I propose to identify an OPC-specificsenescence signature, and to identify novel regulators of senescence via a genome-wide CRISPR-Cas9 knockout screen. I intend to carry out this project with two faculty experts in glial cell biologyand genome-wide CRISPR screens.Research Plan:Aim 1: Define canonical and OPC-specific senescence markers in vivo by single-cell RNA-seqRationale: A comprehensive OPC-specific senescence signature has yet to be established. Such asignature would allow for a more accurate identification of senescent phenotypes in different OPCpopulations and may provide insight into the mechanisms underlying senescence in OPCs.Experimental Design: OPCs will be taken from 20-24 month old mice and senescent cell clustersidentified by flow cytometry using fluorescent antibodies to established senescence markers suchas NOTCH3, B2MG and DEP1, which have been shown to have high levels of expression insenescent cells3. Following identification of senescent OPCs, RNA from both proliferating (non-senescent) and senescent OPCs will be extracted and single-cell RNA-seq performed, with non-senescent OPCs serving as a control to identify genes implicated in aging, but not senescence. Datawill then be analyzed to identify differentially expressed transcripts in senescent OPCs, which willcomprise our OPC senescence signature. This experiment will yield genes both up- anddownstream of senescence and will allow for more accurate identification of senescent OPCs. Inthe future, candidates may be validated through in vivo knockout studies.Possible Outcomes: It is possible that with multiple senescence markers, we may miss OPCs whichdisplay lower levels of markers or do not display some at all. We can account for this in adjustingthe sensitivity of our gating and analysis, or utilizing fewer antibodies for selection.Aim 2: Identify regulators of OPC senescence via a CRISPR-Cas9 knockout screenRationale: Discovery of OPC-specific regulators of senescence will establish mechanismsunderlying OPC senescence and can be used to inform the development of mechanistic in vivostudies.Experimental Design: To identify regulatorsof OPC senescence, I will conduct a genome-scale CRISPR-Cas9 knockout screen with apooled lentiCRISPR library. Complex pooledDNA libraries will be combined, anddelivered in lentiviral constructs in 4-8 weekold OPCs, which should not display highlevels of senescence. OPCs can be culturedand transduced at a large scale which allowsfor genome-wide screens. After transductionand selection, I will select senescent cellsusing the flow-cytometry approach describedFig 1. Experimental outline for a senescence marker-in Aim 1 with multiple antibodies againstbased pooled CRISPR screen.senescence markers. Sorted cells will then beanalyzed to identify genes whose knockout increases or decreases senescence, yielding insight intomechanisms of OPC senescence.Possible Outcomes: If Aim 1 yields OPC-specific markers for which there are robust reporters orantibodies, these can be used in a parallel screen to support our initial findings. Future studies mayalso use the signature from Aim 1 to validate hits from Aim 2 in vivo.Intellectual MeritWhile senescence has been characterized in microglia and astrocytes, significantly less work hasbeen done in understanding OPC senescence and its relevance in aging. Given that the efficiencyof myelination has been shown to decline over time, this proposal, which aims to bettercharacterize OPC senescence, will greatly contribute to our understanding of the effects of agingon oligodendrocyte development and myelination. Furthermore, characterization of OPCsenescence opens up the possibility of mechanistic and in vivo studies, which will broadly increaseour knowledge of the roles of OPCs, and how they change over time.Broader ImpactThis work has implications for the understanding and treatment of neurological diseases, as agingis linked to an increase in disorders such as dementia and Alzheimer’s. Dementia is linked to lossof white matter and decreased myelination, and myelin breakdown is implicated in Alzheimer’s,pointing to a critical role for OPCs. This work could eventually allow for the reversal of senescentphenotypes in OPCs, potentially leading to curative treatments. Additionally, understanding OPCsenescence has important implications for demyelinating diseases such as MS, for which there areno remyelinating therapies. Recovery from such diseases is impaired by lack of understanding ofOPC differentiation; thus, understanding blockades to differentiation such as senescence mayinform future therapeutic development.FeasibilityMy previous work with oligodendrocyte development will significantly contribute to the successof the project. Furthermore, I am rotating in the lab of Dr. Ophir Shalem, whose lab has a strongand successful history of genome-wide CRISPR-Cas9 knockout screens, and who will provide theresources and mentorship need. I am also rotating with Dr. Chris Bennett, who has expertise in theisolation, culture, and sequencing of glia, and can offer the resources and mentorship needed forthis project. Having access to a wide breadth of experts in my fields, as well as Penn’s world-classfacilities and resources, also ensures the feasibility of this project.References: (1) Swenson et al. Translational Medicine of Aging 2019; (2) Neumann et al. Cell Stem Cell 2019; 3)Althubiti and Macip, Methods in Molecular Biology 2019."
65.0,"Introduction: Honey bees (Apis mellifera) are cornerstone pollinators and contribute nearly $20billion to the U.S. agricultural economy each year1. Honey bee populations have drasticallydeclined by an estimated 30-40% in the past three decades, and 2019 marks the largest winter hiveloss ever recorded1. Bee decline threatens the U.S. economy and food supply, which has drivenagricultural stakeholders and the scientific community to investigate reasons for honey bee deaths.A number of factors have already been identified, including habitat and foraging space loss,pesticide exposure, and infection by parasites, fungi and viruses. Bees have a commensalcommunity of microbes aside from pathogens that includes bacterial, viral, and eukaryotic species,collectively known as the microbiome. Like in most organisms, the microbiome in bees plays animportant role in nutrition and shaping host health through immunity and disease susceptibility.The extent to which the honey bee gut microbiome influences health outcomes remains unclearand for these reasons the scientific community is diligently working toward the characterizationof the honey bee microbiota.Intellectual Merit/Background: 16S sequencing has revealed that remarkably simple andspatially organized microbial communities of about 8-10 bacterial phylotypes occupy the honeybee gut, consistent across geographic distributions of bees2. In-depth metagenomic sequencing andsingle-cell characterization at the strain level revealed that each phylotype spans considerablemicrobial genomic diversity, leading to substantial polymorphism within and between hives. Suchvariation between bacterial strains belonging to the same phylotype could result from functionaldiversification (due to niche partitioning) but also suggests co-divergence and adaptation with hostlineages. Bidirectionally, the bee microbiome has been shown to play an important role inmodulating the host physiology. Germ-free studies highlighted that native gut microbiota is ableto stimulate the immune system in adult worker bees3 and the use of probiotics to effectivelymitigate parasite effects shows promise4. However, the contributions of the gut microbiota to hostimmune pathways and the mechanisms by which the host responds to gut variation has yet to beinvestigated. Lastly, the genetic architecture of a honeybee colony makes any two daughter workerbees of sister queens mated with a single drone share ¾ of their genes on average5. Takenaltogether with the consistent microbial phylotypes observed across colonies, this makes honeybees an ideal model for studying host-microbiome interactions. Using a combination ofcomparative genomics and field experiments, I aim to identify possible routes of honey-bee/microbiota co-diversification. I hypothesize 1) that the host genotype, diet, and environmentallandscape shape the functional capabilities of the honey bee microbial community, and 2) thismicrobial community can acutely impact the innate immune system of adult bees, and that thiscommunity can be modulated by the addition of probiotics. I plan to test these hypotheses with thefollowing aims:Aim 1: Determining the contribution of host genetic and environmental landscape in shapingthe functional microbiome of the honey bee microbiota. I will rear several hives derived fromsingle drone-mated sister queens from three different subspecies of A. mellifera: ligustica, carnica,and mellifera. These will be replicated in two geographically separated apiaries (collections ofhives). Bees in each location will have access to the same respective landscape of flora to foragefrom and will also be fed identical nutritional supplements (protein supplementation, sugar syrup).Samples will be collected at the initial hive set-up, then once every 3 months for a year. They willbe collected from nurse bees (who stay within the hive) and foraging bees (who leave the hive).Use of apiaries, acquisition of bees, and subspecies identification is enabled by collaboration withDr. Ramesh Sagili of the Oregon State Honey Bee Lab. High-throughput shotgun metagenomicsequencing will be used to assess and compare the bees’ microbial structure at the phylotype andstrain level between and within a) subspecies, b) nurses/foragers of each subspecies and at eachlocation, and c) longitudinally, to assess patterns of functional microbiome congruence betweenthe genetically and geographically distinct subgroups of bees. Additional data including wintersurvival rates per subspecies will be collected. Microbial samples from the flora the bees foragefrom in the different apiary locations will be collected in an attempt to ascertain the microbes theyare exposed to outside of the hive.Aim 2: Comparative analysis of functional and spatial diversity in the A. mellifera gutmicrobiome following immune system challenge. Germ-free bee studies have foundupregulation of antimicrobial peptides in hemolymph (blood analog in bees) to be associated withinoculation by specific gut microbiota members3. I will determine if altering the microbialcommunity with probiotics can modulate the immune response of the bees and reduce fatalitiesdue to Nosema ceranae (a parasite associated with bee depopulation⁶). To do so I previouslycollaborated with the Honey Bee Lab and performed a three-week in vivo experiment on theaddition of probiotics during Nosema infection. Microbiome samples were harvested from themidgut and hindgut of single bees (Nosema localizes in the midgut). My pilot 16S sequencingconfirmed that our methods are sensitive enough to detect distinct spatial microbial compositions(consistent with the literature). Shotgun metagenomics will be performed to compare strain-levelfunctional diversity between experimental groups and gut regions, as well as determine impact ofprobiotic strains on composition and functional diversity. Functional pathways will be identifiedin each group and quantitatively compared to ascertain up- or downregulation of antimicrobialpeptides and other immune-related genes in the context of infection or probiotic addition. mRNA-seq will be completed to quantify and compare host response to those pathways identified bymetagenomics. Pathway predictions will also be confirmed via LC-MS/MS of antimicrobialpeptides present in the bee hemolymph.Broader Impacts – Research Dissemination: The sequences and metadata generated by thisproject will be made publicly available through the online BeeBiome consortium2, where there isa pressing need for comprehensive honey bee microbiome data. Results regarding probiotictreatment of honey bee hives will be communicated to bee keepers through local and nation-widebeekeeping meetings and publications. I anticipate submitting a first author paper detailing myfindings in spring 2020, as well as presenting my results at the International Society for MicrobialEcology 2020 meeting in Cape Town, South Africa. At OSU, I will utilize opportunities to sharemy research, such as the bi-annual Center for Genomic Research & Biocomputing conferences,where I have presented research previously.Broader Impacts – Science Communication: I will share my research with audiences from K-12 children, community members, and faculty. I plan to involve the community in my research,by expanding this project to include bee gut and local flora samples donated by regionalbeekeepers. This community-driven, crowd-sourced approach is necessary to characterizing honeybee health outside of the lab setting. I also plan to involve high school AP Biology students duringthe collection and characterization of apiary flora (Aim 1). I currently serve as the OutreachCoordinator for the Micro Grad Student Assoc. and am in the process of developing severalopportunities for local K-12 children to learn about honey bees, utilizing hands-on activities at theweekly Saturday farmer’s market. This combination provides an optimal platform for me to talkabout my research and engage with community members on the themes of how humans rely onbees for our food production, and how the health of honey bees impacts us.1. Pollinator Health Task Force. 2016. Report to Congress. 2. Engel et al. 2016. MBio. 3. Kwong et al. 2017. R. Soc.Open Sci 4. Khoury et al. 2018. Frontiers. 5. Johnstone et al. 2012. R. Soc. Bio Sci 6. Rubanov et al. 2019. Sci. Rep"
66.0,"Stomata are small pores located on the epidermis of aerial plant tissues necessary for CO2assimilation and O release. Stomata are also the primary sites of transpiration, accounting for2nearly 90% of all water loss in rice. Plant species can modulate their stomatal density andconductance on newly emerging leaves in response to environmental stimuli such as CO , water2status, and temperature1–3. Despite many recent studies in dicots, limited attention has been paidto characterizing the genetic underpinnings of stomatal development and physiology inmonocots, namely grasses. Grass stomata exhibit specialized anatomical and physiologicalattributes, such as subsidiary cells that flank the guard cells allowing for faster stomatal aperturerates4. Concerted efforts could provide insights into environmental adaptation mechanismsexclusive to monocots. The few studies that have characterized aspects of monocot stomatalbiology have relied on mutant screens to identify key genes or have attempted to characterizehomologs from the model plant organism Arabidopsis thaliana4–6. The use of quantitativegenetic approaches as an alternative might reveal quantitative trait loci (QTLs) associated withthis important trait. I will complete a genome-wide association study on a rice (Oryza sativa)diversity panel to characterize stomata-mediated drought response in rice. Currently availablehigh density single nucleotide polymorphism (SNP) data allows for the resolution of discreteQTLs that are relevant in extant rice variation7. Further investigation of the most significantSNPs will enable the characterization of genetic variation involved in rice stomatal physiologyand development in response to water deficit.Aim 1: Genome wide association study of stomatal traits in drought simulationA hydroponic platform incorporating polyethylene glycol 6000 (PEG)-induced drought stresswill be used to yield a high-throughput and uniform assay of plant stomatal density andphysiology in response to drought. The stomatal density differences will be measured in normalwatering conditions and drought stress lines for each accession. A Li-6400 XT will be used tomeasure stomatal conductance of individual replicates. The optimized phenotyping platform willbe applied to a rice diversity panelof 300 accessions. I will useprincipal component analysis tomaximize coverage of totalgenetic diversity in the selectedlines. Stomatal density andconductance differences betweenthe two treatments will be used asthe phenotypic parameters in theGWAS alongside a high-densityrice array containing nearly 700kSNPs. Association mapping willbe conducted using a custompython script that can account forsubpopulation structure as apotential covariate. All loci abovethe significant p-value thresholdwill be further analyzed to identifylikely candidate genes associated1with stomatal density and conductance modulations responsive to drought. I will then usehaplotype analysis to determine the haplotypes and frequencies at the most significant QTL.Aim 2: Characterize candidate genes using CRISPR/Cas9 mediated knock-outs and ectopicoverexpressionThe candidate genes most closely associated with the highest significance SNPs will be furthercharacterized using CRISPR/Cas9 to induce mutations 8.Targeted mutagenesis will be executedin the Kitaake genetic background, in which I have already successfully produced knockouts.The short generation time of this accession makes it ideal for high-throughput research.Additionally, I will ectopically overexpress candidate genes with a strong promoter in theKitaake background. The stomatal density and conductance of mutant overexpression lines willbe measured to determine if these candidate genes play a role in stomatal development andphysiology.Aim 3: Multiplexing knock-ins of drought adaptation allelesCRISPR/Cas9 and geminiviruses will be used to produce knock-ins of advantageous alleles inthe homologous native location in the Kitaake background. Alleles selected will belong to thehaplotype associated with the highest significance SNPs from the most drought tolerantaccessions. Useful variation may exist in promoters, genes, or non-coding sequences. Thisvariation will be leveraged using the high replication rates of geminivirus replicons to increaserates of homology-directed repair, with precise positioning enabled by CRISPR/Cas9 mediateddouble-stranded breaks9. Quantitative traits are governed by numerous QTL that contributecollectively to a phenotype10. Simultaneous knock-ins of alleles from drought adapted accessionsinto the Kitaake background will be confirmed and assayed for performance in drought. Thisapproach highlights an avenue to leverage natural variation using targeted genome editing forallele swapping.Intellectual Merits: Grass stomatal adaptations are currently understudied. Rice can serve as amodel for other monocot species in investigating novel environmental adaptations that haveevolved relative to dicots. Access to high density marker sets coupled with transformationfacilities can enable biological investigations that go beyond the scope of model plant organisms.Results may be translated to species such as hexaploid wheat, where GWAS and transformationis more challenging, to explore the conservation of adaptive mechanisms among grasses.Furthermore, multiplexing adaptive allele knock-ins could bypass the high time investment andlinkage drag inherent to traditional breeding approaches, and be broadly applied to a range oftraits for which there is existing GWAS data11.Broader Impacts: Improved understanding of drought tolerance mechanisms in monocots canenable eventual crop improvements. These advancements will be necessary to improve plantperformance in the face of impending global climate changes. International collaborators willassist with field testing of the most promising edited lines, integrating a broad community ofplant scientists. I will leverage my connections in NPR Scicommers and local science museumsto share findings of this study with the public and discuss data at conferences, thereby engagingwith all individuals about plant-environmental interactions in the context of climate change.References: [1]Hamanishi, E. T., Thomas, B. R. & Campbell, M. M. J. Exp. Bot. (2012). [2] Gray, J. E. et al.Nature (2000). [3].Zhu, J. et al. Forests (2018). [4].Raissig, M. T. et al. Science (2017). [5] Raissig, M. T. et al.Proc. Natl. Acad. Sci. (2016). [6] Hughes, J. et al. Plant Physiol. (2017). [7] McCouch, S. R. et al. Nat.Commun.(2016). [8]. Doudna, J.A. & Charpentier, E. Science (2014). 9.Wang, M. et al. Molecular Plant (2017).[10] Crowell, S. et al. Nat. Commun. (2016). [11]. Jacobsen, E. & Schouten, H.J. Trends Biotechnol. (2007).2"
67.0,"25% of all marine life.1 They provide invaluable services by protecting shorelines from stormsurge, supplying food sources, and promoting eco-tourism.2 However, coral populations aroundthe world are exhibiting an alarming decline due to climate change, specifically from oceanwarming (OW). OW has severely diminished coral health through increased diseasesusceptibility and bleaching.3 To fully understand how corals might fare under future OWconditions, the potential for coral acclimatization over generations and life history stages must beassessed. Previous research on coral acclimatization has focused primarily on intra-generationalacclimatization (IGA), which investigates if corals can adjust to new conditions within theirlifetime. For example, Brown et al. (2002) found that when G. aspera were exposed to higherlevels of solar radiation, they were less susceptible to bleaching.4 While IGA is crucial inelucidating coral resilience, the study of trans-generational acclimatization (TGA) in corals isessential to understanding the persistence of coral reefs in a warmer future. TGA occurs whenthe phenotype of the offspring is influenced by the environmental conditions experienced by theparents and/or previous generations.5 Epigenetic modifications, or heritable alterations in geneexpression and cellular functions that do not involve changes to the original DNA sequence, arethought to play a role in TGA.6 Most studies on epigenetic modifications and TGA have focusedon exclusively DNA methylation; for example, Strader et al. (2019) found that parentalenvironments of S. purpuratus affected patterns of DNA methylation in offspring.7 However,other epigenetic markers, such as histone modification and chromatin remodeling, may berelevant to TGA in marine invertebrates, but have been seldom studied. I will address thisknowledge gap by investigating multiple epigenetic mechanisms and outcomes of TGA in corals,over multiple generations and life history stages, in the context of OW. Additionally, I willexamine coral physiological processes to better understand all aspects of coral TGA. Discerningthe influence of epigenetics on TGA will contribute to the knowledge of coral resilience andsusceptibility in an evolutionary and ecologically relevant context. The coral Pocilloporadamicornis was chosen for this study, as it is an important reef-building coral in the Indo-Pacificregion and is commonly used in laboratory experiments as a model coral.Aims and Hypotheses: Aim 1: Assess physiological effects of TGA in offspring at severaldevelopmental stages (larval, juvenile). Hypothesis 1: Both larval and juvenile offspring whoseparents were exposed to OW conditions will have a higher tolerance to OW conditions thanlarval and juvenile offspring whose parents experienced ambient conditions. Aim 2: Compare theepigenetic modifications, specifically DNA methylation patterns and histone modifications, ofcoral parents and offspring during several developmental stages (larval, juvenile) to evaluate theacquisition and stability of TGA. Hypothesis 2: Parents exposed to OW conditions will produceoffspring with differentially methylated genes and modified histones compared to offspringwhose parents experienced ambient conditions.Research Methods: I will collect reproductively viable adult P. damicornis from the fringingreefs of Kaneohe Bay, Hawaii and experimentally expose them to OW conditions. To simulatecurrent and future environmental parameters, experimental ambient/high temperatures will bedefined as 26/30°C.8 Exposures will take place in mesocosm tanks with flow-throughexperimental treatment water in the Hawaiian Institute of Marine Biology’s seawater system forone month. Following the adult exposure, I will evaluate the photosynthetic efficiency (F/F ) ofv madult corals to assess their capacity to photosynthesize. Additionally, I will preserve adult tissuesamples for later epigenetic analysis (see below). After the exposure and physiologicalassessment, I will induce adults from all treatments to spawn. I will collect larvae post-spawn1and experimentally expose them to ambient/OW conditions for one week. At the beginning andend of the larval exposure, I will measure lipid content and oxygen consumption from a subset oflarvae in each treatment to determine energy reserves needed for metamorphosis and metabolicrate, respectively. Following the exposure, I will preserve another subset of larvae from eachtreatment for epigenetic analysis (see below). I will transfer the remaining larvae from eachtreatment into 10 L tanks with ambient flow-through seawater and plugs for settlement. After 6months, I will experimentally expose the now-juvenile offspring to ambient/OW conditions forone month. At the end of the exposure, I will measure juvenile F/F ; following photosyntheticv manalysis, I will preserve juvenile tissue for epigenetic analysis (see below). Epigenetics: At theend of all exposures, I will collect tissue from juveniles/adults and a subset of larvae for DNAmethylation and histone modification analyses. Using extracted genomic host DNA, I will assesswhole genome DNA methylation using the MeDIP-seq approach. This method utilizes DNAimmunoprecipitation and next-generation sequencing to estimate methylation levels of specificDNA regions. I will also use genomic host DNA for histone modification analysis. Histonemodifications will be analyzed through the ChIP-seq method, which combines chromatinimmunoprecipitation and next-generation sequencing to identify regions of the genomeassociated with these modifications.Intellectual Merit: Not only will this research considerably enhance knowledge of physiologicaland epigenetic processes in coral biology, but it will be one of the first studies to provide adeeper understanding of coral resilience over multiple generations and life history stages. Theutilization of cutting-edge epigenetic analyses will help to define the contribution of DNAmethylation and histone modifications to TGA, which is currently understudied in corals.Additionally, the cognizance of coral TGA potential in the face of anthropogenic stressors willallow scientists and reef managers to make more informed predictions about future reef healthand population evolution. An increased knowledge of epigenetic mechanisms in corals will alsosupply a starting point to investigate TGA potential in other marine invertebrates who may besusceptible to climate change.Broader Impacts: The Graduate Research Fellowship will enable me to pursue importantresearch opportunities and will equip me with the knowledge and abilities needed to succeed as afuture governmental or non-profit research scientist. Moreover, the GRF will enhance my skillsas a scientific educator and mentor to younger students. I intend to partner with local highschools in the greater University of Hawaii area to connect students with marine science andresearch. Through this partnership, I will provide opportunities for students to undertakeindependent projects within the context of my research. I will guide students through anintegrated overview on how to conduct research projects from the initial proposal to the finalwritten product. More specifically, I want to include low-income high school students during theresearch partnership. Low-income students can often be excluded from fully pursuing theirinterests in science, due to lack of financial and academic support. I hope to provide thosestudents with research opportunities and support, so that they can receive an enrichingexperience.References: 1Reaka-Kudla (1997) Biod. II. 2Constanza et al. (2014) Glob. Env. Chan. 3Hoegh-Guldberg et al. (2007) Sci. 4Brown et al. (2002) C. Reefs. 5Torda et al. (2017) Nat. Clim. Chan.6Eirin-Lopez and Putnam (2019) Ann. Rev. Mar. Scie. 7Strader et al. (2019) J. Exp. Mar. Bio.Eco. 8IPCC (2013) AR5.2"
68.0,"Background: Cancer is among the leading causes of deaths worldwide with approximately 38%of men and women diagnosed with cancer at some point in their lifetime. With the rising cancer1epidemic and the need for cheaper and more accessible drugs for people in developing countries,it is crucial to find new ways to develop pharmaceuticals. One sustainable method is engineeringmetabolic pathways of microorganisms such as yeast (Saccharomyces cerevisiae) or Escherichiacoli to produce the precursor of a drug. One of most successful applications of this technique wasachieved in Dr. Jay Keasling’s lab at the Joint BioEnergy Institute by producing the precursor ofthe antimalarial drug artemisinin, reducing the cost 30-60% and ensuring a continuous supply.2,3Engineering microorganisms to produce pharmaceutical products more efficiently can beapplied to cancer drug development. Production of terpenoid and polyketide by engineeredmicroorganisms would be particularly beneficial as small amounts of the molecules are producedvia natural pathways and yields vary widely based on environmental and epigenetic factors.4Paclitaxel (brand name Taxol) is one of the most successful cancer drugs, and was first listed onthe World Health Organization Model List of Essential Medicines in 2013. However, there wasconcern regarding the high cost of the drug , as it initially required the bark of six 100-year-old5Pacific yew trees to treat a single patient with breast cancer. Although alternate methods have6been developed to extract paclitaxel from needles of the European yew, synthetic biology toolscan be used as a more sustainable alternative. Since paclitaxel is a highly decorated diterpenoid(Fig 1), its complicated structure makes it a good fit to be engineered from yeast due to thehighly versatile DNA transformation system and well-defined genetic system of yeast.The objective of this project isto engineer a yeast strain capable ofsynthesizing paclitaxel which can belater optimized for commercialproduction. This will have an essentialimpact by reducing the cost of a crucialanticancer drug and providing valuableinsight into the pathways required for theproduction of terpenoid and polyketidenatural products from yeast. This projectwill focus on engineering taxadienebiosynthesis in yeast by utilizing glucoseas the hydrocarbon source, studying andidentifying cytochrome P450oxygenation reactions in the pathway,and integrating these components toproduce paclitaxel (Fig 1).Aim 1: Engineering of Taxadiene Biosynthesis in YeastTaxadiene (taxa-4(5),11(12)-diene) biosynthesis in yeast is crucial to the production ofpaclitaxel but the levels of various precursors these organisms produce naturally are insufficientto make the process feasible. The diterpenoid precursor for taxadiene, geranylgeranyldiphosphate (GGDP), is necessary for a heterologous taxoid biosynthetic pathway but isproduced in insufficient quantities in yeast due to competition for steroid synthesis with farnesyldiphosphate. I will introduce heterologous genes from the Sulfolobus acidocaldarius GGDPsynthase instead of the native GGDP synthase from Taxus for improved production of GGDPAT axa-4(5),11(12)-d ien e (TP 450O xygen ationR eaction sP aclitaxelaxad ien e)BA im 1En g in eerin g o f T ax ad ien eBio sy n th esis in Y eastA im 2Stu d y C y to ch ro m e P 4 5 0 -Dep en d en t O x y g en atio nR eactio n s in P ath w ayA im 3Integ ratio n o f T ax ad ien ePath w ay an d O x y g en atio nR eactio n s to P ro d u ceP aclitax elFigure 1. A: Taxadiene intermediate structure catalyzed viavarious cytochrome P450 oxygenation reactions to producepaclitaxel.7 B: Identified route for production of paclitaxel.and taxadiene as there is no competition for steroid synthesis. Introduction of genes from S.4acidocaldarius also results in substantial production of geranylgeraniol, further increasingtaxadiene yields. Yeast will be transformed by the lithium acetate method on SC minimal8medium agar plates via CRISPR/Cas9 and select plasmids (pVV200 (tryptophane), pVV214(uracil), pRS313 (histidine) and pRS315 (leucine)). Yeast will be cultivated for 48 hours withglucose as the carbon source, lyophilized, extracted with pentane, and analyzed by GC-MS.Aim 2: Study Cytochrome P450-Dependent Oxygenation Reactions in PathwayThe oxygenation steps in the biosynthesis of paclitaxel have yet to be fully studied andidentified. After taxadiene biosynthesis, oxidative modification of the olefin and the elaborationof side chains are needed to transform taxadiene into paclitaxel. After the taxadiene skeleton isformed, the olefin must be modified by several P450-mediated oxygenations and coenzyme Adependent acylations. Candidate genes for all but one of the seven steps after taxadiene synthesisare postulated, but the entire pathway has yet to be confirmed. Uracil-specific-excision-reagent9(USER) cloning will be utilized for site-directed mutagenesis of the identified genes andcytochrome P450s and USER primers will be designed using the online AMUSER tool. Allintermediates will be characterized by GC/LC-MS.Aim 3: Integration of Taxadiene Pathway and Oxygenation Reactions to Produce PaclitaxelOnce the taxadiene pathway and oxygenation reactions are identified and characterized,the pathways will be integrated via the lithium acetate method, CRISPR/Cas9, and site-directedmutagenesis to produce paclitaxel. Glucose will be used as the starter carbon source in yeast andwill follow the native mevalonate pathway. The established genes to produce GGDP synthasewill be introduced and the previously identified taxadiene synthase gene that has been codonoptimized for improved yeast expression will be incorporated to produce taxadiene. Then, the4pathway developed with the cytochrome P450 oxygenation reactions will be introduced toproduce paclitaxel. All intermediates will be evaluated using GC-MS. It is possible that someproteins synthesized in the complete pathway are insoluble or inactive in yeast, thus similarproteins will be determined or engineered to be active.Intellectual Merit: My knowledge from chemical engineering coursework and research withdeveloping cell cultures, DNA analysis, and molecular modification of chemical structures givesme an essential, well-rounded training for fulfilling this project. This project will be the first timea polyketide synthase (PKS)-terpene hybrid has been produced in yeast and will mark animperative step in the industrial production of PKSs and thus, in the field of synthetic biology. Iwill collaborate with members of the Joint BioEnergy Institute to learn the genetic technique ofintegrating genes using CRISPR/Cas9 and use my knowledge of DNA sequencing and GC toconfirm the genes responsible for paclitaxel and determine the developed molecules at each step.Broader Impacts: Developing pharmaceuticals from microorganisms is an efficient and cost-effective way to produce the same high-quality compounds obtained from natural products. Byengineering yeast to produce paclitaxel, a lower-cost, more sustainable drug could be developedfor people suffering from lung, breast, or ovarian cancers who would otherwise not have accessto the medicine. If successful, this project will provide a framework for synthesizing other PKS-terpene hybrid chemicals and pharmaceuticals from microorganisms.References: 1. NIH, NCI. 2018. https://www.cancer.gov/about-cancer/understanding/statistics 2. Hale et al., Am SocTrop Med. 2007. DOI: 10.4269/ajtmh.2007.77.198. 3. Ro et al., Nature. 2006. DOI: 10.1038/nature04640. 4. Engelset al., Met Eng. 2008. DOI: 10.1016/j.ymben.2008.03.001. 5. Mendis. WHO Model List of Essential Medicines.2011. https://www.who.int/selection_medicines/committees/expert/18/applications/Mendis.pdf?ua=1 6. Horwitz,SB. Nature. 1994. DOI: 10.1038/367593a0 7. Chang et al., Nature. 2006. DOI: 10.1038/nchembio836. 8. Kaiser etal., Cold Spring Harbor Laboratory Press. 1994. ISBN: 0-87969-451-9. 9. Jennewein et al., PNAS. 2004. DOI:10.1073/pnas.0403009101."
69.0,"Motivation: Virus purification and concentration is critical for the production of vaccines andgene therapy vectors. Today, vaccines exist for 26 viral diseases1, but low yields and high costsof production prevent access to many vaccines. Similarly, production limitations will reduceaccess to viral gene therapy, which may provide cures to single-mutation genetic diseases.Although many technologies exist for virus particle purification, they each face uniqueroadblocks to developing rapid, high-yielding, and ultimately continuous processes.Chromatography is widely-used for virus purification, but suffers from low binding capacities,frequently inactivates viruses, and cannot operate continuously. Ultrafiltration is readily scalableand provides high throughput and recoveries, but fouling reduces flux and removal ofcontaminating proteins is often ineffective. Ultracentrifugation is difficult to scale up and haslow yield, even though purities are high.Aqueous two-phase systems (ATPS), most commonly constructed with two polymers ora polymer and a salt, are proposed as a replacement to simultaneously purify and concentratevirus. Biologically-gentle purification is achieved by choosing the identity and concentration(described by tie-line length, TLL) of phase-forming components, ionic strength, polymermolecular weight, and pH so that the desired bioparticle partitions to one phase and contaminantsto the other. Many viral particles have been purified in ATPS, with yields as high as 79%2, asignificant result in an industry that often accepts overall downstream yields of 30%. Still, thevaccine industry is reluctant to adopt ATPS in part because each bioparticle requires a uniquesystem for optimal recovery and predictive models are lacking to fill this critical gap.So far, attempts to develop a predictive model for bioparticle partitioning in ATPS can begrouped into three approaches. A first approach, the Collander equation, uses known partitioningof bioparticles in ATPSs to predict partition coefficient (K) in new systems3. Because of itsreliance on data, this model cannot predict K for new bioparticles. A more robust methodcombines density gradient theory with thermodynamic and association models. It successfullypredicted the mass transfer of an amino acid in ATPSs4, but cannot model partitioning of largebioparticles like viruses. A better solution by Chow, et al. uses surface and interfacial propertiesto predict partitioning5. Particle diameter, net charge, and contact angle with the ATPScomponents can predict K.No one has yet successfully combined a theoretical model with measurements ofATPS and particle surface properties to predict bioparticle partitioning. Chow, et al.verified their model empirically by successfully comparing K to TLL and pH, but did not attemptpredictions with surface measurements. I propose combining novel methods developed in my labto measure virus surface characteristics with Chow’s theoretical model to together predict viruspartitioning in ATPS, a task which was not previously possible.Hypothesis: Partitioning of virus particles in aqueous two-phase systems can be predicted usingsurface chemistry properties measured at the single-particle level.Experimental Plan: I propose extending Chow, et al.’s models to predict partitioning of virusparticles in polymer-salt ATPS. Chow’s model requires phase properties of ATPS and surfaceproperties of the viral particle to predict K. Methods for characterizing ATPS are rapid and well-known. Turbidity measurements will be used to determine the binodal points and tie lines.Characterization of viral particles is much more difficult. While virus diameters and isoelectricpoints (pI) (related to surface charge of viral particles) may be found in the literature, no methodto measure the contact angle between ATPS and viral particles currently exists.1Historically, virus characterization has depended on bulk solutionmeasurements or amino acid sequencing. Instead, my lab has developed anovel single-particle method to measure virus surface chemistry usingchemical force microscopy (CFM), shown in Fig. 1. In a recently submittedarticle6, we determined the pI of two model viruses using atomic forcemicroscopy probes chemically functionalized to carry positive or negativecharges. Adhesion to the viral particle was measured in varying solution pHand the pI determined6, giving a direct characterization of the viral surfaceand avoiding error from contaminants. A similar single-particle Fig. 1. CFM withcharacterization will be used to determine the parameters of Chow’s virus particlespartition model.The first stage of this work will focus on how virus surface chemistry changes in thepresence of ATPS components individually before combining them. First, virus-sized goldnanoparticles (AuNPs) coated in BSA or lysozyme will be immobilized on a gold surface. Thenadhesion force between the AuNPs and probes modified with charged or hydrophobic ligandswill be measured by CFM. These proteins are known to partition differently in ATPS, and sincecontact angle between these proteins and ATPS may also be determined by traditional sessiledrop methods, comparison will confirm that CFM can be related to surface tension for well-defined systems before extending the method to viruses. Similar determinations of surfacetension by CFM for non-biological surfaces have already been reported7. Then, two enveloped(surrounded by a lipid bilayer) and two non-enveloped viruses will be used to explore varyingviral surface chemistry.Once a relationship between CFM and contact angle is established, the second stage ofthis work will characterize multiple ATPS and adapt Chow’s model to predict virus partitioning.To verify the model as a function of component concentration, three TLLs for three commonpolymer (PEG) and salt (citrate, phosphate, and sulfate) ATPS will be evaluated to show themodel is robust for varying chemistries. Similarly, the pH of ATPS will be varied over the rangeof stability for each virus, typically 4.5<pH<7.5. The model will be complete when it predicts theK of a virus as a function of TLL or pH.Once this work establishes a reliable model for virus partitioning between the bulk phasesin ATPS, partitioning to the interface, which frequently results in the irreversible aggregationand inactivation of virus particles, can be explored.Intellectual Merit: Developing predictive models for virus partitioning in ATPS will add to theunderstanding of viral surfaces and the driving forces behind ATPS, reducing the experimentalcost of developing ATPS to purify new bioparticles in the future.Broader Impacts: By filling a critical gap in the literature, making ATPS research faster, andmaking ATPS more accessible to industry, this work will speed the development and productionof vaccines and gene therapy, ultimately reducing outbreaks of viral and genetic disease andsaving lives. In addition, I will mentor undergraduate researchers who will have the opportunityto develop contact angle measurements with protein-coated AuNPs.References:1. WHO. Vaccines and diseases. 2019 2. Joshi, P.U., et al. Journal of Chromatography B, 2019. 1126. 3. Madeira,P.P., et al. Journal of Chromatography A, 2008. 1190(1-2): p. 39-43. 4. Chicaroux, A.K. and T. Zeiner. Fluid PhaseEquilibria, 2019. 479: p. 106-113. 5. Chow, Y.H., et al.. Journal of Bioscience and Bioengineering, 2015. 120(1): p.85-90. 7(38): p. 21305-21314. 6. Mi, X., et al.. Under review. 7. Drelich, J., et al. (2004). Journal of Colloid andInterface Science 280(2): 484-497.2"
70.0,"Graduate Research Plan StatementTitle: Exploring critical zone structure and function in a tropical urban watershed throughconcentration-discharge relationshipsIntroduction: Streams are recognized as integrators of the surrounding landscape. Stream waterchemistry is thus an excellent indicator of broader critical zone (CZ) processes. The CZ is thespace from the top of the vegetative canopy down to bedrock and lowest extent of freely circulatinggroundwater.1 The CZ framework provides a holistic approach to develop predictive models thatdescribe processes at the earth’s surface, including the constraints on material export from thecontinents to fluvial networks.2 Concentration-discharge (C-Q) relationships in streams provide anintegrated signal of sources and transport processes to examine how solutes and sediment respondto changing patterns of runoff.3 Studies of the CZ are mostly limited to pristine systems; however,C-Q relationships in urban streams may be more complex due to altered hydrology, impaired waterquality and heterogenous subcatchments.4 With increasing pressures on urban landscapes, there isan urgency to understand hydro-biogeochemical processes of the urban CZ that govern waterquality and quantity. Research in urban systems will be highly valuable to cities and communitiesand can better inform management practices and help improve urban infrastructure.4I propose to characterize and compare C-Q relationships across two stream networks withdiffering levels of urban development through a series of whole-network sampling effortscapturing baseflow to storm events. I also propose to study the impacts of hurricanedisturbance on C-Q trends through analysis of long-term water chemistry records. I will testthree hypotheses on variability in C-Q relationships across stream networks associated withwatershed urbanization (H1-H3):H1: Watershed urbanization drives greater variability in C-Q relationships across stream networksassociated with increased impervious surface area.H2: C-Q relationships during storm events are more variable in the urban network due toheterogenous hydrologic signals, and ultimately depend on storm intensity.H3: Both urban and pristine stream networks show increased variability in C-Q relationships afterhurricane disturbance, but the magnitude of variability is higher in urban watersheds.Study sites: This work will be conducted in two watersheds: the urban Río Piedras in metropolitanSan Juan, Puerto Rico and the mostly undeveloped Río Espíritu Santo in El Yunque NationalForest in Río Grande, Puerto Rico, as a reference site. The Río Piedras flows through themetropolitan area with highly modified channels and significant impacts from failing sanitaryinfrastructure.5 In contrast, the Río Espiritu Santo originates in the Luquillo Mountains and ismostly undeveloped except on its coastal plain with significant changes in water chemistry evidentonly after hurricane impacts.6 The University of New Hampshire´s (UNH) Water Quality AnalysisLab (WQAL) group, including myself, has extensive experience working in these two streamnetworks. These watersheds are also a part of the Luquillo Long-Term Ecological Research(LTER) site and Luquillo Critical Zone Observatory (LCZO), which have generated multi-decadalrecords of stream chemistry and discharge. The lab also has ongoing collaborations with researchgroups at the University of Puerto Rico (UPR), who have worked in the Río Piedras: Jorge Ortiz-Zayas’s Tropical Limnology Lab and Alonso Ramírez’s Aquatic Ecology Lab.Proposed approach: (H1) I will establish a synoptic sampling regime of 20 sites in each streamnetwork, ranging from small headwater sites to larger mainstem and coastal sites. I will collectwater samples as well as measure physicochemical parameters with a handheld multiparameterinstrument at least 15 times in the span of 2 years. Samples will be analyzed for nitrate, ammonium,phosphate, dissolved organic carbon, anions, cations, dissolved greenhouse gases, and totalsuspended solids (TSS) at the UNH WQAL Lab. I will also take discharge measurements at each1Carla López-Lloreda NSF Graduate Research FellowshipGraduate Research Plan Statementsite and date either using dilution gauging or acoustic velocity measurements, depending on streamsize. I will target sampling dates that capture a range of flow conditions by monitoring the USGeological Survey (USGS) gauging stations at two sites within each stream network. Thissampling will allow me to characterize spatial and temporal variability in C-Q relationships acrossthe stream network. (H2) I will conduct targeted storm sampling at one USGS gauged site in eachstream network with ISCO automated samplers. These samples will be analyzed for the samesolutes as in H1, with a focus on TSS to calculate sediment flux during storm events. Real-timedischarge data for these events will be obtained online through the USGS´s National WaterInformation System Interface. I will capture events of different magnitude to explore effects ofstorm magnitude and intensity on C-Q relationships and solute and sediment transport. I will usethese results to evaluate specific patterns of hysteresis, which characterize the rising and fallinglimbs of a storm event, providing additional insights into material reservoirs within watersheds.(H3) I will use long-term chemistry data from sites in the Río Piedras and the Río Espíritu Santo,which have been sampled weekly for approximately 10 years for multiple solutes and are USGSgauged sites. I will quantify C-Q relationships before and after Hurricane María in September of2017 which will allow me to examine the resilience of these watersheds to a major perturbation.Intellectual Merit: This work will provide insight into the interactions and mechanisms ofsediment and nutrient production, pathways, and transport in a tropical urban watershed. Studyingstorm events and hurricanes is particularly important because they are “hot moments” of increasedhydrological activity, which transport disproportionate amounts of solutes and sediments tostreams and oceans compared to baseflow conditions.7 Understanding high flow processes iscrucial, as major storm events and hurricanes are expected to increase in intensity and frequencywith climate change.8 And though much C-Q work has been done on temperate systems, tropicalstreams supply disproportionate amount of sediments and solutes to the ocean and studying thesesystems in a global context is becoming increasingly important.9 This work also leverages researchdone by the Luquillo LTER and LCZO research networks.Broader Impacts: During this work, I will continue developing collaborations with local researchgroups in ways that will engage local underrepresented undergraduate students in fieldworkthrough my network and storm sampling efforts. I will work with UPR professors to offerindependent research opportunities to students. This research will provide a useful framework forlocal government agencies to use in their nutrient and sediment management plans across theisland, including restoration projects aimed to help reduce pollution and sedimentation and regaincritical zone services in urban ecosystems.7 For this, I will engage local researchers examiningsediment and nutrient loading and the local Puerto Rico offices of the Department of NaturalResources. I will also collaborate with local organizations working in the Río Piedras such as theSan Juan Bay Estuary and the ENLACE project of the Caño Martín Peña. These projects havelongstanding efforts in the Río Piedras watershed and extensive connections with localcommunities. In collaboration with these organizations, I will use this opportunity to teachcommunities about water quality in their watershed through a series of roundtables and byproviding educational resources to disadvantaged groups that have greater exposure to poor waterquality.References: [1] National Research Council (2001). Basic Research Opportunities in Earth Science. Natl. Acad.Press. [2] Brantley, S. L. et al. (2017). Earth Surface Dynamics, 5(4), 841–860. [3] Chorover, J. et al. (2017). WaterResources Research, 53, 8654–8659. [4] Kaushal, S. S. et al. (2014). Biogeochemistry, 121, 1–21. [5] Potter, J. D. etal. (2014). Biogeochemistry, 121, 271–286. [6] McDowell, W. H. et al. (2013). Biogeochemistry, 116, 175–186. [7]Kaushal, S. S. et al. (2018). Biogeochemistry, 141(3), 273–279. [8] Zimmerman, J. K. et al. (2018). Ecology, 99,1402–1410. [9] Schlesinger, W.H. & Bernhardt, E. (2013). Biogeochemistry (3rd. ed.). Academic Press.2"
71.0,"Overarching career goal: Push the frontier of multiphase flows in extreme conditions that aresubjected to high speed, strong turbulence, and large mass loading. For my graduate study, myaim is to unveil the underlying physical mechanisms of complex couplings between solid and gasphases in compressible particle-laden turbulence, which remains elusive for both industrial andastrophysical applications. The major challenge in this area is the lack of high-quality time-resolved experimental datasets that can illustrate the particle-gas and particle-particle interactionin extreme conditions. To address this issue, I plan to leverage a recently-developed ultra-high-speed diagnostic system to embark on understanding multiphase flows in this exciting new regime.Introduction and Background (Intellectual Merit):From the atomization in internal combustion to collisions and growth of dust particles inprotoplanetary disks (Fig. 1(left)), particles in high-speed compressible turbulent environments isubiquitous in nature and engineering applications. This two-phase interaction produces some keyissues: (i) Multi-scale physics: particles interact with compressible turbulence with many lengthscales and coherent structures. (ii) The coupled interaction can lead to clusters of particles anddroplets, resulting in enhanced collision rates and fast growth1. This is important for rain dropletgrowth in turbulent clouds, a type of incompressible turbulence. In this well-known regime,particles preferentially cluster in regions of low vorticity and high strain rate2, promoting collisionbut inhibiting mixing. This finding may have severe consequences in combustors, where mixingis desired for perfect combustion2. In compressible turbulence, there is a new structure – shocklet3.Rather than high vorticity or strain, it is a region of high pressure. Particles interacting with thisnew structure may alter the mean fields and turbulent characteristics of the flow4. A numericalstudy revealed that light particles cluster in very thin and long filaments on the shocklet surfaces5(Fig. 1(right)), while larger inertial particles form dense clouds downstream of the shocklet.Hypothesis: A new particle clusteringmechanism will become important incompressible turbulence due to the uniquecoherent structure – shocklet. Since shockletsare intermittent spatially and temporally,particles will interact with other low-speededdies as they would in incompressibleturbulence. The dynamic competition between Fig. 1. (left) Artistic illustration of protoplanetary dust.these two clustering mechanisms will pose an (right) Numerical simulation iso-surface displayinginteresting new regime where the particle light particles (green) and eddy shocklets (orange)5.collision rate may be sensitive to small changes of the dimensionless groups, such as theturbulence Mach number, Stokes number, and Reynolds number.Aim 1: Upgrade current 2D experimental facility to a supersonic turbulent environmentTo generate a turbulent and supersonic environment, I will construct a facility to produce a 2Dsupersonic mixing layer using two opposing parallel supersonic streams, a method that has beenused previously to visualize shocklets3. The two jets are separated by a vertical distance, enablingus to capture the interaction between the jets through the shear layer. Particles will be tracked usingan in-house particle tracking code. I have access to different algorithms developed in the lab, whichincludes both 2D tracking and the 3D Shake-The-Box Method6. We have access to the ShimadzuHPV-X2 camera, which captures images at 10 million frames per second at exposure times1Graduate Research Plan Statement Juan Sebastian Rubioof 200 ns. With this camera I will take time-resolved measurements. We also own several Phantomhigh-speed cameras, which can take 40,000 images during one run. With this camera I can performmulti-scale measurements and conduct extensive statistical analysis of the flow. To obtain gasphase velocities, I will seed the flow with sub-micron sized particles and illuminate them with anin-house burst-mode laser (20 mJ per pulse at 100 kHz) and analyze the results using particleimage velocimetry, a method I used previously both during my undergraduate research and at LosAlamos National Laboratory under the supervision of Dr. John J. Charonko. With this innovativeexperimental setup, I will obtain high-quality experimental images for further analysis.Aim 2: Investigate particle physics and its effect on the flow propertiesBecause eddy shocklets are structures with strong compressionParticle bow shocksregions, they can be visualized with either shadowgraph orSchlieren imaging methods. Thanks to the quasi-2D configurationof the proposed setup, shocklets will be visualized by the Schlierenmethod. I have already begun preliminary work to study particlemotion using the underexpanded particle-laden jet facility in ourlab. With the current experimental setup, I already visualizedoblique and normal shocks using the Schlieren method. I alsovisualized the bow shocks that form around individual particlesFig. 2. Shadowgraph experiments(like eddy shocklets) at high frame rates (Fig. 2). Finally, theusing the compressible particle-statistics of particle clustering will be evaluated using the Voronoiladen jet facility at Johns Hopkinsanalysis and the correlation between each of the particle’s location.depicting particle bow shocks.Aim 3: Study the turbulence by characterizing coherent structures - shockletsThe complex coupling covers a multi-dimensional space. Compressible turbulence can bequantified by both the Reynolds and Mach number, which includes both the free stream andfluctuation velocity. Small particles can be characterized by the Stokes number, particle Reynoldsnumber, and particle Mach number. I hypothesize that the particle Stokes number and particleMach number are key parameters that may control the couplings between the two phases. Alarge Stokes number results in a large particle inertia, which may induce a strong particle-basedshocklet. In addition, the particle mass loading is important. As in the incompressible case, the lowmass loading may be key in particle-turbulence interaction, but the particle-particle interaction orparticle-turbulence two-way couplings will not be important when the mass loading becomes large.I will spend part of my thesis to understand the behavior of particles in different parameter regimes.Broader Impacts:Improving our understanding of particle-laden compressible turbulence will have significantimpact in numerous areas of science and engineering. It may provide new insights as to how theuniverse formed. To aid researchers around the world, I will store our experimental data in an opensource repository. Outreach: I will mentor underrepresented undergraduate students on a semesterbasis, provide them with the opportunity of assisting me with experiments, and enable them to co-author in research papers. Through the Johns Hopkins SABES program, I will perform simpleexperiments to show students the importance of particle behavior in the environment.1. Pan, Liubin, et al. The Astrophysical Journal (2011). 2. Squires, Kyle D., & John K. Eaton. Physics of Fluids (1991).3. Papamoschou, Dimitri. Physics of Fluids (1995). 4. Chen, Chang H., & Diego Donzis. Journal of Fluid Mechanics(2019). 5. Yang, Yantao, et al. Physics of fluids (2014). 6. Schanz, Daniel, et al. Experiments in fluids (2016).2"
72.0,"Life Sciences: Systematics & BiodiversityBackground and proposal: Complex body plans evolve through the acquisition ofheterogeneous material properties. In the late 18th century, architects began to combine rigid andflexible materials in order to achieve new levels of structural complexity in response to thelimited space within urban areas. An analogous process happened in animals throughout theCambrian explosion. During this time, complex animal morphologies diversified with theappearance of both rigid and flexible materials, such as skeletons, muscles, and fluid-filledcavities. The relationship between rigid and flexible materials and the production of diversecomplex morphologies in skeletonized animals, such as arthropods and vertebrates, has beenextensively studied. However, little is known about this relationship in gelatinous animals. Injellyfish (Cnidaria: Medusozoa), the underlying material properties are not well understood butstill thought to play a major role in the evolution of diverse morphologies. Jellyfish have a free-living medusa stage (medusoid) with a bell that is responsible for locomotion1. Much of themedusa bell shape appears to be constrained to a concave ellipsoid, conserved across >2,000species of jellyfish1. In stark contrast to this relatively simple medusa morphology, a uniquesubclade, the siphonophores (Cnidaria: Hydrozoa), exhibits morphologies well beyond thisnorm. Siphonophores are colonial animals that use asexual reproduction to producephysiologically integrated chains of individuals, called zooids. Siphonophores swim usingretained, specialized medusoid zooids (nectophores), which propel the colony. Nectophoresdisplay astonishing diversity of extremely complex morphologies2,3 (Fig. 1). In order to achievethis diversity, siphonophores have something typical medusae do not: ridges and facets. In othersystems, the development of ridges and facets is dependent on the distinct underlying materialproperties4. Like free living medusae, nectophores are composed primarily of mesoglea, anexpanded extracellular matrix, which is a mesh network comprised mostly of collagen fiberslocated between epidermal and gastrodermal epithelia5,6. Anecdotal evidence of physicallyhandling siphonophores indicates that the mesoglea has a wide variety of elasticity and stiffnessboth within a nectophore and across species depending on the presence of ridges and facets. It isunknown to what extent the ridges and facets of nectophores depend on the material properties ofthe mesoglea, such as the density, elastic modulus, and viscous modulus. Typical medusae,without ridges and facets, have homogenous mesogleal material properties. I hypothesize thatcomplex nectophore morphologies with ridges and facets require heterogeneous mesoglealdeposition within the nectophore. If supported, the nectophores with complex ridges and facetswill have both regions with elastic properties and regions with viscous material properties. Incontrast, the nectophores that lack ridges and facets will have homogenous mesoglea withmaterial properties comparable to typical medusae. If the core hypothesis is not supported, itwould mean that material properties and nectophore morphology can vary independently. If thisis the case, I propose two alternative hypotheses: (1) heterogenous mesoglea evolved firstfacilitating the evolution of ridges and facets, and (2) ridges and facets evolved first, and weresecondarily reinforced byA: Phylogeny & Morphologyheterogeneous mesoglea. To Ridges/Facets N N Y N Y N Y(Y/N)test these hypotheses, I willcharacterize nectophoremorphology and materialOther Rosacea Vogtia Sphaeronectes Lensia Stephalia Agalmaproperties to test for Medusozoansphylogenetic correlations. Iwill also use the phylogeny tomodel trait evolution of the SiphonophoraeFigure 1: Phylogeny and medusa morphology. Adapted from Totton (1932).Research Proposal Lauren Mellenthinmorphology and material properties. This study will help understand not only how diversity inmorphology arises, but how it evolves. Are mesogleal ultrastructure and correlated materialproperties phenotypically integrated with nectophore morphology? Answering this questionrecognizes the role material properties have in achieving morphological diversity in gelatinousanimals. This work will contribute to the growing interest in the scientific community that realizediverse material properties and their critical role in the evolution of complex body plans.Methods: I will use museum specimens from the Yale Peabody Museum (YPM), which has~180 species with ~2-3 specimens per species to describe the ridges and facets of nectophoremorphology. Using literature and YPM specimens, I will delineate the presence and absence ofridges and facets across siphonophore species. Freshly collected specimens will be used formesoglea and material property analysis. I will use scanning electron and differentialinterference contrast microscopy to image the mesoglea. To analyze material properties, I willuse small angle x-ray scattering and rheology. These techniques characterize the structure of themesogleal mesh at sub-micron lengthscales, density, and viscous and elastic moduli. All tools areavailable at Yale. Using a well resolved phylogeny7, I will test if morphology changes incongruence with mesoglea and material properties using phylogenetic mixed models in Rstatistical software8 with the pglm package. I will also test the order at which morphology andmaterial properties arose via ancestral state estimation with the ape package.Feasibility: A risk of this project is the unpredictability of fieldwork to obtain fresh material formeasurements of material properties. However, working with experts in siphonophore biology inthe Dunn lab and collaborators will alleviate this risk. My previous research experience with Dr.Dean Adams in comparative morphometrics is directly applicable for questions of trait evolution.Former work at the Field Museum and current involvement in YPM has prepared me forhandling museum specimens and contributing to collections for future generations. Collaboratingwith Dr. Alison Sweeney of Yale will contribute to the biophysical aspects of this project and hermentorship reduces radical differences between fields of physics and organismal biology.Intellectual Merit: Using and adding to YPM specimens leverage an important collection for anovel interdisciplinary project. Nectophores are a diagnostic trait of siphonophores and are usedto characterize species, therefore this work will enhance what we know about siphonophoreidentification using gross morphology. Nectophore biology has broader implications forunderstanding how different zooid types contribute to colony integration. This work will alsoinform how extracellular matrix development has influenced metazoan evolution at early nodesin the metazoan tree, potentially with implications for body plan evolution. The emerging field ofsoft robotics currently use animal biomaterial properties to understand efficient fluid mechanics.A major breakthrough was a medusa-like robot. However, nectophores utilize heterogeneous softmaterials to integrate a variety of functions beyond self-propulsion, allowing engineers to designrobots exclusively of soft materials with extensive functional repertoires.Broader Impacts: I plan to bridge the disparate fields of physics and evolutionary biology, bysharing this work. Additionally, by being a graduate affiliate of the Yale Peabody Museum, I amable to share my research and educate about natural history to a broader audience. I will takeadvantage of this unique platform that encourages global curiosity about ocean exploration andoverall scientific curiosity to put my work in perspective. Importantly, these opportunities exciteboth the scientific and public communities about current interdisciplinary research.References: Megill, W.M., PhD diss., McGill University (1991)1, Carré, C., Carré, D. Ordre des siphonophores(1995)2, Totton, A.K. Siphonophora. (1932)3, Gibson, L.J. The Royal Society (2012) 4, Bergheim, B.G. Essays inBiochemistry (2019)5, Gambini, C. Biophys. J. (2012)6, Munro, C. Molecular Phylogenetics and Evolution. (2018)7,R Development Team. R Foundation for Statistical Computing (2008)8"
73.0,"Core-collapse supernovae (CCSNe) are the spectacular explosions that accompany thedeaths of massive stars. CCSNe have been the subject of ongoing research for decades butthe explosion mechanism is still not fully understood. Proper treatment of the CCSN problemrequires all areas of physics; in particular, general relativistic gravity, complex neutrinotransport, turbulent magnetohydrodynamics, and nuclear physics. CCSNe are the primaryengines of galactic chemical evolution; many of the elements heavier than H and He aresynthesized here, those necessary to life in particular. Furthermore, a complete view ofCCSNe is necessary for understanding the compact objects that arise from core-collapse,such as the binary neutron stars and stellar mass black holes that have been detected byAdvanced LIGO and Advanced Virgo[1].Intellectual MeritAs current high-fidelity CCSN simulations lack the ability to properly predict electro-magnetic (EM) emission, I propose to investigate the explosion mechanism drivingCCSNe by further developing the current CCSN simulation capabilities to pro-vide accurate EM predictions. While yielding far more insights into the processes atwork in the CCSN, it will also allow for comparison with observational astronomy. Thiscollaboration of full multimessenger signals is a yet untapped resource that could give newinsights into the explosion mechanism. The proposed project is broken down into three stages:(i) upgrading our nuclear physics, (ii) getting 1D LC and EM information, and (iii) goingto multiple dimensions. My background in stellar astrophysics and computational methodsmakes this project a natural next step.Upgrading our nuclear physics. In the hot interior of massive stars, material is said tobe in nuclear statistical equilibrium (NSE), meaning that forward and backward reactions arebalanced such that elemental abundances are given by relatively simple statistical relations.Current high-fidelity CCSN simulations assume that NSE is satisfied throughout the entirestar. While this is a good approximation in the interior regions of interest most pertinent tothe explosion, it breaks down quickly at large radii so that only the central regions can beaccurately modelled. I will work to transition the equation of state (EOS) to thenon-NSE regime in the FLASH code. This will allow for whole-star simulations andmore accurate nucleosynthesis calculations. Inclusion of the outer regions of the star will alsoallow for modelling of the neutrino-driven wind – a supersonic outflow of stellar materialpowered by neutrinos emitted from the core of the star. This wind is proposed as a possiblesite of heavy element nucleosynthesis. We can then begin to meaningfully study the fullnucleosynthetic signatures of CCSNe.Getting 1D LC and EM information. The ultimate goal of the study of the CCSNexplosion mechanism is the ability to make predictions and understand observations. Armedwith a more realistic EOS and accurate nucleosynthesis, I will study the EM signals emittedduring a CCSN. To achieve this, I will use a new model for driving 1D explosions thatincludes the crucial effects of turbulence and convection and map simulation datainto SuperNu[2], a multi-D Monte Carlo radiation transport code, to producethe EM signals. This is imperative as, to date, we have only one observation of a CCSNthat includes any signals other than electromagnetic. The FLASH code is already capableof handling the gravitational wave (GW) and neutrino emission, so this extension willprovide complete predictions of the multimessenger signals. With this, we can begin to makedirect connections between physical conditions of the explosion and what is observed. Anunderstanding of how, for example, uncertain nuclear physics affects the electromagneticsignals is crucial to the success of the CCSN problem. This will allow us to compare ourfindings to observations and, for the first time, connect observations of CCNSe with detailsof the progenitor stars.Going to multiple dimensions. The final goal of this project is the ability to run fully3D CCSN simulations that for the first time include a proper treatment of the non-NSE EOSand EM information. This project will push the frontiers of current high fidelity 3Dsimulations and greatly enhance their explanatory and predictive powers. Due tothe extreme computational resources required of these simulations, the simulations wouldbegin during years 3-4 using computing allocations available to Dr. Sean Couch, the PI ofthe Michigan State University (MSU) research group. At this stage of the project, I will havethe ability to study the full range of multimessenger signals from CCSNe including EM, GW,and neutrino signals in addition to the nucleosynthetic signatures of the explosion. With allof this in hand, we can make accurate and meaningful predictions of how the various physicsthat go into the CCSN impact the explosion, and how that in turn affects the observations.Broader ImpactThe work presented here will result in the advancement of our understanding of the CCSNexplosion mechanism, galactic evolution, and ultimately, the origin of the elements includingthose that comprise life. The results of this work will promote constructive collabo-ration between theoretical stellar astrophysicists and observational astronomers.EM data produced through this project can be compared against observational data asa benchmarking tool and may also be used by observers to inform future studies. Thisproject aligns with the goals of the DOE’s Scientific Discovery through Advanced Computing(SciDAC) initiative, as well as the National Strategic Computing Initiative, in the push toexascale computing. MSU houses the Joint Institute for Nuclear Astrophysics, NationalSuperconducting Cyclotron Laboratory, Facility for Rare Isotope Beams, and a new De-partment of Computational Mathematics, Science and Engineering and as such it the idealcampus for this interdisciplinary work. In an effort to reach first generation students, Iwill create a chapter of Ask A Scientist at MSU utilizing my connections with the nationalorganization. To best leverage the available resources, I plan to create collaborations withexisting programs at MSU such as the 4-H Michigan Extension, MSU Science Fair, and firstgeneration student mentor program. I will travel to rural Michigan schools to show firstgeneration and low income students that a college education and career in science are optionsfor them. Through this chapter of Ask A Scientist, these communities can continue to benefitafter the conclusion of my graduate studies. Astronomy has amazing potential to transformboth lives and communities1 and the NSF GRFP would give me the resources necessary tobegin my career while using my research as a tool for change.[1] Abbott, B. P., Abbott, R., Abbott, T. D., et al. 2016, Phys. Rev. Lett., 116, 061102[2] Wollaeger, R. T., van Rossum, D. R., Graziani, C., et al. 2013, The Astrophysical Journal SupplementSeries, 209, 361 https://www.nature.com/collections/xtxtmqfrgf"
75.0,"Background and Motivation: Observation of the 21cm hydrogen emission line has the potentialto provide tremendous insights into the evolution of the universe, and is one of the most excitingfrontiers in cosmology. Roughly 400,000 years after the Big Bang, the universe began coolingenough for neutral atoms to form in a period known as recombination. After recombination camea period known as the ‘dark ages’, during which the universe consisted mainly of neutralhydrogen. It gets that name because, although the universe was transparent, no stars had formedyet, so the only radiation was photons from the CMB and 21cm emission coming from thehyperfine spin-flip transition of neutral hydrogen. Thus far, researchers have been unable todirectly observe this period of the universe. Eventually, gravitational collapse allowed the firststars and galaxies to form. Radiation from these galaxies then began ionizing the neutralhydrogen in a time period known as the Epoch of Reionization (EoR). Roughly one billion yearsafter the Big Bang, reionization was complete, and the universe became observable again. Myresearch aims at detecting the cosmological 21cm emission line, which will allow us to studythe mechanisms driving the evolution of the early universe. Improving our understanding ofthis period of the universe is crucial to the field of cosmology. In the most recent decadal surveyby the National Academy of Sciences, experiments aimed at detecting the cosmological 21cmsignal were listed as the highest priority in radio astronomy [1].There are many barriers to observing the 21cm emission line, including the weakness ofthe cosmological signal and instrumentation challenges. Most experiments searching for thissignal use interferometers, rather than traditional dish telescopes, due to their higher resolution,which is particularly important for long wavelength radio waves. The signal we are searching foris 4-5 orders of magnitude weaker than the foreground sources, which means that ourinstruments must achieve an extremely high level of precision. With interferometry,calibration of the array can be extremely challenging, but without exceptionally precisecalibration, systematic errors dominate the experiment and will prevent any attempt torecover the 21cm signal.There are two primary methods of calibrating an interferometer: sky-based calibrationand redundant calibration. Sky-based calibration, performed here using Fast HolographicDeconvolution (FHD), relies on an a priori sky model to solve for the antenna gains.Incompleteness in current sky models has been shown to produce sufficient contamination of thepower spectrum to obscure the desired signal [2]. Redundant calibration makes use of theredundancies in the arrangement of array antennas in solving the calibration equations. Thismethod can largely be performed without the use of a sky model, and in fact an estimated skymodel is actually produced during calibration without using prior knowledge [3]. My researchwill improve the redundant calibration pipeline and use the estimated sky model to informthe model used for sky-based calibration, thus increasing the precision of currentcalibration techniques.Research Project: For my research, I will work primarily with data from the MurchisonWidefield Array (MWA), which is a low-frequency radio interferometer containing 256 tiles,each of which is composed of 16 dipole antennas. Specifically, my work will be based on phaseII of the MWA, which has been running since 2016, and whose data is yet to be fully analyzed.The MWA provides unique opportunities for studying interferometric calibration because it iscomposed of two highly redundant hexagonal arrays and a pseudo-random extended array, whichmakes it workable for both sky-based and redundant calibration. I began working with this dataset during my research as an undergraduate, where I created the first images of the sky modelNSF Graduate Research Plan Statement Dara Storerproduced through redundant calibration and uncovered sources of error that were propagatinginto the model. My undergraduate work was aimed at finding relative agreement between theestimated sky model produced through redundant calibration and the observed data. If achieved,this estimated sky model could be used to inform the sky model used for sky-based calibration,thus lowering the necessary precision of the a priori sky model. Through this research, I foundevidence that positional errors in the antennas were propagating into the estimated sky model andcontaminating the calibration solutions.As a first year graduate student at the University of Washington, I have already joined theradio cosmology group, led by Miguel Morales. This group is one of the leaders of the MWAand the Hydrogen Epoch of Reionization Array (HERA) collaborations, and has developed someof the most important data analysis pipelines for precision calibration. By joining this group, Ihave gained access to better resources and more robust software, which positions me well tostudy the calibration systematics I uncovered as an undergraduate. My research will proceed asfollows:Phase I: I will run simulated data through the same pipeline I used on the real data in myundergraduate research, which will allow me to more precisely examine the systematicscontributing to positional error propagation. I will subtract the model produced throughredundant calibration of the simulated data from the a priori sky model given by FHD. Thisresult will provide insight into significant sources of flux that may be missing from our skymodel.Phase II: I will work with collaborators at the University of Melbourne, led by Professor RachelWebster, to supplement any missing sources in the catalog currently being used for sky-basedcalibration. During my semester abroad in Melbourne I worked on a piece of code, PUMA, thatis used to produce and combine source catalogs, so I am well prepared to study these catalogsfurther. Then, I will run the MWA Phase II data back through this adjusted pipeline, andreexamine the propagation of positional uncertainties.Phase III: I will work with the HERA collaboration as they begin collecting data from thetelescope, which is expected to happen in Spring, 2019. I will compare the results from HERAwith those from the MWA, which will allow me to better determine which systematics arespecific to the instrumentation of the MWA, and which are due to the calibration pipeline.This research plan will allow me to systematically track and eliminate the propagation ofposition errors into the sky model and calibration solutions, which will greatly increase theprecision of interferometric calibration, and bring us closer to a true detection of the 21cmhydrogen emission line.Broader Impacts: Observing the EoR will provide insight into what the early universe lookedlike and the processes that led to the formation of the first stars and galaxies. Understanding theearly universe is fundamental to understanding the modern one, and measurement of the 21cmsignal will have tremendous influence in almost every area of astrophysics. In addition to myresearch, I will work with Professor Morales’ group to continue their long history of supportingcommunity college transfer and other historically underrepresented students through theCHAMP program, as detailed in my personal statement.[1] National Academy of Sciences, New Worlds, New Horizons in Astronomy and Astrophysics[2] Barry, N., Hazelton, B., Sullivan, I., et al. 2016, MNRAS, 461, 3135B[3] Li, W., Pober, J., Hazelton, B., et al. 2018, ApJ, 863, 170"
76.0,"that microbes constantly pass through the human gastrointestinal (GI) tract. During transit,physical and chemical barriers such as peristaltic action, pH gradients, and intestinal enzymesprotect the gut from microbial colonization. However, select bacteria can overcome thesebarriers by adhering to specific niches in the GI tract using surface proteins called adhesins (1).Adhesins locate bacteria in environments conducive to their growth, granting them a selectiveadvantage. Therefore, both the surface properties and environment of a microbe are essential totheir survival. While structural research regarding adhesins and their targets is expanding, little isknown about the parameters governing microbial binding within the GI tract; describing theseparameters therefore can lead to a fundamental understanding of bacterial attachment.Previously, complex microfluidic devices that simultaneously incorporate physiologicalcharacteristics, mechanical forces, and mammalian cell co-cultures have been used to studymicrobes in the GI tract (2, 3). While these are valuable models of in vivo activity, theircomplexity obscures analysis of how individual environmental conditions and the surfacecharacteristics of microbes affect their attachment. To address this challenge, I have developeda modular platform to engineer the adhesive properties of live microbes and investigatetheir attachment under various conditions. This platform uses adhesive ligands conjugated tothe bacterial surface as a proxy for adhesins, allowing tunable ligand density and specificity onbacteria. Using this system, the influence of bacterial surface properties on attachment can beanalyzed in more detail than is possible with unmodified bacteria. Furthermore, by incorporatingfactors (either individually or in combination) such as bile salts, pH variation, fluid flow, andenzymatic activity, the influence of environment on bacterial attachment can be determined. Ihypothesize that bacterial adherence in the GI tract is a consequence of both bacterialsurface characteristics as well as environmental factors. By using a modular platform tocontrol the microbe surface and its environment, the proposed approach can be used to studyattachment of diverse bacterial species to biotic or abiotic surfaces under varying conditions.Aim 1: Determine how the specificity and density of adhesive ligands on microbial surfacesaffect attachment. During my first year as a graduate student, I have developed a platformbased on avidin and biotin binding to mediate the attachment of bacteria to targeted surfaces.Bacteria are first functionalized with biotin using N-hydroxysuccinimide (NHS) chemistry,which forms an ester bond between biotin and primary amines on the bacteria surface. Adhesiveligands (such as antibodies, as shown) are conjugated to streptavidin using amine-basedchemistry and are then linked to biotin groups on bacterial surfaces following mixing (Figure1A). To date, I have demonstrated that biotinylation of bacteria enhances binding to an abioticstreptavidin-coated surface (Figure 1B) and that attachment of Intracellular Adhesion Molecule(ICAM-1) antibodies enhances binding to live Caco-2 cells, a model cell line of intestinal40003000Biotin Targeting Ligand 2000Bacteria100000.0 0.2 0.4 0.6StreptavidinCell Density (OD600)).u.a(ecnecseroulF4000TaTargrgeetteedd3000 CCoonntrtrooll200010000Cell Density (OD600)).u.a(ecnecseroulFA 500040003000200010000 0.2 0.4 0.6 0Control TargetedFigure 1. (A) Schematic of engineered microbe. (B) Concentration-dependent attachment of biotinylated GFP-expressing bacteria to a streptavidin-coated well plate. (C) Attachment of ICAM-1-targeted, GFP-expressingmicrobes to live Caco-2 cells compared to an unmodified control.).u.a(ecnecseroulFC 500040003000200010000Control Targeted).u.a(ecnecseroulFBenterocytes, in comparison to a non-targeted control (Figure 1C). To optimize this system, I willadjust the density and specificity of antibodies on bacterial surfaces. Antibody density iscontrolled by the extent of bacterial-surface biotinylation and will be varied using the ratio ofbiotin mass to bacterial density. The density of biotin sites on the bacteria surface will bequantified following fluorescent streptavidin probe attachment using flow cytometry. Next, theeffect of antibody specificity will be determined with three anti-ICAM IgG antibodies (clonesR6.5, 1A6, and 1A29) with varying specificity for ICAM on Caco-2 cells. Monolayers of Caco-2cells will be grown in tissue culture treated well plates and incubated with GFP-expressingmicrobes that have varying antibody density and specificity. Bacterial attachment will bequantified using the fluorescence signal from attached bacteria, measured using a plate readerand analyzed for their spatial localization using microscopy. By enabling precise control over thesurface characteristics of microbes, this aim provides clear insight into how these characteristicsinfluence microbial binding. The antibody configuration (density and specificity) that providesthe highest levels of attachment in Aim 1 will be further analyzed in Aim 2.Aim 2: Use Design of Experiments to analyze and optimize environmental parameters formicrobial attachment. Design of Experiments (DOE) is a statistical8000approach to determine the sensitivity to and interactions betweenindividual parameters that affect a system response (4). This approach 6000will be used to screen four environmental factors for their relationship 4000to microbial binding: bile salt concentration, pH, intestinal enzyme2000activity, and fluid flow rate. The factors will be tested at two levels thatreflect the upper and lower limits experienced along the GI tract. 0Microbial attachment will be determined using a GFP-expressing strainin well plates (for static studies) or a straight-channel microfluidic chip(for fluid flow studies) that I have previously validated for targetedmicrobial attachment (Figure 2). Attachment of microbes will bequantified both through automated particle counting in ImageJ and with fluorescence intensity inthe well plates or microfluidic channels. Results from the screening experiments will be used toidentify which of the factors significantly influence microbial attachment. A secondary studywith the identified factors will be designed to determine a response surface model and adesirability profile for microbial binding in varying environmental conditions. This will be usedto estimate the conditions that optimize microbial attachment, which will be validatedexperimentally. By optimizing the environmental conditions, this model can determine thelocation of the GI tract that is most conducive for a bacteria’s attachment.Broader Impacts. This interdisciplinary proposal applies techniques from materials science,engineering, microbiology, and biochemistry to analyze parameters that influence microbialattachment and represents a practical, tunable system for modifying the adhesive properties ofmicrobes. Successful completion of this project will provide valuable insight into themechanisms of microbial colonization of the human GI tract. More broadly, due to the ubiquityof microbes in the biomedical sector, modular platforms that can be used to provide mechanisticinsights into a variety of microbes on both biotic and abiotic surfaces are sorely needed. Asresearch is most impactful when communicated directly to the public, I will teach middle schoolstudents the profound role bacteria play in our lives and our environments through MoreheadPlanetarium’s SciMatch program. Additionally, I will broaden the reach of this research with anovel art/science collaboration designed to increase public scientific literacy in Chapel Hill.[1] Stacy et al. Nature reviews. Microbiology 14, 93-105 (2016). [2] Kim et al. Lab on a chip 12, 2165-2174 (2012).[3] Bhatia and Ingber. Nature Biotechnology 32, 760 (2014). [4] Anderson et al. Productivity Press (2007).slleCdehcattAControl TargetedFigure 2. Attachment ofbiotin-conjugated bacteria tostreptavidin-coated channelsunder flow (1μL/min)"
77.0,"Foreword: Because I am a BioMAT trainee with two years of NIH support, my adviser, Dr.Shuichi Takayama, allowed me to build my own project. Motivated by my interest inimmunopathology, I independently created this project after becoming familiar with the workof our established airway disease collaborator, Dr. Rabindra Tirouvanziam at Emory University.My adviser plans to expand my idea into a full grant proposal that I will write with him.Motivation: Inflammatory airway diseases (IADs), including COPDa, CFb, and asthma, are thefifth leading cause of mortality globally.1 Chronic pulmonary inflammation can lead to fibrosis,recurrent infection, and loss of lung function that requires transplant. Neutrophils (PMNsc) are theperpetrators of this excessive inflammation, making them a target of therapeutics and motivatingthe study of mechanisms driving their pro-inflammatory conditioning.plug In vivo models are insufficient due to significant differences in the1.generatorfunction of inflammatory mediators and disease phenotype. They also do notoffer the ability to systematically eliminate confounding variables, making inApicalvitro models attractive for mechanistic studies. In typical in vitro studies,channelinvestigators expose either blood PMNs or epithelial cell lines to a disease-Alvetex related stimulus (e.g. smoke, bacteria) in a static system and measure cells’membrane responses. Despite these efforts, no therapeutics have yet halted the cycle ofdamage inflicted by PMNs, motivating more sophisticated mechanisticBasalchannel studies to inform therapeutic strategies.In vitro models neglect fluid mechanical stress (FMS, caused bythickened lung mucus) and PMN transmigration into the lumen despite1. plug 2. trans-evidence that severe, FMS-induced crackling sounds are one of the top threepropagation migration2 . clinical predictors of poor prognosis in CF and COPD,4,5 and PMNs thattransmigrate into diseased lung fluids acquire a pro-inflammatoryphenotype.2,3 These processes may be connected: thickened mucus causesapical ASLFMS-induced epithelial inflammation that recruits PMNs and makes themepitheliumpro-inflammatory. Stressors are known to induce sterile inflammation incollagenmany cell types.7 Bronchial epithelial cells produce exosomes, cytokines andAlvetexmiRNA in response to compressive mechanical stress, and hypoxia-stressedendothelium epithelial cells release exosomes that activate proinflammatory signaling inbasal ch. macrophages.8,9 I hypothesize that fluid mechanical stress induces sterileinflammation of the epithelium resulting in epithelial exosomes, miRNA andFig. 1: Device design.Fig. 2: Cross-section. cytokines that contribute to the inflammatory phenotype of PMNs. Theobjective of my research is to establish a novel microfluidic model of pulmonaryinflammation, incorporating FMS and PMN transmigration, to discover pro-inflammatorypathways that are inaccessible with current models.Aim 1: Design, develop and optimize the “lung inflammation-on-chip” microfluidic device.I am currently modifying the lab’s established lung device,2 which already includes FMS,to incorporate PMNs by adding a porous AlvetexTM membrane that our Emory collaborators useto model PMN transmigration.3 To generate confluent, primary epithelial and endothelial cells onthe membrane, I will adapt established Transwell coculture methods: I will continuously flowmedia on both sides until confluence, which I will evaluate with trans-bilayer electrical resistanceand staining for tight junctions.10 To differentiate the epithelial cells, I will remove media from theapical channel and flow 5% CO air for 14 days with media flowing in the basal channel. Liquid2plugs will be generated in the absence of neutrophil flow with PBS + 1.2 mg/mL of the surfactantSurvanta; the target speed of the liquid plug is 2 mm/s at an air pressure of 1 kPa to modelphysiological conditions of sublethal stress.11 Liquid plug speed and pressure drop will bemeasured with established methods from our lab.2 Viscosity of the plug-generating fluid will bemeasured with rheometry. Computer-controlled electromechanical actuators will create the airflow switching that generates liquid plugs. To validate transmigration, neutrophils will flow on thebasal side of undamaged epithelium and the apical side will be incubated with either a) RPMIcontrol or, to induce transmigration, b) RPMI+100 nM LTB4 or c) patient airway surface liquid(ASL). PMN analysis described in [3], including flow cytometry and measurements of metabolismand bacterial killing, will validate that the model produces proinflammatory PMNs.3Aim 2: Model stress-induced inflammation and infer novel inflammatory networksEpithelial cells will be exposed to 0, 6, 12 or 24 hours of liquid Liquid PMNplugging at a constant rate and pressure drop (5 plugs/min and 1 kPa), and plugging transmig.then PMNs will transmigrate through the stressed epithelium (see Figs. 1-collect apical & basal fluid2 for diagrams and Fig. 3 for workflow). Exosomes will be isolated withan ExoQuick kit and lysed with 5% Triton X. 40 cytokines (including IL- PMNs : flow supern atant8, CXCL1, IL-1β, IL-6, and IL-10) will be measured with Luminex assays, cyt, assays + exosomesfrom [3]and neutrophil elastase (NE) will be measured with ELISA for intra- and soluble cyto-extra-exosomal groups (extracellular NE activity is a predictor of lung e xosomes kines, m iRNAfunction in CF adults3). miRNA will be isolated from supernatant ande xosomal Lum inex,exosomal lysate with the miRNeasy Mini Kit. miRNA microarrays willcytokines, microarray,identify frequently occurring miRNAs in the supernatant and exosomal miRNA RT-PCRlysate. Quantitative RT-PCR will validate the microarray data.12 I willFig. 3. Aim 2 workflow.compare the ASL and PMNs from models with stressed and unstressed epithelium, and I willinclude no-PMN devices as controls. I will also compare transmigrated and non-transmigratedPMNs from the same device. These comparisons will be made at all 4 timepoints so I can evaluatehow the system evolves from healthy to diseased over extended stress exposure.To interpret my data, I initiated a collaboration with Dr. Kelly Arnold at Univ. ofMichigan, whose lab specializes in analyzing COPD patient sputum and blood using data-drivencomputational approaches to infer cytokine networks driving cell behavior, tissue phenotype anddisease progression. The Arnold lab will use systems biology computational methods to identifyinflammatory PMN markers from my flow cytometry data and infer proinflammatory cytokinenetworks between epithelium and PMNs from the 40-plex Luminex assays. My hypothesis iscorrect if a) PMNs that transmigrate through stressed epithelium are pro-inflammatory (based onassays from [3] or cell surface marker expression) and b) proinflammatory cytokines or miRNAare produced by the epithelium in response to FMS that stimulate PMN inflammation.Broader Impacts: I am uniting leaders in microfluidics, immunology and systems-level dataanalysis to engineer a novel IAD pathology model and discover immunological mechanisms thatwill inform therapeutic design, ultimately reducing lung transplants and extending lifespans.This work is applicable to all IADs and the device can also be used to model immunopathology ofpneumonia, lung cancer, or idiopathic pulmonary fibrosis. I will disseminate my results inpublications, conferences and seminars with incarcerated people, and I will mentor undergraduatesand minority high school students through ENGAGES. ● achronic obstructive pulmonary disease. bcysticfibrosis. cpolymorphonuclear leukocytes. Ref: 1“(COPD).” WHO, 2017. 2Tavana et. al (2011) Biomed. Microdev.3Forrest et. al (2017) J Leukoc Bio. 1-11. 4Konstan et. al (2007) J Peadiatr 151:134-9. 5Jacome et. al (2017) Clin RespJ 612-620. 6Unpub., Tirouvanziam Lab 7Fleshner et. al (2017) Trends in Immuno 38(10):768-76. 8Park et. al (2012)Mech. of Allergy 130:1375-83. 9Moon et. al (2015) Cell Dth 6. 10Hermanns et. al (2004) Lab Invest. 84:736-52.11Yalcin et. al (2007) J App Physio 103(5):1796:807. 12Ohshima et. al (2010) PloS ONE 5:e13247."
78.0,"Motivation: Hydrogenation is an especially important industrial reaction that finds uses inpharmaceutical, agrochemical, fragrance, and fine chemical synthesis. 10-20% of chemicalreactions at Roche (the world’s third largest Biotech company) are catalytic hydrogenations1, andhydrogenation of N to NH consumes an estimated 2% of the world’s energy supply.2 3Supramolecular chemistry utilizing adjustable hemilabile ligands that approximate enzymaticactivity has been an extremely active area of research, and hydrogenation can be improvedsignificantly with respect to its chemoselectivity by tuning the catalyst to minimize over-hydrogenation. Mirkin et al. have constructed elegant ‘molecular tweezers’ that take advantageof chloride binding and supramolecular interactions to create switchable on/off catalytic turnover2.Miller et al. have recently published a PCN (phosphorous-carbon-nitrogen donor atoms) pincerligand that takes advantage of macrocycle-cation interactions to enable both switchable andtunable catalytic activity2; however, this ligand’s catalytic potential has not yet been fully realized.Cation interaction with the macrocycle can speed the catalyzed reaction rate of olefin isomerizationby over three orders of magnitude3. In situ control of catalytic activity via hemi-lability of crownether/cation interactions will revolutionize homogenous hydrogenation catalysis. The ability tocompletely quench catalysis via addition of an anion, resulting in precipitation of a simple salt andre-coordination of the unoccupied crown-ether to the catalytic metal center, will give a new degreeof control to hydrogenation catalysis. This will eliminate over-hydrogenation, a well-documentedissue with isophorone, an essential polycarbonate precursor4 as well as other feedstocks.Enzymes are notable for their ability to use first-row transition metals to catalyze a widevariety of molecular transformations. These metals are generally more abundant, less toxic, andeasier to dispose of than their heavier isoelectric counterparts. Replacing precious metals with‘greener’ options is of vital importance to sustainable chemistry. Hanson et al. have reported anair- and water-stable Co(II) complex with a pincer ligand that is capable of hydrogenating alkenes,aldehydes, ketones, and imines at low pressures of gaseous hydrogen (1-4 atm) and lowtemperatures (>60°C)5. A Re complex with PNP was recently reported to activate N , but does2not have switchable or tunable properties6.Research Plan: Pincer ligands are attractivedue to their thermal and oxidative stability aswell as ease of modification. I hypothesize thatinstalling a hemi-labile macrocycle to a PNPligand will allow significant switchable andtunable activity of an established homogenoushydrogenation catalyst. The synthesis of anovel ligand is shown in Scheme 1 usingcommercially available starting materials andknown methodology. The phosphine,macrocycle, secondary amine, and metal ionscan all be varied to generate a large library ofScheme 1: Synthetic route for L. X= Halide; M=complexes for catalytic analysis. The doubleCo (II), Ir (II), Re (II), Rh (II); M’=Na+, Li+, Ca2+;crown ether moieties are hypothesized toR=Ph, Me, Cy.increase the tunability of catalysis even furtherthan the published example by Miller et. al. Tunable steric bulk arising from the cation complexedcrown-ethers, is hypothesized to allow for substrate specificity in hydrogenation.Coordination of a vacant crown-ether to the catalytically active metal will block theassociation of H that must take place for catalysis to occur; however, when a Group 1 or 2 cation2Kevin Michael Wyss – Research Proposalbinds to the crown ether, it will detach from the Co(II) and allow H to access and be activated by2the transition metal (Scheme 2). My first goal will be to optimize of the synthesis and purificationof L. Characterization of L will include single crystal XRD, mass spectrometry, and NMR.Determination of the stability of L to air and water, and its solubility, will be essential to furtheranalysis of the complex.My second goal is to assess the ability ofL to catalyze the selective hydrogenation offurfural. Furfural is a popular industrialfeedstock that is a bio-based renewable buildingblock for a wide range of polymers andfertilizers. Selective hydrogenation of furfural tofurfuryl alcohol is a vitally important part ofScheme 2: Showing the switchable activity of L. functionalization, and often requires the use ofnoble metals10. It is presumed that hydrogenationusing Ir(II) will occur readily for a variety ofalkenes, alkynes, imines, and carbonyls throughredox pathways as there is significant precedentfor this in literature. A mechanism showing thehypothesized hydrogenation is shown in SchemeScheme 3: A proposed mechanism for the 3. Besides furfural, it is hypothesized that thishydrogenation of furfural to furfuryl alcohol. same mechanism should allow for selectivehydrogenation of substituted benzaldehydes andcyclohexenes, two other classes of molecules that that are of high industrial importance. Screeningmultiple L complexes with an array of substrates, under varying reaction conditions will identifytrends to investigate in further studies. Addition of anions to the reaction solution is hypothesizedto result in a switchable activity. The identity of the cation used to dislodge the crown-ether fromthe active site, is also expected to result in tunable rates of reaction, with Group 2 likely exhibitingthe fastest rate as the fit best within the crown ether.I will then determine whether earth abundant Co(II) can substitute Ir(II) in the catalysis.Hanson et al. assert that the mechanism of hydrogenation proceeds through a Co(II) hydrideintermediate, and that the coordination of a secondary amine to the metal center is essential5. Itis hypothesized that although 3d catalytic pathways often favor one-electron processes due to size,as L still contains the secondary amine, hydrogenation via reductive elimination of the hydrideintermediate can still occur. Use of deuterium-labeled H and solvents to probe the catalytic2mechanism will result in crucial fundamental research in this budding class of catalysis.Mechanistic study of catalytic cycles is an important area of fundamental research, and it isnecessary to improve selectivity and turnover, or to design complementary catalysts.Broader Impacts and Intellectual Merits: Earth abundant metals are cheaper, safer, and greeneralternatives when used as catalysts, and this is an important aspect of establishing sustainablechemistry as well as increasing the long-term economic security of the U.S. by decreasingdependence on unstable sources of precious metals. The work will also contribute to ourfundamental knowledge of switchable and tunable catalysis which is a relatively new andunexplored area.1) Curr Opin Drug Discov Devel., 2001, 4(6), 745-755. 2) Science, 2010, 330, 66-69. 3) J. Am. Chem. Soc., 2014,136, 14519-14529. 4) J. Am. Chem. Soc., 2015, 137, 12121-12130. 5) J. Am. Chem. Soc., 2013, 135, 8668-8681. 6) J.Am. Chem. Soc., 2018, 140, 7922-7935. 7) ACS Catal., 2017, 7, 1720-1727. 8) Russ. J. Gen. Chem., 1986, 56(8),1777-1781. 9) J. Organomet. Chem., 2017, 845, 82-89. 10) Sci. Rep., 2016, 6, 28558."
79.0,"Introduction: Conventionalseismicmomentresistingframes(SMRFs)aredesignedtoresistanddissipateseismicenergybytransferringtheloadsanddistributingpermanentyieldingtotheprimary members, such as beams and columns. While this design philosophy performs well inproviding strength and collapse resistance to a structure, damage to major structural memberspresents a major drawback in economical repairs. Therefore, most recent alternative designs notonlyseektodissipateseismicenergyandavoiddamageintheprimarymembers,butalsotomitigatedamageintheconnectionsthemselves. Inessence,thedevelopmentofsuchaconnectionincreasesseismicresiliencyinstructures,avoidingexpensiveanddisruptivereplacementofentirememberswhilealsolimitingexcessivedeformationsattheconnections. Onesuchmethodistheslidinghingejoint(SHJ):1 Figure1showsthe proposedSHJconnectionwithmodifications. Theflangesofthebeamareconnectedtoslidingplateshingedtothecolumn. Thus,asthecolumnandbeamrotateduringseismic events, theconnection’srotation causesthe platestoslip, andenergyis dissipatedintheformoffriction.Because the moment resistance is dependent on the frictionprovided betweenthe platesand flanges, challenges intheir designincludeensuringthattheconnectionsstillprovideadequatestrengthand safety under service. Additionally, the benefit in mitigatingtheneedtoreplaceconnectionsafterdamagecanonlyberealizedby ensuring that the joint return to its original position. Sinceit is desired that the connection also be economical and simpleto build, the proposed research will be the first to examine theperformance of posttensioned (PT) strands as the self-centeringmechanismcoupledtoaslidinghingejoint(SHJ-PT).Theproposedstudy will be focused around the achievement of the followingprimaryobjectives: 1)developmodelsfortheSHJconnectionandFigure1: SHJconnectionwithPTstrands,and2)performsimulationandanalysesonthemodels PTstrands1and,resourcespermitting,experimentaltestingofthesubassembly.Hypothesis: Posttensionedstrands providean economical, easily-constructable, and geometri-callyflexiblemechanismofrecenteringfortheslidinghingejointconnections.Objective 1: Development of Models for SHJ and PT Strands The proposed connectionconsists of a beam and column connected with shear plates. The SHJ as described by Clifton(2005)2 willbeemployedasthemethodofenergydissipation. AsshowninFigure1,steelstrandsparalleltothebeamareanchoredtothecolumnsinordertostressthebeam. Whiletheexperimentaltesting of full-scale structures under seismic loads is one method to examine response behavior,suchtestsarecostlytoperformandgenerallystillrequiresupplementalanalysestoassesslocalizedmaterialresponse. Expandingonexistingmethods,3 ananalyticalprocedurewillbedevelopedtoestablishtherelationshipbetweentheconnectionrotationandthemechanicalresponsedevelopmentin the PT steel strand. For a range of rotation induced by seismic loads, the response of the PTstrandwillbedeveloped. SimilartoworkbyKhoo(2012),4 theSHJcanbemodeledusingasystemof rotational springs, thus providing the SHJ’s response to seismic load. When coupled with thepreviousmethod, thetotalstructuralresponseandbehavioroftheSHJ-PTcanbestudied; output1GCCliftonetal.“Slidinghingejointsandsubassembliesforsteelmomentframes”. In: 2007.2GCClifton. “Semi-rigidjointsformoment-resistingsteelframedseismic-resistingsystems”. PhDthesis. 2005.3ConstantinChristopoulosetal.“PosttensionedenergydissipatingconnectionsforsteelMRFs”. In: (2002).4Hsen-HanKhooetal.“Developmentoftheself-centeringSHJwithfrictionringsprings”. In: (2012).1strainsanddisplacementsfromthePTstrandsmodelarepassedtotheSHJspring-model’srotationsandanalyzed (andvice versa)in orderto fullyunderstandthe interactionbetween thetwo systems.Additionally,finiteelementmethodanalysiswillbeperformedtocheckthatthestressesontheplatedonotexceedthefailurelimitsoftheplates2.Objective 2: Perform Seismic Simulations and Analyses on Models Working with Dr. Pa-tricia Clayton (UT), I will numerically investigate the performance of the SHJ coupled with PTstrands under earthquake simulations. Using the component models developed under Objective1, building models will be constructed. These building models will be subjected to time-historyanalyses simulating a series of ground motions representing the maximum considered event andservicelevel earthquake. In thisobjective, thegoalsare toarrive atadequate responseresultsfromwhichaproceduretodeterminedesignparameterscouldbeestablished. Asametricofachievement,the results will be subjected to validation using existing test data from previous studies5,6. Uponthe model structure’s achievement of data validation and providing sufficient response to bench-markloads,thecomputationalstudycanbeexpandedtoobservetheperformanceofthestructuresutilizingvariationsofthedesignedconnection,suchasusageataspecifiedspacingsandbaysorwith varying strengths of the sliding hinge plates. Resources permitting, testing of the proposedSHJ-PTconnectionsubassemblycanbeperformedusingthefacilitiesattheFergusonStructuralEngineeringLaboratoryattheUniversityofTexas.IntellectualMerit: Thoughthereisexistingresearchonthedevelopmentoftheslidinghingejoint6,1,2,4 andtheanalysisandtestingofreplaceableconnectionsutilizingPTstrands7,8,5,effortsto couple these concepts in a design have yet to be extensively studied. Results9,4 from previoussimulationsand physical testinghavedemonstrated theSHJ’sability to mitigate damage aswell asitspotentialtobecoupledwithself-centeringmechanismsandwarrantsfurtherresearchintonoveldesigns. Asitstands,theSJH-PT’sadvantagesare: 1)mitigationofdamagetoprimarymembersandlimitingdamageontheconnection;2)constructionusingconventionalmaterialandskills;3)abilitytoself-centerafterevents. Thesebenefitswarrantfurtherstudyintotheconnections’strengthandserviceabilitypotentials. ThestudyalsoaimstoaddressconcernsbasedonpracticalityofPTstrands in connections based on the effects of gap-opening and the compression that the strandsinduceinthebeamflanges1.BroaderImpacts: DrawbacksincurrentpracticeinSMRFsthatemployweldedconnectionsinclude seismic damage to beams and columns that require disruptive and costly replacement ofthecomponent. ThesuccessfuldevelopmentofSMRFsusingenergy-dissipationmethodsmeansremovingtheneedtoreplaceconnectionsafterseismicevents, leadingtoamoreflexiblerecoveryprocessforstructuresafternaturaldisasters. Thisplaysahugeroleinpresentingretrofittingoptionstoboostresilience forstructuresinareaswhere seismicrisksarerisingdue toenvironmental andindustrial impacts. I will also work to increase the acceptance of the SHJ-PT connection in thestructuralengineeringcommunitythrough1)publicationsinnotablejournals,suchasJournalofStructuralEngineeringandJournalofConstructionalSteelResearch,2)attendingconferencesinthediscipline,and3)workingcloselywithindustryentities,especiallythosealreadywithproprietarywork in semi-rigid moment connections such as Simpson Strong-Tie and Skidmore Owings &Merrill,inordertofurtherdevelopandpopularizeenergydissipationbasedSMRFconnections.5JamesMRiclesetal.“Posttensionedseismic-resistantconnectionsforsteelframes”. In: (2001).6HHKhooetal.“Experimentalstudiesoftheself-centeringSlidingHingeJoint”. In: (2012).7Ying-ChengLinetal.“Seismicperformanceofalarge-scalesteelself-centeringMRF”.in: (2012).8PatriciaMClaytonetal.“Seismicdesignandperformanceofself-centeringsteelplateshearwalls”. In: (2011).9GregoryAMacRaeetal.“Theslidinghingejointmomentconnection”. In: (2010).2"
80.0,"Improving Bounds on the Entropy of Odd Cycle GraphsKeywords: graph entropy, independent set, indistinguishabilityIntroductionThe entropy, also known as the Shannon capacity, of a graph is an important quantity ininformation theory, and can be used to study the zero-error capacity of a noisy communicationchannel. This channel can be represented as a cycle graph G in which each vertex represents atransmitted symbol and each edge indicates indistinguishability betweensymbols. A cycle graph is a graph which consists of a single cycle, i.e. a seriesof vertices connected in a loop. For instance, the cycle graph C (shown in5Fig. 1 with one of its independent sets in blue) represents a communicationchannel with five distinct symbols (herein called a, b, c, d, and e) in whichadjacent symbols can be mistaken for each other due to noise in the channel.Figure 1. TheThe question posed is to determine the most efficient communication schemagraph C with an5independent to transmit data with no errors and maximize precious band-width, and thisindicated in blue.information density is encapsulated by the quantity known as graph entropy.BackgroundDue to their graph theoretic properties, the entropy of all even cycle graphs is known. The samequantity is far more elusive for odd cycle graphs, however. In 1979, Lovász famouslydetermined the entropy of C to be √5, but the entropy of C , for all odd p ≥ 7, is unknown. In a5 p2017 paper, Mathew and Östergård [1] used a stochastic search of independent sets guided bypossible symmetries to establish the current best bounds on the entropies of C for p up to 15.pEven in the few short years since their research, computers have increased significantly,presenting the opportunity to further improve these bounds by using new algorithms, highperformance computing, and theoretical results.ProposalTo further improve the known bounds on odd cycle graph entropy, I propose using today’sincreased computing power to run a variety of stochastic independent set search algorithms inparallel on high-performance computing clusters. Determining the entropy of a graph involvesmaximizing the size of its independent set, and the hope is that this search will yield at least aslight improvement in the previous bounds found in [1], particularly on the entropy of C .7Another source of potential untapped by Mathew and Östergård is the algorithmic Lovász locallemma, proven to succeed by Moser and Tardos in 2010 [2]. Because there is a natural family oflocal modifications to be made to a graph’s independent set, the lemma gives an algorithmic wayto explore the space of independent sets.A third approach is to turn the problem of finding a graph’s entropy by constructing a maximalindependent set into a boolean satisfiability problem (abbreviated SAT) and apply a SAT solver.Over the last decade, the field of SAT-solving has produced numerous sophisticated and effectivemethodologies, yielding a variety of strategies for approaching the entropy problem [3].MethodsI plan to focus initially on the entropy of C , in three stages: stochastic independent set search7algorithms, application of the algorithmic Lovász lemma, and use of multiple SAT-solvingstrategies.Noemi Glaeser Graduate Research Plan NSFGRFP 2018In the initial stage, I will attempt to improve the bounds on entropy by writing code toprobabilistically constructing independent sets. With various start configurations (an empty set, arandom set, or a simple suboptimal construction, for instance), I will allow an iterative programto run for a limited time span, attempting to add points to the set. The method of adding pointscan be varied, e.g. allowing replacement of one point for another, or two points for another, butnever removing more than two points at a time. Another approach is to simulate physics in thesearch, for instance by favoring the addition of points that produce more rigid configurations,which would result in the lattice structure suspected in optimal packings. Each algorithm will beoptimized and modified to run in parallel on a high-performance computing cluster.Once the improvements from the initial stage have been exhausted, I will move on to applyingthe algorithmic Lovász local lemma to the problem. This involves a similar construction of theindependent set, but one that allows the insertion of illegal points and adjusts the existingstructure to restore a legal configuration. These changes propagate outward from the point oforigin and are guaranteed by Moser and Tardos to eventually stabilize.Finally, the problem can be redefined in terms of a Boolean expression to be satisfied by thelargest possible independent set. At this point, several free and open source third-party SATsolver algorithms, some of which are highly parallelizable, can be applied to the expression. Theexpression may also be rewritten in various ways, and the algorithms again applied, to improvethe chances of a favorable result. The practice of applying SAT solvers is becoming increasinglyeffective in addressing well-known problems, notably in [4].ConclusionIntellectual MeritShould these approaches prove successful, they can be applied to similar problems, particularlythe entropies of C with p ≥ 9. The algorithms developed may also prove to be useful for otherpproblems in graph and information theory, in particular the outline of the iterative stochasticprogram, the physics-inspired approach to packing problems, and the novel application of thealgorithmic Lovász local lemma.Broader ImpactA more accurate understanding and estimate of the entropy of these odd cycles has directimplications for the definition of error-correcting codes. Knowing the entropy of C , for instance,7offers a constructive proof of the existence of a specific optimal information density, alsoyielding the construction of a 7-symbol encoding mechanism that realizes this density. This willlead to more efficient but still error-free communication through noisy channels, which couldimpact all digital communications, but in particular unreliable modes such as the satellitecommunication by phones, internet, and even space probes.[1] Mathew, K.A., & Östergård, P.R.J. (2017). “New lower bounds for the Shannon capacity of odd cycles”.Designs, Codes and Cryptography, 84: 13-22. doi:10.1007/s10623-016-0194-7.[2] Moser, R.A., & Tardos, G. (2010). “A constructive proof of the general Lovász local lemma”. Journal of theACM, 57(2): 1-15. doi:10.1145/1667053.1667060.[3] Gong, W., & Zhou, X. (2017). “A survey of SAT solver”. AIP Conference Proceedings, 1836(020059): 1-10. doi:10.1063/1.4981999[4] Heule, M.J.H., Kullmann, O., & Marek, V.W. (2016). “Solving and Verifying the Boolean Pythagorean Triplesproblem via Cube-and-Conquer”. Lecture Notes in Computer Science: 228–245. doi:10.1007/978-3-319-40970-2_15."
81.0,"[1], a major gap still exists between the skills of these graduates and the skills needed forindustry success [2]. Two major components of this gap are programming skills (e.g. code style)and computational thinking (e.g. extending algorithms). My research will enable teachers toclose these gaps by building a toolkit to integrate better-targeted problem types than thosecurrently in use.Programming assignments in CS classrooms, primarily code tracing and code writing,lack the granularity to target students’ Zones of Proximal Development (ZPD, i.e. challengingbut solvable problems). Code tracing questions involve reading and understanding code, but theymay not trigger students’ mental models of concepts because they are tedious or too easy [3, 4].Code writing questions are a large leap from code tracing, conflating many programming skillsinto a single solution (e.g. design, computational thinking, programming, code style) andsupporting a wide space of disparate approaches and solutions.Extrapolating from earlier results [3], I propose the use of Parsons problems (e.g. [5]) tohelp students remain in their ZPD while learning computational thinking and programmingthrough advanced CS concepts. Parsons problems involve unscrambling chunks of code, oftenindividual lines, from a target program into a correct solution. Such problems provide similarlearning gains to code writing problems – often 30% faster – for introductory assignments [3].My research will enable teachers to integrate Parsons problems into existing curricula tobetter attain their teaching outcomes by providing a toolkit for these new problems.Preliminary Work Within my Ph.D., I have been studying how Parsons problems can beapplied to improve CS pedagogy. In Spring 2018, I ran an exploratory between-subjects studywhich found that when students begin by solving a Parsons problem instead of writing code, theyare more able to generate multiple alternative solutions, addressing a skill gap in the “ability togenerate alternate solutions” [2]. In Fall 2018, I ran a within-subjects study, followed by astructured interview, teaching algorithms to students who had not taken an algorithms class.They were taught two algorithms by either writing code from a pseudocode specification (i.e. alanguage-independent solution) or by solving a Parsons problem. Students with a range of skillsnoted that Parsons problems let them focus on the logic of the algorithm, engaging them incomputational thinking. Students found writing code from pseudocode to be either too complex,distracting their focus, or too trivial, not engaging with the algorithm. These results suggest thatParsons problems can support a variety of students in practicing their computational thinking.Approach In my thesis research, I will explore how we can leverage new problem types, e.g.Parsons problems, to supplement existing teaching tools for advanced CS concepts. I will runlongitudinal studies on these new problem types by partnering with UC Berkeley professors whoteach relevant classes with hundreds of students. I will then synthesize the results from thesestudies to develop a toolkit for teachers to help teachers easily adapt existing material into Parsonproblems and achieve their curricular desires.RQ1: How can Parsons problems support the development of computational thinking withalgorithms? Based on my Fall 2018 study, I am now exploring how to help students furtherfocus on computational thinking with new Parsons problems that flexibly blend pseudocode withcode within or between problems. By using pseudocode, students are constrained to rely less onsyntax and more on computational thinking. I will measure students’ learning gains of the taughtalgorithms as well as their performance on interview-style algorithm questions.RQ2: How can Parsons problems improve programming ability by teaching programmingidioms? One major risk of supplementing existing assessments with Parsons problems is that itcould hurt students’ programming skills by reducing their time spent practicing writing code. Toovercome this pitfall, I will explore how Parsons problems can improve code writing by teachingprogramming idioms (i.e. common code and design patterns such as finding the five largestnumbers in a list). There is a strong connection between students’ ability to write well-styledcode and their ability to select and apply appropriate programming idioms [6]. However,complex idioms are often not explicitly taught. Results from my Spring 2018 study indicate thatParsons problems could support students exploring multiple solutions to a problem usingdifferent idioms, helping them compare when they are effective to use. They could also exposestudents to a range of problems where an idiom is applicable, helping students learn how it canbe applied. I will run a formative study to better understand how students learn and select idioms.I will measure ABC scores of solutions, a well-established metric for code complexity, toevaluate students’ ability to efficiently apply idioms [6].RQ3: How can instructors easily integrate Parsons problems into their teaching? Even ifthese new problem types are found an effective teaching tool, it must also be straightforward forinstructors to generate and integrate them into the classroom. I will interview professors toexplore the range of teaching methods used in classes and homework. These interviews willguide the design of a system to give teachers a powerful tool to target specific learning goalswith more problem types. For example, a teacher could use think-pair-share in class to encouragestudents to share their problem-solving strategies by having students discuss which line ofpseudocode should be placed next in a Parsons problem. Or, the large corpora of studentsolutions could automatically generate Parsons problems for teachers to modify and use.Resources UC Berkeley provides rare access to collaborate with teaching professors in large,innovative classrooms. Here, my research will change how thousands of students learn CS.Intellectual Merit My work will enable further research of teaching tools throughout the CScurriculum. My proposal explores how students learn and use computational thinking andprogramming idioms in complex problems through problem types and assessments. While thereis a plethora of research on teaching introductory CS concepts, there is minimal research on howto teach advanced CS concepts, which are closer to real-world needs. The results of my workwill empower teachers to create new resources to help students learn complex CS concepts.This research will be the first to explore the effectiveness of Parsons problems beyondintroductory courses, creating new interactions and contexts for Parsons problems. This willinspire applying Parsons problems in new ways: incorporating them into more domains in CScurricula, using them for post-school learning such as API tutorials or system documentation, ornew situations where engaging with multiple solutions is beneficial.Broader Impact My research is inspired by a desire to make CS concepts more accessible.Code writing problems are “one of the most significant reasons for giving up” by online learnersin introductory classes [3]. These techniques will help improve learners’ self-confidence inthese areas, with the aim of reducing impostor syndrome and attrition, as a step towards makingCS programs more inclusive.The results of this research will be disseminated within top-tier publications in HCI andCS Education. My software engineering experience enables me to make the toolkits developedover the course of my research robust and publicly available. Together, these will helpresearchers and content creators make knowledge more accessible to a diversity of audiences.[1] https://nces.ed.gov/programs/digest/d17/tables/dt17_322.10.asp [2] Radermacher et al. “Gaps between industryexpectations and the abilities of graduates,” SIGCSE ’13 [3] Ericson et al. “Solving parsons problems versus fixingand writing code,” Koli Calling ’17 [4] Denny et al. “Evaluating a new exam question,” ICER ’08 [5] https://js-parsons.github.io/ [6] Wiese et al. “Teaching Students to Recognize and Implement Good Coding Style,” L@S ’17"
82.0,"Introduction: Habitat loss and fragmentation due to land development disrupt ecosystemservices, degrade carbon stocks, and threaten biodiversity1. Restoring connectivity betweenhabitat patches is an effective approach to conserve biodiversity in a fragmented landscape, butlimited funding requires prioritization of reconnecting habitat patches with high diversity. Thetheory of island biogeography2 suggests that area of a habitat patch and amount of space betweenpatches (hereafter the “matrix”) are both important for restoration3. Consideration of only patchand matrix area, however, is inherently a flat perspective: an abundance of life lives above-ground, around 40% of biodiversity in forests4. Habitat volume may better predict biodiversitythan area, and if so should be an important metric for establishing restoration priorities.The concept of an ecosystem as a multidimensional space of discrete niches is well-established5, and although a species-volume relationship has been recently proposed, it has notbeen rigourously tested6. My previous research shows that distinct microhabitats exist in amultidimensional space within forests7, and evidence suggests that canopy height and structure,which in part determine the number of available niches, influence diversity8. Taller, morestructurally complex canopies may provide more “vertical niche space” (VNS) for species to use.VNS crossed with patch area can be a metric for patch volume. Some evidence suggests thatVNS is more important for determining alpha diversity (hereafter alpha) than patch area9, andhigh-volume patches (fig. 1B) are expected to maintain higher alpha than low-volume patches(fig. 1C). Patch isolation (mean distance to closest patch on all sides) determines how easilyorganisms can cross between patches, and therefore influences alpha3. Depending on the landuse of the matrix (fig. 1E&F vs. fig. 1G&H), matrix VNS will vary, and high matrix VNS mayalso increase alpha of adjacent patches.In regions with immense biodiversity but rapid ratesof deforestation, such as Madagascar10, careful considerationmust be given to restoring land between high-diversitypatches. Conservation International (a conservation NGO) hasscheduled large-scale restoration work in the Ambositra-Vondrozo Corridor (AVC) of Madagascar, but baselinebiodiversity and forest cover monitoring is necessary.Herpetofauna (reptiles and amphibians) are particularlythreatened both in Madagascar11 and globally12. Herpetofaunaare abundant at all forest heights and some species arepersistent in even small forest fragments, making them anexcellent model taxon to test a species-volume hypothesis. Byintegrating high-resolution remote sensing of forests fromsatellites and an unmanned aerial vehicle (drone) with on-the-ground herpetofaunal surveillance, I will test the species-volume hypothesis to inform both ecological theory andrestoration efforts.Hypothesis: I hypothesize that volume of habitat patches and inter-patch matrix more accuratelypredicts alpha diversity than patch area and isolation distance alone. Aim 1: I will determine howwell patch area and isolation of habitat patches predict patch alpha. Aim 2: I will then build uponthe species-area theory by evaluating how well patch volume (area crossed with VNS) andmatrix volume (patch isolation crossed with VNS) predict patch alpha. Aim 3: I will use foreststructure and patch alpha to hierarchically prioritize restoration sites.Methods: To select sites, I will first use Landsat satellite-derived estimates of forest cover13 andICESat LiDAR-derived coarse estimates of canopy height14, and will calculate patch area andisolation using the SDMTools R package15. I will choose sites that are accessible and encompassforest patches that vary in size and structure. To acquire high-resolution models of volume, I willmonitor a total of ~84 km2 (40 days of flights, 0.7 km2 coverage each) via a senseFly eBee®drone. An equipped CANON Powershot® will record photographs that I will stitch togetherusing Pix4D photogrammetry software to produce 3D orthomosaic point clouds. I will divide thestudy region into 30m2 cells and substract orthmosaic points from a digital elevation model toderive mean and variance in canopy height (synthesized into a single VNS index) for each cell16.For both patches and matrix, I will multiply VNS by the standardized cell area to calculatevolume of each cell. I will record herpetofauna richness and abundance in forest patches acrossthe region by conducting 30 vertical surveys (from forest floor to top of canopy), sufficient forspecies accumulation (Scheffers, personal communication). I will perform generalized linearmodels17 (GLM; pending data structure and distribution) to model alpha in relation to 1) theinteraction between patch area and isolation and 2) the interaction between patch volume (sum ofcell volumes) and matrix volume (sum of non-forest cell volumes within a 5-km buffer zone of apatch). I will then conduct three restoration prioritization analyses using the software Zonation,which will prioritize cells by accouting for desired habitat inputs while iteratively removing theleast valuable cells. In analysis (A1) inputs will be patch area and isolation; in (A2), patch/matrixvolume; and in (A3) alpha of patches. I will contrast site selection for restoration by analyzingthe correspondence between output cells from A1 and A2 to cells with high diversity (A3).Resources: I will be advised by Dr. Brett Scheffers (University of Florida; UF), an expert onMalagasy herpetofauna, I am familiar with single-rope canopy access, and the members of theScheffers lab are certified with 1,000s of hours of canopy access. I will build point cloud modelsusing UF’s HiPerGator 2.0, the world’s third fastest university computer.Intellectual Merit: My proposed research extends a classic ecological theory, the species-arearelationship, by combining cutting-edge tools with conventional field methods. If my hypothesisthat habitat patch volume can predict diversity more accurately than area is correct, this studywill contribute to Understanding the Rules of Life, one of NSF’s 10 Big Ideas, and my workflowwill establish an efficient pipeline for estimating biodiversity. Once such drone methods areachievable via satellite, my study can be replicated without any site visitation. My diversitymonitoring may also contribute novel data on critically endangered and data-deficient species11.Broader Impacts: My work will inform the ambitious forest restoration projects planned for theAVC (2019-2024) and I have communicated with Conservation International to monitor sites ofmutual interest. Forest restoration will enhance ecosystem services, absorb carbon emissions, andmitigate flooding of local communities, and my forest structure data can be used to quantifycarbon stocks for offsetting projects in the region. As part of USAID PEER funding (2017-2021)to Dr. Brett Scheffers, we will collaborate with a Malagasy graduate student to train communitiesto monitor on-the-ground carbon stocks, thereby assisting them with active protection of theirforests. I will also facilitate a letter exchange between Malagasy students and the RiversideElementary School in the US, with which I have established contact on the matter. Citations: [1]Foley, J. A. et al. (2005) Science. [2] MacArthur, R. H. & Wilson, E. O. Princeton University Press, 2001. [3]Laurance, W. F. et al. (2002) Conserv. Biol. [4] Ozanne, C. M. P. et al. (2003) Science. [5] Hutchinson, G. E. (1957)Cold Spring Harb. Symp. Quant. Biol. [6] Gatti, R. C. et al. (2017) Plant Ecol. [7] Klinges, D. H. et al. Amer Nat. inreview. [8] Bergen, K. M. et al. (2009) J. Geophys. Res. Biogeosciences. [9] Basset et al. (2015) PLOS One. [10]Myers, N., et al. (2000) Nature. [11] Andreone, F. et al. (2008) PLOS Biol. [12] Böhm, M. et al. (2013) Biol.Conserv. [13] Hanse, M. et al. (2013) Science. [14] Simard, M. et al. (2011) J. Geophys. Res. [15] VanDerWal, J. etal. (2014). R package. [16] Lisein, J. et al. (2013) Forests [17] Webster, C. et al. (2018) Remote Sens. Environ."
83.0,"A Quantum Field Theoretic Approach to Disordered and Amorphous SolidsThe objective is to formulate a fundamental theory of defects in disordered solids using quantumfield theory (QFT) methods, with the ultimate goal of understanding amorphous materials.Motivation: P. W. Anderson said in 1995, “The deepest and most interesting unsolved problem​​in solid state theory is probably the theory of the nature of glass,1” glass being the prototypical​​highly-disordered amorphous material. Defects describe disordered materials in a more concrete,physical way, and are central objects of study in materials science. They govern the deformationof solids and overall mechanical properties, but also significantly affect electronic, optical, andother functional properties.2 This alternative approach to disordered systems holds great promise.​​Due to their long-range nature and effects, extended defects in particular, includingdislocations, grain boundaries, etc., are difficult to model and not well understood theoretically.Common computational methods like density functional theory (DFT) scale poorly with systemsize, making such defects too costly for simulation.2 Classical molecular dynamics is based on​Newtonian mechanics, so doesn’t take into account any quantum effects. While there existempirical models for the effect of defects on these functional properties, they need manyparameters, and none are fully ab initio. A radically different approach is needed.​ ​Introduction and Background: The classical theory of dislocations more or less fully explainsmechanical properties of materials. However, there remain many open questions on howdislocations and defects in general affect functional properties, that remain so because theclassical treatment is insufficient. I propose to describe extended defects in disordered solids as​quantum fields that give rise to quasiparticles, enabling a deeper understanding of defectinteractions. Motivated by the example of phonons as quasiparticles that quantize the latticedisplacement field, we define a new quantum field for dislocations and its associated quanta –the “dislon”3. Much as the phonon theory led to great advances in understanding the effect of​​lattice vibrations on photons and electrons, this new theory will lead to a similar paradigm shift.Initial Successes–the Dislon: A dislocation is an extended crystal defect. Critical to formalizing​​them is the Burgers vector b, representing the dislocation-induced lattice distortion and​ ​​associated displacement field u. This u is the classical field we turn into a quantum field for the​ ​​ ​first quantization. Conceptually, the constraint imposed by b is very important, as the only thing​distinguishing a phonon from a dislon, both being just quantized u at heart.​ ​​Already this theory has been successfully appliedto supplant previously incomplete explanations ofmaterials phenomena, such as the effect of dislocationson superconducting critical temperature T . The expression above is analytically derived and​ ​cdescribes the competition between quantum​ vs. classical effects.3 It predicts the direction of T​ ​ ​cchange after increasing dislocation density, which affects Poisson’s ratio ν and Lamé parameters​λ, μ. It is somewhat surprising because the expression combines variables/parameters describing​ ​ ​both mechanical and electronic properties, not usually seen together in one formula.Research Plan: I plan to join the Energy Nano Group, led by Prof. Mingda Li, creator of thedislon theory. His group combines theory and experiment, and I will contribute to the theory sideof research. With the dislon as the origin, we can organize our future work along three axes.Axis 1–Deepening: The dislon theory still has great potential to be applied to many other types​of interactions. One example is dislon-induced topological phase transitions, where we turn atopologically trivial material into a topological insulator by tuning its bandgap. I will includeelectron-dislon interactions into band structure calculations, which avoids the computationally1Haihao Liu Graduate Research Plan Statement October 2018expensive supercells required for DFT. Another application is dislon-enhanced Andersonlocalization, the suppression of electron diffusion in disordered systems.4 Dislons give us a way​to explore this effect in crystalline materials, which thus far has been challenging to observe.There is still much work to be done extending the theory itself. Most promising is theincorporation of gauge symmetry, a classical theory of which already exists for dislons.5 The​goal is to quantize this, analogous to quantum electrodynamics (QED) for electrons. In the same​way photons arise naturally from QED as a force carrier, we would expect something similarfrom a quantum gauge theory of dislons, that can shed light on the nature of plasticity.Axis 2–Broadening: The quantization procedure outlined for dislons can be readily generalizedto account for anisotropy and discrete lattices (current derivation is for continuum limit). Theinitial success with dislons means this is a promising approach to defects in general. In​conjunction to the work Axis 1 on 1D dislocations, I will generalize the quantization process to​2D grain boundaries and 3D inclusions. An analytical theory allows computation of interfacialtransmission coefficients for the Landauer formula from microscopic and no ad hoc parameters.​ ​Axis 3–Experimental: There will be a strong experimental component to inform and augment​​the theory development. Working with our collaborators at Oak Ridge, we will probe phonon-dislon interactions using advanced techniques like inelastic X-ray and neutron scattering, to seeif measured thermal transport and relaxation coefficients match those calculated from dislontheory. Additionally, we will use our lab’s crystal growth facilities to synthesize materials withcontrolled dislocation density, to explore dislon-induced topological phase transitions.Intellectual Merit: With the dislon model, all dislocation effects are incorporated: strain,coulombic, and vibrational. We now have a systematic framework to investigate the effect ofdefects on functional properties, by including a defect Hamiltonian. This allows us to calculateconstants such as deformation potential coefficient ab initio, which will lead to a deeper​ ​understanding of material properties far beyond any empirical model. We can also now use toolsfrom QFT like Feynman diagrams to study complex electron-phonon-dislon interactions.One may ask, why should extended defects be quantized to begin with? The intuition is thatextended (as opposed to point) defects have spatial extent, captured by the “field” part of QFT,and its resulting internal dynamic structure is described by the “quantum” part. We have shownthis idea applies to dislocations, suggesting it applies generally to all extended defects.Broader Impacts: These theories will have a profound impact on the direction of condensed​​matter and materials research. Much work now is on trying to find new materials with desiredproperties. By understanding how defects can induce such properties, we vastly expand thefamily of known materials exhibiting them, without needing to find completely new materials.As a radical theory that sits at the intersection of quantum field theory and materials science,two disciplines with relittle crosstalk, there is much educational potential. Through talking withmy colleagues in the materials science department, I aim to start bridging the gap between thesetwo communities. I plan to help develop a course introducing QFT to engineers, that I could be aTA for, and eventually down the line, perhaps even write a textbook on this theory.So far, over 20 years after Anderson’s comments, we still only have the empirical model ofelectrons in glass developed by Mott.1 By understanding defects, we hope to ultimately have a​fundamental theory of amorphous materials, as a limiting case of infinitely many defects.Works cited: [1] Anderson P W, Science 267, 1615-16 (1995) [2] Mott N F and Davis E A, Electronic processes in​ ​ ​​ ​non-crystalline materials (2012) [3] Li M, arXiv preprint, arXiv:1808.07777 (2018) [4] Anderson P W, Phys Rev​ ​ ​109, 1492-505 (1958) [5] Kadic A and Edelen D G B, A gauge theory of dislocations and disclinations (1983)​​ ​ ​2"
84.0,"Unraveling the process of polysaccharide utilization in complex bacterial ecosystemsIntellectual Merit – Introduction:Bacteria do not exist in isolation in nature; they form complex communities in which theymust recognize, compete over, and, share nutrient resources.1,2 The gut microbiome is an idealmodel to study this type of ecosystem, as we know what nutrients these bacteria are exposed toand have access to powerful tools to study taxonomy and metabolism. Gut bacteria break downpolysaccharide nutrients and convert them to health-beneficial end products of metabolism calledshort-chain fatty acids (SCFAs) that are taken up and used for energy by host intestinal cells.1,2However, there is a gap in our understanding of what factors give rise to the emergentphenomenon of SCFA production. The leading hypothesis in the field is that communities thatfail to respond to a given polysaccharide lack certain “keystone species” that are integral tometabolism.1 The search for keystone species has focused on primary polysaccharide degraders,1but findings in our lab indicate that these are abundant even in samples otherwise characterized asnon-responders (Fig. 1). In contrast with the notion of a single species as a keystone, I hypothesizethat community-level polysaccharide metabolism is driven by the presence of corecommunities of multiple species that function asan assembly line. This would explain how samplescan fail to produce SCFAs despite the presence ofprimary degraders. By shifting the focus to speciesthat consume degradation byproducts, I will revealnovel cross-feeding interactions and develop amodel to predict polysaccharide response fromcommunity composition. Our lab has a collection ofstool samples from multiple healthy donors thathave been characterized for SCFA production (Fig.1), making me well situated to conduct thisresearch. I will address my hypothesis in the Figure 1: Bacterial communities derived fromfollowing aims: stool samples from 9 donors (A-I) containprimary degraders of all tested polysaccharides.3Intellectual Merit – Research Plan:Aim 1: Isolate the core communities from multiple stool donors.I will grow bacterial communities from stool samples on minimal media with inulin as thesole carbon source in our lab’s “artificial gut,” a set of eight bioreactors.4 Inulin is a well-studiedpolysaccharide, a polymer of fructose with a single terminal glucose residue. The species thatpersist after three weeks of growth in this media, as measured by 16S sequencing, will include allspecies that consume inulin or inulin byproducts. By reducing complex communities to only thosespecies involved in inulin metabolism, I will test the hypothesis that core communitycomposition is directly related to SCFA production. I will next quantify expression of genesencoding select carbohydrate active enzymes and transporters for all species present using RT-qPCR. I hypothesize that degradation will occur in waves, with primary degrader speciesupregulating genes of interest at early time points, followed by secondary degraders. While Iexpect all samples to exhibit a robust first wave of upregulation, I hypothesize that themagnitude of the second wave will correlate with SCFA production. If there is no correlation,this would support the alternative hypothesis that strain-level variation drives differences inpolysaccharide response. In this case, I would expect the gene expression experiments to reveal anincreased number of species that upregulate the genes of interest in SCFA-producing samples.Graduate Research Plan Statement Jeffrey LetourneauAim 2: Differentiate primary, secondary, and tertiary degraders.Our lab has developed a microfluidics growth assay that allows for the isolation ofsingle cells in droplets (Fig. 2). Species that grow in this assay are defined as primary degraders,since cross-feeding interactions are prevented. I will identify secondary and tertiary degraders bytaking conditioned media from primary degraders, which will contain partially broken downpolysaccharides and byproducts of their breakdown, and using this media as the sole carbon sourcein a subsequent assay. Conditioned media will be characterized using the lab’s GC and HPLC tomeasure SCFAs and polysaccharides, respectively. I hypothesize that while stool samples fromall donors will contain some primary degraders, samples unable to produce SCFAs will lackkey secondary and/or tertiary degraders. Growth willbe determined by 16S sequencing to measure relativeabundance and flow cytometry to calculate the totalnumber of cells. The use of 16S will also allow me todetermine which bacteria are involved at which stage ofpolysaccharide utilization. I hypothesize that the primarydegraders will comprise of both generalists (Bacteroidesovatus) and specialists (Roseburia inulinivorans, forinulin), secondary degraders will include acetateproducers (Bifidobacteria and Lactobacilli), and tertiarydegraders will include acetate- and lactate-utilizingFigure 2: Droplets containing bacterialbutyrate producers (Eubacterium and Anaerostipes).cultures each derived from single cells.5Broader Impacts – Disseminating Research:To date, I have shared my research findings with diverse audiences fromkindergarteners to faculty and will continue to use the results of this project as a means ofpromoting science education. I am making my research accessible to middle and high schoolersby teaching for a Saturday program called Duke Splash, where I have previously taught Intro toMicrobiology and Bread Science. I am in the process of developing two new classes to debutthis November, Nutrition Science and Data Science, both of which incorporate data from myown research on polysaccharide metabolism. At Duke, I have many opportunities to share myresearch, such as the monthly Duke Microbiome Center seminar, where I recently presented myfindings on transcriptional memory of polysaccharides in gut bacteria. To reach undergraduates, Iwill be giving a talk at the annual University Scholars Program (USP) Symposium, the theme ofwhich will be “(in)dependence.” With this theme in mind, I will be presenting on how humans aredependent on gut bacteria to help metabolize dietary fiber as it relates to my research. Previously,I spoke at the USP Graduate Research Seminar on my work as a rotation student. Beyond Duke, Iplan to present my research at conferences such as the 2019 Keystone Microbiome Conference.Broader Impacts – Importance and Innovation:Emergent properties of complex systems can be difficult to deconstruct, and this projectprovides a methodology for doing so in a novel, high-throughput manner that can be applied infuture studies. By determining how emergent polysaccharide metabolism phenotypes arise, Iwill address a key gap in our understanding of how microbial ecosystems respond tonutrients. These results may be applied in human diet research to predict individualpolysaccharide response and in bioremediation to develop co-culture methods for effectivedegradation of pollutants. Moreover, my findings will raise exciting new questions related toevolutionary biology as to how polysaccharide utilization came to be an assembly line process.References: 1. Makki et al. 2018. Cell host & microbe. 2. El Kaoutari et al. 2013. Nature reviews Microbiology.3. Villa. 2018. Unpublished. 4. Silverman et al. 2018. bioRxiv. 5. Bloom. 2018. Unpublished."
85.0,"Animals harbor a suite of innate fears, knowing them from birth in the absence offirsthand experience. These fears are rooted in evolution and are often species-specific. Forexample, mice respond defensively to odors related to foxes and cats, two of their most commonpredators. Alternatively, humans respond defensively to snakes and spiders, both of which can behighly-lethal and are endemic to East Africa, the original range of genus Homo. These factorsstrongly imply a genetic origin for these fears, though none has yet been investigated.Aversive responses have both behavioral and hormonal components. The two brainregions necessary and sufficient for innate aversive odor responses in mice are the corticalamygdala (CoA) and the amygdalo-piriform transition area (APir). The CoA mediates innateolfactory behavior, and is organized spatially based on the emotion a given odor evokes —neurons responsive to aversive odors are located in the anterior CoA, and neurons responding toall other odors are posterior.1 APir controls the hormonal stress response to innately aversiveodors, stimulating secretion of corticotropin-releasing hormone (CRH) by the hypothalamus,raising peripheral corticosterone levels.2 Neither region has any other known functions. Adistinct, spatial organization to neuronal populations that mediate specific behavioral functions,independent of individual experience, strongly implies genetic control over the developmentalprograms creating these pathways. For instance, a past study examining similar populations inother regions showed each one expresses a set of marker genes specific to their own population.3Thus, neuronal populations in CoA and APir may similarly express their own sets of markergenes. I propose to identify the first set of marker genes for neurons controlling innateaversive responses to a set of specific stereotyped odors.Aim 1: Identify neurons specifically mediating innate olfactory aversion. Hypothesis: Ifthese regions respond to innately aversive odors, then the specific responsive neurons withinthese regions should be identifiable based on the population’s activity in odor exposure.Method: I can mark these neurons using a transgenic mouse strain with neurons that Cre-dependently express eYFP if active within a transient, hours-long period after peripheraltamoxifen injection.4 I will identifyinnately aversive odor-responsiveneurons by exposing mice to eitherwater or trimethylthiazoline (TMT),a well-validated innately aversivefox odor, shortly after peripheraltamoxifen injection. The water-responsive group represents neuronsactive at rest, while the TMT-responsive group represents neuronsactivated by innately aversive odors.Differences in response between thetwo conditions should reflectregional activity differences.Anticipated Results: The eYFP-Figure 1. Preliminary Results and Research Plan. After odorexpressing population should be exposure, cells (blue) in the amygdala express Arc (green). A.enriched in CoA and APir in the Amygdala neuron activity after water exposure. B. Activity afterTMT-exposed mice compared to the TMT exposure. C. Proposed research plan. BLA: basolateralamygdala nuclei, CeM: centromedial amygdala nuclei.water-exposed mice. The regionsNSF GRFP 2018 1James R. Howe Graduate Research Planthey innervate, the BLA, CeM, and the hypothalamus, which control general aversive responses,should be enriched as well. Preliminary data corroborates these predictions (Figure 1A, 1B).Aim 2: Identify genes exclusive to innate olfactory aversion neurons. Hypothesis: Neuronsactive during TMT exposure should express a suite of marker genes not expressed in neuronsactive during water exposure throughout the brain. The eYFP-expressing activated neurons canbe dissociated on ice via an optimized combination of RNA polymerase inhibitors, physiologicalsolutions, and extracellular matrix-specific cold-active proteases to keep cells alive and eliminategene expression artifacts.5,6 I can combine this technique with dissection and fluorescence-activated cell sorting to isolate single live eYFP-expressing cells from CoA with high fidelity.7Method: I will use an efficient, well-validated, high-resolution form of single cell RNA-sequencing to precisely assay the expression of all genes in all isolated cells (Figure 1C).8 Thisapproach closely resembles the method used in a recent series of experiments in the neuroscienceliterature.9 A custom computational pipeline purpose-built for this experiment will analyze thedata. Machine learning algorithms will classify cells into groups based on similarities inunderlying gene expression. Differential expression analysis will identify the most highlyupregulated genes in each group of cells compared to all others. Gene ontology (GO) analysiswill then identify these genes’ functions. RNAscope, a multiplexed single-molecule RNAfluorescent in situ hybridization platform, will externally validate these results.10 I collaboratewith three groups across multiple disciplines and institutions to perform these techniques: inbiology at the University of Cincinnati, biochemistry at UCLA, and bioengineering at UCSD.Anticipated Results: Using this framework, I expect to identify at least one group ofneurons present in the TMT-responding population but not the water-responding population,with at least one corresponding suite of highly-expressed genes. These will both be confirmedvia RNAscope. We expect these genes to display enriched neural development-related GO terms.Intellectual Merit: This would be the first study to identify and validate the heritability of innatebehaviors, the specific neurons mediating these behaviors, and their underlying genes. Findingsuch genes would allow the targeted stimulation and genetic access of these neurons for the firsttime, making modification or simulation of specific odor responses (even in the absence of priorexperience) possible, a valuable future research tool. Using such tools, researchers could createfar more precise experimental designs, allowing researchers to answer more specific hypothesesthan ever before. The availability of such novel technologies at the intersection of psychology,molecular biology, and sensory neuroscience will have many implications for studies in all threefields and will further stimulate interdisciplinary research incorporating aspects of all three.Broader Impacts: During this project, I will train undergraduate students from underrepresentedcommunities at UCSD in molecular biology and behavioral techniques, as well as mentor themin research methods, both at the bench and away from it. The computational and molecularmethods will be made open-source on GitHub and protocols.io. I will communicate the results inopen-access peer-reviewed academic journals, and I will also write articles in popular mediaoutlets throughout the project based on what I study and discover along the way. The markergenes identified in this project could lead to advancements in commercial research technologiesand pharmacology, as each one could serve as a possible target for future drug developmentshould any of these populations become relevant to certain research questions or diseases.References: 1Root et al. Nature 2014 515:269-273. 2Kondoh et al. Nature 2016 532:103-105. 3Kodama et al. JNeurosci 2012 23:7819-7831. 4Guethner et al. Neuron 2013 78:773-784. 5Wu et al. Neuron 2017 96:313-329.6Adam et al. Development 2017 144:3625-3632. 7Hempel et al. Nat Methods 2007 2:2924-2929. 8Torre et al. CellSyst 2018 6:171-179. 9Tasic et al. Nat Neurosci 2016 19:335-346. 10Wang et al. J Mol Diagn 2012 14:22-29.NSF GRFP 2018 2"
86.0,"S.MooreBackgroundLet L be a finite dimensional semisimple Lie algebra. A subset H ⊂ L is said to be a Car-tan subalgebra if H is a maximal toral subalgebra (a subalgebra in which all elements are ad-diagonalizable). In particular, H will be abelian, implying that every h ∈ H is simultaneouslyad-diagonalizable. We call α ∈ H∗ a root of L if α (cid:54)= 0 and there exists nonzero v ∈ L such that[h,v] = α(h)v ∀ h ∈ H. The set of roots, R , is finite. Let S = {α ,α ,...,α } ⊂ R be aφ φ 1 2 n φbasisofH∗ suchthatanyα ∈ R canbewrittenasα = (cid:80)n c α withallc eithernonpositiveorφ i=1 i i inonnegative integers. We call elements of S simple roots. If α ∈ R has all c nonnegative, thenφ φ iαissaidtobeapositiveroot. WedenotethesetofpositiverootsbyP . ThesesetsS ⊂ P ⊂ Rφ φ φ φ(together with some more data) are called the root system φ of L. For example, the root system ofsl (C)(denotedA )hassimpleroots{α ,α }andpositiveroots{α ,α ,α +α }.3 2 1 2 1 2 1 2A(Bridgeland)stabilityfunctiononarootsystemisamapZ : P → H = {z = x+iy ∈ C | y > 0}φsatisfying Z(α + β) = Z(α) + Z(β) for all α,β ∈ P . As such, Z is uniquely determined byφZ | . We also typically require that Z be generic, meaning that Z(α) (cid:54)= cZ(β) for any c ∈ RSφwheneverα (cid:54)= β ∈ P . SeeFig. 1forexamplesofstabilityfunctionsonA .φ 2For α ∈ P , the phase of α under Zα +α φ1 2is the angle from the positive real axis toα +α1 2α Z(α). For generic Z, this induces a combi-1α2 natorial ordering of the elements of P viaφα α2 1 decreasing phase. Two stability functionsZ,Y : P → H are said to be combinatori-φallydifferent ifZ andY inducedifferentor-Z Z1 2 derings of P . In particular, Z and Z (seeφ 1 2Fig. 1) are combinatorially different stabil-Figure1: TwostabilityfunctionsonA .2ityfunctionsonA .2Our goal is to understand simple wall crossings of stability functions, which are defined asfollows: Let Z and Y be stability functions of a root system φ. If the induced combinatorialorderingsofP underZ andY arethesameexceptthataconsecutivetripleτ,τ +ω,ω underZ isφrearrangedtoω,τ +ω,τ underY,thenY issaidtobeobtainedfromZ byasimplewallcrossing.For example, Z is obtained from Z by a simple wall crossing. Intuitively, a simple wall crossing2 1arisesfromtakingapaththatconnectsZ andY inthespaceofstabilityfunctions. Suchapathwillnecessarily cross through a non-generic stability function in which τ,ω, and τ +ω have the samephase. Notethatthespaceofstabilityfunctionsissimplyconnected,soanytwostabilityfunctionsmaybeobtainedfromoneanotherviaafinitenumberofwallcrossings.The aim of this project can be broken into two main goals: First, given a root system φ, weaimtocombinatoriallydescribethegraphofcellsofstabilityfunctionsonφseparatedbysimplewallcrossings. Second,wewishtodeterminetherelatedidentitiesamongmotiviccharacteristicclasses of geometrically relevant spaces (see below). To accomplish these aims, we will use a1combination of methods from combinatorics and rational function identities for neighboring cells(see[RR]).IntellectualMeritSuch wall crossings have impacts beyond the study of Lie algebras. In particular, to a rootsystem φ, we may associate a Cohomological Hall Algebra C (defined by [KS]). This will be anφinfinite-dimensional, non-commutative, associative algebra whose product is denoted by ∗. Suchalgebras are motivated by string theory. To each α ∈ P , [RR] assigns a motivic characteristicφclass c0 ∈ C . The element c0 is a class in an equivariant cohomology (K-theory) algebra of aα φ αgeometrically relevant space (such as the Grassmannian, or flag manifold). Such c0 have variousαinterestinginterpretations,suchasmotivicChernclasses,Chern-Schwartz-MacPhersonclasses,orstableenvelopesinOkounkov’snewtheoryrelatinggeometrytophysics(see[MO]).Supposethatwehaveasimplewallcrossingwhichpermutesτ,ω+τ,andω. By[RR],thisgivesrisetoanidentityc0 = [c0,c0]intheCohomologicalHallAlgebra. Notethatthisresultissimilarω+τ τ ωin nature to wall-crossing formulas (also known as quantum dilogarithm identities) in Donaldson-Thomas theory [KS]. Such an identity gives a convenient way to calculate c0 for α ∈ P \ S ,α φ φas the commutator [c0,c0] is well understood for τ,ω ∈ S . For example, in A we can calculateτ ω φ 2(cid:16) (cid:17) (cid:16) (cid:17)c0 = [c0 ,c0 ] = c0 ∗ c0 − c0 ∗ c0 = 1 + yb − 1 − b = (1 + y)b. That is, theα2+α1 α1 α2 α1 α2 α2 α1 a a a(cid:16) (cid:17)class c0 is obtained as the difference of the K-theoretic total Chern class 1 + yb and theα2+α1 a(cid:16) (cid:17)K-theoreticEulerclass 1− b .aDisseminationofResultsI will present the results of this project in a variety of settings. Locally, I plan to present at theTriangle’s annual Assocation for Women in Mathematics conference (established last year) and atUNC’s Graduate Student Seminar. On a larger level, I plan to return to a national conference topresentaswell. Furthermore,resultswillbepublishedinarelevantmathematicaljournal.BroaderImpactsAfter graduating, I plan to become a professor. As described in my personal statement, a largefocus of my career will be in mentoring undergraduates in research projects. I have previouslymentored a high school student in a research project where she explored various non-Euclideangeometries. If awarded the NSF GRFP, I will continue building my mentoring capabilities bycreatingaprojectforUNC’sDirectedReadingProgram. Thisprogramallowsgraduatestudentstomentorundergraduatesthroughasemester-longreadingproject. MyprojectwouldbebasedinLiealgebra,culminatinginanunderstandingoftherootsystemsassociatedtoeachsl (C). IwillalsonbecomeinvolvedintheMcNairScholarsProgramatUNCbyhelpingwiththeirresearchprogramoverasummer. Thiswillallowmetheopportunitytohelpminorityundergraduateresearchersinavariety of fields (not just mathematics) by providing them with critical feedback at various stagesintheresearchprocess.References[RR] R. Rimanyi. Motivic characteristic classes in cohomological Hall algebras (Preprint). Available at http://rimanyi.web.unc.edu/research1/,2018.[KS] M.KontsevichandY.Soibelman.Stabilitystructures,motivicDonaldson-Thomasinvariantsandclustertrans-formations.Availableathttps://arxiv.org/abs/0811.2435,2008.[MO] D.MaulikandA.Okounkov.QuantumGroupsandQuantumCohomology.Availableathttps://arxiv.org/abs/1211.1287,2018.2"
87.0,"Applications to Airborne Wind Energy SystemsIntroduction: While wind energy capacity has tripled in the past decade[1], the installation oftowered wind energy systems in remote and deep-water offshore locations, as well as the abilityto harness wind resources above 100m, is severely limited by tower and foundation constraints.[2]Airborne wind energy (AWE) systems solve this problem by replacing the conventional towerwith tethers and a lifting body (usually a kite or wing). Two approaches to AWE systems havebeen adopted: (i) ground-based generators, where the lifting body is cyclically spooled in and outand power is generated on the ground[3], and (ii) airborne generators, in which the generator is aturbine attached to the lifting body.[2][4] Both technologies possess the potential for vastly increasedenergy generation through the execution of cyclic crosswind flight, which results in apparent windspeeds that can far exceed the true wind speed on a high lift/drag lifting body.[2] However, thesuccessful implementation of crosswind flight requires a robust control framework for optimizingthe crosswind flight path in the presence of disturbances.AWE systems executing crosswind flight are one of many control systems that executerepetitive (cyclic) motion, under a varying environmental profile, in order to maximize aneconomic metric (average net power output for AWE systems). Iterative Learning Control (ILC)presents a foundation for addressing this problem, allowing the controller to draw from previousiterations to inform decisions at the present iteration. However, traditional ILC techniques focuson tracking a prescribed path/trajectory in the absence of an external disturbance that can varyfrom iteration to iteration, rather than optimizing the path itself to maximize an economic metricin the presence of an iteration-varying disturbance. The proposed research will, for the firsttime ever, fuse techniques from library-based flexible ILC[5] and optimal control to arriveat a disturbance and performance-weighted ILC (DPW-ILC) framework that: Bases its learning on an economic performance index, rather than setpoint tracking, and Biases its learning to emphasize previous iterations whose conditions match the present.Research Plan: The proposed research will focus on a DPW-ILC formulation (Fig. 1), applied toan AWE system executing crosswind flight. This control formulation involves two critical featuresthat occur in the iteration domain, the designs ofwhich will encompass key components of theproposed graduate research:1. Maintaining and managing a library of previousiterations and results: DPW-ILC is predicated uponmaintaining a library of relevant previous iterations’selected path geometries, correspondingperformance (iteration-averaged power output forthe AWE application), and associated measuredFigure 1. Block diagram of the proposeddisturbance (wind speed in the AWE application). AsDPW-ILC control scheme, as applied to aniterations progress, a critical task will involveAWE system.managing the library size, maintaining those libraryentries that maximize a statistical measure of information for future ILC updates.2. Economic DPW-ILC update: The DPW-ILC framework must identify those previousiterations that are most relevant to the present iteration in terms of having similardisturbance values (wind speed in the AWE application) and favorable performance(iteration-averaged power output in the AWE application). Quantification of arelevance index, which will be informed by related work in higher-order trackingILC[7][8], will be a significant element in the creation of the DPW-ILC update.Formal stability and convergence analysis will be performed on the resulting DPW-ILCapproaches. In particular, the following general questions will be posed: Defining regret as the difference between the realized and optimal performance, how doeslong-term expected regret depend on the statistical properties of the external disturbance(e.g., variance, temporal length scale)? How do the aforementioned regret bounds depend on the library size?These convergence analysis questions also lead to metrics against which designs can be evaluated(for example, a low regret bound that is robust to the library size is highly desirable).The DPW-ILC approaches will also be experimentally validated on a unique lab-scale, water channel-based platform. In particular, the authors of [8] designed a water channel-based setup for closed-loop flight testing of tethered systems, and [2] verified dynamic scalingbetween lab scale and full scale conditions. This existing platform, which has to-date been used tocharacterize AWE designs under constant flow profiles, will be extended to characterize real-worldwind profiles, which will be dynamically scaled to the water channel level. Specifically, wind datafrom a Cape Henlopen, DE wind profiler will be scaled down to the water channel level to createlow-frequency, iteration-to-iteration variations for initial validation of DPW-ILC algorithms. Afterthe successful performance of this first round of experiments, high frequency, intra-iterationvariation will be applied using wake generation devices upstream of the AWE model.Intellectual Merit: The DPW-ILC framework pioneered in this research will be the first to fuseeconomic ILC with library-based higher-order ILC, creating an entirely new avenue of researchwithin the ILC community. Furthermore, the research will result in the first dynamically scaledexperimental validation of AWE flight control strategies on a lab-scale platform, under realistic(and also dynamically scaled) wind profiles.Broader Impacts: The creation of robust, optimized control systems for AWE systems will renderwind energy a viable alternative to diesel fuels[4] in remote, off-grid locations and a long-termsolution for deep-water offshore locations. Furthermore, the control methodologies createdthrough this research will be applicable to other engineered systems that execute repetitive (cyclic)motion, under a varying environmental profile, to maximize an economic metric. Examplesinclude active exoskeletons, pick-and-place robotic systems operating under variable plantconditions, and even traditional wind turbines.[1] AWEA. https://www.awea.org/wind-101/basics-of-wind-energy/wind-facts-at-a-glance. [2] Cobb, M. et. al.,“Lab-Scale Experimental Characterization and Dynamic Scaling Assessment for Closed-Loop Crosswind Flight ofAirborne Wind Energy Systems” ASME J. Dyn. Sys., ’17. [3] Fagiano, L. et. al.,“High-Altitude Wind PowerGeneration,” IEEE T. Egy. Convers., Vol. 25, No. 1, ’10. [4] Altaeros, Inc., http://www.altaeros.com/.[5] Hoelzle, D. et. al., “Flexible iterative learning control using a library based interpolation scheme,” 51st IEEE CDC.[6] DiMarco, C., et. al., “Disturbance & Performance-weighted Iterative Learning Control with Application toModulated Tool Path-based Manufacturing,” ASME DSCC ’16. [7] Cobb, M., et al, “Iterative Learning-BasedWaypoint Optimization for Repetitive Path Planning, with Application to Airborne Wind Energy Systems,”56th IEEE CDC. [8] Deodhar, N. et. al., “Laboratory-Scale Flight Characterization of a Multitethered Aerstat for WindEnergy Generation,” AIAA Jnl., Vol. 55, No. 6, 2017."
88.0,"I propose to study planetary system structures around low-mass stars by conducting radialvelocity (RV) observations of known single-planet transiting systems observed by Kepler/K2 andthe Transiting Exoplanet Survey Satellite (TESS). RVs and spectroscopy will be completed withMAROON-X1, an instrument with which I will have guaranteed clear-sky observing time as astudent at the University of Chicago. I will address if there is a separate population of singleplanet low-mass stellar systems or if they have an inclined inner-most planet. This study willresult in the publication of compelling individual systems as they are identified and a fullstatistical analysis once the full sample has been obtained.Background & Research Proposal: Planet formation modelspredict planetary systems form in the same orbital plane. However, 𝚹=15°there are several systems2 that suggest the inner-most planet maybe inclined by a significant degree. Heavily inclined planetsFigure 1: The inner-most planetwould go undetected during exoplanet transit surveys (observing (black) lies 15° off the plane of thestellar flux over time), Figure 1. The analysis of Kepler/K2 system and does not transit, whilean outer planet (purple) does.transiting exoplanet system yield an overabundance of singletransiting planets, Figure 2.3 It is possible the single transitsdetected are the inner-most inclined planet and the remaining planets have a different orientation.The overabundance of single transiting planets is most notable around low-mass M-dwarfstars (70% of the Milky Way population). M-dwarfs are smaller and cooler than the Sun (< 0.7M , T < 4000K). With nearly 300 current planet detections from NASA’s Kepler/K2 missions,Sun effit is estimated each M-dwarf hosts at least 2 small planets (<4 R ); TESS is predicted to find 500 additional planetsEarthorbiting M-dwarfs.4 By studying planets around M dwarfs,I will be studying the dominant environment of planetformation in our galaxy.Follow-up RV measurements of planetary systems willallow us to identify planets that do not transit. I will besearching for non-transiting companions to knownFigure 2: Comparison of the Keplermulti-planet yield (blue) to the best-fit transiting planets to understand the population of planetarymodels (red). Models under-predict systems with mutual inclinations. By conducting a large RVthe number of singly transitingsurvey of transiting planets with the MAROON-Xsystems and over-predict the numberof multiple transiting systems. spectrograph, under construction at the University ofChicago and to be commissioned on the Gemini Northobservatory in early 2019, I will answer the following questions: Do low-mass stars have1 Seifahrt, A., Bean, J. L., Stürmer, J., et al. 2016 “Development and construction of MAROON-X,” in [Ground-based and Airborne Instrumentation for Astronomy VI], Proc. SPIE 9908, 9908452 Montet, B. T., Morton, T. D., Foreman-Mackey, D., et al. 2015, ApJ, 809, 25; Rodriguez, J. E., Becker, J. C.,Eastman, J. D., et al. 2018, ArXiv e-prints, arXiv:1806.083683 Ballard S. and Johnson J. A. 2016 ApJ 816 664 Barclay, T., Pepper, J., & Quintana, E. V. 2018, ArXiv e-prints,arXiv:1804.05050!1significantly inclined inner-most planets? If so, what physical mechanisms are responsiblefor causing the inclination shift? If not, why do these systems only host one planet?I will compile an initial catalog of M-dwarf systems from the Exoplanet Archive and theTESS Input Catalog prior to data release. Once data are available, I will run the TESS datathrough my developed software, ELLIE, to search for planet candidates. I will vet candidates,prioritizing stars in my catalog, and determine RV follow-up feasibility based on predicted planetradius and levels of stellar activity identified in the light curve. This process will be repeateduntil July, 2020, when the entire sky observable by MAROON-X has been observed by TESS.I am choosing MAROON-X to conduct this study because it is optimized for the redoptical (peak emission of low-mass stars) and obtains spectra of the stars. By obtaining spectra ofstars, I will be able to calculate accurate stellar parameters, following methods developed duringmy internship at NASA Goddard Space Flight Center. Additionally, MAROON-X has a predictedprecision of <1 m/s, allowing for potential detections down to 1 M . By pursuing my PhD atEarththe University of Chicago with the MAROON-X instrument science team, I am guaranteed toobtain data, regardless of bad scheduled nights. I propose to conduct 5 full nights of observingper semester for 3 years, for a total of 240 observing hours.I will obtain mass and density measurements of transit detected planets in addition toidentifying new planets. Measuring both parameters will prove essential when choosing planetsfor atmospheric characterization with the James Webb Space Telescope, currently set to launch in2021. Obtaining both a radius (via the transit) and mass (via RV) measurements will help usbetter understand the compositions of relatively nearby planets, improving our understanding ofplanet formation around the most common stars in the Milky Way.Intellectual Merit & Broader Impacts: My years of previous research experience, includingpublishing papers and giving talks, have prepared me well for the challenges which lie ahead. Ihave the necessary knowledge of Python and other tools necessary to complete the projectproposed here. I have experience efficiently and accurately analyzing large data sets5 andobservations6, and vetting planet candidates.7 I am ready to undertake the project presented here.My current outreach experiences have prepared me for future plans to speak about myresearch at local K-12 schools. I plan on working with local teachers to improve STEMeducation and educator development at the elementary/middle school level by creatingeducational in-class astronomy activities as well as create a website that follows my work thatteachers will be able to use in the classroom. Interactive tools will include how to create lightcurves and how the presence of different objects will change a light curve. I will attend theNational Science Teachers Association national conference to give a demonstration on how touse my website. I also plan on taking advantage of events hosted in Chicago. Such events includeAstronomy on Tap: Chicago, which brings the universe into a local Chicago pub, and SoapboxScience, which promotes women in STEM by placing them on a box in highly populated areas indowntown Chicago to talk about their work.5 Feinstein, A. D., Montet, B. T., et al (in prep)6 Feinstein, A. D., Schlieder, J. E., Livingston, J. H., et al, 2018, AJ (submitted)7 Liang, Y., Crossfield, I. J. M., Schlieder, J. E., et al, 2018, ApJ 156 22; Crossfield, I. J. M., Guerrero, N., David, T.,et al, 2018, ArXiv e-prints, arXiv:1806.03127!2"
89.0,"Graduate Research Plan StatementReconstructing Morphologies of Distant Galaxies with the JWST Mock CatalogKeywords: Galaxy Evolution, Early Galaxy Structure, Near Infrared ImagingAbstract:In today’s universe, galaxies have simple morphologies (i.e. shapes and structures). Theyare ellipsoidal and symmetrical, often with an additional spiral component like our own MilkyWay. However, there is strong evidence to suggest that galaxies in the early universe were clumpyand distorted, possibly driven by their assembly. The question then arises: how and why didgalaxies change over time from asymmetrical structures to the objects we see today? The JamesWebb Space Telescope (JWST), NASA’s upcoming flagship space observatory, will revolutionizeastronomers’ ability probe from the formation of the first galaxies over time until today. As amember of the JWST NIRCam team at the University of Arizona, I propose to create an analysisframework for the extraction of morphological information from the unique shapes and structurespresent in young galaxies. My proposed study will provide the necessary tools to understandthe changing look of galaxies over cosmic time, fulfilling one of the primary aims of the JWSTmission: understanding galaxy evolution from the first galaxies until today.Background and Motivation:The morphologies of galaxies are tied to the overall evolution of galaxy populations overcosmic time. For example, in today’s universe we use the shapes of galaxies to infer their recenthistories; i.e. large spheroidal galaxies have undergone a merger with a galaxy of similar mass,whereas spirals have not (e.g. Mihos & Hernquist 1996). However, the deepest observations fromthe Hubble Space Telescope reveal that galaxies eleven billion years ago exhibit asymmetries andclumps in their images (e.g. Elmegreen et al. 2007, 2009). With few detections of distant galaxies,astronomers have been unable to fully characterize the evolution of galaxy morphology overcosmic time. Instead, the community has turned to complex hydrodynamical simulations, such asIllustris (Genel et al. 2014), to model galaxy evolution. While simulations can prove valuable forunderstanding certain astrophysical processes, they require tens of millions of CPU hours and canbe difficult to compare to observations. Therefore, there exists an opportunity to providemethods to generate images of early galaxies with physical shapes that can be used to developtools to extract morphological information from upcoming JWST data.Methods:The need to accurately simulate the data of the upcoming JWST Advanced DeepExtragalactic Survey (JADES) has led to the development of the JAdes extraGalactic UltradeepArtificial Realizations (JAGUAR) mock catalog package (Williams et al. 2018). The package usesan empirical model for galaxy properties across cosmic time, including morphologies. However,the JAGUAR morphologies are modeled by simple symmetrical spheroids, an unrealisticassumption for early galaxies as shown in Figure 1. My first task will be to assign realisticmorphologies to each mock galaxy. Here I will couple the results of hydrodynamical simulations,similar to Illustris, with existing observations of distant galaxies to inform the shape, structure, andcomposition of morphological components in each mock JAGUAR galaxy. By folding these inwith JWST data simulation tools, I will produce physically motivated images of early galaxies withcolors and luminosities that agree with observations of the distant universe. Following my creationof mock galaxy images, I will test techniques to extract morphological information from the data.Astronomers have attempted to tackle the problem of accurate characterization of distinctfeatures in images with an ever growing suite of machine learning techniques. I will robustlyexamine existing techniques and find the approach that is best suited for categorizing asymmetricNSF Graduate Research Fellowship Plan Raphael E. HvidingGraduate Research Plan Statementand distorted morphologies of early galaxies. These include ensemble classifiers, such as a randomforest decision trees employed in classifying galaxy mergers, e.g. Goulding et al. (2017), or deeplearning algorithms trained on existing data sets, e.g. Sánchez et al. (2018). While both have beenused to great effect, these procedures have only been tested in the local universe. I can thereforeadapt and test candidate algorithms on my simulated images, measuring the method’s ability torecover input parameters. I will evaluate the efficacy of a broad set of techniques to find those thatextract morphological parameters accurately for early galaxies over a wide range of cosmic times.The Steward Observatory at the University of Arizona is the ideal host institution for thisendeavor, hosting the Principal Investigator of the NIRCam instrument on JWST (Professor MarciaJ. Rieke) and the primary authors of the JAGUAR project (C. C. Williams and K. N. Hainline). Iam therefore confident I can integrate my enhanced morphological modelling with current mockcatalog efforts. Ultimately, I will produce a data analysis framework optimized for extractingmorphological information from early galaxies validated through observations andsimulations which will help determine why galaxies look the way they do today.Fig. 1: Young galaxies from current observations on the left (Bowler et al. 2017) compared with current modelsin the JAGUAR mock catalog on the right (Williams et. al 2018). Note the discrepancy in the level of structure.Conclusions and Broader Impact:My simulations of early galaxies and corresponding extraction algorithms will haveimmediate implications for the characterization of complex morphologies of young galaxies.These will be useful for any large-scale extraction of galaxy parameters in the early universe andessential for the success of the extragalactic component of the JWST mission. My tools will bemade publicly available to the astronomical community to further the understanding of galaxyevolution to one day understand the nature and fate of all galaxies.In addition, I aim to bring the results of my research to the general public in Tucson. Giventhe intuitive nature of galaxy shapes, I aim to create lesson plans for the elementary school childrenI work with through Project ASTRO. By using my simulated images of galaxies, I will present arealistic view of the scientific capabilities of JWST in a fun and informative manner to inspirecuriosity about extragalactic astronomy. Furthermore, simulated JWST observations of realisticimages of galaxies are ideal for public lectures. By presenting a compelling visual narrative ofwatching galaxies change shape over time, I can communicate the main outcomes of my study thatuniquely engages an audience. I plan to present my work at public talks that are held throughoutTucson, including the Steward Observatory weekly lectures and the Astronomy On Tap series.With support from the NSF Graduate Research Fellowship, I can develop useful andrelevant tools for the astronomical community while taking advantage of the intuitive natureof galaxy shapes to bring high level cutting edge science questions to the general public.References:Agertz+, 2009, MNRAS, 397, L64 Elmegreen+, 2009, ApJ, 692, 12 M i h os+, 1996, ApJ, 464, 641Bowler+, 2017, MNRAS, 466, 3612 Genel+, 2014, MNRAS, 445, 175 Sánchez+, 2018, arXiv: 1807.00807Elmegreen+, 2007, ApJ, 658, 763 Goulding+, 2017, PASJ, 70, S37 Williams+, 2018, ApJS, 236, 33"
90.0,"Kyle T. DavidIntroduction. Arrow worms (chaetognaths) are a phylum of free-living predatory marineplankton. They are the second most abundant zooplankton group and represent a significantproportion of marine biomass1. Despite their abundance and ecological significance, arrowworms are very poorly understood. Charles Darwin2 commented on the “remarkable… obscurityof their affinities” and in the 174 years since, arrow worms have been placed in many differentbilaterian groups, including nematodes, annelids, molluscs, crustaceans, arachnids, andchordates1. Most modern molecular analyses place arrow worms within protostomes (Fig. 1), buta consensus has not yet been reached3,4,5. Internal relationships within the phylum are similarlyambiguous1,6. I will broadly sequence arrow worm transcriptomes to determine relationshipswithin and outside the group and use these transcriptomic data to elucidate the evolution ofdevelopment within animals.3,4,5Figure 1. Four conflicting topologies that have all been recently recovered from molecular phylogeniesAim 1: Infer a Robust Chaetognath Species Tree. The inclusion ofarrow worm transcriptomes to a larger protostome dataset will addsignificant power to phylogenetic analyses and resolve evolutionaryrelationships that have confounded biologists for hundreds of years1.Aim 2: Explore the Origins of Bilaterian Development. Thoughconsidered protostomes by most modern researchers, arrow wormspossess deuterostome-like development (enterocoely, secondaryPhoto: Michael Le Rouxmouth formation, radial cleavage). This makes arrow wormsuniquely positioned to explore novel questions on the origins of development in bilaterians. Ifarrow worms are indeed the sister-group to protostomes (Fig. 1A), it is likely thatdeuterostomous development was present in the bilaterian ancestor. Alternatively, if arrowworms are instead nested somewhere within protostomes (Fig. 1B-D), it is likely these featuresare an example of convergent evolution.Methods. The Halanych Lab has an established history of collecting and sequencingtranscriptomes of non-model marine invertebrates. Our lab has sequenced and annotated 59transcriptomes listed on NCBI’s Sequence Read Archive (SRA). I will collect specimens of atleast one representative from each of the 11 arrow worm families recognized by the WorldRegister of Marine Species. I will be able to accomplish this through a previously establishedrelationship with Dr. Janet Voight, an Associate Curator at the Field Museum of Natural History,who has access to these groups as well as with samples previously collected from my lab. I alsoaim to participate in the Graduate Research Internship Program (GRIP) available to GRFPfellows, which would allow me the opportunity to intern at the Smithsonian under Dr. JonNorenburg in order to study and sample their collections. It may be necessary to collect from thefield as well, which will be possible through research cruises like the Icy Inverts AntarcticaCruises with which my lab has a history of participation. RNA samples will be extracted,prepared, and sequenced through previously validated Halanych lab protocols3. The generalizedbioinformatics pipeline is represented in Figure 2. I will use the skills I have learned from myrecent participation in the Workshop on Molecular Evolution to infer maximum likelihood andBayesian gene and species trees while using a variety of model assumptions and parameters in acomparative approach. Several deuterostomes (sea urchin, acorn worm, mouse, human) willserve as an outgroup.Figure 2. Simplified bioinformatics workflow for species and gene tree inferenceIntellectual Merit. There is currently only a single arrow worm sequence on the SRA. Thisproject will increase the amount of genetic data for this poorly understood group by an order ofmagnitude. A well resolved tree will also provide a phylogenetic framework for understandingthe evolution of several key features in animal evolution and provide evidence for the ancestralbilaterian state. Arrow worms are known to have many unique features including lamellarphotoreceptors7 and mosaic hox genes8 in addition to a putative whole genome duplicationevent9. Increasing the availability of coding sequences in this group will allow myself and othersto explore expansions/losses of several significant gene families (e.g., opsin and hox genes) andtest for evidence of whole genome duplication within this enigmatic group.Broader Impacts. Results will be disseminated widely to expert (i.e., publications, symposia,talks) and non-expert (i.e., Skype a Scientist, outreach events, for details see PersonalStatement) audiences. Through connections already established with faculty, I will also be ablepresent my work as a guest lecturer through Auburn University’s Alabama Prison Arts +Education Project, which provides pre-college classes to prisoners. In 2016, the New York Timesreported that inmates who participate in college programs have a 4% re-offence rate, creating a500% return on investment in prison education initiatives. Alabama law does not allow prisonersto take remote classes meaning courses must be run on-site and in-person, something that wouldonly be possible for me to participate in with GRFP support. All assembled transcriptomes andraw reads from this project will be made publically available on the SRA. I am committed toopen-source software and will continue to upload all scripts required to reproduce analyses to mypublic repository (github.com/KyleTDavid). I will also mentor students through the NSFResearch Experience for Undergraduates (REU) program, of which my lab is a participatingmember in computational biology. Students will receive a primer in basic programming skillsand an introduction to phylogenomic workflows, as well as an opportunity to pursue independentprojects.[1] Bone & Pierrot-Bults. (1991). Oxford University Press. [2] Darwin. (1844). Journal of Natural History. [3]Kocot et al. (2017). Systematic biology. [4] Marlétaz et al. (2006). Current Biology. [5] Matus et al. (2006). CurrentBiology. [6] Gasmi et al. (2014). Frontiers in zoology. [7] Goto et al. (1984). Cell and tissue research. [8] Papillonet al. (2003). Development genes and evolution. [9] Marlétaz et al. (2008). Genome biology.2"
91.0,"Gravitational Waves in Astrometry and Pulsar Timing ArraysAbstract: Gravitational waves are fluctuations in the fabric of spacetime and, in general​​relativity, they can be characterized by two polarizations states (commonly called the tensor Eand B modes). A background of such gravitational waves can be detected through astrometricmeasurements and pulsar timing arrays, and the angular power spectra of these measurements foreach polarization state is known. However, the capability of these experiments for localizinggravitational wave sources has not been studied in depth—this is of great importance since it willfacilitate comparison with electromagnetic data. In addition, it is often assumed that abackground of gravitational waves will conserve parity; however, this is not guaranteed sincesources such as supermassive black hole mergers are known to produce circularly polarizedgravitational waves that may give rise to chiral backgrounds. Thus, my intention is to determinehow the locations of gravitational wave sources may be determined from astrometry and pulsartiming array data, as well as calculate the parity-breaking power spectra.Proposal: The advent of gravitational wave astronomy has provided a new window onto the​​universe for astrophysicists. Traditional barriers that are opaque to electromagnetic radiation canbe penetrated by gravitational waves, which thus provide a novel way to research black holes,early universe processes, and other phenomena that are otherwise difficult to study using light.While it is possible to detect gravitational waves by direct observation, the existinginterferometers of LIGO and Virgo are not suitable for studying the polarization content ofgravitational waves, since at least five detectors are required to isolate the polarization states.Pulsar timing arrays and astrometric measurements may provide better constraints on thepolarization content of gravitational waves. Light interacting with a gravitational wave will haveits trajectory altered and this causes the apparent position of light sources to be deflected and thearrival of light pulses to be delayed. Thus, it is possible to study a stochastic background ofgravitational waves using astrometric missions such as Gaia by observing how the positions of afield of stars changes over time, as well as by timing millisecond pulsars against each other tomeasure correlated signatures in pulse arrival times.The correlation functions and angular power spectra of such experiments have beencalculated for each polarization state of gravitational waves by a variety of methods [1-3]. Thepower spectra will provide a starting point for analyzing a gravitational-wave backgrounddetected by astrometry or pulsar timing arrays; however, clearly there is more to a study ofgravitational wave backgrounds than just the polarization content. I propose to investigate twokey aspects of these gravitational wave experiments: their ability to localize sources and theirability to probe chiral gravitational waves. Neither issue has been studied in greatdepth—however, both projects will enhance experiments by facilitating comparison withnon-gravitational-wave data and challenging the common, but possibly false, assumption that abackground of gravitational waves will preserve parity.First of all, after detecting a background of gravitational wave, is it possible to localizesources of the signals? In other words, will the signal exhibit any preferred directions? I proposeto study whether a gravitational wave background will exhibit such an asymmetry using bipolarspherical harmonics [4, 5]. The coefficients of the bipolar spherical harmonics can beconstructed from the same quantities used to calculate the power spectra and should be able toshow whether the signal will have a dipole asymmetry. In addition, it is sometimes assumed thatthis stochastic background of gravitational waves will conserve parity. Then the energy densities1Wenzer Qin NSF GRFP: Research Planin the left and right-handed circularly polarized states should be the same, which implies thatcross-correlation of tensor-E and B modes and the redshift-B mode cross-correlation will bezero. However, sources such as supermassive black hole binaries are expected to to emitcircularly polarized gravitational waves, and in this case the detected background would be chiraland the cross-correlations would not vanish. Therefore, I propose to calculate the parity-breakingpower spectra, i.e. the E-B and redshift-B cross-correlations for a chiral gravitational wavebackground.Since gravitational wave astronomy is a relatively new field, the results of these researchprojects will be useful for the development of pulsar timing arrays and astrometric surveys asgravitational wave detectors. The ability to locate gravitational wave sources from theseexperiments will be extremely useful, as it will allow us to compare measurements withelectromagnetic data from the same region and therefore study gravitational-wave-emittingphenomena in greater depth. In addition, as stated earlier, for a chiral gravitational wavebackground, the EB and redshift-B cross-correlations will not vanish. Normally, if thesefunctions were expect to be zero, then they could be used as null tests for systematic errors inthese experiments; however, since we do expect some astronomical sources to emit chiralgravitational waves, subtracting these cross-correlations out of the data may result in the loss ofreal and important physics. Therefore, an expectation of what the cross-correlations should looklike beforehand will be important for analyzing the data from astrometry and pulsar timingarrays, and that is what this project seeks to establish.I would like to carry out this research at the California Institute of Technology, since thistopic of research overlaps significantly with the work of Sterl Phinney and Yanbei Chen. I wouldalso be happy to work with Daniel Holz at the University of Chicago or Franz Pretorius atPrinceton University, since their research also focuses heavily on gravitational waves. The NSF​fellowship will support me in my goals by allowing me to begin research in graduate school assoon as possible and spend as much time as I can developing the skills and knowledge necessaryfor my future career in physics research.Timeline:Years 1-2: Calculate the bipolar spherical harmonic coefficients from the redshifts and​position deflection of stars. Use these to determine whether the gravitational wavesignal will exhibit a preferred direction/dipole. Publish results on how to useastrometry and pulsar timing arrays to locate gravitational wave sources.Year 3: Use the total-angular-momentum formalism to calculate the parity-breaking​cross-correlation power spectra. Publish the functions and their derivations.[1] L. G. Book and E. E. Flanagan, “Astrometric Effects of a Stochastic Gravitational Wave Background,” Phys.Rev. D 83, 024024 (2011) [arXiv:1009.4192 [astro-ph.CO]].[2] L. O'Beirne and N. J. Cornish, “Constraining the Polarization Content of Gravitational Waves with Astrometry,”Phys. Rev. D 98, no. 2, 024020 (2018) [arXiv:1804.03146 [gr-qc]].[3] D. P. Mihaylov, C. J. Moore, J. R. Gair, A. Lasenby and G. Gilmore, “Astrometric Effects of Gravitational WaveBackgrounds with non-Einsteinian Polarizations,” Phys. Rev. D 97, no. 12, 124058 (2018) [arXiv:1804.00660[gr-qc]].[4] A. Hajian and T. Souradeep, “Measuring statistical isotropy of the CMB anisotropy,” Astrophys. J. 597, L5(2003) [astro-ph/0308001].[5] L. G. Book, M. Kamionkowski and T. Souradeep, “Odd-Parity Bipolar Spherical Harmonics,” Phys. Rev. D 85,023010 (2012) [arXiv:1109.2910 [astro-ph.CO]].2"
92.0,"NSF GRFP Application – Research ProposalResearch Question and Intellectual Merit: How does internal migration influence thegeographic diversity of intergenerational income mobility (IIM1) in the U.S.? The IIM literaturehas seen a surge in activity, in part thanks to Chetty et al. (2014) (henceforth CHKS), who linkseveral years of IRS tax data to investigate IIM in the U.S. on an unprecedented scale. Amongtheir key findings is that the expected economic outcomes of a child vary drastically based ontheir commuting zone (CZ) of origin.Both CHKS and much of the literature that has followed it have focused on theimportance of the characteristics of where an individual is from in influencing their expectedincome mobility as opposed to where (or whether) they go. This may be in part because CHKSthemselves appear to put the issue to rest: they find that their IIM estimates do not changemeaningfully after limiting their sample to individuals who stay in their original commutingzone, nor do they appear to be strongly correlated with CZ-level net migration rates.However, limiting the sample to stayers is insufficient to fully investigate the role of self-selected migration in forming the landscape of IIM in the U.S. if this sample is endogenouslydetermined2, and focusing on more narrow migration patterns than net rates uncovers a moresuggestive relationship. Figure 1 juxtaposes state-level IIM estimates with the college graduateoutflow rate3 in each state. With few exceptions, the most income-mobile states in the country(namely, those in the rural Midwest and the Mountain States) also exhibit some of the highestrates of out-migration. Table 1 reveals this visual association to be statistically robust on a basiclevel after controlling for the most important correlates of IIM that CHKS identify.This project will more meticulously consider the importance of internal migration ingenerating spatial variation in IIM through the development and estimation of a structural model.In doing this, I will provide new insight on an oddity that has not been thoroughly probedhitherto: the fact that children from underprivileged backgrounds seem to fare the best whencoming from some of the most remote and forgotten-about places in the country. Creating aformal model will also allow me to add to the relatively much smaller recent literature thatcarefully evaluates policy counterfactuals regarding IIM.Methodology: I intend to construct and solve a lifecycle model that follows the migration andchild-rearing decisions of agents from high school graduation into early adulthood. The modelwill expand the classic Becker and Tomes (1979) framework to incorporate local labor marketconditions and moving opportunities. Agents are born in a home CZ to parents of a certainincome level, who also endow them with a set of inherited attributes and human capitalinvestments. The children then choose whether to stay or move to a new location, after whichthey select how many children to have of their own and how much to invest in them. Investmentsin children are differentially costly across locations to reflect heterogeneity in public schoolquality. In this framework, local labor market quality will induce dual effects on IIM: strongerlabor markets will improve the outcomes of stayers but will also depress incentives for agents toleave and find a better match. This may provide motivation for recent empirical findings thatconventional measures of local labor market quality have little predictive power for IIM.1 Measured as the expected national income percentile in 2011-2012 of a child born in 1980-1982 to parents whowere in exactly the 25th national income percentile over the years 1996-2000.2 If a highly income mobile CZ also has high rates of out-migration, and natives who stay do so because theyreceived unusually good income realizations in their home, then the CZ will continue to exhibit high levels of IIMeven after the sample restriction. The related-but-distinct thought experiment I consider is what would happen toIIM in the U.S. if those that would move from their home CZ are somehow restricted from doing so.3 Measured by taking the sample of income-earning college graduates from the 1980-1982 birth cohorts in 2011-2012 and computing the percentage of individuals born in a state who are observed living elsewhere.1Garrett AnstreicherNSF GRFP Application – Research ProposalFigure 1: IIM (Percentile) and College Table 1: OLS Estimates for VariousGraduate Outflow (%) in U.S. States Covariates of State-Level IIMVARIABLES IIMCollege grad outflow 0.0899**(0.037)Share single mothers -0.728***(0.240)Student-teacher ratio -0.336(0.193)Constant 66.81***(13.19)Observations 49R-Squared 0.697Table Notes: Standard errors in parentheses. ***p<0.01, ** p<0.05, * p<0.1. Non-displayed controlsinclude share black, Theil segregation index, collegegraduation rate, labor force participation rate, highschool graduation rate, violent crime rate, and Ginicoefficients.Figure Notes: IIM estimates for top map fromhttp://www.equality-of-opportunity.org/data/. Datafor bottom map from 2011 and 2012 AmericanCommunity Survey (Ruggles et al., 2017).The central mechanism I aim to capture resembles an intranational brain drain: parentsfrom areas with cheap human capital and poor labor market conditions will face incentives toheavily invest in their children, who in turn will leave their home CZ. The process of leaving willallow the child to select their most compatible labor market, greatly increasing their chances ofclaiming a higher wage and bolstering the measured IIM of their place of origin.Broader Impact and Conclusion: In addition to motivating the high IIM of remote areas, Iintend to evaluate the efficacy of various educational policies. An example is New York’sExcelsior Scholarship, which remits tuition under the stipulation that recipients stay in the statefor some time following graduation. Such a policy may work well in increasing the supply ofcollege graduates in states where opportunities are abundant such as New York, but it may not benearly as effective in rural areas with more condensed wage distributions. Expanding this modelto consider general equilibrium effects could also allow me to address myriad issues. How willgeographic wage distributions in the U.S. evolve over time in response to self-selected migrationflows? Will the brain drain I capture lead to further economic deterioration in the rural U.S., orwill its declining living costs induce more highly skilled individuals to return? These areimportant questions that my model may be extended to answer.ReferencesChetty, R.; Hendren, N.; Kline, P. and Saez, E. “Where is the Land of Opportunity? The Geography ofIntergenerational Mobility in the United States.” The Quarterly Journal of Economics, 129(4): 1553-1623, 2014.Becker, G. and Tomes, N. “An Equilibrium Theory of the Distribution of Income and Intergenerational Mobility.”Journal of Political Economy 87(6): 1153-1189, 1979.Ruggles, S.; Flood, S.; Goeken, R.; Grover, J.; Meyer, E.; Pacas, J. and Sobek, M. IPUMS USA: Version 8.0American Community Survey. Minneapolis, MN: IPUMS, 2018. https://doi.org/10.18128/D010.V8.0.2"
93.0,"Measuring Rayleigh Wave Phase Velocity in the Antarctic Upper Mantle from AmbientSeismic NoiseBackground and MotivationTwo compelling questions make the Antarctic region worth studying: 1) Why is there asignificant age difference between West and East Antarctica? And 2) How exactly will globalsea-levels rise in the future? Divided by the Transantarctic Mountains, West Antarctica issignificantly younger than the East Antarctica craton (Hansen et al., 2014). Resolving the agedifference between Antarctica’s two halves will help us understand the tectonic history andevolution of the Antarctic region. On the other hand, sea-level rise has serious implications oninfrastructure displacement as we lose land surface area. Simulations of global sea-level risehave high uncertainty but could benefit from incorporating bedrock uplift, mantle viscosity, andgeothermal heat flux (Gomez et al., 2015). Approaching both questions requires betterconstraints on mantle properties underneath Antarctica.Investigating Antarctica poses unique challenges for manytraditional measurement techniques. About 98% of Antarctica’s landsurface area is underneath a thick ice-sheet (Fretwell et al., 2013), anduncertainty in mantle viscosity convolutes anticipating changes in theEarth’s surface in response to ice-sheet melting and growth. These twofactors make measuring geothermal heat flux impractical. Furthermore,traditional seismic tomography methods rely on earthquakes forseismic signals which are scarce in and around the Antarctic region.An emerging approach in seismic tomography is to use ambientseismic noise – signals primarily generated from interactions between Earthquakes 1966-2017Figure 1: Topography map ofocean water waves and solid Earth – in addition to earthquake data tothe Antarctic plate. Colorscharacterize mantle properties. This method has been published by represent bedrock elevation inBensen et al. (2007) and has been widely adopted by seismologists meters and pink dots areearthquakes that occurred inwith over a thousand citations. One study shows incorporating ambient1966-2017. Tectonic platenoise can increase phase-velocity map resolution in the Indian Ocean boundaries are plotted asby 20% relative to maps generated by relying solely on earthquake white lines.data (Ma & Dalton, 2016). While there exists many studies employingambient noise, the number of similar studies on the Antarctic region are relatively scarce.Proposed MethodologyI will obtain long-period vertical component data from the Incorporated ResearchInstitutes of Seismology (IRIS) for all active, unrestricted stations south of -55 degrees latitudewhich encompasses all of Antarctica. The data will be processed in 4 h stackable (i.e. able to becombined through addition via linearity) windows. To ensure a high signal-to-noise ratio in ourphase arrival time measurements, I will discard 4 h windows that are not entirely full.Correlation measurements between all station pairs will be done in the frequency domain bycomputing the cross-spectrum ρ (ω) as done in Ekström (2014):ijkKevin Trinh NSF Research Statement𝑢 (𝜔) 𝑢∗ (𝜔)𝜌 (𝜔) = 𝑖𝑘 𝑗𝑘𝑖𝑗𝑘√𝑢 𝑖𝑘(𝜔) 𝑢 𝑖∗ 𝑘(𝜔)√𝑢 𝑗𝑘(𝜔) 𝑢 𝑗∗ 𝑘(𝜔)The letter u represents a 4 h seismogram passed through a fast Fourier transform. ω is frequency,i and j are station indices, and k is a 4 h window index. The asterisk * denotes a complexconjugate. Performing an inverse fast Fourier transform on the cross-spectrum yields a cross-correlation in the time domain.Measurements of phase arrival times can be made from cross-correlations. These arrivaltimes will be used to perform inversion and thus yield phase-velocities for many small, discreteregions in Antarctica. Earthquake data can be incorporated with ambient noise data to accountfor regions with low data count (i.e. not many paths traversing the discrete region). Additionally,the smoothing of our inversion will account for regions with little data and can be adjusted toyield the best results. I will conduct numerous tests to identify optimal smoothing parameters andrelative weighing between ambient noise and earthquake-based data. These steps result in a 2Dphase-velocity map and can be repeated to map varying depths of the Antarctic upper mantle.Anticipated ResultsThe speed at which wave phases propagate through solid Earth is related to materialproperties such as temperature, composition, and partial melt. I expect to see West and EastAntarctica to be dominated by slow- and fast-velocity anomalies, respectively, which shouldagree with past studies using p-waves to image the Antarctic mantle. Improved resolution intomographic maps of the Antarctic upper mantle may help me observe undiscovered geologicalfeatures such as cratons and oddly pronounced and heterogenous velocity anomalies.Proposed Timeline:Year 1: Download and process seismogram data from IRIS from 1900 to 2017.Year 2: Generate 2D seismic tomography maps.Year 3: Identify optimal smoothing parameters and relative weights. Repeat mappingprocess for varying depths of the Antarctic upper mantle.ReferencesBensen, G. D., Ritzwoller, M. H., Barmin, M. P., Levshin, A. L., Lin, F., Moschetti, M. P., et al. (2007). Processing seismicambient noise data to obtain reliable broad-band surface wave dispersion measurements. Geophysical JournalInternational, 169(3), 1239–1260. https://doi.org/10.1111/j.1365-246X.2007.03374.xEkström, G. (2014). Love and Rayleigh phase-velocity maps, 5–40 s, of the western and central USA from USArray data. Earthand Planetary Science Letters, 402, 42–49. https://doi.org/10.1016/j.epsl.2013.11.022Fretwell, P., Pritchard, H. D., Vaughan, D. G., Bamber, J. L., Barrand, N. E., Bell, R., et al. (2013). Bedmap2: improved ice bed,surface and thickness datasets for Antarctica. The Cryosphere, 7(1), 375–393. https://doi.org/10.5194/tc-7-375-2013Gomez, N., Pollard, D., & Holland, D. (2015). Sea-level feedback lowers projections of future Antarctic Ice-Sheet mass loss.Nature Communications, 6, 8798. https://doi.org/10.1038/ncomms9798Hansen, S. E., Graw, J. H., Kenyon, L. M., Nyblade, A. A., Wiens, D. A., Aster, R. C., et al. (2014). Imaging the Antarcticmantle using adaptively parameterized P-wave tomography: Evidence for heterogeneous structure beneath WestAntarctica. Earth and Planetary Science Letters, 408, 66–78. https://doi.org/10.1016/j.epsl.2014.09.043Ma, Z., & Dalton, C. A. (2016). Evolution of the lithosphere in the Indian Ocean from combined earthquake and ambient noisetomography. Journal of Geophysical Research: Solid Earth, 122(1), 354–371. https://doi.org/10.1002/2016JB013516"
94.0,"rates of gun-related homicides and emergency department visits are notoriously higher in the U.S.than in other developed countries. Gun violence disproportionately affects low-income andminority residents; homicide is the first (second) leading cause of death for young black (Hispanic)men [1]. Early death and incarceration contribute to staggering numbers of “missing” black men(83 black men per 100 black women), creating other social problems in minority communities [2].Therefore, decreasing gun crime would reduce inequality by improving outcomes fordisadvantaged minority groups. In addition, reducing gun violence would benefit taxpayers bydecreasing Medicaid and Medicare spending on gun-injury related health care.1 Therefore,governments have several reasons to examine potential policy solutions to reduce gun crime.Background: Revitalizing urban areas with green spaces could be part of a policy solution toreduce gun violence, although the effects of vegetation on crime are theoretically and empiricallyambiguous. On the one hand, trees and shrubbery could provide hiding places for criminals andinhibit neighborhood surveillance by obstructing views of the streets. On the other hand, greenerspaces could deter crime (1) by providing community gathering spaces, thereby placing more eyeson the ground and (2) by dampening criminals’ sense of aggression through the physiologicallycalming effects of nature [3]. Understanding how green spaces affect criminal activity hasimportant consequences for safety in urban neighborhoods.Intellectual Merit: A naïve comparison of gun crime between more and less green areaspotentially includes selection bias, since more affluent, less crime-ridden areas also tend to begreener. Even a comparison across time for areas that become green can produce biased estimatesif a confounding factor like gentrification of a neighborhood simultaneously increases green spacesand decreases crime. To circumvent such endogeneity, my research would exploit vacant lotrenovation programs as close-to exogenous variation in green spaces, thereby identifying thecausal impact of greening spaces on gun crime rates: a policy-relevant parameter.By combining this policy-induced variation with objective, detailed data on gunshots andgeographic imagery and data across several American cities, my proposed research seeks touncover how greening urban spaces affects gun violence: one important category of crime.Studying this effect is challenging with typical, reported crime data since renovating lots mightaffect reporting rates (if more people are present to report crime, for instance) and actual amountsof criminal activity. My study will address this issue by using new data from ShotSpotter gunshotsensors (described below). Furthermore, existing studies on the effects of greening vacant lots oncrime rely on relatively sparse crime data in a single locality [4] [5]. In contrast, I would utilizedata on a long time horizon, with more frequent observations,2 across several counties andmunicipalities.3 Therefore, I could contribute longitudinal and more precise, generalizableestimates of the effect of greening spaces on gun crime to the existing literature.Data: ShotSpotter is a technology that captures incidents of gunfire using audio sensors, providingcomprehensive data on these events including precise geographic coordinates and timestamps. Akey advantage of these data is that they are not subject to reporting bias or underreporting, therebyproviding a more objective measure of gun crime: my outcome measure [6]. In order to measure1 Medicaid and Medicare picked up nearly half of the costs of caring for Chicago survivors of gunshot woundsamong costs between 2009 and mid-2016 analyzed by the Chicago Tribune.2 According to Carr & Doleac, 911 reports of shootings (reports of assault with a dangerous weapon) capture just12% (2-7%) of all gunfire incidents recorded by ShotSpotter.3 ShotSpotter has been employed in at least 90 U.S. counties or cities since 2000, of which I currently have access toover 1,500 locality-months’ worth of data representing 27 unique localities.the treatment (greening of vacant lots), I will utilize cities’ databases on vacant lot renovationswhere readily available.4 To allow for analysis in cities where such databases are not available, Iwill use machine-learning algorithms on high-resolution digital aerial imagery and LIght Detectionand Ranging (LIDAR) data to classify areas as green spaces, trees, or other objects of urban spaces,akin to methods described by Zhou & Troy [7]. While I have not worked with these kind ofgeographic data before, my background in machine learning coupled with support from GISexperts at my university’s library would allow me complete this step of my project. I will combinethese data in ArcGIS to create a lot-time level panel dataset.5Methods: The first part of the empirical analysis involves an event study, difference-in-differences(DD) approach before and after greening of vacant lots occur. Control observations will be vacantlots that were not renovated. The primary outcome measure will be the number of ShotSpotter-detected gunfire incidents within a specified radius from each lot. I will check the results usingdifferent radii from lots both (1) as a robustness check and (2) to determine how close to a greenlot one should live to experience its effects: a question that remains underexplored in the currentliterature. Regression analyses will include year and month fixed effects (FE) and lot-, Censusblock-, or city-level FE. In specifications with city FE, I will control for Census block-levelcovariates available from the American Community Survey (ACS) including median income,home ownership rates, racial demographics, and other variables that could be associated with crimelevels. I will cluster standard errors at the lot level: the level of treatment. Further analyses wouldadjust for spatial correlation. In addition to basic DD estimates, I will also employ methods ofsynthetic control to establish comparison groups that better demonstrate common pre-trends.A potential concern with this quasi-experimental approach is that greening spaces mightjust push the same amount of crime to other areas of a city not-yet renovated. However, thisphenomenon would attenuate my estimates of the treatment effect since crime would increase incontrol areas relative to treatment areas.6 To further investigate the prevalence of this phenomenon,I could look at citywide impacts before and after periods of lot restoration.Assuming encouraging findings, I would also complete a cost-benefit analysis. I wouldgather information on the average cost to turn a vacant lot green and maintain it, and associatedadministrative costs. On the benefits side, I will use estimates of the social costs of gun crime(criminal justice claims, loss of life, and other costs [8]) to estimate costs avoided because ofdecreased gun violence. More broadly, I will translate my findings into units like dollars and livessaved that are salient and easily interpretable for policy-makers. I will also submit my findings topeer-reviewed publications and present at crime, urban policy, and economics conferences.This research has important implications for determining the potential of urban renewalpolicies, such as vacant lot restoration programs, to reduce crime. If vacant lot restoration programsare effective at curbing gun violence, minority populations would disproportionately benefit.References: [1] CDC data. [2] Wolfers, J., et al. (2015, April 20). The New York Times. [3] Kuo, F. E., & Sullivan,W. C. (2001). Environment and Behavior, 33(3). [4] Branas, C. C., Cheney, R. A., MacDonald, J. M., Tam, V. W.,Jackson, T. D., & Ten Have, T. R. (2011). American Journal of Epidemiology, 174(11). [5] Garvin, E. C., et al.(2013). Injury Prevention, 19(3). [6] Carr, J., & Doleac, J. L. (2016). Brookings Research Paper. [7] Zhou, W., &Troy, A. (2008). International Journal of Remote Sensing, 29(11). [8] Gani, F., Sakran, J. V., & Canner, J. K.(2017). Health Affairs, 36(10).4 For example, Branas et al use such a database to study Philadelphia, PA.5 A lot-day dataset is possible for cities in which the exact renovations dates are known. Otherwise, I will create adataset using whatever courser time level lot greening could be detected using aerial imagery and LIDAR data.6 To determine the effects of spillover effects more exactly, future randomized trials could consider varying theproportion of lots renovated within a city among a sample of several cities."
95.0,"Catalyzed by Amino Acids in EnzymesBackground: Proton-coupled electron transfer (PCET) reactions refer to the sequential orconcerted transfer of both a proton and an electron. PCET reactions are indispensable to life,occurring throughout cellular respiration and photosynthesis, and they even drive the photocyclesof many light-sensing photoreceptor proteins. These proteins often accomplish this chemistrythrough the use of tyrosine and tryptophan residues, which are oxidized to their correspondingradical species that subsequently play a role in the reaction mechanism. PCET reactions involvingtyrosine and tryptophan are of particular importance to the biological processes mentioned above.Motivation: Despite the emerging prevalence of tyrosine (Y) and tryptophan (W) mediatedPCET reactions, much of the basic science remains unknown. The local environment of theseresidues varies from coordination to a metal ion, such as iron or manganese, to being buried in ahydrophobic core. How does the local protein environment stabilize and direct the reactions ofthese radicals without causing oxidative damage to the protein? Are there any common trends inthe existing enzyme systems that utilize tyrosine or tryptophan residues for facilitating catalysis?These questions are difficult to study experimentally due to turnover times dictated byconformational changes, high redox potentials, and the reactive nature of the radicalintermediates. To overcome these limitations and isolate a single, well-defined active site, asmall (cid:68)-helical protein with a buried Y or W residue (denoted (cid:68) X, where X refers to the3catalytic amino acid), has been created. Without significant perturbation of the protein structure,the native Y/W residues can be reversibly oxidized, and the redox potential can be tuned byincorporating Y/W chemical derivatives.2Proposed Study: I will use the well-characterized (cid:68)X systems of our experimental collaborators3as a base to build an extensive computational model, with the goal of understanding the role ofthe solvated protein environment and electronic effects on amino acid mediated PCET reactions.To address these issues, I will use two main approaches, which will provide the necessaryinformation for the culminating study on PCET kinetics. In my first approach, I will investigatethe effect of the protein environment by computing the redox potential of Y/W derivatives usingdensity functional theory (DFT) in both implicit solvent and with electrostatic embedding toinclude the (cid:68) X protein environment. In my second approach, I will use molecular dynamics (MD)3to probe the role of water and protein conformational changes in this system. These two approacheswill provide the information needed to compute the PCET rate constant.3Aim 1: I will assess how the protein environment influences the redox potential by computing theredox potentials of a series of amino acid derivatives with implicit solvent and in the proteinenvironment through electrostatic embedding. Thepartial charges representing the protein environmentwill be obtained from the MD simulations in Aim 2.The experimentally measured relative redoxpotentials from our collaborators on tyrosine and itsTable 1. Mean unsigned errors (MUE) of thederivatives in the (cid:68) X scaffold will be used to3 relative redox potentials with respect to p-cresol.benchmark our methods. The influence of theAs shown, the mean unsigned error (MUE) isprotein has been viewed as a constant shift below the accepted error threshold of 1 kcal/mol.compared to aqueous values, and finding theoretical Data includes a series of fluorinated tyrosineevidence to support or disprove this assumption, as derivatives. The calculations were performed atwell as an explanation, would be valuable. the DFT B3LYP/6-31++G** level with thePCM solvation model.1Preliminary data (Table 1) for implicit solvationstudies reproduces the ordering and magnitude of the experimental redox potentials in the proteinvery well, suggesting that the protein is uniformly affecting each chemical species and cancels outwhen computing relative redox potentials.Aim 2: I will characterize the role of protein conformational motions and water accessibility inradical formation and decay. Water serves as the proton acceptor in many PCET systems, andaccess to the often-buried redox-active residues may be gated by conformational changes. MDstudies will be used to build a hypothesis of the mechanism of water entrance into the hydrophobicinterior of the (cid:68) X proteins. The water exchange dynamics and probability distribution will be3assessed from calculation of the radial distribution function and the average residence time ofwater in the hydrophobic pocket. In addition, the protein conformational changes associated withwater entering and leaving the pocket will be analyzed. If water is found at a high occupancy, therepresentative conformations for water will be examined in Aim 1.Aim 3: I will predict the rate constants for these PCET reactions using a vibronically nonadiabaticPCET theory and will probe the electronic effects as the substituent on the Y or W is changed. Theinformation calculated from the previous aims will be used as input to the analytical rate constantexpression for vibronically nonadiabatic PCET. The underlying PCET theory is related to Marcustheory for electron transfer reactions,4 but the transferring proton is also treated quantummechanically to include hydrogen tunneling.3 In the past, this theory has been applied to enzymessuch as soybean lipoxygenase,5 illuminating the role of protein motions on the large kinetic isotopeeffect observed experimentally. Application to the (cid:68) X system will provide an unprecedented3opportunity to conduct a systematic study on a series of substituted Y and W residues in acontrolled protein environment. These results will allow a much deeper understanding ofbiological PCET reactions.Intellectual Merit: The proposed work aims at advancing our fundamental understanding ofbiologically relevant PCET reactions through theoretical examination. The (cid:68) X protein system3will allow the study of the protein environment and electronic effects in tyrosine and tryptophanresidues, which can serve as a model for understanding important radical chemistry in DNAsynthesis, cellular respiration, and photosynthesis. The knowledge gained from a well-constructedcomputational model can motivate the synthesis and incorporation of unnatural tyrosine andtryptophan analogs into biological systems, thereby tuning their energy transfer capabilities.Additionally, the incorporation of unnatural amino acids into proteins for use as fluorophores ormechanistic probes is growing rapidly. With these advancements, an understanding of these probesand their chemical reactivity in the protein environment will be crucial to successful protein design.Broader Impacts: To aid experimental collaborators and non-specialists in understanding thiswork, I will develop a biological PCET module for our webPCET Java server.6 The webPCETserver is freely accessible and provides an overview of PCET and related research by illustratingthe theoretical underpinnings through interactive calculations. By construction of this module, Iwill be improving the accessibility of theoretical chemistry to biochemists and enzymologists, whomay otherwise shy away from mechanistic and chemical studies.1a) Becke, A. D. Phys. Rev. 1988, 38 (6), 3098-3100; 1b) Miertuš, S.; Scrocco, E.; Tomasi, J. Chem. Phys. 1981, 55(1), 117-129; (c) Becke, A. D. J. Chem. Phys. 1993, 98 (7), 5648-5652. 2) Martínez-Rivera, M. C.; Berry, B. W.;Valentine, K. G.; Westerlund, K.; Hay, S.; Tommos, C., J. Am. Chem. Soc. 2011, 133 (44), 17786-17795. 3)Soudackov, A.; Hammes-Schiffer, S., J. Chem. Phys. 2000, 113 (6), 2385-2396. 4) Marcus, R. A. J. Chem. Phys.1956, 24 (5), 966-978. 5) Li, P.; Soudackov, A. V.; Hammes-Schiffer, S. J. Am. Chem. Soc. 2018, 140 (8), 3068-3076. 6) webPCET Application Server, Yale University, http://webpcet.chem.yale.edu (2009); Hammes-Schiffer, S.;Soudackov, A. V."
96.0,"Bio-production of synthetic rubber using engineered Escherichia coliIntroduction: In a society with both a growing dependence on energy and a depleting reservoirof fossil fuels, it has become increasingly important to design chemical syntheses that aresustainable, renewable and cost-effective. One synthesis of particular concern is that of isoprene,a precursor to synthetic rubber, since the current production relies on finite petrochemicalsources.1 Recent advances in synthetic biology and metabolic engineering have made it possibleto biosynthesize isoprene using glucose extracted from plant biomass, a renewable feedstock.Despite these advances, previously studied synthesis pathways report low product yield due topoor catalytic activity, making them economically unfeasible for large scale production.2,3In order to overcome this roadblock, I propose to use a keto acid-mediated pathway tobiosynthesize isoprene. Keto acids can be used as a selection in directed evolution (DE), a vitaltool in the enhancement of enzyme activity.4 In order to employ DE however, enzyme specificitymust be high enough for the desired conversion. Computational techniques, such as docking andfunnel metadynamics, can be utilized to elucidate key amino acids involved in binding andcatalytic active sites. These amino acids can then be mutated to enhance enzyme specificity. Inthis work, I focus on the conversion of citramalate to butanoic acid, a key step in the synthesis ofisoprene, by expressing carnitine-CoA ligase (CaiC) and carnitine-coA transferase (mvaE) in E.coli. I hypothesize that engineering specificity and activity in heterologous CaiC and mvaEenzymes using a combined theory-experiment approach will increase butanoic acid yield,making the biosynthesis of isoprene more feasible for scale-up.Research Aims: The primary objectives of this project are to (1) manipulate specificity and (2)increase activity of CaiC and mvaE to optimize conversion of citramalate to butanoic acid, whichcan then be converted to isoprene through a series of organic reactions (Fig. 1).Figure 1: Workflow to sustainably produce isoprene from plant biomass by designing enzymes, supplementingexperiment with modeling to engineer protein design, and using results from computation to inform experiment.Preliminary results: During the summer of 2018, I obtained preliminary data by working on theupstream synthesis of isoprene using engineered E. coli in Dr. Kechun Zhang’s lab at theUniversity of Minnesota through the NSF-funded Center for Sustainable Polymers. Specifically,I was able to produce citramalate from glucose via citramalate synthase (CimA) using a ketoacid-mediated pathway (Fig. 1). The next phase of the project is to convert citramalate tobutanoic acid, the next intermediate in the biosynthesis of isoprene.Methods: (Aim 1) CaiC and mvaE enzymes are known to perform the desired reduction oncarnitine, a molecule of similar structure and functional group composition to that ofcitramalate.5,6 I will use computational modeling to design more specific enzyme active sites forcitramalate. The crystal structure for mvaE will be obtained from the Protein Data Bank. I willKristen C. Vogt NSF GRFP Graduate Research Planthen build a homology model for CaiC based on the crystal structure of L-carnitine CoA-transferase (CaiB) and generate force fields describing carnitine and citramalate from quantumchemical calculations. I will run molecular docking of CaiC and mvaE enzymes with citramalatefollowed by molecular dynamics (MD) simulations to equilibrate systems. I will then use funnelmetadynamics to calculate protein-substrate binding free energy to provide an estimate of thebinding affinity between both enzymes and substrates.7 Insights gained from these simulationswill inform key amino acid mutations to improve enzyme specificity.(Aim 2) Next, I will use directed evolution to improve enzyme activity using a keto acid-pathway and growth-based selection.4,8 I will use error-prone polymerase chain reactions (PCR)to create mutant libraries of CaiC and mvaE enzymes. PCR products will be cloned into a DNAbackbone, electroporated into E. coli, and plated on Luria broth (LB) plates containing 100g/mL Ampicillin. I will measure the total product formed from enzyme conversion using a 4-aminoantipyrene assay.8 Enzymes with readings 50% greater than parental standards will beselected for rescreening. Once both enzymes are optimized for activity and specificity, theirDNA sequences will be ordered, replicated using PCR, ligated into a DNA backbone, andtransformed into E. coli. I will then run fermentation for 48 hours in a 37 C thermoshakerrunning HPLC and OD every 12 hours to monitor butanoic acid production.9600Resources and support: In order to address these aims, I will work in collaboration with theZhang and Truhlar groups at the University of Minnesota (UMN) to develop the experimentaland theoretical components of isoprene synthesis, respectively. Access to supercomputing timethrough NSF’s XSEDE will allow for the proposed computational simulations.Intellectual Merit: The combined theory-experiment workflow outlined in this proposal is usedto overcome low yield by improving enzyme activity and specificity in heterologous CaiC andmvaE enzymes. This methodology can be applied in any biosynthetic reaction to synthesizenovel non-natural metabolites at higher yields over varying conditions.7 Even if highly accuratefree energies are challenging to obtain from simulation, mechanistic information obtained fromMD can be used to inform the next stage of experiment. Future directions of this project includeconverting butanoic acid to isoprene and investigating gene knockouts to further increase yield.Broader Impacts: The synthesis of isoprene, a commodity used in countless goods, such asadhesives, tires, and shoe soles, is currently unsustainable due to reliance on limited petroleumresources. Biosynthesizing isoprene using fermentation offers a renewable and cost-effectivealternative. Increasing yield will make it feasible to utilize this technology in large scaleproduction to move away from harmful, depleting syntheses and towards a more sustainablefuture. I plan to regularly present results from this work at conferences and make publicationsavailable to the public via open-access publication methods. Lastly, because parts of the aboveproject, such as using recombinant DNA technology and running fermentation, lend themselvesto undergraduate research, I will mentor and engage undergraduates in order to provide themwith access to authentic research experiences early in their careers.1. Singh, R. Org. Process Res. Dev. 2011, 15 (1), 175–179. 2. Zhao, Y.; Yang, J.; Qin, B.; Li, Y.; Sun, Y.; Su, S.;Xian, M. Appl. Microbiol. Biotechnol. 2011, 90 (6), 1915–1922. 3. Yang, J.; Nie, Q.; Liu, H.; Xian, M.; Liu, H.BMC Biotechnol 2016, 16. 4. Atsumi, S.; Liao, J. C. Appl. Environ. Microbiol. 2008, 74 (24), 7802–7808. 5. Eichler,K.; Bourgis, F.; Buchet, A.; Kleber, H. P.; Mandrand-Berthelot, M. A. Mol. Microbiol. 1994, 13 (5), 775–786. 6.Hedl, M.; Sutherlin, A.; Wilding, E. I.; Mazzulla, M.; McDevitt, D.; Lane, P.; Burgner, J. W.; Lehnbeuter, K. R.;Stauffacher, C. V.; Gwynn, M. N.; et al. J. Bacteriol. 2002, 184 (8), 2116–2122. 7. Limongelli, V.; Bonomi, M.;Parrinello, M. PNAS 2013, 110 (16), 6358–6363. 8. Bloom, J. D.; Labthavikul, S. T.; Otey, C. R.; Arnold, F. H.PNAS 2006, 103 (15), 5869–5874. 9. Kuhn, J.; Müller, H.; Salzig, D.; Czermak, P. Electronic Journal ofBiotechnology 2015, 18 (3), 252–255."
97.0,"humanscalestructuresoutofmodularcomponentsinrealworldenvironments.IntroductionAutonomousunderwatervehicles(AUVs)fittedwithspeciallydesignedgripperswillbuild concrete retaining walls and artificial reefs with modular blocks. Blocks will be designed toprovidepassiveerrorcorrectiononbothpickupandplacement,makingthesystemrobusttonoisefromlocalizationandcontrol. Localizationwillbeachievedwithspeciallydesignedinfrastructurepartiallyembeddedintheblocksthemselvestoprovidecertaintynearassemblyareas.Underwater construction is both dangerous and expensive because specially trained humandivers must build and maintain structures by hand. At moderate depths, extreme measures mustbe taken to protect divers including the use of hyperbaric chambers to treat decompression sick-ness. Small mistakes or equipment failures during a dive are disastrous, often resulting in death.Atextremedepthsbuildinginpersoniseffectivelyimpossibleduetothereducedcapacityofpres-surized air tanks at high pressure. The substantial cost and risk of using divers on site leads us tofavor assembly on land and then transportation to the final location which constrains the types ofstructuresthatcanbebuilt.Though autonomous underwater construction technology could open a frontier of possible ap-plications, no autonomous system exists to date. Teleoperation based solutions have received at-tention in the literature including a rubble leveling robot [2] and a back hoe [1]. Teleoperationeliminates the need for accurate localization, but it requires that large amounts of data are passedback to the human operator at a high rate. Communication underwater is often achieved usingeither a physical tether or acoustic networking. Managing long tethers is difficult and acousticcommunicationislowbandwidth,limitingthepossiblerangeofteleoperationbasedsolutions.Research Plan My initial system will be built around a BlueROV2 underwater robot which isavailableintheDartmouthroboticslab. TheBlueROV2isa10kilogram,0.5meterlongrobotwith6degreeoffreedommotion. Itisanattractiverobottobasethesystemonbecauseitincludesawellmaintainedcodebaseandseveralsensorsforlocalizationincludingtwoinertialmeasurementunits,pressuresensors,twocompasses,alowlightHDcamera,andashortbaselineacousticpositioningsystem. IwillutilizevisualmarkerscalledARTagsforvisualpositioninginformation.Research Question 1 How can we best exploit accurate localization information when it is avail-able, and smoothly switch to coarse grained techniques when it is not? Approach My preliminaryexperiments on localization suggest that sensor accuracy varies depending on the robot’s positionand velocity. I will empirically model the noise and accuracy of the sensors under relevant cir-cumstances, then design a sensor fusion algorithm which exploits the most reliable information atevery instant. Research Question 2 Given some desired structure, how can we design a feasibleand robust build plan for the structure? Approach To design a feasible build order for a structure,itwillbenecessarytoconsiderthephysicalconstraintsofboththebuildingblocksandtherobot’smaneuvering capabilities. I will model the build ordering constraints induced by the structuralandmaneuveringconstraintsasaconstrainedoptimizationproblem. Theobjectivefunctionofthisproblemwillencodetheabilityoftherobottoexploitlocalizationinformationthroughoutthebuild.My initial work on build order optimization in 3D printing can be generalized to suit this applica-tion[3]. ResearchQuestion3Howcanweautomaticallyreacttobuilderrorscausedbychangingenvironmental circumstances? Approach To gain insight into the failure modes of the system, IwilltestitrepeatedlyonaselectedfewbuildplansinboththepoolandLakeSunapee,NH.Duringeach test, I will record and categorize the failures that occur. Based on the most common types oferrors, I will develop automatic recovery mechanisms. For example, if a block is not fully seatedonanotherblock,therobotcouldgentlynudgethemintoplace. Iftherobotpassesthroughacloudofsilt,itcouldstopandwaitforthecloudtosettlebeforecontinuingthebuild.ExperimentPlanFirst,Iwillisolateeachsensoranddetermineitsaccuracylimitations. Toestab-lishtheaccuracyoftheIMUandARTagreadings,Iwillutilizeanindustrialroboticarmavailableinthelabtocollectaccuracyandnoisedatabasedonknownprogrammedmotions. Toevaluatethepositional accuracy of the sensor fusion algorithm on land, I will utilize a highly accurate VICONpositioning system as ground truth. With the sensor quality models in hand, I will begin iteratingon the sensor fusion algorithm. Preliminary debugging style experiments can be conducted in a 6foot diameter water tank in the lab. Frequent field tests in the athletic pool and nearby lakes suchas Lake Sunapee will inform further iterations. Simple tests such as repeatedly moving a blockback and forth on a platform in calm clear waters will help isolate the quality of localization data.Build order and error recovery algorithms will be tested by selecting several simple build plansand repeatedly testing them in varying environmental circumstances. The ultimate goal will be tosuccessfullyexecuteabuildplanneartheshoreoftheCarribeanseaduringoneofthelab’syearlytripstotheBellairsResearchInstituteinBarbados.Intellectual Merit Underwater construction will require the co-development of localization in-frastructure and sensor fusion strategies to rapidly instrument a build site. Rapidly deployablelocalization infrastructure will have applications in any autonomous robotic system attempting toachieve manipulation tasks in a remote or harsh environment. Rather than attempting to jump tounaided manipulation in totally unstructured environments, I will be taking the realistic approachof exploring the minimal amount of additional infrastructure required to complete manipulationtasks. This work will also advance the evaluation of the trade offs between computational andphysical complexity in autonomous robotic systems. For example, designing blocks which moresuccessfullycorrectforerrorcouldallowmanipulationbehaviorstobemoresimplewhilerequiringamorecomplexblockgeometry. Developingtechniquestorigorouslyevaluatetradeoffsbetweencomputationalandphysicalcomplexityforcomputational-physicalsystemsisanimportantstepindesigningrobustroboticsystemsforrealworldenvironments.Broader Impacts A system which can robustly place modular components on one another couldenable the mostly autonomous creation of retaining walls or artificial reefs. As ocean levels con-tinuetorise,retainingwallswillbeincreasinglyimportantindevelopedcoastalareas. Bystackingcomponentsofartificialreefs,wecouldenablelargerscalereefrestorationactivities. Asthetech-nology advances, it could enable more subtle applications as well. It could enable us to moreefficientlybuildoffshoreenergyinfrastructureorenableustoscaleunderwateragriculture.This project is a valuable opportunity for young researchers to gain hands on experience withrobotics and software development, preparing them for a productive career in an exploding field.During the conduction of the preliminary study, I worked with two high school students who con-tributed directly to this research. The students gained exposure to robotic software design andmechanical modeling. I will continue using this work as an opportunity to mentor driven youngresearchers.[1]TaketsuguHirabayashietal.“Teleoperationofconstructionmachineswithhapticinformationforunderwaterappli-cations”.In:AutomationinConstruction15.5(2006).21stInternationalSymposiumonAutomationandRoboticsinConstruction.[2]T.S.Kimetal.“Underwaterconstructionrobotforrubblelevelingontheseabedforportconstruction”.In:201414thInternationalConferenceonControl,AutomationandSystems(ICCAS2014).[3]S.LensgrafandR.R.Mettu.“Animprovedtoolpathgenerationalgorithmforfusedfilamentfabrication”.In:2017IEEEInternationalConferenceonRoboticsandAutomation(ICRA)."
98.0,"Keywords: Aging, stress response, RNA biology, DrosophilaBackground: Aging is characterized by the accumulation of cellular damage, the physiologicaldecline of tissue and an increased susceptibility to disease resulting from the failure to maintainhomeostasis in the face of endogenous and environmental stresses [1]. A key mechanismunderlying protein homeostasis (proteostasis) in response to stress is the assembly of RNA stressgranules (SGs). When stress dissipates, SGs disassemble and cells return to homeostasis, thusSGs dynamic behavior offers a potential molecular mechanism that links aging and cellularstress resilience. Interestingly, changes in SG dynamics have been identified in age-dependentneurodegenerative disorders, yet SGs remain unexplored in normal aging.SGs are non-membrane bound organelles that assemble in the cytoplasm of cells whentranslation initiation is inhibited or during stress (e.g. heat shock, osmotic pressure, oxidativestress) [2]. SG formation has been shown to increase fitness during stress [3]. During transientstress, SGs stabilize mRNA and delay the aggregation of proteins linked to neurodegeneration [4-5]. SGs preferentially sequester long, poorly translated RNAs as well as a diverse set of proteinssuch as nuclear pore complexes, RNA binding proteins and others varying by cell type andstressor [6-7]. SG assembly is rapid: a dense core is formed by an established network of protein-protein interactions, nucleated by G3BP1, followed by the assembly of a dynamic shellcomprising RNA and RNA binding proteins that trigger liquid-liquid phase separation. Afterstress subsides, SGs spontaneously disassemble and allow sequestered factors to return to theirfunctions [8]. When SGs fail to disassemble, such as during chronic stress, they disrupt, notmaintain, proteostasis and facilitate protein aggregation [9]. Two previous studies found that SGcomponents aggregate with age, but it is unknown how normal aging alters the nucleation,stability, or disassembly of SGs [10-11].I hypothesize that (1) the dynamics of SGs will be altered throughout aging and (2) thecomposition of SGs will correspondingly be altered by age.Aim 1: Determine the dynamics of SGs during aging in response to stressUsing a Drosophila model where Rasputin (RIN), the homolog of G3BP1 and the onlyprotein required for SG formation, is endogenously tagged with GFP (RIN-GFP), I will visualizeSG formation in the fly brain [12]. Drosophila share over 60 percent of their genome withhumans, providing a translatable and practical model to study SGs throughout aging (lifespanaverages 100 days). To determine if age impacts SG dynamics (e.g. assembly and disassembly)in fly brains, I will dissect adult fly brains and immunostain for GFP. Using a confocalmicroscope, I will quantify the distribution and sizes of RIN-GFP puncta in various regions ofthe fly brain. Drosophila will be dissected at five time points across aging (1, 20, 50, 80, 100days). To capture the altered dynamics of SGs between types of stress, heat shock and oxidativestress through paraquat ingestion will be used to stress flies just before dissection. Controls willinclude age matched Drosophila that will not be subjected to stress. To distinguish between SGassembly and disassembly, flies will be dissected just after stress (assembly) or two hours afterstress (disassembly). Ten to twenty flies will be studied per time point and treatment.Expected outcomes, potential pitfalls and alternatives. Preliminary experiments show thatSG assembly declines with age in flies (data not shown) thus I expect less robust assembly ofnew SGs for older Drosophila. I expect most SGs to disassemble one hour after stress for youngDrosophila. For old Drosophila, I expect less dynamic SGs or slower disassembly. The assemblymechanism of SGs varies slightly by stressor. Oxidative stress has canonically been used to elicitSG formation [2]. The dynamic behavior of heat shock induced SGs could defy expectationsbased on research into SGs generated by oxidative stress. Previous research shows some SGaggregation in aging [10-11]. If SG disassembly does not visibly change with age, though, changesin SG composition could alter SG dynamics in other ways. These experiments will show for thefirst time how aging fly brains respond to stress by assembling SGs. Future research willexamine the relationship between altered SG dynamics and phenotypes of aging (e.g. behavior).Aim 2: Determine the composition of SGs during aging in response to stressSG dynamics are impacted by the composition of SGs. For example, the recruitment ofprotein kinases ULK1 and ULK2 and the ATPase VCP to SGs is required for SG disassembly[13]. Age-related alterations to SG composition are likely responsible for the expected decline indynamic SG formation during aging. SGs will be isolated using immunoprecipitation (IP) ofGFP tagged RIN protein/RNA complexes from the neurons of the same experimental Drosophilaand controls described above. IPs will be optimized using IgG controls to ensure specificity ofRIN-GFP complexes. Mass spectroscopy and RNA-sequencing will be used to identify theproteins and RNAs comprising SGs throughout the various stress and aging conditions. Key SGmarkers will be cross-referenced. The results will be analyzed using statistical models to identifywhich proteins and RNAs are enriched or depleted in specific conditions and age time points.Expected outcomes, potential pitfalls and alternatives. The differential recruitment ofproteins to SGs has physiological impacts on cells during the stress response and can alter SGdynamics. For example, if SGs formed during old age increasingly sequester nuclear porecomplexes, proteostasis is more likely to be disturbed in aging [6]; similar logic applies to otherpathways. RNAs sequestered to SGs mediate protein recruitment but do not impact globaltranslation [8]. By linking the composition of SGs with different assembly and disassemblyphenotypes, the impact of age on the mechanism of SG-supported stress resilience can be morefully understood. To follow up candidates identified by IP/mass-spec, overexpression orknockdown of genes in Drosophila will be used to identify the specific role of proteins in thealteration of SGs dynamics in the stress response throughout aging.Intellectual Merit and Broader Impacts: For the past three years, I worked with Drosophilastudying RNA biology in aging and the cellular stress response. Through my research, Ioptimized IP procedures to isolate SGs and prepare them for analysis by mass spectroscopy andRNA-seq. To analyze this data, I created statistical models using the R programming language.Given SGs role in stress resilience and neurodegeneration, understanding the impact of age onthe dynamics of SGs is important. These findings will help generate new hypotheses about therole of the stress response in aging. Additionally, researchers are pursuing treatments to theneurodegenerative disease amyotrophic lateral sclerosis that eliminate SGs in humans. SGelimination could significantly impair the ability of neurons to survive especially during aging.The proposed experiments will provide key insights into new strategies to maintain cellularhomeostasis in the human body, specifically the brain, and extend the health span as well aslifespan. As part of my research, I am responsible for leading and training a small team ofundergraduates in our study of RNA biology in aging. In addition to effectively communicatingmy research at two international conferences and to my community, I helped review currentresearch on the role of SGs in protein aggregation for an upcoming publication.References cited: [1] Rieraetal et al., 2016. Annu. Rev. Biochem. 85, 35-64. [2] Parker et al., 2009. Mol. Cell 36,932-941. [3] Riback et al., 2017. Cell 168, 1028–40. [4] McGurk et al., 2018. Mol. Cell 71, 703-17. [5] Bley et al.,2015. Nuc. Acids Res. 43, 23. [6] Khong et al., 2017, Mol. Cell 68, 808–20. [7] Markmiller et al., 2018, Cell 172,590–604. [8] Jain et al., 2016. Cell 164, 487–98. [9] Zhang et al., 2019. eLife 8, 39578. [10] Lechler et al., 2017.Cell Reports 18, 454–467. [11] Moujaber et al., 2017. Bioch. Acta 1864, 475–486. [12] Anderson et al., 2018.Human Mol. Genetics 27, 1366-81. [13] Wang et al., 2019. Mol.Cell 74, 742-57."
99.0,"Investigation of the Catalytic Properties of Cerium(IV) Oxide in Metal Oxide LaserIonization-Mass Spectrometry ImagingBackground: Matrix-assisted laser desorption/ionization-mass spectrometry imaging (MALDI-MSI) is an emerging and powerful analytical technique, which allows the spatially resolvedcharacterization of a wide range of analytes within biological specimens.1 Metal oxide laserionization (MOLI) is a recently described variation on MALDI in which a metal oxide, ratherthan an organic acid, is utilized as the matrix.2255m/z Unlike the other metal oxides, Cerium(IV) Oxide(CeO ) demonstrates a unique property of laser2induced fatty acyl catalysis when applied to281 phospholipids and energized by standard lasersm/zfound in MALDI-TOF MS instruments, as seen inFigure 1. This property of laser-induced catalysis byFigure 1. MOLI-MS using CeO 2 on POPC CeO provides a considerable opportunity in various2biological and clinical applications in which fatty acidprofiling may be needed.3,4 Beyond clinical applications, CeO -based materials also have a2variety of applications as a catalytic system in fuel cells, thermochemical water-splitting, organicreactions, and photocatalysis.5 Because of the involvement of CeO in a variety of fields, and the2potential it has to impact future technologies, a further investigation of the biological catalysisproperties of this compound are warranted.Preliminary Results: The Cox group in Colorado has headed theinvestigation for the use of MOLI techniques in the identification ofbacterial species. This group discovered that CeO could be utilized2for identification with improved stability and reproducibilitycompared to other metal oxides.6 Previously, MOLI has not beenused in conjunction with MSI in order to induce fatty acyl catalysisdirectly from tissue for possible bacterial detection. While MSI isfound to be a promising technique, there are only very few researchgroups that currently have the instrumentation available to conductMSI studies. At Harvard Medical School, the Agar group has beenFigure 2. MOLI-MSI of control working in the field of MSI for over a decade. During my time inmouse brain: A) 255.4 m/z &the group this summer, I developed and optimized a technique forB) 281.5 m/zCeO deposition on biological tissue, which is currently being2prepared for submission. This technique describes the deposition of CeO for MOLI-MSI, such2as in Figure 2, as well as possible clinical applications.Although MOLI using CeO has shown considerable promise, the mechanism for which2fatty acyl catalysis occurs when laser energy is applied to CeO is still unknown. Most2commonly, when MOLI-MS is used, analyte ionization of phospholipids typically occurs byprotonation due to interactions with the Lewis acid/base sites on the metal oxide. However, onlyno protonation occurs with CeO -induced catalysis, indicating that the mechanism of cleavage is2unique. It is postulated that much of the catalytic activity of CeO arises from oxygen vacancy2defects in the surface which occur at MALDI-like conditions (high temperature, low pressure).6Proposed research: My preliminary results have developed a novel technique for theapplication of CeO to clinical problems. However, it has left unanswered a critical question2about the mechanism of fatty acyl cleavage that occurs when CeO is used for MOLI-MS/MSI.2Without understanding the mechanism of catalysis, it is difficult to fully interpret the massMadison McMinn | 2018 NSF GRFP Research Statementspectra generated by this method. My future research plans consist of three specific goals,detailed below. By achieving these goals, I plan to elucidate the mechanism of catalysis that isunique to CeO , when it is used with biological samples.2The first goal is to expand beyond phospholipids, and study compounds that also containfatty acid chains, such as diacylglycerols, sphingolipids, triglycerides, acyl-carnitines, acyl-coenzyme A thioesters and other acyl-bound biomolecules. I am interested in determining if thecleavage of fatty acid chains is unique to phospholipids, or if CeO can also induce this property2on other compounds. This will serve to determine the depth and breadth of this application.Also, if certain compounds are unable to undergo catalysis by CeO , structural differences can be2identified and studied. For these experiments, I plan to use commercially available lipidstandards to evaluate catalysis in a simple, and direct way.The second goal is to apply the knowledge gained in the first goal of this proposal tocomplex systems. Since isolated and purified compounds do not exist naturally, it is critical tosee how effective this technique is when applied to a complex biological specimen. For this, Iplan to correlate mass spectra obtained with a typical MALDI matrix and with CeO . I aim to2correlate the known lipid composition with the fatty acid composition, to see if certain speciesare more prone to cleavage when present in a complex sample. This would be relevant in MOLI-MSI with heterogenous tissue samples, where lipid compositions can vary greatly throughout thespecimen.The third goal is to investigate the surface chemistry of CeO using experimental and2computational methods. I plan to perform studies where CeO particles of varying sizes are2probed by electron/neutron diffraction, since X-ray diffraction is not an ideal technique for thismaterial, due to the low scattering power of oxygen. These studies aim to determine if a greaternumber of oxygen defects contributes to improved catalytic cleavage. Diffuse ReflectanceInfrared Fourier Transform Spectroscopy will be performed to study the surface morphology ofCeO before and after it is subjected to MOLI-MS. Once the surface structure of CeO is well2 2understood, computational studies can be performed using density functional theory calculations.Intellectual Merit & Broader Impact: Elucidating the mechanism of CeO -induced fatty acyl2catalysis will allow scientists to use my developed MOLI-MSI technique and the MOLI-MSdatabase for bacterial identification by the Cox group with increased confidence. Also, theinformation obtained from my first research goal has the potential to advance knowledge infields that use fatty-acid containing molecules, such as cosmetics, nutrition, and metabolomics,in addition to biological applications. Furthermore, elucidation of the catalysis mechanism ofvaried metal oxides, and what induces this variance, can contribute fundamental knowledge tothe field of catalysis chemistry, especially metal oxide catalysis. In regard to the broader impactin biological applications, fatty acid profiling of tissue specimens has been an extensive area ofstudy, dating back nearly a century. Most current approaches use many time-consuming stepsand, more concerningly, result in the loss of spatial relationships between these molecules.Preserving these spatial relationships is critical in the analysis of a wide variety of diseases,including many cancers, which demonstrate heterogenous tissue distribution. We have shownthat MOLI-MSI using CeO can provide in situ fatty acyl characterization of biological tissues2while preserving regional distribution. By better understanding the chemistry of CeO induced2fatty acyl catalysis, a more informed interpretation of resulting MS spectra and therefore thetissue composition can be appreciated. This work will lay the groundwork for a potentially newclinical and translational diagnostic approaches.1.Reyzer ML, Caprioli RM. J Proteome Res. 2005, 4(4), 1138-1142. 2.Schwamborn K, Caprioli RM. Nat RevCancer. 2010, 10(9), 639-646. 3.Voorhees KJ, Saichek NR, Jensen KR, Harrington PB, Cox CR. J Anal ApplMadison McMinn | 2018 NSF GRFP Research StatementPyrolysis. 2015, 113, 78-83. 4. Choe SS, Huh JY, Hwang IJ, Kim JI, Kim JB. Front Endocrinol (Lausanne). 2016,7(30). 5.Hodson L, Skeaff CM, Fielding BA. Prog Lipid Res. 2008, 47(5), 348-380."
100.0,"Evidence from the surface and atmosphere of Mars indicates that Mars was once a much wetterworld. Today, we know that nearly all the water has been lost [6]. Understanding the evolutionof water on Mars and its atmosphere is critical to answering questions such as: did life ever existon Mars, or does it now? What can Mars tell us about possible futures for Earth or evolutionarypathwaysofexoplanetatmospheres?IntellectualMeritTo approach these questions, we need new models that capture the complex chemistry and dy-namics governing escape of water. Thermal escape of hydrogen (H) is the main loss process forbothwaterandtheatmosphereasawhole[6]. BecauseHescapesmoreefficientlythanitsheavierisotope, deuterium (D), understanding variations in the D/H ratio is the key to understand-ing loss of Martian water. However, the most recent atmospheric escape studies that included Dchemistry only considered global averages of D/H, and were 18+ years ago [7, 10]. Since then,D/Hmodelingworkhasstalled,andnostudieshaveinvestigatedoutgoingfluxofD[6].Twenty years of data from the Hubble Space Telescope, ground-based telescopes, and Mars or-biters, landers, and rovers have augmented our knowledge of the D/H ratio on Mars. We nowknow it varies with season, altitude, and geographical location ([9], and references therein). Thisvariability is apparent in atmospheric water vapor, which can form clouds and be transported bydust storms. Studies have shown that planetary boundary layer (PBL) water ice clouds can de-crease the total water column by up to 15% on timescales of a few days [4]. Orbiter data [3, 5]shows that dust storms boost water in the mesosphere, which was demonstrated by Chaffin et al.[2]toenhancelossofHwithinweeks. IproposetousethesenewdataasinputsandconstraintsinthefirststudiesinnearlytwodecadesoftheroleofD/HinMartianatmosphericloss.ResearchGoals1. Explainhowseasonal,altitudinal,geographicalD/Hvariationsaffectatmosphericloss.2. Understandtheeffectsofplanetaryboundarylayercloudsonatmosphericloss.3. Quantifythecontributionofduststormstoatmosphericlossenhancement.ModelingMethodology,Preparation,andCurrentResultsDue to computational resource limitations, 1D photochemical models are required to simulate themartian atmosphere on time-scales of 105+ years. Though limited in space, 1D models can pro-vide context for end-member cases of more expensive 3D calculations. During my first year ingraduate school, I expanded a 1D photochemical model built by my advisor, Michael Chaffin,doubling the number of chemical pathways modeled and adding deuterium chemistry. Fol-lowing Chaffin et al. [2], the model solves a photochemical system of coupled partial differentialequations. Modificationstoaddressresearchgoalsrequireonlyminorchangesasfollows.1. New,high-precisiondatatoconstrainD/HinaltitudeandtimeisforthcomingfromtheESATrace Gas Orbiter to [8]; we can model this data as a time- and altitude-depndent function.Spatialvariancecanbeestimatedwiththis1Dmodelbyindividualruns.2. Bothdiurnalandseasonalvariationsinwatervaporabundanceduetocloudsandduststormscan be included with time-dependent calculations of the water vapor profile, which is pre-scribedinthemodel. CloudaltitudescanbeestimatedusingCuriosityrovermoviesandtheMarsRegionalAtmosphericModelingSystem(MRAMS)[1].IrecentlystudiedtheeffectsofDchemistryandchangestothetemperatureprofileandwaterEryn M. Cangi Research Proposal 2018-2019 NSF GRFP applicationvapor mixing ratios on escape by calculating the fractionation factor f, which represents howefficiently D escapes with respect to H. (A fractional value 0.xx means that D escape is 0.xx% asefficient as H escape). Selected results are shown in Figure 1. This is the first effort to modeldifferential escape of H and D in ∼18 years. Our results show that prior calculations greatlyoverestimated the relative escape of D due to systematic inaccuracies in atmospheric temperaturemeasurementsandphotolysisratecoefficientsavailableatthetime. Isharedtheseresultswithcol-leaguesatthe50thmeetingoftheAmericanAstronomicalSocietyDivisionforPlanetarySciences(DPS),andamcurrentlycompletingworkonwritingtheseresultsinalead-authorpublication.Figure 1: Fractionation factor (percent efficiency atwhich D escapes with respect to H) for 6 model runs,comparedtotworeferences. Labelsindicateadjustmentsto three temperature profile control parameters: T ,surfT , and T . “↓T ”, e.g., means the temperature attropo exo exotheexobasewasloweredforthatmodelrun.Adjustmentsof±25%tothemeanprofileweretested.Thelowsurfacetemperaturecaseproducedanunstableatmosphere(pho-tochemicalsystemhadnosolution)andwasdiscarded.BroaderImpactThe public imagination is already captivated by Mars, as a possible habitat for extraterrestriallife and a target for future crewed missions. As mentioned in my personal statement, next year Iwill join CU-STARS, a departmental program that brings extracurricular science lessons toColoradopublicschools. ExcitementaboutMarsfromallages,andthefactthatatmosphericlosscan be explained without complicated jargon, makes my research an excellent topic for reachingout to schools around Colorado. In terms of engaging the wider public, I also plan to make myresearch available to the public by giving talks at University of Colorado’s Fiske Planetarium,a method of outreach where I can draw on my earlier training in theatre. To understand possiblefuturesforMars,weneedtounderstanditshistory;myfirsttalkwilldiscussthehistoryofmartianatmospheric escape and implications for hypothetical future terraforming efforts (and theethics thereof). I believe in making it easy for the public to access and understand the sciencetheir taxes pay for; in addition to presenting at conferences and publishing papers, I maintain apersonalwebsitewithexplanationsofmyresearchforbothlaypeopleandfellowscientists.MarsresearchcontributesnotonlytoMarsscienceandmissions,butalsotoexoplanetaryscience.Compared to the requirements to understand exoplanet atmospheres, Mars is a cheap and readilyavailable laboratory. It is valuable not only for scientific opportunities, but because for decades, ithas captivated disparate groups of people. Now more than ever, humanity needs goals that unifyusandremindusthatweareallinthistogether;myworktounderstandtheevolutionofwaterandtheatmosphereonMarswilladvancethosegoals.References: [1]Campbell,C.,etal.2018,AAS/DPSMeetingAbstracts,300.03. [2]Chaffin,M.,etal.2017,NatureGeoscience,10,174-178. [3]Fedorova,A.,etal.2017,Icarus,300,440-457. [4]Haberle,R.M.,etal.2017,TheAtmosphereandClimateofMars. [5]Heavens,N.,etal.2018,NatureAstronomy,2(2),126-132. [6]Jakosky,B.,etal.2018,Icarus,315. [7]Krasnopolsky,V.2000,Icarus,148. [8]Villanueva,G.L.,etal.2018,AAS/DPSMeetingAbstracts,303.09. [9]Villanueva,G.L.,etal.2015,Science,348(6231),218-221. [10]Yung,Y.,etal.1988,Icarus,76(1)."
101.0,"Background. How does motivation drive learning? Evidence abounds that reward,motivation, and curiosity can all enhance learning and memory1; these findings have far-reachingimplications for education. However, a fundamental problem undermines our ability to apply thisresearch in classrooms: extrinsic reinforcement can actually decrease intrinsic motivation2. Inother words, although rewards like candy, stickers, and money are often used as incentives forstudents, these secondary reinforcers may decrease internal motivation, curiosity, and fulfillment.In the brain, dopamine pathways are strongly implicated in reward and motivation1.Dopaminergic cells in the ventral tegmental area (VTA) project to the hippocampus andsurrounding medial temporal lobes3, influencing memory by enabling the brain to prioritize andremember important information4. Moreover, high-reward contexts increase sustained VTAactivation and memory encoding5. Past studies of intentional encoding strategies have shown theimportance of elaborative and self-referential processing6, but have yet to link these methods todopaminergic modulation. Importantly, it remains an open question whether cognitive strategiescan act upon dopaminergic pathways to enhance memory, either immediately or over time.Cognitive neurostimulation, the volitional modulation of one’s own brain activity throughmental imagery and thoughts, offers a promising method of enhancing motivation. However,past research has found that without guidance, individuals struggle to self-motivate and modulateVTA activity7. Neurofeedback provides individuals with real-time information about their ownbrain activity. Past studies in the Adcock lab have successfully used neurofeedback to trainparticipants to self-activate the VTA; this activation is associated with self-reported motivation7.A day later, trained participants retained the ability to self-activate, even without neurofeedback.Intellectual Merit. Thus far, no study has shown that self-activation of the VTA caninfluence memory encoding or consolidation. This missing link is essential for elucidatingneural mechanisms of motivation and memory, as well as extending cognitive research toeducation. The proposed research will take a novel approach to address this gap in the literatureby embedding neurofeedback training within a memory task. The present study seeks to: (1)Train participants to drive intrinsic motivation and self-activate the VTA, (2) Test whether self-activation enhances memory encoding and consolidation, and (3) Identify effective motivationalstrategies with a data-driven approach. I hypothesize that with neurofeedback, participantswill learn to self-motivate and drive VTA activation, thus enhancing subsequent memory.Methodology. Fifty healthy participants will be recruited to participate in a study at theDuke University Brain Imaging and Analysis Center, which houses a GE Premier 3T MRIscanner. First, participants will complete two trait motivation surveys, the Motivational TraitQuestionnaire8 and the Behavioral Inhibition-Approach System9 (BIS/BAS). In the scanner, Iwill collect fieldmap, T1-weighted structural, and functional scans (TR=1s, voxels=2x2x2 mm3).Participants will complete three kinds of tasks: Activate task. Participants will beinstructed to self-motivate by using personally-relevant thoughts and mental imagery (e.g., onepast participant reported success with visualizing a cheering crowd7). Using PYNEAL software,previously developed in the Adcock lab, I will calculate real-time VTA activation and informparticipants with a dynamic thermometer display. Watch task. Participants will passively viewthe thermometer display, but will be informed that fluctuations are random, not neurofeedback.On these trials, the thermometer display serves as the control task, equating visual input with theActivate task. Encode task. On each trial, participants will try to memorize a series of 7 objectimages (2 sec. each), sampled randomly without replacement from a set of 336 images.In total, participants will complete 8 runs of 6 trials each. A random half of the trials willbegin with the Activate task (20 sec), and the other half will begin with the Watch task (20 sec).NSF-GRFP Graduate Research Plan: Alyssa H. Sinclair 2The Encode task (20 sec) will conclude every trial. Between runs, participants will verballydescribe the motivational strategies employed on preceding trials. After the MRI scan,participants will be randomly assigned to either the Same-Day group (memory test immediatelyafter the scan, n=25) or the Next-Day group (memory test 24-hours later, n=25). In a behavioraltesting room, participants will complete a recognition memory test of the images from theEncode task (336 old images, 168 novel images), and rate confidence on a 5-point Likert scale.Analyses. In summary, I will employ a 2x2 design (Task: Watch, Activate X Time:Same-day, Next-day) to address the following questions: 1. Does VTA self-activation enhancememory? I expect that within-subjects, average memory accuracy (d', signal detection theory)and event-related VTA activation will be greater on Activate than Watch trials. Moreover, trial-wise VTA activation will be parametrically related to memory for the stimuli encoded on a giventrial. Previous work in the lab has detected similar neuromodulatory effects on single trials10.2. Does self-activation of the VTA influence memory encoding and/or consolidation? IfVTA-activation enhances consolidation, then the Next-Day group will exhibit greater disparity inmemory accuracy between Activate and Watch trials (relative to the Same-Day group), becauseconsolidation is time- and sleep-dependent. Within the Next-Day group, I will compare memoryaccuracy for Activate and Watch trials to control for sleep-consolidation effects that areindependent of VTA-effects. An alternative hypothesis is that VTA-activation will improvememory equally in both groups, reflecting selective effects at encoding.3. What cognitive factors drive motivation and enhance memory? Using the traitmotivation survey data, I will test whether individual differences in personality (e.g., higherscores on trait motivation and the BIS/BAS Reward Responsiveness subscale) predict success onthe Activate task and subsequent memory accuracy. Moreover, I will employ a data-drivenapproach to identify the self-reported motivational strategies that most effectively increasedVTA activation (e.g., verbalizations, various types of mental imagery). Importantly, the existingliterature on motivation and reward is constrained by a limited set of strategies that are imposedby experimenters. Informed by my fMRI findings, I will develop future behavioral studies thattest the efficacy of the diverse motivational strategies that participants intuitively employ.Broader Impacts. Motivation is a core component of learning. Critically, low-incomeand disadvantaged students exhibit low intrinsic motivation, which predicts poor academicoutcomes11. In 2016, a staggering 29.7 million American children (41%) lived in low-incomefamilies12. In classrooms, fostering intrinsic motivation can improve learning outcomes andstudent retention9. Extrinsic reinforcers, such as monetary rewards, can have restricted and short-lived effects; in contrast, intrinsic motivation predicts long-term student success10. The proposedresearch seeks to empower individuals to drive intrinsic motivation and self-activatemotivational brain systems, thus engaging the brain to improve learning. With a novelneurofeedback approach, I will identify cognitive strategies that effectively act upon dopaminesystems to enhance memory. In future behavioral studies, I will directly test whether thesestrategies can successfully bolster motivation and memory without neurofeedback. The presentprogram of research seeks to uncover accessible and non-invasive methods of fostering intrinsicmotivation and improving memory, thus broadly benefiting learning and education.References: 1. Wise, R. A. Nat. Rev. Neurosci. 5, (2004). 2. Butler, R. Br. J. Educ. Psychol. 58, (1988).3. McNamara, C. G. & Dupret, D. Trends Neurosci. 40, (2017). 4. Lisman, J. E. & Grace, A. A. Neuron 46, (2005).5. Murty, V. P. & Adcock, R. A. Cereb. Cortex 24, (2014). 6. Kirchhoff, B. A. Neurosci. 15, 166–179 (2009).7. MacInnes, J. J., Dickerson, K. C., Chen, N. & Adcock, R. A. Neuron 89, (2016). 8. Heggestad, E. D. & Kanfer, R.Int. J. Educ. Res. (2000). 9. Carver, C. S. & White, T. L. J. Pers. Soc. Psychol. 67, (1994). 10. Adcock, R. A., et al.Neuron 50, (2006). 11. Schultz, G. F. Urban Rev. 25, (1993). 12. Koball, H. & Jiang, Y. NCCP, (2018)."
102.0,"Nature versus nurture? Maternal responses to infant distress callsIntroduction & Significance: The brain has the extraordinary capability of attributing differentlevels of importance to the different types of input signals it receives. For example, hearing one’sname, even at very low volume, elicits strong neural signals, as the brain has learned therelevance of that particular sound. The process by which this occurs is known as synapticplasticity, which allows the brain to alter its connections based on experiences associated withparticular sensory inputs. Synaptic plasticity is usually experience-dependent, and a class ofmolecules known as neuromodulators have the role of strengthening specific neural circuitsdependent on particular situations. Here I examine the action of one important neuromodulator,oxytocin, which is involved in a multitude of social interactions, including maternal care.Maternal behaviors are observed in all mammalian species, including mice. As infants,mouse pups are especially helpless, relying on their mother (called a ‘dam’) for all of their needs.Pups become scattered from the nest as the dam moves around, and must communicate with thedam that they have become isolated. To do so, they emit isolation ultrasonic vocalizations(USVs), triggering the dam to respond by retrieving the pup and returning it to the nest[1]. Whiledams retrieve pups with high accuracy, virgin female mice that lack prior experience with pupsfail to exhibit this behavior, generally neglecting the calls of a nearby pup[2]. However, afterbeing cohoused with a dam and pups for several days, virgin female mice can learn to retrievepups with comparable accuracy to the dam[2]. A virgin’s acquisition of this pup retrieval behavioris accelerated by administration of the neuromodulator oxytocin [2]. This behavior can beeliminated by inactivation of the left auditory cortex (A1), which contains a significantly higheramount of oxytocin receptors (OXTR) than the right A1[2].My proposed graduate research is concerned with the specific features of isolation USVstimuli that cause A1 to recognize the behavioral relevance of these sounds. Specifically, Ipropose to examine perceptual attributes of the isolation USV encoded by the maternal A1 thatenable the dam to recognize and respond to this sound, as well as the role of oxytocin-dependentplasticity in acquiring USV-induced pup retrieval behavior by inexperienced virgins. Recentwork demonstrated that human A1 distinguishes screams from conversational speech by anacoustic quality known as ‘roughness,’ defined as the rate at which the volume of soundchanges[3]. By detecting roughness, human A1 rapidly engages subcortical structures to assessdanger[3]. I hypothesize that similar acoustic perceptual features allow the maternal A1 todistinguish, and attribute behavioral relevance to, the sound of nearby pup isolation USVs, andthat learning of pup retrieval behavior through experience relies on oxytocin-dependent synapticplasticity that strengthens the A1 response to such perceptual features.Aim 1A: Which acoustic features differentiateisolation USVs from other vocalizations? Tounderstand how the USV response is encoded inthe dam A1, I will chronically implant electrodearrays into adult female mouse A1, and obtainsingle-unit recordings in response to natural, pup-evoked isolation USVs from a speaker. ThisFigure 1: Example single-unit recordings from process (Figure 1) allows clear visualization oftetrode implants in A1. An increase in activity istemporally-precise spike activity in A1 as itobserved when isolation USV stimulus beginsrelates to sensory input from isolation USVs.Additionally, by observing behavior that dams exhibit when hearing the isolation USV stimulus,Katherine Furman – Graduate Research StatementI can visualize how A1 activity correlates to both sensory input and behavioral output (in theform of pup retrieval).Using the modulation power spectrum (MPS), which can visualize sounds two-dimensionally on both spectral and temporal domains[3], I can examine the portions of acousticspace in which these naturally-produced isolation USVs reside. By comparing this to the MPS ofadult USVs (which are behaviorally neutral to the dam) I will isolate which acoustic features areunique to the pup isolation USV and have behavioral relevance to A1.Aim 1B: Are these acoustic features relevant to A1? If pup isolation USVs contain specificacoustic ‘roughness’ features distinguishable by the maternal A1, synthetically manipulatedUSVs which lack these features should result in a weakened response compared to natural pup-evoked isolation USVs. Using MATLAB I will synthesize audio clips which mimic pup USVs,but lack the spectral/temporal features previously identified as unique to isolation USVs. I willthen play these to maternal animals, measuring behavioral and neural responses to calls withsimilar statistics as USVs, but varying in their frequency, temporal modulation (rhythm), androughness.Using single-unit recordings from electrode arrays in A1, I will observe neural activity ofA1 in dams when they are exposed to synthetically manipulated USVs played from an ultrasonicspeaker. If I’ve successfully identified the differentiating feature(s) making isolation USVsunique from other mouse vocalizations, I expect that dam A1 neurons will exhibit a stronger,more temporally-precise response to hearing pup-evoked isolation USVs (as was observed in[2]), than synthetically manipulated USVs. I also expect that pup retrieval behavior will besignificantly diminished, if not eliminated, when exposed to synthetically manipulated USVs.Aim 2: Are these specific elements dependent on oxytocin signaling? To test the hypothesisthat oxytocin promotes maternal pup retrieval by strengthening the A1 response to uniquespectral/temporal features of isolation USVs, I will observe the changes in A1 activity as a resultof changes to endogenous oxytocin systems. Using transgenic Oxy-Cre mice will allow targetedexpression of light-sensitive opsins in oxytocin-releasing neurons, the activity of which can bemanipulated with light of specific frequencies. I will express channelrhodopsin-2, which is ableto activate neurons in response to blue light, in pup-naïve virgin female mice. These mice will beexposed to pup isolation USVs concurrently with optogenetic stimulation of oxytocin-releasingneurons. By continuously pairing isolation USV audio with stimulation of endogenous oxytocinover a number of days, I hypothesize that the A1 activity of the naïve female will change tomimic the strong, temporally-precise response observed in dams.Intellectual Merit & Broader Impacts: With the help of the NSF GRFP, I will be the first toidentify the specific acoustic features, over both spectral and temporal domains, which areunique to pup isolation USVs when compared to other mouse vocalizations. By identifying theA1 single-unit activity displayed in response to isolation USVs, and by identifying the changesin activity when crucial isolation USV features are eradicated from the stimulus, I aim to observethe specific activity patterns recruited by A1 in attributing behavioral relevance to infant-relatedsounds. By observing the changes in neural activity induced in pup-naïve virgins afteroptogenetic stimulation of oxytocin, I will be able to observe the unique form ofneuromodulatory plasticity evoked by oxytocin in A1 which allows experience-dependentlearning of maternal pup retrieval behavior. By examining maternal auditory processing in suchdepth, the field can better understand the interplay between auditory input and oxytocin to yieldbehavioral output.References: 1. Ehret (2005) Infant rodent ultrasounds – a gate to the understanding of sound communication. BehavGenet 35:19. 2. Marlin et al. (2015) Oxytocin enables maternal behaviour by balancing cortical inhibition. NatureKatherine Furman – Graduate Research Statement520:499 3. Arnal et al. (2015) Human screams occupy a privileged niche in the communication soundscape. CurrBiol 25:2051."
103.0,"An investigation of thermal effects on Anax junius nymph growthBackground:Earth’s climate is changing, and scientists are already observing impacts on biota acrossmany taxonomic groups.1 Odonata are known to be useful biological indicators of environmentalchange at a macro-scale, including climate change.2 Odonata are highly temperature-sensitive,with direct effects on their physiology (e.g., developmental rate) and other life-history traits (e.g.,phenology).1 Additionally, distributional and phenological records for Odonata are extensive, sothey are excellent model organisms for studying the impacts of climate change on animaldistributions, life history strategies, and development. Finally, the fossil record and historic datashow that Odonata have survived rapid and dramatic climatic transitions in the past. However,present-day rates of climate change are substantially greater due to anthropogenic causes.3Historically, Odonata have proven to be resilient and adaptable, but their current response isunknown. In sum, Odonata are considered sentinels of climate change, and there is growinginterest in examining changes in their phenology and physiology as the climate warms.Odonata have been closely researched in the field. Studies using Odonates in appliedresearch areas, such as climate change, are beginning to gain attention, but overall, research inthis area is lacking.4 I believe that Odonata would be an exceptional research subject to help usunderstand how freshwater organisms are responding to warming temperatures. Shifts in airtemperatures will influence lentic water temperatures through convection and by changingevaporation rates.5 Odonata are likely to reflect the mismatches between water and airtemperatures due to climate change, demonstrating a potential temporal decoupling betweenaquatic and terrestrial species.5 Understanding this response in Odonates is particularlyimportant, because they play an important role in structuring food webs, especially in fishlessponds which harbor unique biodiversity among macroinvertebrates, and are quite numerousacross the landscape in many glaciated regions.6Research Proposal:I propose an investigation to examine the effects of warming temperatures on larvaldragonflies using the species Anax junius (the common green darner dragonfly, Order: Odonata,Family: Aeshnidae), in laboratory experiments. Although lab and field observations oftemperature effects on larval Odonate development have been done independently, this proposedstudy will allow for a comparison between the lab experiment and data collected in the field inorder to see if the lab findings in the lab hold up in real ecosystems. This proposal aims to 1)determine a range of temperatures that allow for optimal growth conditions for A. junius nymphs,and 2) compare the laboratory results to water temperature and A. junius emergence timingobserved in the field by students and citizen scientists in order to better understand the effectsthat climate change has on aquatic ecosystems.Preliminary Work:For the past three summers, I have worked with my mentor Dr. Emily Schilling atAugsburg University on projects studying dragonflies from the family Aeshnidae. Our studieshave focused on species showing evidence of modified life history strategies as an adaptiveresponse to climate change. Through this research, we have developed relatively simple, costeffective and trustworthy sampling methods for nymphs, exuviae, and adults, that can easily bereplicated by others.Methods and Materials:Aim 1) For this study, I have selected Anax junius, because this species is commonthroughout North America and adults are easily identified in the field (as opposed to otherAeshnids), which need to be observed in hand for species identification. Additionally, A. juniusis known to be migratory, meaning that this species’ distribution covers a large geographic area.For the laboratory component of my study, I will set up fifteen 20-gallon tanks (30”x12”x12”),each containing ten A. junius nymphs. Each tank will have a heater to regulate the temperatureand a HOBO Dissolved Oxygen Data Logger to monitor the dissolved oxygen differencesamongst the temperature treatments. Tanks will be supplied with emergence supports andcovered with mesh to capture emerging adults. There will be five temperature treatments (10°C,15°C, 20°C, 25°C, and 30°C), with three replicates of each. Nymphs will be measured for theirhead-width-to-wing-sheath ratio three times per week in order to monitor growth, the number ofdays it takes each nymph to emerge will also be recorded. All molts, deaths, and emergences willbe documented each measuring period.Aim 2) In order to get students and the general public more involved in STEM, I amgoing to enlist the help of volunteer scientists to broaden the scope of my data set. I will do thisby contacting high schools and universities with NSF grants, and by posting ads on social media.I will also contact the Dragonfly Society of the Americas to enroll citizen scientists. For therecruited volunteers, I will let them choose a pond to sample and send them a temperature loggerthat continuously records water temperature, dip-nets for sampling dragonfly nymphs, and aguide on nymph and adult identification for A. junius. Lastly, I will create a web page wherevolunteers can easily upload their data and observations from their field sites. By using citizenscientists, I will be able to sample a larger geographic area than would be possible on my own,and collect data from multiple regions simultaneously.Broader Impact:By examining the data I receive from citizen scientists around the country, I will be ableto gain insight as to which regions in North America are seeing the most dramatic changes inwater temperature and gain a better understanding of the biological response to thisenvironmental change. It is important to determine regions of concern so conservation planningcan be prioritized in those areas. All humans and a large proportion of earth’s biodiversityrequire fresh water to survive. That is why research focusing on freshwater ecosystems isessential. Since climate change is a global issue, it is important to involve people in climate-related research that can ultimately inform how we protect freshwater ecosystems, arguably ourmost precious ecological resource. By engaging students and citizens in science, by allowingthem to be a part of the data collection process, I hope to get more individuals interested inhelping preserve and conserve the limited resources we have on Earth for generations to come.References:[1] Hassall, C., D. J. Thompson. 2008. The impacts of environmental warming on Odonata: areview. International Journal of Odonatology 11(2): 131-153. [2] Bried, J. T., C. Hassall, J. P.Simaika, J. D. Corser, J. Ware. 2015. Directions in dragonfly applied ecology and conservationscience. Freshwater Science 34(3): 1020-1022. [3] Pritchard, G. & M. Leggott. 1987.Temperature, incubation rates and the origins of dragonflies. Advances in Odonatology 3: 121-126. [4] Bried, J. T., M. J. Samways. 2015. A review of odonatology in freshwater appliedecology and conservation science. Freshwater Science 34(3):1023-1031. [5] Matthews, J. H.2010. Anthropogenic climate change impacts on ponds: a thermal mass perspective. BioRisk5:193-209. [6] Schilling, E.G, C. S. Loftin, A. D. Huryn. 2009. Macroinvertebrates as indicatorsof fish absence in naturally fishless lakes. Freshwater Biology 54(1):181-202."
104.0,"Regardless of signs of recovery from the economic crisis of 2007-2008, economic issuesremain salient, and many Americans continue to experience stress due to their economicsituation. Economic stress consists of both subjective and objective evaluation of one’sfinancial and employment-related stress1. My research will focus on four forms of economicstress: income inadequacy, financial fragility, underemployment, and job insecurity. Financialstress occurs when individuals perceive their personal financial situation to be insufficient toafford their needs and wants (perceived income adequacy) and are unable to cope withunexpected expenses (financial fragility), consequently leading to financial strain. While theunemployment rate in the United States is relatively low (below 5%), many workers are stillexperiencing employment-related stress due to underemployment and job insecurity.Underemployed workers hold jobs that insufficiently use their skills, abilities, education, orqualifications and may also receive less hours and pay than desired. Job insecurity is anindividual’s subjective evaluation of the “perceived threat to the continuity and stability ofemployment as it is currently experienced”3. Employee perceptions of job insecurity have beenempirically shown to increase stress, reduce mental, physical, and work-related wellbeing, andpredict organizational commitment and turnover intention at work2-6. Perceived job insecuritymay induce more stress than actual job loss or unemployment because the anticipation of job lossmay prevent coping strategies to manage the stress. Along with unemployment, job insecurityhas been a popular focus of economic stress research. However, there has been lessconcentration given to occupational health impacts of broader financial issues (e.g. 19).Economic stressors linked to the Great Recession, such as job insecurity, are associatedwith increased somatic symptoms experienced by individuals and a greater likelihood of alcoholabuse as a potential coping mechanism7. Relationships have also been found between perceivedjob insecurity of men and psychotropic drug use8. Additionally, empirical evidence suggests thatillicit drug use may be a coping strategy for recessions and unemployment9. To my knowledge,research has not examined opioid use as a mediator of the relationships between economicstress and occupational health.For decades, the United States has struggled with an opioid epidemic. Opiates are drugsderived from the opium poppy plant that chemically interact with opioid receptors on nerve cellsin the brain and in the nervous system to produce pain relief and pleasurable effects10. Opioidoverdoses are driven by synthetic opioids (i.e. fentanyl), semi-synthetic opioids (i.e. oxycodone),and heroin and have led to four times more of American opioid-related deaths in 2015 comparedto 199911-12. Long-term opioid use frequently starts with the treatment of acute pain13. Prescribedopioid pain relievers are the prescription drugs most often misused, resulting in a 72.2% increasein deaths due to synthetic opioids – not including illegally produced fentanyl – from 2014 to201514. The number of opioid prescriptions written in 2012 would have been enough for everyadult in the United States to have one bottle of opioid painkillers11. This longstanding problemhas led to many societal consequences. The overuse and misuse of opioid substances costs theUnited States 80 billion dollars each year in healthcare, criminal justice, and productivity costs15.While the consequences of opioid use have been well-researched in other social domains16-17, the relationships between opioid use and the workplace have received less attention.Current research shows that opioid use is related to absenteeism and work productivity18. Myresearch will bridge this important gap in the literature on economic stressors, opioid use, andwork-related outcomes.Gwendolyn Watson NSF Research ProposalBroadly speaking, my goal is to establish a stream of research that will answer thefollowing questions: (1) What is the nature of the relationship between multiple economicstressors (job insecurity, fragility, underemployment, and income adequacy) and opioiduse? (2) What are the causal mechanisms linking opioid use and economic stress? (3) Howdoes opioid use relate to occupational health outcomes? Particularly I am interested in theimpact on employee work engagement such as organizational commitment and turnoverintentions.Opioid UseWork engagementEconomic StressorsRetentionOrganizationalJob insecurity CommitmentFinancial fragility Occupational Health Outcomes PerformanceUnderemployment Other outcomesIncome inadequacyThis project will be a short-term investment with long-term goals. My short-term goalsare to focus on the first two questions to establish the relationship between economic stressorsand opioid use, as well as to identify causal factors to help explain the relationship. I will beanalyzing a series of archival datasets and in-process data collection to test these relationships.Currently, my advisor Dr. Bob Sinclair is administering a longitudinal study online throughAmazon’s Mechanical Turk (MTurk) that includes the variables of interest for my research(economic stressors, opioid use, and multiple occupational health outcomes). The first wave ofthis data collection is complete with over 700 participants. I also have access to multipleadditional sources of survey data including other unpublished MTurk data sets, studies of retailemployees, nurses, and larger population surveys. To test these initial relationships, I willconduct Multiple Regression Analyses and Structural Equational Modeling as applicable to eachdataset. Having access to many existing and in-progress datasets will facilitate my short-termproductivity and provide me with experience so that I can collect my own data in the futureMy long-term goals are to continue expanding on economic stress and opioid use to linktheir relationship to organizational and occupational health outcomes. I would like to furtherexplore the workplace implications and potential interventions if opioid use is found to be acoping mechanism for managing both employment-related and financial economic stress. Mycurrent resources for data sets and collection will allow me to pursue my research interests andbecome a scholar in this area of this research.The NSF Graduate Research Fellowship will help me establish a program of work thatwill advance knowledge and have broader social impact. The proposed program of work willadvance knowledge by bridging gaps in the literature concerning the causal links amongeconomic stressors, opioid use, and work-related outcomes. In the long run, I hope to establish aprogram of multidisciplinary collaborative research connecting my work in appliedpsychology with scholarship in economics, public health, and business. Understanding theintricacies of the relationships between the variables of interest will have broader social impactas we will be able to identify potential antecedents of opioid use to create social ororganizational interventions. This knowledge will help organizations better understand how toaddress issues of economic stressors and opioid use and ultimately mitigate negativeoccupational health outcomes.REFERENCES: [1] Voydanoff, P. (1990). Journal of Marriage and the Family.[2] Probst, T. (2004). Sage Publications Inc. [3] Shoss, M. (2017). Journal of Management [4] Cheng, G. H.-L., & Chan, D. K. S.(2008). Applied Psychology: An International Review [5] De Witte, H., Pienaar, J., & De Cuyper, N. (2016). Australian Psychologist [6] Probst, T. M., Stewart, S. M., Gruys, M. L., & Tierney, B. W. (2007).Journal of Occupational and Organizational Psychology [7] Vijayasiri, G., Richman, J. A., & Rospenda, K. M. (2012). Addictive Behaviors [8] Lasalle, M., Chastang, J. F., & Niedhammer, I. (2015). Journal ofPsychiatric Research [9] Nagelhout, G. E., Hummel, K., de Goeij, M., de Vries, H., Kaner, E., & Lemmens, P. (2017). International Journal of Drug Policy [10] American Society of Addiction Medicine. (2016).[11] Heavey, S. C., Chang, Y., Vest, B. M., Collins, R. L., Wieczorek, W., & Homish, G. G. (2018). International Journal Of Drug Policy [12] Sarpatwari, A., Sinha, M., & Kesselhei, A. (2017). Harvard Law andPolicy Review [13] Shah, A., Hayes, C. J., & Martin, B. C. (2017). MMWR: Morbidity & Mortality Weekly Report [14] Rudd, R., Seth, P., David., F., & Scholl, L. (2016). MMWR: Morbidity & Mortality WeeklyReport, 65(50): 1445-1452. [15] Florence, C.S., Zhou, C., Luo, F., & Xu, L. (2016). Medical Care [16] Centers for Disease Control and Prevention (2014). [17] Zibbell, J. E., Asher, A. K., Patel, R. C., Kupronis,B., Iqbal, K., Ward, J. W., & Holtzman, D. (2018). American Journal of Public Health [18] van Hasselt, M., Keyes, V., Bray, J., & Miller, T. (2015) Journal of Workplace Behavioral Health. [19] Leana, C., & J.Meuris. (2015). The Academy of Management."
105.0,"Investigating morphological variation in SiphonophoresBackground & Proposal: Historically, Siphonophores have been mistaken for jellyfish due totheir transparent bodies, long tentacles, and stinging nematocysts [1], [2]. Like many othercnidarians (e.g., corals), Siphonophores are colonial animals and are made up of multiple animalbodies, calledzooids, which arise from the same embryoand function together as one organism.Within the Siphonophore, zooid types are arranged in a specific pattern, which is repeated acrossthe organism and determined at the growth zones of the Siphonophore [4]. Siphonophores have ahigh degree of functional specialization and precise organization within the colony, which setsthem apart from most other animal species [3]. Though Siphonophores are a diverse group, welack an understanding of how the organizational pattern of zooid type differs across species, andto what degree this morphological variation of patterns is conserved. Understanding theconservation of pattern type, will inform us of the functional specialization structures that areindicative of their survival. To answer these questions, I will use geometric morphometricmethods to compare differences among Siphonophore species. This approach builds on recentwork done in the Casey Dunn lab at Yale, draws directly from myexperience in Dr. DeanAdams’s lab,and is motivated by my own interest in complex trait evolution. Last year, theDunn lab published a transcriptome-based Siphonophore phylogeny and used it to reconstruct theevolutionary history of changes in Siphonophore sexual systems, life history traits, habitats, andzooid types. In their comparisons of zooid type, Munro et al. [1] used only the binarycharacterization of presence/absence of each zooid type, making this study void of any zooidorganizational pattern classification. Previous studies have also suggested that organizationalpatterns of zooid type are species-specific [5].These organizational patterns have never beenexamined from a phylogenetic perspective. I am interestedin extending the work done in Dr.Dunn’s lab by quantifying morphological variationof zooid types to determine their evolutionaryhistory and organizational pattern within the Siphonophore colony.Understanding the evolutionof zooid types is key to unraveling the mechanisms behind coloniality and functionalspecialization. Broadly, this study will improve our understanding of complex traits innon-model organisms from which we lack critical information about their basic biology. Theaim of my study is to determine the evolution of organizational patterns and variation ofzooid specialization in Siphonophores by applying novel methods to quantifythree-dimensional data.To quantify the morphologicalvariation of zooid type beyondpresence/absence descriptions, I will usemicro-computerized tomography (CT) scans tocharacterize organizational patterns. This project willanalyze traits of Siphonophores that is currentlynotunderstood within the scientific community.Methods:I will collect at least three specimens foreach of the 33 species analyzed in the phylogenyproduced by Munro et al [1] to quantify zooidmorphology. Specimens will be collected via bluewater SCUBA diving or remotely operated vehiclesfrom the Monterey Bay Aquarium Research Institute.Collected samples will be stored and preserved insolutions of formaldehyde, as standard procedure [6]. In the Dunn lab at Yale, I will stainsamples using osmium tetroxide to enhance thevisualization of body structures and then use themicro-computerized tomography scanner available on site to scan collected specimens. Using CTscans, I will obtain images of x-rays for every species. To quantify zooid structures from thesescans, I will develop a novel landmark scheme appropriate for use in Siphonophores and obtainthese data using the programAvizo™ (Fig. 1). I will then perform multivariate computationalanalysis for these landmarks using thegeomorph package[7] in R [8]. To test for correlationsbetween zooid morphology and phylogenetic history, I will perform a phylogenetic regressionfor Procrustes shape variables, which will identify patterns of zooid shape variation across theSiphonophore phylogeny. I will then determine the rate of evolution for zooid shape andorganizational pattern by performing morphological disparity tests. These results will indicatethe tempo and mode by which these morphological structures have evolved and the degree ofconservation across species.Feasibility: In the Dunn Lab, I will work with experts in evolutionary and Siphonophorebiology. At Yale, having access to the largest Siphonophore collection to date would allow me toassess all preserved specimens to incorporate into my research. My past research experience inpreparing and maintaining museum specimens, as well as operating and analyzing data from aCT scanner will allow me to successfully complete this project. In the Casey Dunn Lab, I willapply methods from my work with Dr. Dean Adams’s lab including geometric morphometrics,biostatistics, and phylogenetics to complete this project.Intellectual Merit: The collections from this study will illuminate our understanding of thediversity across the Siphonophore phylogeny. It will also aid in the development of newtechniques to maintain and preserve non-model specimens for theYale Peabody Museum. I willuse morphological data to reveal how Siphonophore phenotypes have dispersed throughout theirevolutionary history. Applying computational approaches to compare morphology has been anongoing limitation for research in evolutionary biology. This study will further develop theseapproaches by using a novel combination of techniques such as multivariate analyses and CTscanning. Major outcomes of this study will be the identification of species-specificorganizational patterns, as well as a greater understanding of phenotypic plasticity of zooid types.These results will inform biologists on the evolution of coloniality, functional specialization, andthe morphological specificity of zooids. All CT scans, specimens, and codes from these analyseswill be openly accessible to scientists via data sharing platforms.Broader Impacts: Throughout my dissertation, I willparticipate in public outreach and theeducation of young scholars in science by giving a series of presentations about my experienceas a scientist, research methods, and results at theYale Peabody Museum. At Yale, I will continueto participate in the Society for the Advancement of Chicanos/Hispanics and Native Americansin Science and begin working with Pathways to Science programs to help low-income,first-generation, and underrepresented students pursuing science. I plan to engage students inthese programs and the public by using the unique context of museums. I will work jointly withcurators to help build interactive exhibits by providing field video blogs, preserved specimens,and topics that expand upon the direct implications of my work into more generally societallyrelevant fields such as declining biodiversity and global climate change. Importantly, theseproposed exhibits not only give a diverse public face to scientists, but also use the museum tohelp spark scientific curiosity in the public.References:1) Munro et al.Molecular Phylogeneticsand Evolution127(2018):823-833. 2) Cooke et alClinicalToxicology3(1970):589-595. 3) Mackie, G.O.LowerMetazoa(1963)329-337. 4) Goetz FE.Nanomia bijugawholeanimal and growth zones from http://commons.wikimedia.org/wiki (2018). 5) Dunn, C.W., Wagner, G.P.,DevGenes Evol216(2006):743-754 6) Holst et al.Journalof Plankton Research38(2016):1225-1242. 7) Adams et al.Geomorph(2018) R package version 3.0.6 8) R CoreTeamR(2013)."
106.0,"Rationale: Coral reefs provide services totaling $10 trillion despite covering only ~0.3% of theocean floor1. Their evolutionary success relies on the association between coral animals andsymbiotic algae. Corals provide shelter and nutrients for symbionts which in turn supply sugarsand O to their hosts2. Corals host symbionts within the symbiosome, an intracellular space2defined by the coral-derived symbiosome membrane. This membrane is thought to allow coralsto regulate delivery of nutrients to the symbiont but the specific transport mechanisms are mostlyunknown. Alarmingly, human-caused ocean warming, acidification, and eutrophication disruptthis symbiosis leading to the expulsion of symbionts (known as ‘bleaching’), decreased coralfitness, and death2. However, the lack of mechanistic knowledge of healthy symbiosis impairsour ability to understand why bleaching occurs, identify resilient and vulnerable species, anddesign conservation strategies. The mechanisms that deliver nitrogenous molecules (N ) tomsymbionts are particularly important. Healthy corals must provide symbionts with enough N formthe repair of photosystem proteins and other basic functions; however, excess N could result inmsymbiont overgrowth and bleaching2. Thus, corals must possess yet unidentified mechanisms toregulate N delivery to symbionts.mI propose to study the mechanisms controlling N delivery to symbionts and tomcharacterize responses to environmental stress in two coral species with differential susceptibilityto eutrophication. In other animal models, NH moves across membranes via Rhesus channels3(Rh). When paired with an acidification pathway, NH gas combines with H+ to form NH + that3 4is trapped on the other side of a membrane3. Coral Rh is an ideal candidate for transporting NH3across the symbiosome membrane for N delivery for three reasons: (1) an “Rh-like” gene ismupregulated in anemones upon symbiont acquisition4, (2) corals acidify the symbiosome usingV-H+-ATPases, which would favor NH + trapping in the symbiosome5, and (3) NH + is4 4symbionts’ preferred N source6. I hypothesize that (1) corals supply N to symbionts via Rh inm mthe symbiosome membrane, (2) N supply is controlled via transcriptional and translational Rhmregulation and changes in Rh localization, and (3) future ocean conditions can bypass the Rhpathway resulting in bleaching. Preliminary Results: I cloned the first coral Rh from Acroporayongei (ayRh) (MH025799), developed anti-ayRh antibodies, and confirmed ayRh proteinexpression via Western Blots. I found that ayRh is more abundant in the symbiosome membraneduring daytime compared to the night via immunofluorescence microscopy (IFM) (Fig 1).Aim 1: Establish ayRh Transport and Function. In vitro: Iwill express recombinant ayRh in Xenopus oocytes andmeasure its transport kinetics. Oocytes injected with ayRhcRNA or scrambled cRNA (controls) will be incubated withthe radiolabeled NH /NH + analog [14C]methylammonium,3 4and uptake rates will be measured with a gamma counter.Since some vertebrate Rhs can also transport CO 7, I will2determine ayRh CO permeability by measuring CO -induced2 2changes in oocyte pH with the pH-sensitive dye SNARF1. Iwill run statistics in R and Prism™. I predict that ayRh isNH - and not CO -permeable, supporting my hypothesis of3 2Figure 1. Diel Rh localization to the Rh-mediated N m delivery. If ayRh transports both, I willSM (n = 50) (p = 0.0246*). adjust my hypothesis and explore the role of Rh in providingcarbon and N for symbiont photosynthesis and metabolism. In vivo: I will explore themcorrelation between Rh abundance and N transport rate in isolated coral cells hostingmsymbionts5. I will measure Rh abundance by Western Blot and NH + uptake rates from seawater4using spectrophotometry. I predict a direct relationship between Rh abundance and capacity forN transport. All materials are already available in my collaborating and host labs.mAim 2: Characterize Coral Rh Regulation. I will expand on my preliminary results (Fig.1) toidentify mechanisms that regulate Rh abundance in the symbiosome membrane. In addition to A.yongei, I will work with Stylophora pistillata, which is more resilient to N eutrophication8. Thismcomparative approach may unveil species-specific mechanisms that confer resilience in pollutedoceans. Transcriptional and translational Rh regulation will be tested using qPCR and Westernblotting in coral samples taken during day and night timepoints. Rh’s subcellular localization anddynamics will be assessed in unprecedented detail via IFM on a super-resolution confocalmicroscope. Building on preliminary experiments, I will sample every three hours over a two-day period. Furthermore, I will use the highly specific photosynthesis inhibitor DCMU todetermine if the presence of Rh in the symbiosome membrane depends on photosyntheticactivity or simply on the presence of light2. I will automate IFM data collection and quantitativeanalysis with ZENTM software; I will use my coding experience to create custom workflows toachieve high throughput and bias reduction during analysis. I will run statistics in R andPrism™. I predict the Rh pathway is present in both coral species, that Rh trafficking to andaway from the symbiosome membrane depends on photosynthetic activity, and that Rh mRNAand protein abundance will remain relatively constant reflecting basal turnover rates.Aim 3: Establish Rh Responses to Stress. To determine the effects of future ocean conditionson Rh, I will grow A. yongei and S. pistillata in three conditions: (1) control, (2) elevated N (10mμM NH Cl), and (3) elevated N and CO (10 μM NH Cl, 1000 μatm CO ). I will collect4 m 2 4 2samples at 12:00 and 24:00 daily over a 70-day period (10 days of control, 30 days of treatment,and 30 days of recovery in control conditions) and rapidly analyze Rh expression and subcellularlocalization as described above; this method will also allow me to quantify symbiont density toestimate bleaching. Additionally, I will study symbionts’ photobiology using respirometry andPAM fluorometry and genotype symbionts to explore potential effects of symbiont strain. I willrun statistics in R and Prism™. I predict the Rh pathway will be initially downregulated in bothexperimental treatments. I also predict that corals in elevated N and CO conditions willm 2undergo the highest degree of bleaching due to larger loss of host control over symbiont growth;these effects will be more pronounced in eutrophication-sensitive A. yongei. Finally, I predict theRh pathway will gradually return to normal during recovery and reestablishment of symbiosis.Intellectual Merit/Broader impacts: This study will characterize a novel N transportmmechanism in coral symbioses and develop much-needed biomarkers to evaluate species-specificvulnerability to environmental stress and early detection of bleaching. It also has the potential toreshape our understanding of coral symbioses by establishing a novel diel regulatory mechanismthat traffics proteins to and from the symbiosome membrane. I am well qualified to conduct thisresearch based on my experience with IFM, molecular biology, coral biology, and computerscience. In my PhD, I will continue to mentor undergraduates through my tutoring program,many of whom are Latina females, and I will expand my program to low income high schools.Results from my project will be presented to the scientific community through peer-reviewedpapers and conferences, and to the general public in youth activities, lectures, and exhibitsthrough Sally Ride Science and the Birch Aquarium (which hosts 450k visitors annually). Mycareer goal is to be an R1 professor and these activities will shape my future outreach andeducation programs. References: (1) Global Environ Change 2014, 26, 152-158. (2) Microbiol Mol Biol R,2012, 76, 229-261. (3) Transfus Clin Biol 2006, 13, 85-94. (4) G3-Genes Genom Genet 2014, 4, 277-295. (5) PNAS2015, 112, 607-612. (6) Mar Biol 1983, 167, 157-167. (7) Membranes 2017, 7, 61. (8) Mar Biol 2000, 19, 103-113."
107.0,"The Magnetic Origins of Solar Coronal PlumesSun: corona — Sun: magnetic fields —Sun: UV radiationI. IntroductionThe corona is a diffuse cloud of plasma that surrounds the Sun that is ~104 times hotter​​than the photosphere at the surface of the Sun. The mechanism for coronal heating is one of themost sought after solutions in solar physics, as it could explain the origin of the solar wind, astream of charged particles that bombards Earth and other planets. In order to determine asolution to the coronal heating problem, solar physicists study structures that arise in the coronaas a consequence of the ever-changing solar magnetic field, like coronal plumes. Plumes aresporadic, fountain-like structures that are rooted in a strong patch of dominant-polarityphotospheric magnetic flux, surrounded by a predominantly-unipolar magnetic field. Plumes arelocated in the least active regions in the solar corona: in either coronal holes or in quiet regions.Studying the formation of plumes could shed light on how the corona is heated, as theremay be a fundamental mechanism that heats plumes that may be the same in other coronalstructures. Several observations have been presented regarding how plumes form and disappear,but none have succeeded in determining the mechanism that generates plumes.In the Summer of 2017, to further investigate plume evolution, I tracked the lifetimes ofsix coronal plumes, three in quiet regions and three in coronal holes using SDO/AtmosphericImaging Assembly (AIA) 171 Å images and SDO/Helioseismic and Magnetic Imager (HMI)magnetograms with Dr. Sanjiv Tiwari at an NSF REU program at the University of Alabama inHuntsville and NASA Marshall Spaceflight Center. We based our study on two previous studies,one by Raouafi et al.1 and Wang et al.3. Raouafi et al.1 infer from observation that plume heating​ ​ ​​ ​ ​is a consequence of magnetic reconnection at the base, whereas Wang et al.3 observe that plume​​heating is a result of convergence of the base magnetic flux. Both papers suggest that the baseflux in their plumes is of mixed polarity, most of which is unobservable due to the spatialresolution of current instruments. Raouafi et al. and Wang et al. both suggest that this is theprimary mechanism responsible for sustaining plume heating, and do not consider othercontributing factors. I specifically investigated whether or not a critical magnetic field strength is​necessary for plume production, and determined from that a critical field strength of 250-500Gauss, along with base flux convergence and divergence, is necessary for plume formation.While these preliminary results were extremely promising, indicating that a critical field strengthmay be necessary for plume production, further work needs to be done in order to confirm them.II. Specific AimsAs a graduate student, I will extend this study to include coordinated high-resolutionspectroscopic data from the Interface Region Imaging Spectrograph (IRIS) and the ExtremeUltraviolet Imaging Spectrometer (EIS) on the Hinode spacecraft in conjunction with SDO/AIAand SDO/HMI data. We will also extend our SDO/AIA observations to include those in 193 Å,211 Å, and 304 Å emission. This increased emission coverage will allow us to observe plumesfrom the upper layers of the corona down to the chromosphere, the region between the surface ofthe sun and the corona where smaller-scale jet eruptions occur. Including spectroscopic data willallow us to further investigate smaller-scale jet eruptions in the chromosphere and transitionregion by observing cooler emission lines, and will allow me to create dopplergrams, whichshow the redshift and blueshift of spectral lines, in order to observe how flow patterns evolvethroughout each plume’s lifetime. In order to determine a solution to the problem of underlyingmixed polarity, we plan to propose observations to the Daniel K. Inouye Solar Telescope(DKIST) when it comes online in 2019. As the largest solar telescope in history, the increasedspatial resolution of DKIST will allow us to resolve regions as small as ~20 km2, thus giving us​​the opportunity to observe minute emergence of opposite-polarity regions. To ensure that anyconclusions of this study are statistically significant, we will expand our dataset to include alarger sample of 100 coronal plumes, 50 in quiet regions and 50 in coronal holes.III. Preparation and Relation to Career GoalsThis project allows me to continue my already fulfilling work on coronal plumes with Dr.Tiwari, who has since moved to working at the Lockheed Martin Solar and Astrophysics Lab(LMSAL) in Palo Alto. Stanford is an ideal setting at which to conduct this research, as its closeaffiliation with LMSAL would allow me to continue working with Dr. Tiwari, as well ascollaborate with other solar physicists at LMSAL. Extending this project to includespectroscopic data and ground-based telescope observations would give me the skills to conductmore comprehensive observations of the solar corona, and increasing my previous study’ssample size would give me the statistical and computational skills I need to conduct further,more rigorous studies on larger datasets. This fellowship would give me the freedom to focus onobtaining a conclusive result, thus bringing me another step closer to a career in solar physicsresearch, education, and outreach.IV. Broader ImpactsWith DKIST beginning operations in 2019, and the Parker Solar Probe, a mission tocollect in-situ data on the corona, planned to launch in 2018, a wealth of data will soon beavailable for scientists to learn more about our nearest star. For most of my undergraduate career,I was unaware that there were so many unanswered questions about our nearest star. During mytime as a graduate student, I look forward to involving younger students in this research in orderto help the field of solar physics gain more exposure among young scientists. I have beeninspired by the Pre-Major in Astronomy Program in place at the University of Washington,which is a mentorship program aimed at involving underrepresented undergraduate students inresearch early in their careers. I hope to do similar work by mentoring high school students in thegreater Bay Area through Stanford’s Science in Service program.V. References1Raouafi, N.-E., & Stenborg, G. 2014, ApJ, 787:118 — 2Tritschler, A., Rimmele, T. R.,​ ​​Berukoff, S., et al. 2016, Astronomische Nachrichten, 337, 1064 — 3Wang, Y.-M., Warren, H.​​P., & Muglach, K. 2016, ApJ, 818:203"
108.0,"The nature of dark energy is one of the biggest mysteries in physics and astronomy today.To quote Michael Turner, dark energy is “a problem for the 22nd century discovered by accidentin the 20th century.” The Dark Energy Spectroscopic Instrument (DESI) is a massive next-generation survey that will attempt to constrain the dark energy equation of state. DESI willmeasure the spectra of over 30 million galaxies and determine their redshift. These redshifts,combined with measurements of Type Ia supernovae (SNe Ia), provide the strongestmeasurements of cosmological distances, our way of knowing the expansion rate of the universe.DESI offers the potential to spectroscopically observe ~105 supernovae (SNe) includingmany SNe Ia [1]. Interestingly, while SNe Ia are used as standard candles, their origins are notfully understood. Evidence exists for two types of progenitors: a degenerate white dwarfaccreting matter from a giant companion star, or two coalescing white dwarfs [2]. Identifying alarge population of SNe Ia will help answer the progenitor question and provide constraints ondark energy. My background in handling large astrophysical datasets (see: Personal Statement)has prepared me make valuable contributions in this area. I propose to develop an efficientcomputational procedure to identify SNe Ia in the DESI survey.In order to obtain accurate, unbiased distance measurements from SNe Ia, spectroscopicmeasurements are crucial in calibrating corresponding photometric observations. In particular,DESI will be able to spectroscopically complement future large-sky surveys such as the LargeSynoptic Sky Telescope (LSST), which will begin its science observing in 2021 but collectimmensely more data (expected ~1 million transient alerts per night with ~1 million SNIaobserved over a decade [2]), and the Zwicky Transient Factory. In doing so, we can understandjust how “standard” these standard candles are and provide complementary redshift coverage.Further, it is to our advantage to identify SNe Ia in real-time and send out alerts for followupobservations. Moving forward, generalized data-analysis pipelines that are able to handleenormous quantities of data will be fundamental to the success of future experiments.I propose the following analysis and timeline to develop such a computational procedure:1. (year 1) Identify SNe Ia in galactic spectra. 2. (years 2-4) Extend the identification algorithmto detect and classify galactic spectral anomalies (outliers) in general. 3. (final year) Develop anautomated pipeline that will run in real time to identify transients.In step 1. I will focus on identifying SNe Ia in the DESI catalog. This will requireconstruction of spectroscopic models of galaxies and applying a statistical test to a large sampleof galaxy spectra to look for deviations from the model expectations. Spectra with significantdeviations (anomalies) will be tested further by fitting a SN Ia spectral template to see if theanomaly is in fact a supernova.I propose to develop several complementary tests to identify SNe Ia spectra.Previous studies have searched for SNe Ia in the Sloan Digital Sky Survey (SDSS) catalog usingsingular-value-decomposition of a large sample of galaxy spectra to construct a basis ofeigenspectra. The eigenbasis is used to fit galaxy spectra, and the residual spectrum is searchedfor features corresponding to a SNe Ia (note that the model in this case, i.e. the individualeigenspectra, does not represent a physical object - only the linear combination has a physicalinterpretation). Using this method, Graur & Maoz [3] report 90 SNe Ia in SDSS data release 7.A first alternative approach involves constructing a χ2 statistic (or likelihood test) of SNeIa templates with the observed spectra, defining anomalies based on the χ2 goodness of fit. TheRyan Rubenzahl NSF Research Proposal University of Rochesteradvantage is that no unphysical basis is being used. As a sanity check, I will cross-correlate mysample of SNe Ia with those found in previous studies [3]. With this sample, I will calculate anestimate of the SNe Ia rate to help answer the progenitor question and make first-order distanceestimates using SNe Ia redshifts to build a framework for future photometric calibrations.While useful for cosmology, this method should be capable of identifying more than justSNe. In step 2. I will generalize this procedure to allow the classification to include any numberof other astrophysically interesting phenomena. As a first step, this will involve adding templatesfor each source of interest, for example a two-galaxy-spectrum model to represent sources ofstrong gravitational lensing, which offer excellent tests of the general theory of relativity. Oncethe algorithm is efficient at detecting several different classes of objects, I will drop all a prioriassumptions. In this case, the proposed algorithm will be general and unassuming of anyparticular class of object, allowing the potential of discovering new phenomena. A successfulalgorithm will also identify bad spectra either due to instrumental issues or other errors, learnwhat those patterns look like, and avoid or even correct for them in the future. At this stage, aplethora of astrophysical phenomena beyond just SNe may be observed and studied.Previous studies have tried general approaches to anomaly detection using predictivelearning algorithms such as a random forest (decision tree), and have even found larger yieldsthan targeted identification algorithms [4, 5]. I will study these approaches and develop amachine-learning algorithm to classify spectroscopic anomalies with DESI. I will work to boostthe efficiency as well as the yield of outlier spectra while minimizing false-positives. In step 3. Iwill maximize the efficiency of the algorithm so that it can be used in real-time in a pipeline.These approaches will each be tested and trained on existing spectroscopic data obtainedby SDSS. I will also test simulated spectra generated for DESI. Simulated data in particular willgive an estimate of the classification purity of the pipeline for the various phenomena we areaiming to observe. Once DESI is online, the learning algorithm will be applied to the real data,being continuously trained as the dataset grows.An integral part of my work on this project will be engaging the public in activeparticipation. The citizen-science project Galaxy Zoo Supernovae demonstrated that members ofthe general public are remarkably good transient-spotters: 93% of supernovae were correctlyidentified by the public with no false-positives [6]. I will make the results of my pipeline,including sample data, available to existing citizen-science platforms which have a proventrack record of engagement and popularity with the public. Participants will enjoy hands-oninvolvement in the data analysis alongside lessons detailing the qualitative astrophysics ofsupernovae and how their signature can be seen in galaxy spectra through the heavy elementsproduced in the explosion. The data collected by citizen scientists can support actual results byproviding confirmation or rejection of suspected outlier spectra. My findings, combined with thecitizen-science results, will lead beyond DESI and into future LSST analysis and other data-intensive astronomy projects.References[1] DESI Collaboration, 2016, Final Design Report I [4] Baron & Poznanski, 2017, MNRAS, 465, 4530[2] Maoz & Mannucci, 2012, PASA, 29, 447 [5] Buisson et al., 2015, MNRAS, 454, 2026[3] Graur & Maoz, 2013, MNRAS, 430, 1746 [6] Smith et al., 2011, MNRAS, 412, 1309"
109.0,"Key Terms: mechanotransduction, micropipettes, chemotaxis, phagocytosis, β integrin2Introduction: Future medical innovation will require a detailed knowledge of the causalsequences of events in biological processes. Currently, much of the understanding of theseprocesses comes from correlative studies, whereas cause-effect relationships are less oftenexplored. For instance, in immune cells, several signaling pathways are associated with dramatic,global bursts in cytosolic calcium concentration, but it remains unclear which pathways triggerthe calcium burst and which depend on it. In human neutrophils, these bursts are correlated withseveral mechanically demanding processes, including β -integrin-mediated cell arrest1, the onset2of active cell spreading on immobilized IL-82, and the acceleration of β -integrin-mediated2phagocytosis3. On the other hand, my prior work in the Heinrich Lab has shown that pure (i.e.adhesion-free) complement-mediated chemotaxis neither causes nor requires such global calciumsurges4 (see Fig. 1B). We further demonstrated that unphysiologically high levels ofchemoattractant can cause calcium bursts, but contractile forces stalled or even reversedpseudopod formation in such cases. These findings imply a close connection between calciumbursts and mechanical behavior. The purpose of this project is to examine the cause-effectrelationship between changes in cytosolic calcium concentration and mechanical responsesof human neutrophils to chemotactic and phagocytic stimuli on a single-cell basis.Background: Store-operated calcium entry (SOCE) is considered the dominant mechanism forcalcium bursts in human neutrophils. In this paradigm, ligation of certain receptors, such as G-protein coupled receptors (GPCRs), triggers a signaling cascade that leads to the depletion ofintracellular calcium stores (usually via IP production). This prompts a calcium influx from the3extracellular space through channels such as Orai1. However, our own findings and severalearlier studies indicate that this view of SOCE is incomplete, as GPCR ligation can causechemotaxis without triggering a calcium burst4,5. Furthermore, shear force on high-affinity β -2integrins is known to mediate calcium influx1, which implies that mechanotransduction isimportant for SOCE in neutrophils. It also remains largely unclear which cellular activitiesdepend upon the elevated calcium levels afterstore release and calcium influx. Calcium burstsoften precede F-actin-mediated spreading1-3, butthis connection is not fully understood.I hypothesize that β -integrin-mediated2mechanotransduction is key to inducing aglobal calcium signal in human neutrophils,which controls a mechanistic switch betweentwo distinct modes of cytoskeletalorganization and dynamics. I will primarilyuse single-cell, single-target micropipetteexperiments (Fig. 1A) to quantify aspects of themechanical response (e.g. cell morphology,cortical tension, or surface area) whilemonitoring intracellular calcium concentrationusing a calcium-sensitive dye (e.g. Fluo-4 orFura-2). This will be supplemented by data fromFig 1. A: Experimental setup. B: Neutrophilother biophysical experiments, as well asshows a calcium burst during phagocytosis, butmathematical modeling. not during pure chemotaxis4.Aim 1. Uncover specific mechanical or biochemical cues that are necessary and/orsufficient to induce calcium bursts. Before micropipette experiments, human neutrophils willbe treated with an actomyosin inhibitor (e.g. latrunculin A, cytochalasin D, blebbistatin) or a β -2integrin (LFA-1 or Mac-1) blocking antibody. Our analysis of the calcium response will revealthe roles of the respective molecules in calcium burst induction. I will also use reflectioninterference contrast microscopy (RICM) to measure the contact areas of neutrophils spreadingon glass with a known ligand density, determining if a threshold of engaged receptors can triggera calcium burst. Application of a measurable force on β integrins on a neutrophil using atomic2force microscopy (AFM) will allow me to explore whether force can directly stimulate a calciumburst or if there is a synergistic effect between force and number of integrins engaged.Aim 2. Characterize the mechanical and morphological changes that require calcium storerelease and/or calcium influx. I will conduct micropipette experiments after depletingextracellular calcium with EGTA or emptying internal calcium stores with thapsigargin. Insimilar experiments, I will block IP -dependent store release using a PLC inhibitor (U73122), or3use murine neutrophils with a deficient calcium influx (Orai1+/- or Orai1-/-, collaboration with Dr.Scott Simon, BME Dept.). These experiments will indicate the relative importance of calciumstore release and calcium influx for mechanical changes such as elevated cortical tension orsurface area expansion. I will also collaborate with Dr. Soichiro Yamada (BME Dept.), usingconfocal microscopy to simultaneously image actin arrangement and calcium concentration in aneutrophil-like cell line (PLB-985) transfected with GFP-actin and loaded with Fluo-4. I willassess actin structure and dynamics following calcium bursts in these cells.Aim 3. Incorporate global calcium signaling into an established computational model ofneutrophil phagocytosis. I will collaborate with Dr. Samuel Walcott (Math Dept.) to build onthe computational model developed by Herant et al.6, which accurately describes the phagocyticbehavior of neutrophils. The model predicts a key role for cytoskeletal membrane anchors,connections that form between integrins and F-actin via adaptor proteins. The assembly of thesecomplexes is associated with elevated calcium levels1,3. I will incorporate the calcium-dependence of cytoskeletal membrane anchor strength into the model and leverage this revisedmodel against the phagocytic behavior of neutrophils in the above experiments.Intellectual Merit: My three years of experience with micropipette experiments and quantitativedata analysis have prepared me well for this important work. This project will fill a fundamentalknowledge gap regarding one of the most dramatic signaling events in the life of a neutrophil. Inaddition, clarifying the sequence of molecular events leading from receptor engagement tocalcium burst to protrusive force generation may elucidate similar mechanisms in other cells.Broader Impacts: An improved quantitative and mechanistic understanding of immune cellswill strengthen the foundational knowledge for novel medical treatments such asimmunotherapy. With an understanding of the cause-effect relationship between calciumsignaling and immune cell motility, new therapeutic targets for immunodeficiencies andautoimmune diseases could also be identified. Furthermore, because calcium bursts are easilydetectible and are strong indicators of immune cell activation, my research may inform thedevelopment of future diagnostic tools. I will include undergraduate students in this project,share findings in publications and at international conferences, and inform the public by creatingand sharing videos online (www.youtube.com/heinrichlab).References: [1] Dixit, N. et al. (2011) J Immunol. 187(1):472-481 [2] Beste, M.T. et al. (2015) Ann Biomed Eng.43(9):2207-2219 [3] Dewitt, S. and M.B. Hallett (2002) J Cell Biol. 159(1):181-189 [4] Francis, E. and V. Heinrich(2017) Revision under review. [5] Laffafian, I. and M.B. Hallett (1995) J Cell Sci. 108(10):3199-3205 [6] Herant,M. et al. (2011) PLoS Comput Biol. 7(1):e1001068"
110.0,"Development of a pressure-sensitive kinetic blood-brain-barrier Aβ clearance modelIntroduction: Alzheimer’s disease (AD) is a chronic neurodegenerative disease and themain cause of dementia worldwide. Recently discovered, the glymphatic system is a wasteclearance pathway that exchanges the central nervous system (CNS)’s fluids which has beenshown to be one of the main facilitators of the clearance of beta-amyloid (Aβ), one of the hallmarkpathology of Alzheimer's disease (AD).1,2 This system carries the soluble Aβ peptide to bedischarged through the blood-brain barrier (BBB) by specialized transporters and has been shownto become impaired in ageing, leading to its toxic accumulation in the brain.3 Furthermore, AD isoften implicated with cardiovascular alterations affecting blood pressure and though theirtreatment has been correlated with reduced incidence of AD and slower cognitive declines in ADpatients, their mechanistic relationship remains unclear.4 Although, Aβ clearance has been mainlycharacterized in vivo in animal models, they also involve the interplay of other cellular andenzymatic clearance mechanisms.4 Thus, a validated dynamic in vitro model would provide aplatform to quantify and predict the yet unexplored effects of abnormal blood and cranial pressuresin the BBB’s clearance of Aβ which are critical to advance our understanding of how one of themost prevalent vascular changes correlated with AD, affects the main clearance gate protecting usfrom it. The objective of this proposed research is to build a mathematical model from thekinetic characterization of pressure effects in the transport of Aβ through a microfluidicblood-brain-barrier device to predict the effects of pathologic changes in cerebral perfusionpressure in the clearance of Aβ from the brain.Approach: The proposed project will execute the following aims: (1) to adapt and validatecurrent microfluidic BBB technology for this project, (2) to experimentally characterize the invitro BBB’s Aβ kinetic transport as a function of protein load and pressures, and (3) to develop amathematic model of the Aβ efflux across the brain in health and in disease.Aim 1: Microfluidic models have recently succeeded inrecreating and mimicking the selective boundary properties of theBBB; one example includes the NeuroVascular Unit (NVU) modeldeveloped at Vanderbilt University by Dr. Wikswo’s lab (Fig. 1),involving two distinct chambers representing the blood and thebrain sides, separated by a three-dimensional and sequential cultureof an immortalized line of the human neurovascular cells buildingthe structure of a complete BBB.5 Our device will build upon thismodel to allow for the controlled monitoring of pressure and flow Fig. 1: Wikswo’s lab blood-rates while applying its ability to recreate the human BBB’s brain-barrier-on-a-chip device.5heterogeneity and structural complexity. Firstly, the devise will be equipped with loading portvalves, a variable pulsatile pump to mimic vascular perfusion pressure and a syringe pump tomaintain an accurate pressure and simulate glymphatic flow on the brain chamber. The boundary’sintegrity under these dynamic conditions will be validated via transendothelial electrical resistancemeasurements (TEER) or alternatively via fluorescent microscopy to confirm proper endothelialtight junctions. Thereafter, pH, temperature, viscosity, and salt content on both compartment fluidswill be matched to their human physiologic conditions, as protein behavior is sensitive to thesefactors.Aim 2: Commercially-available Aβ and Aβ peptides, will be infused at different1-40 1-42concentrations separately on the brain compartment, at different pressures under physiologic meanblood and glymphatic system flow rates to measure the BBB’s transport rates at which Aβ leavesthe brain compartment. Right after running through the devise the solution will be sampled andSergio Rodriguez Labra | Research StatementAβ measured by ELISA. After multiple trials, a differential mass balance on the two compartmentswill be used to calculate two diffusive rate constants, one for the Aβ going from the brain to theblood side, and a reverse rate to account for potential Aβ reuptake into the brain compartment,allowing for the overall rate of Aβ transport to be calculated for different Aβ concentrations andpressures. To validate the physiologic operation of both of the known Aβ transporters, LRP1 andRAGE, in the cells, their commercially-available natural ligands will be similarly run as a control,comparing their transport rates to their physiologic literature values.6Aim 3: Using the calculated Aβ transport rates, statisticson R will be used to confirm the data’s power and a mathematicmodel on MATLAB will be built to describe the Aβ efflux as afunction of Aβ concentration and the pressures across bothchambers, thus, quantitatively correlating the relationshipbetween Aβ transport at different healthy and pathologic peptideburdens in the human brain, and under physiologic and abnormalpressures on both sides of the BBB. The developed model will bevalidated testing its predictions on the quantitative change in Aβ Fig. 2: Possible effects of pressureaccumulation in the microfluidic device after sudden or chronic in A clearance for a fixed A load.pressure changes likely to be produced by stroke, traumatic brain injuries, and cardiovasculardiseases. This will produce a predictive computational model of the decrease in BBB-mediated Aβclearance with ageing and disease.Broader Impact: The development of a mathematical model focused on cranial and bloodpressure will allow for the estimation of Aβ accumulation in the brain due to reduced BBBclearance and predict the increased risk to acquire AD after people develop hypertension,hypotension, stroke, or traumatic brain injuries, when it is much easier to take preventative andtherapeutic measures than trying to arrest an evolved AD later on. Furthermore, by consideringAβ concentrations, this adaptable predictive model will be able to incorporate future Aβbiomarkers’ data for personalized medicine diagnostics using the patient’s own biometrics.Finally, the improved microfluidic device will serve as a platform for characterizing the effects ofabnormal blood pressures in the arterial pulse-driven glymphatic system, thus, describing itssynergistic dysfunction in disease, and for studies describing the pharmacodynamics of brain-penetrant drugs in altered vascular perfusion or cranial pressure conditions.Studying the link of the discussed highly prevalent clinical conditions has importantrepercussions in everyone’s everyday lifestyle decisions. To generate awareness, I will use mycontinued participation at the Society of Hispanic Professional Engineer’s national conferencesand the blog I will manage during grad school to present and break down the significance of myfindings to the general public, inspiring them to pursue similar projects in STEM.1 Nedergaard, Maiken. ""Garbage truck of the brain."" Science 340.6140 (2013): 1529-1530.2 Tarasoff-Conway, Jenna M., et al. ""Clearance systems in the brain - implications for Alzheimer disease."" NatureReviews Neurology 11.8 (2015): 457-470.3 Kress, Benjamin T., et al. ""Impairment of paravascular clearance pathways in the aging brain."" Annals ofneurology 76.6 (2014): 845-861.4 Hamel, Edith, et al. “Neurovascular and cognitive failure in Alzheimer’s disease: benefits of cardiovasculartherapy.” Cellular and molecular neurobiology 36.2 (2016): 219-2325 Brown, Jacquelyn A., et al. ""Recreating blood-brain barrier physiology and structure on chip: A novelneurovascular microfluidic bioreactor."" Biomicrofluidics 9.5 (2015): 054124.6 Deane, R., et al. “Clearance of amyloid- peptide across the blood-brain barrier: implication for therapies inAlzheimer’s disease”. CNS & Neurological Disorders-Drug Targets 8.1 (2009): 16-30"
111.0,"Zack MorrowIntroduction and Previous WorkAt the molecular level, density functional theory (DFT) describes the electronic stateof a system through functionals, which are mappings whose domain is a function space [1].Existing chemistry software packages (e.g., Gaussian) use DFT to provide evaluations ofa potential energy surface (PES) at molecular coordinate locations. In order to drivesimulations of molecular dynamics, one needs potential energy in order to solve for thereaction path. However, the evaluation of the true PES at the internal coordinates is fartoo expensive to carry on a dense grid over the full domain.Sparse grids provide a means to keep the computational cost in check. We computeand store evaluations of the true PES only at the sparse points. We then build a sparseinterpolating polynomial of the PES as a surrogate, which we evaluate on the full grid overthe domain. The evaluations of the interpolant are significantly less expensive than theevaluations of the true PES; the main expense occurs in evaluating the true PES at thesparse interpolation points, which is done at the front end and stored for later use.Previous work in our group by James Nance investigated the Smolyak construction ofsparse grids and its application to molecular dynamics and surface-hopping problems [2,3]. Nance worked in collaboration with the research group of Prof. Elena Jakubikova inNC State’s Department of Chemistry, our current collaborators. The sparse grid code thatJakubikova’s group utilizes today is the code written by Nance as part of his thesis.Proposal: Intellectual MeritNature tends to an energy-minimizing state, and accordingly, stable molecular geome-triescorrespondtolocalminimaofthepotentialenergysurface(PES).Inordertoconstructthe PES itself, we first take q to be a fixed geometry and find the electron energy levels Eiby solving (e.g., with Gaussian) the time-independent Schr¨odinger equation, a well-knownquantum mechanical relationship encoding the energy of a system:Hˆ Ψq = E Ψq, i ∈ {0,1,2,...}. (1)i i iˆHere, H is the molecular Hamiltonian operator (connected to the total energy of the sys-tem), the eigenvalue E is the energy of electronic state i under geometry q, and Ψq is thei iwavefunction corresponding to E (connected to the probability that a given electron in aimolecule under geometry q has energy E ).iNow, as a function of all admissible geometries q, we denote E (q) to be the PESicorresponding to energy state i. Again, stable molecular geometries correspond to localminima on the PES; moreover, transitions of a molecule from energy state i + 1 to statei occur when the molecular geometry corresponds to a local minimum on E (q). Thei+1reaction path to an energy-minimizing configuration is the solution toq˙ = −∇E (q), (2)iwhich, pictorially, is the path of steepest descent on the PES from the initial geometry to alocal minimum. Using Equation (2), we can simulate numerically how molecular geometryevolves in time after excitation to higher energy states and subsequent relaxation.Since the true PES E (q) is far too expensive to compute on the full grid, we generate aiset of sparse grid points and utilize the sparse interpolating polynomial Es(q) as a surrogateifor the true PES in our simulations. Currently, we use a MATLAB code to manage thegeneration and evaluation of the sparse interpolant Es(q), and the dynamical simulationiroutines run on university desktops and laptops. However, the simulation code will soonbe migrating to the XSEDE platform, a geographically distributed computing cluster onwhich it is infeasible to use MATLAB. We are therefore replacing the MATLAB sparse-gridmanager with an open-source C++ sparse-grid manager called Tasmanian, developed atOak Ridge National Laboratory, which additionally comes with a Python wrapper [5].I have replicated previous PES results using the new Tasmanian package and am cur-rently working to integrate it fully into our dynamical simulation codes. One difficultyto resolve is that Tasmanian currently does not compute gradients internally—a problemwhen using Es(q) in Equation (2). To boost accuracy and exploit parallelizability, gradi-ients are best evaluated inside the sparse-grid manager itself. I will spend next summerat Oak Ridge working to add gradient-computation routines to the Tasmanian package,which must meet rigorous Department of Energy software standards. In the meantime, Iam familiarizing myself with the high-performance computing environment at NC State,in addition to becoming as comfortable with C++ as I am with Python and MATLAB.Beyond next summer, I will very likely need to refine the gradient routines, and I will alsocontinue my literature review on quantum chemistry and the analysis of sparse grids.Proposal: Broader ImpactsSparse grids as a general category have ready applications in any field where compu-tational cost is a major concern. In the realm of chemistry, computationally tractablemethods of handling high-dimensional DFT-driven dynamical simulations have a wide ar-ray of benefits to society, including public health, renewable energy, and national security.The research I propose to undertake can advance the state of the art of simulations inpharmacological modeling, photochemistry, conversion in solar cells, nuclear chemistry,and nuclear power [3, 4], to name a few. Additionally, the gradient routines that I willadd to the Tasmanian code will be useful to all who use the publicly available Tasmanianpackage to manage sparse grids in their research.ConclusionSparse grids are powerful tools, making simulations that were once intractable becomefeasible. I possess the drive, prior computational laboratory experience, and proven aca-demic background to carry this project through to completion and to communicate myresults to both specialist and non-specialist audiences.[1] Hohenberg,P.andKohn,W.“InhomogeneousElectronGas”.Phys. Rev.136.3B(1964),B864–B871.[2] Nance, J. and Kelley, C. T. “A Sparse Interpolation Algorithm for Dynamical Simulations in Com-putational Chemistry”. SIAM J. Sci. Comput. 37.5 (2015), S137–S156.[3] Nance,JamesD.“InvestigatingMolecularDynamicswithSparseGridSurrogateModels”.PhDthesis.North Carolina State University, 2015.[4] Peherstorfer,Benjaminetal.“SelectedRecentApplicationsofSparseGrids”.NumericalMathematics:Theory, Methods, & Applications 8.1 (2015), pp. 47–77.[5] Stoyanov, M. TASMANIAN Sparse Grids. Tech. rep. ORNL/TM-2015/596. ORNL, 2015."
112.0,"Improving the production of biofuels by understanding metabolic pathways in microalgaeThe objective of the proposed research is to quantitatively assess the metabolic capabilities ofmicroalgae to identify inefficiencies that limit cell growth and lipid synthesis. The long term goalis to create a strain of microalgae that is maximized for biofuel production. Currently, plantbiodiesel is the main source ofbiofuels. However, the demand for oilhas outpaced the amount of biodieselthat can be produced in this manner.Microalgae are a viable alternative toplants due to their ability to produceup to 370 barrels of oil per hectare,which is more than 100 times greaterthan the oil produced throughsoybeans- the main crop for biofuel.1Even so, efforts to enhance theirbiofuel- producing capability is stillneeded in order to realize theirindustrial viability. One of the biggestchallenges with algae biofuels is theunderstanding of mechanisms thatinfluence the production oftriacylglycerol (TAG), a precursor tobiodiesel.The objective of the proposedresearch is to develop a platform toidentify reactions that limit TAGproduction in the central carbonFigure 1: Metabolic network for Ptmetabolism of algae (Fig 1). TheThe colored boxes indicate different cellular compartments.microalgae, PhaeodactylumDark yellow circles indicate the metabolites that can betricornutum (Pt), is ideal for biofuelmeasured using GC-MS and LC-MS. While circles indicateproduction: 1) they efficiently fix metabolites that cannot be measured. Red dotted lines indicateatmospheric CO 2- responsible for that reactions exist between TP, ACA and TAG.absorbing at least 25% of the totalamount of carbon dioxide processed by the seas, 45-50 billion tons of organic carbon 2 2) theyaccumulate up to 45% of their dry cell weight in TAG 3.In recent years, advances in genomic tools for Pt such as genome editing4 and stabledelivery vectors5. allow us to further enhance the ability of Pt to produce TAG. However, thegenes that correlate to these metabolic inefficiencies are currently unknown so gene alterationsare conducted through educated guessing.Stable isotope tracers, such as 13C, are added to biological systems to track patterns ofisotope incorporation into numerous products synthesized by the cell, including TAG. Couplingtracers with Isotopically Nonstationary Metabolic Flux Analysis (INST-MFA), the metabolicfluxes in central carbon metabolism as well as the transport rates across cellular compartments(Fig 1) can be determined. With this knowledge, reactions that divert carbon away from TAGcan be identified and subsequently targeted for gene editing. Through this method, we will beable to create a strain of Pt that is optimized for TAG production.1Amy Zheng NSF Research ProposalThe proposed work will be broken down into two major tasks: 1) Describing the centralcarbon metabolism of Pt using INSTA-MFA 2) Highlight metabolic targets for deletion andassess its effect on TAG production.Task 1: Developing flux map of central carbon metabolism in Pt The objective is to findwhich reactions contribute to TAG production using INSTA-MFA. INSTA-MFA combines ofcomputational and experimental methods in order to describe the metabolism of an organism.This is due to the infeasibility of measuring all metabolites within an organism. Therefore, themetabolites that cannot be explicitly measured (white circles in Fig 1) must be interpolated usinga model. In the computational portion, a model is compiled from literature and biochemicaldatabases focusing on the central carbon metabolism. Central carbon metabolism the main focusof our model because these pathways contain the major carbon reactions. Carbon enters theorganism as CO and is turned into biomass or TAG.6 TAG is synthesized from ACA and TP2(red dotted line Fig 1). We have created this model for Pt which includes all of the measurablemetabolites and the major carbon cycles such as the Calvin, Tricarboxylic Acid Cycle andPentose Phosphate Pathway (Fig 1).On the experimental side, metabolites are tracked by feeding the 13C tracer as sodiumcarbonate (yellow circles Fig 1), allowing us to track the pathway of the carbon through theorganism. The metabolites containing the tracer in the organism will increase over time as itbecomes incorporated into the major cycles. This pattern of incorporation over time is called theMetabolite Labeling Data (MLD).In INSTA-MFA, MLD is combined with the computational model to understand thelabeling pattern of unmeasurable metabolites. The results gives us the fluxes through all of thereactions present in the model, also known as a flux map. Using the flux map, we can identifybottlenecks, which are genes corresponding to reactions that direct CO away from TAG.62Task 2: Highlight metabolic targets for deletion and assess its effect on TAG productionThe objective of the second area is to produce the diatom with the maximum amount of TAGproduction by targeting the genes correlated to the bottlenecks.From our simulation created in Area 1, we can identify reactions that improve TAGproduction through gene alteration. However, there is a gap in knowledge on how these genemutations affect the metabolism of the diatom. Using INSTA-MFA, we can predict which geneslimit TAG production by looking for bottlenecks. Then, we can delete those genes with helpfrom our collaborators at Colorado State University, who have developed methods for genomeengineering in diatoms, to produce desired mutants. After the mutants have been synthesized, wecan assess the changes in metabolism and identify additional bottlenecks by using INSTA-MFAagain. Through this iterative process, we can create a strain of diatoms that produce themaximum amount of TAG.Broader Impacts: Within the scientific community, this project will help us understand howCO is incorporated into photosynthetic organisms. On an industrial scale, increasing the2efficiency of biofuel production in Pt will eliminate our reliance on fossil fuels. INST-MFAallows us to understand the metabolism of Pt by combining 13C isotope experiments andsimulations to create a unique flux map. From this map, we can identify genes that can bemutated to increase TAG production. By understanding how metabolism within Pt functions, wecan create a diatom that produces the maximum amount of TAG physically possible.Sources: [1] Chisti Biotechn Adv 25, 294-306 (2007). [2] Young et al.Metab Eng 13, 656-665 (2011). [3]Falkowski, et al. Aquatic Photosynthesis. 2nd edn, (Princeton University Press, 2007). [4] Hu et al. Plant J 54, 621-639 (2008). [5] Weyman et.al Plant Biotechnol J. 13, 460-470 (2015) [6] Cheah et al. Systems Biology 25-70 Wiley(2017).2"
113.0,"I propose to develop new theoretical and computational methods for investigating activatedchemical processes. Specifically, I will develop a method for calculating derivatives of rateconstants, transport properties, and other dynamical timescales with respect to temperature(T), pressure (p), and chemical potential (µ). I will use these to calculate activation energies(E ) and activation volumes (∆V‡) of transport properties in CO -expanded liquids (CXLs).a 2Motivation: There is a growing interest in green alternative solvents for use in catalyticreactions.1 Onesuchalternativemedia, CXLs, areofparticularinterestduetotheirincreasedsafety, cost-effectiveness, and transport properties when compared with traditional organicsolvents.2 Using a CXL can give up to a five-fold reduction in the amount of solvent neededfor a reaction compared to the neat solvent, while significantly increasing mass transportimportant for catalysis where reactions are often diffusion-limited. Diffusion in CXLs hasgenerally been seen to be monotonic with changes in p, T; however a separate, computation-ally expensive, vapor-liquid coexistence simulation is currently required at each phase point(p,T) before transport calculations can be run with molecular dynamics (MD).Introduction: Instead, I propose a direct method by which the entire T-, p-, and µ-dependence of transport properties in CXLs may be evaluated from simulations at a singlephase point. Traditionally, the T-dependence and activation energies of transport propertiesare calculated from a series of simulations at different temperatures and evaluating theirArrhenius behavior. While this is generally satisfactory, there are systems in which calcu-lations over large temperature ranges are difficult or inconvenient, as in the case of CXLswhere small changes in T and p change the composition of the liquid phase.Preliminary Work: A general method has been devel-opedinpreviousworkbywhichtheT-dependenceoftrans-port properties and their activation energies can be ex-tracted from simulations at a single temperature. Thisis achieved by launching non-equilibrium MD trajecto-ries from different points along a single NVT trajectory.This was originally applied to the reactive flux correla-tion functions and was later generalized by our group towork for any rate constant, transport property, or dynam-ical timescale calculated from a time-correlation function Figure 1: The ratio of the energy-(TCF).3−4 This also allows for decomposition of E into weighted mean-squared displacementa(MSD (t)) to the mean-squared dis-kinetic and potential energy contributions, providing oth- Hplacement (MSD(t)) is presented inerwise unobtainable mechanistic insight into the E .a red and is equal to E at the longa,DWith this method, the first derivative of transport time limit, presented in blue.properties with respect to state variables (e.g., T, p) canbe calculated. This has been successfully applied previously to the diffusion coefficient (D)to calculate the E of diffusion of bulk water, as pictured in Figure 1. A typical Arrheniusacalculation finds E should be 3.5 kcal/mol while this direct method found a value of 3.48akcal/mol. The second derivative is also similarly calculable with respect to these variables.For a system with a monotonic dependence on T, and p, as in the case of CXLs, thesederivatives and a single value of the transport property are all that is needed to determineits value at other state points. This greatly reduces the number of simulations necessary toevaluate the T-dependence and drastically cuts down the computational expense while alsogaining additional insight into the decomposition of the E .a1Graduate Research Plan Ezekiel A. PiskulichAim-1 Application to the NpT Ensemble: With the NpT ensemble, fluctuations occurin both energy and volume that allow for the calculation of both E and ∆V‡. Usingaa similar derivation to our previously published works, we have been able to show that∆V‡ = k T∂ln(D) = lim(cid:104)δV(0)[r(t)−r(0)]2(cid:105). Experiments and simulations have previouslyD B ∂p t→long (cid:104)[r(t)−r(0)]2(cid:105)used an ”Arrhenius-like” plot of ln(D) vs p to calculate ∆V‡; however, these calculationsrequire that measurements be taken across an enormous range of pressures (1- 10,000 bar)to distinguish a measurable change in D with respect to p. Yet in some cases ln(D) is notlinear in p. This should allow us to probe this non-linearity which is generally inaccessibleusing traditional methods. Additionally, cross-derivatives, such as ∂Ea, can be calculated,∂pallowing us to extract the p-dependence of E from simulations at a single p.aAim-2 Application to the µVT ensemble: In the µVT ensemble, the first derivative of atransport coefficient or other dynamical timescale with respect to the chemical potential canbe written as ∂CAB(t) = β(cid:104)δN(0)A(0)B(t)(cid:105) . In practice, this derivative can be calculated∂µ µVTbyrunninganNVT simulationinwhichasub-volumehasbeendefined, allowingthenumberof molecules in the sub-volume to fluctuate. This provides a means by which changes in rateconstants, diffusion coefficients, or other dynamical timescales with respect to the chemicalpotential can be calculated without separate simulations at different compositions.Aim-3 Application to CXLs: I propose to apply this method to a variety of CXLs ofindustrial importance, including CO -expanded ethylene oxide (EO) and methanol (MeOH)2which are involved in a non-phosgene route for the industrial commodity chemical, dimethylcarbonate.6 The methods described in the previous aims will be used to probe the T-, p-,and µ-dependence of their transport properties and other relevant dynamical timescales fromsimulations at a single point. Ideally, this will allow for the calculation of the entire surfaceof diffusion coefficients, reorientation times, and other dynamic timescales for these CXLSwithout requiring more than a single phase coexistence simulation.Intellectual Merit: The methods proposed within this work are simple to apply, signif-icantly decrease computational costs, and provide deeper insight into the mechanisms oftransport properties. Additionally, they provide a convenient means by which first (andhigher-order) derivatives with respect to T, p, and µ may be calculated. This will allowfor entire dependence of these properties on these macroscopic variables to be calculatedwithout requiring expensive phase coexistence calculations at each phase point.Broader Impacts: The EO–CO and MeOH–CO system is a green alternative solvent2 2consideredfortheproductionofdimethylcarbonate, animportantprecursorinpolyurethaneproduction and will be investigated in collaboration with chemical engineers at the Centerfor Environmentally Catalysis.6 I will also be co-organizing the 2019 Liquid Gordon ResearchSeminar for graduate and postdoctoral students. I will continue to mentor undergraduatestudents throughout the course of my studies. Furthermore, I will pursue the outreachprogram proposed in my personal statement. The methods proposed in this work can beextended to solve a wide variety of chemical problems.[1]P.AnastasandN.Eghbali. Chem. Soc. Rev.,39,pp. 301-312(2010). [2]P.Jessop,andB.SubramaniamChem. Rev.,107,pp. 2666-2694(2007). [3]O.O.MeseleandW.H.Thompson. J.Chem. Phys.,145,134107(2016). [4] Z.A. Piskulich, O.O. Mesele and W.H. Thompson. J. Chem. Phys., 147, 134103 (2017). [5]K. Krinicki, C. Green, and D. Sawyer. Faraday Discuss. Chem. Soc., 66, pp. 199-208 (1978). [6] Z.A.Piskulich, B.B. Laird and W.H. Thompson. Fluid Phase Equilib., Submitted, (2017).2"
114.0,"INTEGRATING CONNECTED PEDESTRIANS IN INTELLIGENT INTERSECTIONCONTROL SYSTEMS (IICS)Keywords: Automated Vehicle, Pedestrians, V2X ConnectivityINTRODUCTIONBroader Impact: With approximately 1.3 million road traffic deaths worldwide, roadway safetyis a major health problem that affects humans around the globe. Nine out of ten of those seriousroadway crashes are due to human behavior. Emerging automated and connected vehicletechnologies have potential to transform the transportation system by removing fatal humanerrors. Using a variety of sensors and terrain information, automated vehicles (AV) andconnected vehicles (CV) will have the ability to communicate with infrastructure (V2I),surrounding vehicles (V2V), and all roadway users (V2X). While embracing technology,engineers must consider all road users; not just automobiles. Complete Street policies adoptedacross the country and require streets to be planned, designed, and maintained to enable accessfor users of all ages and modes of transportation. Advances in AV and CV technology mustintegrate all modes transportation to achieve a safer and more efficient transportation system.Intellectual Merit: AV technology removes the ability for pedestrians to visibly communicate(i.e. eye contact) with a driver. One possibility of keeping pedestrians connected, proposed inthe project, is based on connected pedestrian detection. With a large portion of the USpopulation in possession of a “smart” or connected device, pedestrians may have the ability toconnect with the infrastructure and vehicles. Pedestrians would eventually be to indicate whichroad they wish to cross to get the right-of-way. AV and CV vehicles in possession of pedestriandata can make safe and informed decisions to improve efficiency at an intersection. Although itis not feasible to have 100% saturation of connected pedestrians, this project develops theframework for connecting pedestrians into an intelligent intersection control systems.RESEARCH PLANThe goal of my Ph.D. research is to optimize intersections with AVs, CVs, and pedestrians. Withthe resources and support from the University of Florida (UF), I will develop, test, deploy, andanalyze a pedestrian-integrated intelligent intersection control systems (IICS). My researchexpands ideas from my current undergraduate collaborations with Dr. Lily Elefteriadou, directorof the UF Transportation Institute, Dr. Ruth Steiner, an Associate Professor at the UFDepartment of Urban and Regional Planning.Broader Impact: During my research process, I will include undergraduates in my team, mentorengineering students, and present the project to multiple audiences. A diverse undergraduateresearch team will assist my project with accessible tasks, exposing them to the research setting,and facilitating a passion for transportation engineering by working with cutting-edgetechnologies. I will continue mentorship in established programs at the UF ASCE student chapterand College of Engineering. I will disseminate my work through multiple publications inTransportation Research Board and other scientific journals. I will present my work toundergraduates at their club meetings and research fairs. Practicing engineers will gain access tomy work through my involvement in professional societies (ASCE) and start to integrate AV andCV technologies into their long-range plans.Intellectual Merit: Recent publications developing system control algorithms incorporating AVand CV technologies intelligent intersection control systems (IICS) assume a mixed-traffic ofconventional, connected, and autonomous vehicles in undersaturated conditions [1,2]. With myRebecca Kiriazes Graduate Research Proposalestablished connections at the UF, I can procure all necessary equipment including autonomousvehicle, detectors, IICS, and a testing location.OBJECTIVE 1: INTEGRATING PEDESTRAINS IN ALGORITHM (FIGURE 1)The central computer will receive each vehicles and pedestrian arrival information. An algorithmwill compute the parameters of theAV or CV to minimize travel timedelay while considering the estimatedmovement of the connected pedestrianand conventional vehicles. Theoptimized AV or CV parametersdetermine the intersectionsignalization and the AV or CVtrajectory [1]. Challenges indeveloping the algorithm includepredicting pedestrian movement withthe presence of AV, CV, orFigure 1: Intelligent Intersection Control System (IICS) withconventional vehicles [3].Connected PedestriansOBJECTIVE 2: PEDESTRAIN AND IICS COMMUNICATIONPrevious research in smartphone-based detection and localization has been developed forvisually impaired pedestrians [4]. Smartphone-based connectivity will be established in the IICS.OBJECTIVE 3: TESTING AND EVAULATIONFull scale testing will take place to establish working connection between pedestrian, vehicles,and infrastructure [2]. Multiple scenarios with varying frequency and volumes will be tested andthe results will be recorded and established performance measures will be analyzed.OBJECTIVE 4: ROADWAY SAFETY EVAULATIONAdditional testing will determine the intersection effectiveness of the perceived pedestriansafety. Response time and post-crossing participant survey will be analyzed to increase theaccuracy of the IICS pedestrian prediction and inform future designs of vehicle-to-pedestriancommunication [5]. From this testing, a series of pedestrian safety workshops will be presentedto inform the public on safe interactions with AVs and CVs.CONCLUSIONBroader Impact: This proposal strengthens the connection between transportation engineeringand urban planning in development of emerging technologies. It is expected that results of theproposed project will facilitate the adoption of connected and autonomous vehicle technologies.Adopting these technologies will result in a safer and more efficient transportation system.Intellectual Merit: This project will encourage the academic community to investigate vehicle-to-pedestrian issues including non-connected pedestrians, data security, moral dilemmas, and theeffect AV will have on mode choice.REFERENCES[1] Pourmehrab, M. et al. 2017 Unpublished.[2] Omidvar, A. et al. 2017. Unpublished.[3] Marisamynathan, S. et al. 2014. Journal of Traffic and Transportation Engineering. (103-110)[4] Murali, V. et al. 2013. IEEE Int Conf Multimed Expo Workshops. July 2013. (1–7)[5] Clamann, M. et al. 2017. Transportation Research Board. (AND10)."
115.0,"Motivation: Humans are inherently good at cooperation in teams, and our ability to worktogether enables us to overcome challenges that a single individual would otherwise be unable tocomplete. The same can be said for autonomous robotic systems: for many applications a team ofrobots working together can complete a task more efficiently than an individual robot workingalone. Another advantage of multi-robot systems is that the agents can be mechanically simplerthan a single, general purpose agent required to complete the same set of tasks. Introducingheterogeneous robot types into the team allows specialized agents to focus on the tasks they aregood at, and in many cases, increases the efficiency of the team.Specialization improves teams, but introduces a new challenge: if a team is confrontedwith a task that no members of the team have the expertise to complete, the team will fail. Thecurrent solution to this challenge is to create large teams with a high diversity of agents, but thissolution is inefficient and leaves highly specialized agents in the team under-utilized. Humanssolve this problem intuitively: if the team does not have a capable member then one is recruitedfrom an outside source, and when that task is complete and that person's skill set is no longerrequired, they are released from the team. Consider a situation where a child is lost in a themepark and security for the park sends out a quadrotor-based search team to look for the child. Thequadrotors may be able to fly over the park’s walkways and above open areas searching for thelost child, but might determine that the child may have entered an area that they are unable toinvestigate. In this case the search team should be able to recruit the help of other agents in thearea, like concession service robots on the ground or park employees, to search the areasinaccessible to the quadrotors. Then when the search is over, the recruited agents can return totheir previous assignments.Background: This question of dynamic team building is largely unexplored in robotics, butrepresents a necessary functionality as the diversity of robot systems increases. Previous researchin this problem domain has focused on defining this challenge and presenting assessment metrics[1]. However, formal methods for coordination of these types of teams are limited.In 2017, I worked with researchers at Oregon State University on the design and testingof a novel distributed coordination and task planning algorithm for heterogeneous robot teamscalled Distributed Monte Carlo tree search (Dist-MCTS). By generalizing the tasks, rewardfunctions, and agent abilities, Dist-MCTS remains agnostic to the type of agents in the team,enabling coordination of teams composed of agents with different abilities. Simulated trialsshowed that Dist-MCTS teams earned 47% more cumulative team reward than teamscoordinated using a distributed auction-based approach. While it is effective at organizingcomplex teams, this algorithm does not allow for dynamic team formation.Research Proposal: I propose to explore the challenge of creating dynamically formed teams bymodifying the Dist-MCTS high-level planner and implementing it in a larger framework for thedynamic formation of heterogeneous multi-robot teams. Two essential extensions must be madeto the Dist-MCTS algorithm before it can be used for dynamic formation of teams. These focuson scalability and p olicy estimation.A primary restriction of the current Dist-MCTS algorithm is scalability. If too manyagents are added to the team (20+) or the number of tasks increases beyond a certain threshold(100+), the planning space becomes too high-dimensional and the solution quality declines. Toaddress the challenge of scalability, I will incorporate autonomous sub-teaming and task spacesegmentation into the existing algorithm. This adaptation reduces the complexity of the planningoperations for all agents across the macro-team. Extensibility is a key requirement forapplications to dynamically formed teams because the planning space has the potential to expandrapidly during complex missions.The second I will make to Dist-MCTS is the incorporation of an adaptive task selectionmodel for inclusion of independent agents like humans or unknown robots in the team. Previouswork [2] has demonstrated preliminary results for a method to estimate the policy of anindependent agent like a human and use this to inform the actions of multi-agent teams. This isnecessary because it cannot be guaranteed that the recruitable agents in the operatingenvironment of a dynamically formed team will be able to communicate with the team. Policyestimation for these independent agents will allow the existing team to coordinate itself aroundagents without requiring direct communication and enable teams to be formed of robots that arenot built by the same research group or manufacturer.Methods: I plan to develop a novel algorithm for coordination of dynamically formed teams inthree phases: algorithm design, simulation testing and refinement, and h ardware validation.I. The first phase will focus on integrating the modified Dist-MCTS in a larger softwareframework and developing the components necessary to facilitate dynamic teamformation. This will include creating a method for assessing newly discovered tasks anddetermining a functional set of protocols for recruiting new agents to the teams.II. With the new planner in development stages, I will test and refine the system with amodified version of the simulator used to assess the Dist-MCTS algorithm. A key pointin this phase will be investigating how teams should recruit and release members as tasksare discovered and completed.III. With a refined result, I will apply this high-level planner to multi-robot teams in areal-world hardware trials in unknown, dynamic environments to assess its validity inapplication. For a complete test of this algorithm, these hardware trials will be focused onnot only validating the team’s basic functionality, but in testing its applicability tocomplex multi-robot task domains like collective construction.Broader Impact: This proposal addresses a key challenge in the design and operation ofcollaborative multi-robot systems, and will provide a platform for a variety of other potentialresearch topics including rapid deployment of heterogeneous teams, and optimization of agentstructures in such teams. Dynamic formation of multi-robot teams will revolutionize robotics byincreasing the versatility of the multi-agent teams and the complexity of possible missions.As advances in robotics continue and more robots become integrated in everyday life,these types of teams will become increasingly useful in a wide variety of application domains.One application for these types of teams could be in STEM education, where students learnabout how robots interact with both the real world and each other through demonstrationsinvolving these teams, allowing them to draw parallels between human teamwork and robotteamwork.[1] Jones, E. G., Browning, B., Dias, M. B., Argall, B., Veloso, M., & Stentz, A. (2006). Dynamically formedheterogeneous robot teams performing tightly-coordinated tasks. In Proceedings 2006 IEEE InternationalConference on Robotics and Automation, ICRA 2006 (Vol. 2006, pp. 570-575). [1641771][2] L. Milliken and G. A. Hollinger, “Modeling user expertise for choosing levels of shared autonomy,” in Proc.Planning for Human-Robot Interaction Shared Autonomy and Collaborative Robotics Workshop, Robotics:Science and Systems Conference, 2016."
116.0,"Question AnsweringAlvin WanKeywords: visual question answering, attention, computer visionI. Introduction II. PropositionVisual Question Answering (VQA) is a task To broaden the scope of informationthat fuses both computer vision and natural incorporated, I propose running objectlanguage processing, where a computer detection on the original image to extract allmust answer questions about a provided identifiable entities; this can be achievedimage. State-of-the-art approaches leverage with a pretrained model, such as YOLO9000.attention networks in deep learning, which The set of attributes obtained fromhelp to focus the neural network on portions captioning the image as well as describingof the image. In particular, these approaches these objects could then be fed into externalsee improved performance when applying information queries.attention to both the question and the image Provided that attention has improved1. Further improvements are supported by performance when applied to questions anduse of external knowledge bases. images alike, coupled with the fact thatleveraging external information likewiseRelated Work improves performance, I propose applyingattention to external information as well.Attention networks can currently leverage Once performance has been verified, I thenexternal information by captioning the treat previous background in the sequence ofimage, extracting a set of attributes, and questions, as external information. This thensupplanting the final answer-generator with allows the VQA bot to utilize previoussummaries of facts related to those context.attributes. However, what if the provided In preparation for real-time inference andcaption already ignores important context in memory constraints, we will additionallythe image? A caption may ignore a beach consider size and space-efficient methods forball in the background, but a pointed accomplishing these improvements, so thatquestion may not. What’s more--what if the bot is able to build conversation.additional context in the conversation isneeded? The user may ask for “the number Evaluationof people wearing jeans” and “of those​people, the number of people wearing red A number of public benchmarks provide​shirts”. I propose broadening the scope of adequate testbeds for both more higher-levelinformation incorporated, when querying for processing and more rote, simple questions.external information, and applying attention The COCO-QA and DAQUAR benchmarksto all the data retrieved, to build more would serve this purpose, additionallystateful, conversational VQA bots. providing comparison with existingstate-of-the-art methods. Other benchmarksthat address subsets of the VQA task, suchas image captioning, exist for intermediateevaluation.1 Lu et. al. “Hierarchical Question-Image Co-Attention for VisualQuestion Answering“ (2016)III. Research Plan architecture and information retrieval bothwill be optimized by minimizingYear I: Question Attention, Broadened fully-connected layers, using convolutionalInformation Retrieval layer reductions, and rigorous memoryprofiling. Attention networks should beObjective: Test a number of varying trained and validated as part of an onlineimplementations for raw information-based learning algorithm.attention.Methodology: Employ object detection and IV. Conclusionimage tagging to increase the quantity ofinformation queries. We can use both Intellectual Merit - Should this work​shallow and deep featurizations to produce a succeed in proving an effective method ofrich set of data descriptors. Then, apply information distillation for incorporation,attention to external sources to determine visual question answering as a field couldboth quality and relevance of external take several steps forward in studying notinformation--we can begin by modeling just computer vision for images, or naturalrelevance as a binary classification problem, language processing for questions, butthen by regressing to continuous-valued distributed systems for large-scalerelevance. information retrieval and processing.Year II: Stateful Visual Question Broader Impacts - One application of an​Answering improved bot, with enhanced visual questionanswering capabilities, is personal assistantsObjective: Utilize previous conversation for the visually-impaired. Consideringcontext to aid in question answering. computer-aided descriptions are substitutesMethodology: Use attention networks to for the user’s vision, the quality of visualdetermine what types of external information question answering is highly-valued.are needed, whether the information However, the challenge is more complexpertains to objects, an intangible quality, or than simply answering a number of isolatedprevious conversation context. Attention questions; the bot must be able to leveragenetworks should successfully discern the conversation context itself i.e., previousrelevance of samples collected prior to questions, the user’s behavioral tendencies,learning. This work may extend to year and finally, external information that maythree, as various modalities of external make answers more accurate--for example,information may require significantly more if a price tag is shown but the store-widedata processing and filtering. discount is announced online. Thus, withmore refined methods of incorporatingYear III: Towards more Conversational outside data, the bot could see majorBots improvements in its value for thevisually-impaired.Objective: Run such evaluation andanswering in real-time.Methodology: This interest directly stemsfrom my current work in reduced model sizesand real-time inference for self-driving cars.In a similar manner, we cannot always relyon network connections for high-level,fast-paced conversation. Neural network"
117.0,"Energy Agency estimates that by2025, 70 million electric vehicles(EVs) will be on roads worldwide.As a result, research on increasingefficiency, reliability, andpracticality of EVs and associatedsystems will be of increasingimportance. Described herein is awireless power transfer (WPT)approach for the dynamic chargingof EVs. The goal is to address twochallenges; reduction of componentstress during high-power, high-frequency operation and electromagnetic field containment.Literature Review: Dynamic charging, also known as roadway charging, consists of embeddedroadway coils that transfer power to receiving coils on vehicles in motion (see figure) and has beendemonstrated to increase the range of EVs. However, power transfer levels of 50-100kW arerequired to maintain the EV battery state of charge while the vehicle is in motion [2]. Anotherchallenge is the health implications of electromagnetic fields emanating from the coils. TheSociety of Automotive Engineers (SAE) J2954 standard sets limits on stray electromagnetic fields[3]. Therefore, their reduction must be addressed if dynamic charging is to achieve mass adoption.Objectives: To develop a high efficiency, high power multi-coil WPT system that will allowfor localized electromagnetic field production between source and receiving coils.Hypothesis: A reflexive WPT system comprised of: coils with embedded capacitors, saturableinductors and custom magnetic geometries, will enhance field containment capability and allowfor efficient, high power dynamic EV charging with minimal electromagnetic field emissions.Research Plan: Stage I-Initial Investigations: A WPT testbed based on a reflexive fieldcontainment compensation approach [4] will be fabricated. This topology achieves fieldcontainment by exploiting the receiving coil’s reflected capacitive reactance to neutralize thesource coil’s inductive reactance. The source coil’s current is thus attenuated when the coils areuncoupled, thereby reducing emanated fields. Based on my recent findings [5], saturable inductorswill be used to enhance the field confinement effect. The goal of this stage is to achieve a powertransfer of 10kW at an efficiency above 90% while maintaining a 30-fold field attenuation factorbetween uncoupled and coupled conditions. Stage II-Coil Embedded Capacitors: At powertransfer levels of 50-100kW, the high voltages at the terminals of the inductor coils stress theresonant tank capacitors making the SAE J2954 mandated high frequency (~80KHz) operationchallenging to implement. Previous studies have demonstrated this power transfer level only atlower frequencies [6]. Self resonant coils have been shown to eliminate the need for capacitors [7],however these are limited to use in MHz level resonant frequencies and lower powers. To addressthis, coil enclosures will be designed and built with polyethylene dielectrics spacers that allow forembedding large parasitic capacitances to reduce the voltage stress on the external resonant tankcapacitors and allow for efficient high frequency operation. Stage III-Additive ManufacturingBased Magnetic Structures: Custom magnetic structures will be implemented in the coils to allowfor optimum channeling of flux during operation to further reduce stray fields and improvecoupling. This will be preceded by extensive finite element analysis of the desired magneticstructure geometry. The magnetic structures will be fabricated using an additive manufacturingprocess recently demonstrated at Oak Ridge National Laboratory [8]. A supplier for the requiredmagnetic nano-alloy powder (FeNbSiCuB) and polyphenylene sulfide mixture has already beenidentified. Stage IV-Optimization: This stage will focus on the challenge of optimizing systemperformance at ~100kW for high efficiency operation, conformance to SAE standards and EVtesting. Soft switching will be employed on the Silicon Carbide based inverter while processingminimal reactive power to improve efficiency. The test EV will be modified to carry the receivingcoil and necessary power electronics to interface with its rechargeable batteries. Based on the SAEstandards, shielding for the receiving coil will be designed to prevent fields from penetrating theEV cabin. An array of segmented source coils will be embedded on equal intervals of test track.As the EV drives along the track, the power transfer and field containment capability of the systemwill be characterized and compared to simulation figures.Timeline and Collaboration: The proposed duration of the project is three years and will beperformed under the supervision of Dr. Srdjan Lukic at North Carolina State University’s (NCSU)NSF funded Future Renewable Electric Energy Delivery and Management Engineering ResearchCenter (FREEDM ERC) in collaboration with Dr. Tim Horn of the Center for AdditiveManufacturing and Logistics (CAMAL). Being one of the nation’s leading centers for additivemanufacturing, CAMAL’s facilities have specialized equipment capable of fabricating magneticstructures from magnetic nano-alloy powders. The systems level integration will be performed onthe EcoPRT EV mentioned in the personal statement.Anticipated Results: Through the use of saturable inductors, custom magnetic structures, and coilembedded capacitors, high frequency power transfer at 50-100kW power levels with high fieldattenuation factor between uncoupled and coupled conditions will be demonstrated. Noting that aWPT system is a transformer with a large air gap, this project strives to meet a theoretical systemefficiency of 98+%, or comparable to plug-in charging.Intellectual Merit: This research plan focuses on developing novel WPT systems that enabledynamic charging and, more generally, on pushing the boundaries of high power WPT bydeveloping better models of complex coil designs with integrated passives. Additivemanufacturing will allow for novel magnetic structures that are optimized for specific applications,and this methodology can be utilized in other high power high frequency applications.Broader Impacts: The mass proliferation of EVs is essential in addressing both climate changeand the dependence on fossil fuels. Through the implementation of WPT systems for EV roadwayuse, the proposed project will assist in making feasible a system that will allow for the efficientand reliable increase in range and thereby practicality of EVs. I will regularly present findingsfrom this research effort at scientific conferences and high profile journals. With NCSU beinglocated in the Research Triangle area, I will share findings with industry to facilitate industrialproliferation of the technology.(1) Clean Energy Ministerial, Electric Vehicle Initiative & International Energy Agency (2017). Global EV Outlook2017. (2) Z. Pantic, et. al., ""Inductively coupled power transfer for continuously powered electric vehicles,"" 2009IEEE Vehicle Power and Propulsion Conference, pp. 1271-1278. (3) Wireless Power Transfer for Light Duty Plug-In Electric Vehicles and Alignment Methodology, no. SAE Standard J2954, 2016 (4) K. Lee, et. al., ""Reflexive FieldContainment in Dynamic Inductive Power Transfer Systems,"" in IEEE Transactions on Power Electronics, vol. 29,no. 9, pp. 4592-4602, Sept. 2014. (5) A. Dayerizadeh, et. al., ""Saturable Inductors for Superior Reflexive FieldContainment in Inductive Power Transfer Systems,"" 2018 IEEE Applied Power Electronics Conference andExposition (APEC), Accepted. (6) G. Jung et al., ""High efficient Inductive Power Supply and Pickup system for On-Line Electric Bus,"" 2012 IEEE International Electric Vehicle Conference, Greenville, SC, 2012, pp. 1-5. (7) A. Kurs,et. al., “Wireless power transfer via strongly coupled magnetic resonances,” Science, vol. 317, no. 5834, pp. 83–86,Jul. 2007. (8) U.S. Department of Energy (2015). Electric Drive Technologies: 2015 Annual Report."
118.0,"Today almost 2 million people in the U.S. face functional impairment due to limb loss andamputations with more than 185,000 amputations occurring every year. Neural prostheses aredevices that aim to return full functionality to patientsthrough brain-machine interfaces (BMIs). Emergingneural prostheses decode the user’s intention fromneural signals recorded directly from the brain andcreate a closed-loop sensory feedback system throughneural stimulation as shown in figure 1. The primarycomponents of this technology are the neural signalinterpretation algorithms and the neuromodulators(implanted neural recording and stimulation hardware).Recent advances in neural decoding techniques indicatethe achievable high accuracy of BMIs. Previous workby Dr. Rajesh Rao demonstrates the viability of anunsupervised hierarchical k-means clustering algorithmto predict human behavior from brain recordings [2]. Figure 1: Closed-loop Feedback System [1]Advances in neuromodulators include recent work by Dr. Jan Rabaey on OMNI a wireless, low-power modular and distributed closed-loop neuromodulation device for chronic use [3].Proximity of neuromodulators to neural tissue results in stringent power restrictions; any neuraldecoding algorithms must occur on external machines. Neuromorphic computing systems,hardware designed to function like biological neurons, are highly capable of enhancing brain-machine interface functionality. Classification algorithms on neuromorphic processors use 2 ormore orders of magnitude less energy than on existing digital hardware. Implementing aneuromorphic processor in neural prostheses has the potential to improve BMI powerconsumption and mobility by eliminating data transmission and external hardware. A need forthe consolidation of these 3 components - neural decoding, neuromorphic computing andneuromodulation - in hardware for BMI implementation has been clearly identified [4].PropositionThroughout my undergraduate degree, I have conducted research on neuromodulators’ hardware-software interface, gained experience in neural signal processing and learning algorithms (suchas SVMs, PCA and hyperdimensional computing), and worked on and gained an understandingof neuromorphic computing for adaptive learning hardware. I had the experience of workingwith three distinguished professors - Dr. Jan Rabaey, Dr. Rajesh Rao and Dr. Hugh Barnaby - onthese distinct yet complementary areas. If I have the honor of receiving the NSF GRFP, Ipropose to fuse my knowledge in each to implement complex adaptive learning algorithms onneuromorphic hardware integrated with a neural recording and stimulating system.Research PlanYear 1: Evaluation and integration of neuromorphic hardware models with neural recordingand stimulation devices. Cutting-edge neuromorphic chips such as, but not limited to, Intel’sLoihi, IBM’s True North, and the commercially-available Intel Curie module (if unable to obtainthe former two) will be evaluated on power consumption, learning capabilities, applicability toneural decoding and accessibility. Consequently, an interface between the neuromorphicprocessor and the neuromodulation system including data transmission to and from each modulewill be designed.Year 2: Implementation of adaptive learning algorithm on neuromorphic hardware for neuralsignal decoding/interpretation. Various filters and learning algorithms will be evaluatedincluding, but not limited to, k-means clustering, support vector machines, and spiking neuralnetworks given potential performance on neural data and constraints of the selected processor.This involves research, design, implementation and testing of the algorithms on theneuromorphic processor to determine functionality and competence.Year 3: Testing, validation, improvement and finally study of system to advance knowledge ofpossibilities/limitations of neuromorphic applications in neural engineering. This process willinvolve testing of the system as a whole, ensuring data transmission between the neuromodulatorand neuromorphic processor and functionality of the algorithm on the processor. Once thesystem is finalized, studies will be conducted to determine accuracy, speed, and powerconsumption of the system signifying operability in brain tissue.Further study: Research beyond the initial 3 years will include 2 years of in vivo studies to testand validate the system’s recognition of motor intention from neural data in animals.FacilitiesTo conduct this study, I will work with Dr. Jan Rabaey at UC Berkeley. He has expressedconsiderable interest in working with me if I receive the NSF GRFP. I will integrate theneuromorphic hardware model with his group’s previous work on OMNI, the neuromodulationdevice. The neuromodulator is the primary component of my proposal on which theneuromorphic processor and learning algorithm are built. Working with Dr. Rabaey in UCBerkeley and continued mentorship from Dr. Barnaby and Dr. Rao on the neural decoding andneuromorphic modules will provide the resources I need to meet the goals of this proposal.Intellectual Merit and Broader ImpactsPrevious work claims that a neuromorphic neural interface will eliminate the need for externalmachines and significantly reduce power consumption enabling the possibility of a fully-implanted system. Potential for success has been demonstrated through simulations andmodeling but the lack of a direct hardware implementation limits understanding of the truefeasibility and impediments of utilization of neuromorphic processors in a closed-loop feedbacksystem particularly regarding accuracy, speed and power consumption. This project willdevelop enabling technology that will advance the knowledge of the capabilities andlimitations of neuromorphic applications in neural engineering. The work produced from thisproject will be presented at national and international conferences.Medically, the highly competent neural interface this research addresses has the potential tochange lives through applications in bypassing spinal cord injury, deep-brain stimulation, andengineering plasticity for neurorehabilitation. Socially, this interdisciplinary project promotescollaboration between academic institutions. My experience with TYE taught me that the driversof interest in engineering are role models and incredible technology. When I talk to middle andhigh school girls about my research - mind-controlled prosthetics - their eyes light up withpossibilities. Throughout my graduate career, I will continue mentoring young girls to pursueengineering and will use this research to spark excitement for engineering in young minds.[1] S. J. Bensmaia et al., “Restoring sensorimotor function through intracortical interfaces: progress and loomingchallenges,” Nature Reviews Neuroscience, vol. 15, no. 5, pp. 313–325, 2014. [2] N. X. R. Wang, R. P. N. Rao etal., “Unsupervised Decoding of Long-Term, Naturalistic Human Neural Recordings with Automated Video andAudio Annotations,” Frontiers in Human Neuroscience, vol. 10, 2016. [3] A. Moin, J. Rabaey et al., ""Powering andcommunication for OMNI: A distributed and modular closed-loop neuromodulation device"", 2016 38th AnnualInternational Conference of the IEEE Engineering in Medicine and Biology Society (EMBC), 2016. [4] F. Broccardet al., “Neuromorphic neural interfaces: from neurophysiological inspiration to biohybrid coupling with nervoussystems,” Journal of Neural Engineering, vol. 14, no. 4, p. 041002, Feb. 2017."
119.0,"impending possibility of “The Big One”—a M8 or greater earthquake along the San Andreas FaultSystem (SAFS) in California. While strike-slip systems exist across the world, the SAFS is uniquein that it terminates at the Mendocino Triple Junction (MTJ), which is the only known example ofa modern FFT system—a tectonic triple point bounded by two transform (F) boundaries and asubducting trench (T)[1]. The MTJ formed at approximately 30 Ma when the Pacific-Farallon ridgesystem was subducted beneath the North American Pacific Trench, creating the northwardmigrating triple point, and changing the tectonic regime of the plate boundary from a convergentstyle to a current strike slip style at the latitude of the SAFS.[1]. This change has had drastic effectson the Pacific Coast ever since, resulting in high levels of deformation and seismic activity. Theproject proposed herein seeks to better understand this geologically complex and sociallymeaningful system, by aiming to identify and characterize the first recognized ancient equivalentof the MTJ at the southwestern extent of the Paleozoic-era Norumbega Fault System (NFS) ofMaine. My PhD work will investigate a ridge-subduction model for the Norumbega TripleJunction (NTJ) put forth by Kuiper 2016[2] by 1) utilizing field and microstructural analysis toevaluate whether dextral faults that curve in a direction opposite to Riedel faults in the NFSare equivalent to stepover faults in the SAFS and 2) testing whether these faults areprogressively younger to the southwest, indicating a southwestward migration of the NTJ,analogous to the modern northward migration of the MTJ. If the southern terminus of the NFSis an appropriate type locality for the FFT style triple junction, then the region may provide insightinto the evolution and behavior of strike-slip tectonics in the SAFS and around the world. Theidentification of such an analogue would be particularly significant given the strong outcropexposure of structural features long the Maine coast in contrast to the more veiled features of themodern Mendocino Triple Junction. Regardless of model success, this work will provide afurthered paleogeographic model for the evolution of New England—a complex and meaningfulregion in its own right.Context Along its ~300 km extent from SW New Brunswick to S Maine, the mid-Paleozoic NFSis a NE-trending right-lateral transpressive system that parallels the Appalachians[3]. The NFSterminates to the SW, along high grade metamorphic rocks and migmatites associated with theNashoba terrane of Eastern Massachusetts[4]. The youngest age of partial melting in the Nashoba(~360 to 380 Ma) is coincident with ages of dextral shear in southern parts of the NFS obtained byAr/Ar age-dating[5,3]. These coeval ages suggest that while dextral movement occurred along theNFS in Maine, convergent style tectonics were still taking place in the nearby Nashoba terrane,indicating a triple point existed between the two. Furthermore, work done by Gentry et al., 2016illustrates a lack of dextral NE-trending subvertical lineaments, shear zones, and faults inMassachusetts. These observations suggest an abrupt southern termination of the NFS, not unlikethe modern MTJ placement against the northern Cascade arc volcanoes in the SAFS[6,7].Hypotheses Splay-shaped faults in the NFS and SAFS play a key role in testing the Kuiper 2016model. These structures look like expected Riedel-shaped faults, but curve in a direction oppositeto the expected Riedel orientation [2]. In the SAFS, these features are known to be associated withdextral activity, and are possibly either slip-transfer faults from the SAFS to the Mendocino TripleJunction or linkage faults between various strands of the SAFS[8]. If the subducted ridge model iscorrect, the Norumbega Triple Junction would have moved SW, mirroring the current northwardmigration of the MTJ. If this is the case, the splay-shaped dextral faults in the NFS should beyounger to the south, paralleling the age pattern inferred from the slip-transfer and linkage faultsin the northern SAFS[8]. Alternatively, such features in the NFS could be original sinistral (Riedel-expected-orientation) structures which were subsequently reactivated, resulting in dextraloverprinting. This alternative will be investigated alongside the work proposed herein.Methods and Work Plan Beginning in 2018, I will add to my background of coursework in hightemperature geochemistry, structure, and geodynamics through graduate-level work inmicrostructure, kinematics, and geochemistry. During this time, I will identify optimal sites formapping based on high quality LIDAR imagery in collaboration with previous workers and theMaine Geological Survey. Over the next two summers, I will mentor an undergraduate fieldassistant and conduct detailed structural mapping at sites across southern Maine, with the goal ofidentifying pre-NFS convergent folds displaying overprinted dextral shear indicators such as S-Cfabrics, shear bands, and stretching lineations, all of which indicate the formation of theNorumbega Triple Junction.[9] Following sample acquisition, Backscattered Electron Imaging(BSE) analysis will be utilized to reveal spatial relationships between mineral assemblages anddeformation fabrics sampled along the NFS (extending from the north towards hypothesizedyounger southwestern extents). This will allow for the selection of mineral candidates for U-Th-Pb age-dating. Analyses will be conducted using either an electron microprobe (EMP), or a laserablation system coupled to a high-resolution, single collector inductively coupled plasma massspectrometer (LA-ICPMS). Given that the EMP provides only an elemental age and has a smallerspot size than ICPMS, the exact methodology will depend on the size of the domains chosen foranalysis. Both methods have been shown to display strong enough precision to resolve geologicalevents in the study region (1-3% for the EMP and <3% for LA-ICPMS).[10] Results from each ofthe two field seasons will be synthesized and used to inform a workplan for future field andanalytical work. Final results will take the form of my PhD dissertation and associated peerreviewed publications. Results will also drive the outreach campaign outlined in my PersonalStatement. While this project is ambitious, my prior educational, professional, and researchexperiences pair with the resources available at Colorado School of Mines and elsewhere to ensurethat I have the skillset, perspective, and support necessary to succeed.Broad Impact The affirmation of a ridge-subduction model for the NFS not only has the potentialto establish a type locality for the enigmatic FFT style triple junction, but moreover would informscientists seeking to decipher the kinematics of the currently active MTJ by allowing forinterpretations from well exposed outcrops along the NFS to be applied to the SAFS—extendingour base of knowledge about an active and dangerous natural system. Even if the model cannot beconfirmed, the completion of an in depth structural history of the region will enable a strongerunderstanding of the mid-crustal dynamics associated with the evolution of the New EnglandAppalachians. Finally, the completion and communication of this work will not only bescientifically relevant, but will enable me to build upon the goals outlined in my personal statementby establishing a career that will impact public discourse and geoscience education.References[1] Furlong, K.P., and Schwartz, S.Y., 2004, Annual Review of Earth and Planetary Sciences. v. 32. [2]Kuiper, Y.D., 2016. Geology, v. 44. [3] West, D.P., 1999, Geological Society of America Special Paper, v. 331. [4]Goldsmith, R., 1991, United States Geological Survey, Professional Paper 1366 E–J. [5] Buchanan et al., 2014,Geological Society of America, Abstracts with Programs, Vol. 46, No. 2. [6] Gentry et al., 2016, Geological Societyof America, Abstracts with Programs, Vol. 48, No. 7.[7] Nicholson et al., 1994, Geology, v. 22. [8] Wakabayashi etal. 2007, Tectonophysics, v. 392. 9] Swanson, M.T.,1999, Geological Society of America Special Paper, v. 331. [10]Neymark et al., 2016, Economic Geology, v. 111."
120.0,"coral and is a crucial reef-building coral. Due to mass mortality from white band disease (WBD)in the Caribbean, however, A. cervicornis is currently designated as critically endangered by theIUCN Red List of Threatened Species. While the etiological agent of this disease is unknown, mylab recently discovered that a bacterium associated with the disease is strongly stimulated bynutrient pollution. In early 2017, I assembled the genome of this obligate intracellular parasite ofA. cervicornis and, based on its phylogenetic position and genome content, I hypothesize that it isresponsible for WBD and the destruction of Caribbean Acropora. Yet we do not yet know itsmechanisms of transmission and disease development (pathogenesis) and further experiments areneeded to confirm its role as the agent of disease. Using a combination of comparative genomicsand field experiments, I aim to evaluate the gene expression, biogeography, and evolution of thisbacterium to help prevent and manage this disease on coral reefs in the future.Background: WBD has been observed in the Caribbean, Red Sea, and the Pacific, but itsmechanisms of pathogenicity are uncharacterized. Transmission experiments suggest that WBD iscaused by bacteria,1 with species of Rickettsiales implicated as possible etiological agents,2,3 yetthese taxa are present in both healthy and diseased coral microbiomes. Recent studies4,5 led by myadvisor at Oregon State, Dr. Rebecca Vega Thurber, indicated that exposing corals to nitrogenstimulates the growth of an intracellular bacterium (order Rickettsiales). A strong negativecorrelation was found between the abundance of this taxon and coral growth (r2=0.9987, p<0.001)in the presence of nutrients.5 In A. cervicornis, this taxon increased from <11% of the microbialcommunity to ~88% after 8 weeks of enrichment. In an unpublished study, tissue homogenateswere generated from diseased and healthy A. cervicornis. The diseased homogenate, which causeda sixfold increase in mortality of exposed corals, was found to have a relative abundance of >50%Rickettsiales, while these species comprised only 0.1% of the healthy homogenate.While known pathogens in the genus Rickettsia clustered together in a 16S rRNAphylogenetic tree, I discovered that the intracellular parasite of A. cervicornis clustered mostclosely with uncultured symbionts of marine invertebrates, primarily corals and sponges.6 Basedon strong statistical support for the distinction of these intracellular symbionts of marineinvertebrates from other Rickettsiales, I proposed a new genus, Marinoinvertebrata gen. nov., ina publication in preparation for the ISME Journal.6 I named the newly-discovered parasite M.rohwerii sp. nov. after the lab that first observed it.3 Given their abundance in corals exhibitingreduced growth and signs of WBD, I hypothesize that: (1) Marinoinvertebrata spp. are membersof the healthy coral microbiome but have evolved mechanisms of pathogenesis (encoded byvirulence genes) that are modulated by environmental factors. (2) The increased expression ofthese genes due to nutrient exposure, in tandem with weakened host immune function caused bypollution, leads to coral disease. I will address these hypotheses through two central questions:Q1: How do mechanisms of pathogenesis and environmental response differ in speciesof Marinoinvertebrata from distinct regions? (Aim 1) I will compare the genome of M. rohweriito genomes of disease-causing Rickettsia to identify homologs to virulence genes. I will alsocompare the pathogenicity of this organism with that of related species from different regions.Q2: How does concurrent exposure to nutrients and infection by Marinoinvertebrataspp. alter host physiology and induce disease? (Aim 2) I will conduct nutrient enrichmentexperiments on six genotypes of A. cervicornis to induce growth of Marinoinvertebrata spp. I willtrack parasite abundance using quantitative PCR as well as changes in microbiome composition,host/pathogen gene expression, growth rate, and disease progression. Lastly, I will use nanoscalesecondary ion mass spectrometry (NanoSIMS) to trace parasite nutrient assimilation.Research Plan: Aim 1: Via the KAAS server,7 I will use reference genomes of pathogenicRickettsia to guide my search for homologous virulence genes in the assembled genome of M.rohwerii. Using this method, I previously uncovered a complete Type IV secretion system in thisgenome, which is involved with host infection and genetic exchange in related bacteria8, as wellas the NtrY-NtrX two-component system involved in sensing extracellular nitrate levels. However,additional virulence and environmental response genes present in Rickettsia may have more distanthomologs in Marinoinvertebrata spp. As part of the Global Coral Microbiome Project and TaraPacific, I have access to microbial community data from hundreds of Caribbean and Indo-Pacificcoral samples and have identified species of Marinoinvertebrata in samples from Australia, SaudiArabia, and Colombia. I will assemble the genomes of these species and determine whether theyalso possess virulence genes, and whether these are modulated by environmental-sensing genes.Aim 2: I will expose six different genotypes of A. cervicornis (raised in nurseries at MoteMarine Lab (MML)) to various levels of inorganic nitrogen to stimulate Rickettsiales proliferationas shown previously.4,5 Three of these genotypes are sensitive to WBD and three are resistant, asdetermined by Dr. Erinn Muller, who will be my host at MML. From the genome of M. rohwerii,I will generate quantitative PCR markers to track its absolute abundance throughout the enrichmentexperiments. Coral fragments will be sampled weekly with the help of students from MML’s after-school program, and high-throughput RNA sequencing will be used to assess Rickettsiales andhost gene expression. I will track coral health through growth, photosynthesis, and respiration ratesand changes to the host microbiome using 16S rRNA amplicon analysis. Finally, I will spend thesummer of 2019 working with Dr. Xavier Mayali of Lawrence Livermore National Laboratory,using NanoSIMS to isotopically trace whether M. rohwerii scavenges nutrients from the host, fromsymbiotic algae, or from the environment.Intellectual Merit: Our ability to directly alter host-microbe interactions using nutrientenrichment provides a reliable model to ascertain which genes play a role in disease initiation andhost response. Beyond its implications for coral disease, the opportunity to reconstruct the genomeof a novel pathogen is rare and may uncover new mechanisms of transmission, especially whenthis pathogen is traced throughout different regions and coral hosts. As coral reef fish are crucialto the economy of many tropical regions, it is critical to combat the rapid destruction of theirhabitat by disease. The PCR primers I develop for this experiment can be used to quantify diseaseprogression and track the spread of M. rohwerii, and our understanding of the host and pathogentranscriptomes will contribute to further studies on antibiotic treatment of WBD. Lastly, as MML’scoral nurseries were damaged by Hurricane Irma, my research will inform recovery efforts asgenotypes most resistant to Marinoinvertebrata infection will be used in new nurseries.Broader impacts: Given my extensive advising and leadership experience, the robusteducational programs already established by MML will provide an excellent framework to involvethe local community in my research. Through MML’s Research-Based After-School Program forStudents, I will work directly with high school students passionate about ocean conservation tointroduce them to lab- and field-based research by helping them develop short-term experimentson how nutrient dose effects parasite growth. Dr. Muller and I will lead volunteer teams topropagate new nurseries and learn about the effects of coral disease. These teams will “adopt” theirown corals to observe over time, increasing their personal investment in the reef. I will also workwith the Oregon Coast Aquarium as a Scientific Interpreter to lead demonstrations showing hownutrient pollution negatively effects the health of all marine organisms, not just coral systems.Citations: [1] Gignoux-Wolfsohn et al. (2012) Sci. Rep. [2] Miller et al. (2014) PeerJ. [3] Casas et al. (2004) Environ.Microbiol. [4] Zaneveld et al. (2016) Nat. Commun. [5] Shaver et al. (2017) Ecology [6] Klinges et al. (in prep.) ISMEJ. [7] Moriya et al. (2007) Nucleic Acids Res. [8] Cascales et al. (2003) Nat. Rev. Micro."
121.0,"Introduction: Organic (polymeric) semiconductors (OSCs) are readily processible,leading to numerous advantages over traditional inorganic semiconductors.[1] These advantagesinclude the ability to be fine-tuned for properties such as solubility, thermal processing, andoptoelectronic properties, which allows OSCs to be leveraged for a variety of applications.[2]Through this molecular design, the charge carrier mobility of OSCs has been improved over thepast three decades by seven orders of magnitude.[2] OSCs have been targeted for use in many futuretechnologies, such as organic thermoelectric devices and organic solar cells, which can be used asalternative, green energy sources.One challenge in realizing this potential is the inherent structural and electronic disorder inpolymers used as OSCs. In analogue to inorganic semiconductors, OSCs can be doped to increaseelectron or hole conductivity. These dopants take the form of small acceptor/donor molecules,which can be introduced into the polymer matrix a variety of ways. These methods include mixingthe polymer and dopant in solution (solution doping), immersing or casting the dopant solution ontop of the previously-cast polymer film (sequential doping), and subliming the dopant into thepreviously-cast polymer film (vapor doping). Although solution doping can be utilized for scale-up procedures such as roll-to-roll processing, solution doping leads to polymer aggregation andeventual precipitation, which leads to poor quality films. This causes a lower conductivity than assequential and vapor doping, which have better local and long range ordering.[3]Despite the progress in doping methods, the dynamics for molecular doping into polymerfilms are not well known. This is due to the complexity of the charge transfer mechanism ofmolecular dopants in OSCs. In consequence, I propose to develop an easy-to-use platform to studythe dynamics of OSC doping in situ, which will reveal both fundamental doping mechanisms aswell as efficient and effective doping methods. The Institute for Molecular Engineering (IME) atThe University of Chicago is a vibrant place for collaboration, and in conjunction with the Rowangroup (synthetic) developing novel polymers for OSCs and the de Pablo group (computational)modelling advanced doping mechanisms, this platform would provide a method for probing thedynamics and optimization of a polymer/dopant pairing. Further understanding on the dynamicsof OSC doping will inform further fine-tuning of OSCs and their development for use in novel,alternative-energy sources.Preliminary Results: In order to develop a platform for studying the dynamics of doping,I have used a model polymer-dopant pairing of Poly(3-hexylthiophene) (P3HT) and 2,3,5,6-Tetrafluoro-7,7,8,8-tetracyanoquinodimethane (F4TCNQ). P3HT has been widely studied as aconductive polymer due to its processability and ability to form an ordered semi-crystallinemorphology. The conductivity of doped P3HT has been shown to increase six orders of magnitudefrom pristine to highly doped states.[5] Our custom-built chamber allows for measurement of insitu conductivity response to doping (Fig. 1), which is crucial for this platform. I have performed) mc/S(y t ivit112 ... 050 )m c/S(ytivitcudnoC111111 000000 ------ 165432100R R Ru u un n n 1 2 3Dopi1 n0 g1 time (s) 102R RR u uu n nn 2 31 F coPsloaon3i gmg nH-u dplTour lee g-tchFst ir.4opeT2 nleoIC:ntdNsaeoQtIsta fnespthoaaonrksaswi et etnuestc regime, showinguA B d n 0.5 Onset Linear Saturation growth from 2E-6 to 2Figure 1: (A) Chamber holds electrode array with o C regime regime regime S/cm over nine0.0 minutes of vaportungsten contacts. (B) Chamber sits above0 200 400 600 doping. Data collectedsubliming dopant, with contacts for in situconductivity measurements. Doping time (s) 14 Sept., 16:00 CST.1Mark DiTusa NSF GRFP Research Statementinitial conductivity measurements on P3HT/F4TCNQ polymer-dopant pairing spun coat onto aninterdigitated electrode array (IDA) we designed in the Pritzker Nanofabrication Facility atUChicago. These samples were vapor doped in our chamber for over nine minutes while in situconductivity measurements were made. Dopant mass, surface area, and doping temperature wereheld constant between measurements. These measurements showed a profile that increased sixdecades in close agreement with multiple literature values.[1,4,5] These measurements were shownto be consistent over multiple runs (Fig. 2). My measurements also showed three doping regimes:an onset regime, a linear regime, and a saturation regime. These three regimes, which has not beenpreviously reported in literature, will be individually probed for evidence on the dynamics ofmolecular dopants during the doping process. I have also conducted Grazing-Incidence Wide-Angle X-ray Scattering (GIWAXS) on pristine P3HT and P3HT doped with F4TCNQ at the 8-ID-E beamline in the Advanced Photon Source (APS) at Argonne. This technique showed us detailedinformation about the crystallinity of the film and how the dopant disrupts this structure. Thesemeasurements indicate that, for P3HT, the polymer backbone spacing is reduced and sidechainspacing increased by the presence of molecular dopant.Research Plan: With the platform for measuring conductivity in situ complete, I plan touse this platform in conjunction with complementary characterization techniques to study novelpolymer-dopant systems. These polymer-dopant systems will be provided by our collaborationwith the Rowan groups within the Institute for Molecular Engineering at UChicago. This projectalso allows me to be trained further at the Pritzker Nanofabrication Facility to produce theinterdigitated electrode arrays necessary to measure polymer-dopant properties in situ.I will employ a complementary group of characterization techniques to probe these systems.UV-Vis-NIR spectroscopy in conjunction with FTIR spectroscopy will be used to identify chargedspecies in films at all three doping regimes, allowing us to measure the concentration of chargecarriers in the polymer films. Raman spectroscopy and microscopy will be used to measure andmap the distribution of charge carriers in our systems in different doping regimes. ConductiveAtomic Force Microscopy will allow us to map conductivity on the surface of our systems. Thesetechniques will occur at the Materials Research Center at UChicago, an NSF MRSEC facility.Our relationship and proximity with Argonne Nation Laboratory allows us to utilizeadvanced techniques to characterize the polymer-dopant system. Synchrotron (high energy) X-rays are required for this project to probe the small length scales of our polymer films. Aspreviously detailed, GIWAXS obtains measurements of the local crystallinity of the polymer film.Beamline 8-ID-E at the APS also has expertise in X-ray Photoelectron Correlation Spectroscopy,which allows for in situ measurement of the slow dynamics of the doping system. Resonant SoftX-ray Scattering at beamline 29-ID-D obtains morphology over large length scales (10-1000 nm).Conclusions and Broader Impacts: The data I will obtain from in situ measurements andcharacterizations will give us a more complete picture of how molecular dopants infiltrate andmodulate conductive polymers throughout the entire doping process. Through our collaborationswith the Rowan and de Pablo groups in the Institute for Molecular Engineering at UChicago, wewill be able to use our platform with novel polymer-dopant systems, aiding in the discovery ofsystems with high conductivities. This, in turn, will allow for the improvement of organicsemiconductor devices, furthering the development of OSCs for use in critical (opto)electronicapplications such as thermoelectrics and organic photovoltaics. Receiving the NSF GRFP willallow me to realize these goals and to present at public outreach events about the need foralternative energy sources and how my research brings these technologies closer to realization.1. Adv. Mater. 2017, 1703063 2. MRS Commun. 2015, 5 (3), 383-395 3. J. Mater. Chem. C. 2016, 4, 3454-3466 4.Macromolecules. 2017, 50 (20), 8140-8148 5. Phys. Rev. B. 2015, 91, 0852052"
122.0,"ranging applications. Robotic systems are perfectly suited for repetitive or dangerous constructiontasks, from brick laying and creating city infrastructure, to building extraterrestrial or disaster-relief structures. This latter application presents a formidable challenge in robotics: to enter anunknown and uneven environment and autonomously build pre-designed or adaptively designedstructures to stabilize the site and prepare it for human presence. Already, there are many designsfor emergency relief structures and space infrastructure that are well-suited for this type ofautonomous construction, but existing robotic systems are not able to build them.There are two primary approaches to improving construction capabilities. The firstapproach is to create complex systems that rely on high-accuracy perception, completerepresentation of surroundings, and precise movement and control. While this method could becapable of building a greater variety of structures, it has problems with cost, computation, androbustness that current technology cannot address. The second approach relies on distributedsystems that absorb high levels of error through mechanisms and control, rather than trying toperform perfect actions.This second approach can take great inspiration from biology. Termites, which buildmounds millions of times their own size to house their colonies, and beavers, which cobbletogether dams to adapt their environment for their habitation, demonstrate the extraordinarypotential of these systems. Additionally, the compliant or underactuated mechanisms that composemany animals show the potential for error-absorption and robustness in material choice andmechanism design.In this vein, some recent work has explored the use of robot collectives for construction.These systems take control and communication methods from biology, such as distributeddecision-making based on the state of the built structure, called stigmergy, and communicationthrough pheromones. In [1], a multi-robot system built simple structures with blocks usingstigmergy, and mimicked ""tagging"" the structure with pheromones by using color-coded LED's.In [2], a multi-robot system relied on a stored blueprint to build complex structures much largerthan an individual agent, and relied completely upon stigmergy for representation of the currentbuilt structure. Even more similar to termite construction, [3] presents an algorithm forconstruction of a ramp using amorphous material similar to the soil used by termites. These roboticsystems rely upon simple agents and control policies to absorb errors and robustly and efficientlybuild.Other work takes inspiration from the underactuated and soft mechanisms present in natureto make compliant robots. These soft robots are extremely effective at absorbing error; theirflexibility simplifies control and damps out unwanted perturbations. However, soft robots arepresently limited by difficulty of manufacture and poor performance of soft actuators. There existsa large body of work developing soft robots, but these concepts have not been applied toconstruction tasks.Research Plan: My aim is to enable collective construction that is robust and effective on uneventerrain. It will consist of a mechanical design phase and an algorithm design phase, supported bya foundation of tools to evaluate system success objectively.I. Metrics: First, I aim to develop a novel metric to quantify error tolerance in a multi-robotconstruction system. Presently, most metrics that would apply are within the realm of controltheory: metrics such as the size of zone of attraction, or the degree to which an action in the systemis passively stable. These are effective in characterizing aspects of a collective construction systemon the micro-level, in terms of individual actions, but fail to characterize the system on amacroscopic scale. I will create and validate a metric that effectively characterizes the response todisturbances and errors of a collective construction system. This will allow comparison of myfuture work with its biological counterparts, and will give the necessary basis for verifying acollective construction system.II. Physical System: I plan to create a physical robotic system capable of robust collectiveconstruction on uneven terrain. My research group at University at Buffalo, under Nils Napp, isthe foremost group exploring autonomous construction on uneven terrain, a broad and applicablesubset of the autonomous construction field. One approach that is almost untouched within thefield is the use of soft, compliant, or underactuated robots and robot components to increase errortolerance. In the field of behavioral robotics, soft robots are ideal: their simplified control andadaptable structures make them perfectly suited. However, the lack of effective untetheredactuation systems make them underutilized. I intend to use soft components in my robotic system,focusing on passive mechanisms and flexible-rigid interfaces to increase error tolerance withoutrelying upon soft actuation.Additionally, I will extend research I performed in the past year, developing a roboticplatform for construction over uneven terrain. I will modify it to be highly modular, allowing softcomponents to be swapped in and out easily, and enabling new directions of research involvingself-charging and even self-healing agents.III. Control System: I will develop new control methods to improve coordination and efficiencyin collective construction applications. Presently, there exist few control systems capable ofcontrolling multiple robots towards a construction objective over uneven terrain. One of the onlyexamples, presented in [3], makes non-navigable terrains navigable through deposition ofexpanding foam. With the Napp group at UB, I extended this in a paper submitted to ICRA thisyear, which modified the algorithm to work with a single-agent system and discrete objects: filledbags. I intend to generalize this work to construct any arbitrary structure, by developing newplanning policies for the order of voxel construction based upon the structure shell and otherparameters. Additionally, I will incorporate policies for a range of materials: continuous materialssuch as foam, and discrete amorphous objects such as filled bags.Broader Impact: The broader impact of the project lies in its motivation: autonomousconstruction can be used to save lives in disaster areas, and to build structures on different planets.Robots can stabilize buildings and make rubble navigable in areas of disaster, build levee walls toprevent flooding, build emergency shelters, and build structures on the moon and mars.Additionally, the project could have a parallel initiative in educational outreach, byincorporating high school and undergraduate students in important roles. Because the core of theproject is small, highly modular robots whose abilities are augmented through collaboration,undergraduates and even high school students can take part in construction of the robots whilelearning about robotics and experiencing the environment of a research lab.Further, these modular robots can be easily integrated into demonstrations in schools tofoster interest in robots and STEM in general. The coordinated robots could inspire elementary,middle, and high school students to become involved with robotics, and could form the foundationfor a program to increase college attendance in STEM fields.[1] M. Allwright, N. Bhalla, C. Pinciroli, M. Dorigo, M. All- wright, N. Bhalla, C. Pinciroli, and M. Dorigo,“Towards Autonomous Construction using Stigmergic Blocks,” 2017.[2] J. Werfel, K. Peterson, and R. Nagpal, “Designing Col- lective Behavior in a Termite-Inspired RobotConstruction Team,” Science, vol. 343, no. February, pp. 754–758, 2014.[3] N. Napp and R. Nagpal, “Distributed amorphous ramp construction in unstructured environments,” SpringerTracts in Advanced Robotics, vol. 104, pp. 105–119, 2014."
123.0,"VehiclesBackground and Motivation: Solar-assisted electric vehicles (SEVs) are the ultimatezero-emission vehicles since they do not contribute to greenhouse gas emissions. However, dueto the low power output of the photovoltaic array, widespread use of SEVs can only be realizedif the vehicle system is highly energy efficient. Such rigorous optimization for limited powerapplications will lead to universal efficiency increases in vehicles of all kinds. One major boostin vehicle efficiency is to utilize in-wheel motors. For example, Protean Electric’s in-wheelmotors were found to increase the 244 mile range of the Tesla Roadster by 14%.1However, this​​pivotal technology also increases unsprung mass; in Protean’s case, 30 kg at each wheel. Theaddition of unsprung mass causes more energy losses in the shock absorbers due to increasedvibrational forces in the suspension.2 It also adds complications traditional vehicle control for​ride comfort and safety.3 I would like to propose a comprehensive approach to maintain ride​comfort and vehicle safety while harvesting suspension energy loss so that in-wheel motors canbecome the enabling technology for SEV’s.Research Method: While working at the Advanced Transportation Energy Center (ATEC) and​Future Renewable Energy and Electricity Distribution Management (FREEDM) Center at NorthCarolina State University (NCSU), I will develop multi-level control for an adaptive regenerativeshock absorber (ARSA), which will lead to improvements in electric vehicle efficiency. Anexisting high efficiency ARSA will be optimized to make it comparable in weight to traditionalshock absorbers. The novelty of the design will be the adaptive control strategy, which adjustsARSA parameters to changing road conditions to optimize safety, comfort, and efficiency.The first layer of the control strategy will determine if an energy consumptive active orenergy regenerative semi-active control should be used. The second layer will use an adaptivealgorithm to adjust ARSA parameters based on vehicle response to road excitation. At the thirdlevel, an energy optimization strategy will ensure that the most energy is captured based on thecorresponding mode of operation. The dynamic nature of the suspension will require quickresponse from the control scheme so the controller will be implemented in a closed-loop withnegative feedback.Intellectual Merit: The SEV is a highly interconnected system and understanding the​relationships between its subsystems can increase its overall efficiency. This work will result inmore intelligent suspensions that allow in-wheel motors to make better electric vehicles,including those assisted or driven by solar-power – the pinnacle of sustainable transportation.The potential of the ARSA is recognized among automotive suspension engineersworldwide.4,5,6 Previous work has resulted in the development of suspension control algorithms​optimized for specific conditions or objectives.7 An adaptive, multi-level control scheme will​allow all benefits of the ARSA in dynamic situations.Facilities: NCSU is the ideal place for this research due to the extensive resources available and​established collaborations. At FREEDM, I will have access to the dSPACE vehicle chassissimulator, which serves as the vehicle model, to quickly simulate the ARSA and develop controllogic via software-in-the-loop (SIL). Once my design is constructed, I can integrate it with the​Lab Rapid Assessment Tool (LabRAT), a bare-skeleton vehicle made for bench testingcomponents, at ATEC. ATEC also has an all-wheel drive dynamometer which I will use to getcontrol data for comparison to simulation and road tests. The solar car team, SolarPack, willprovide access to the prototype SEV for full integration of the prototype ARSA. Connectionsthrough SolarPack, such as the Haas Formula 1 racing team, can be leveraged to arrange premiertesting facilities for accurate practical experiments.Timeline:1. Year One - Simulation and Design​ ​ ​​Objective: Design and simulate a highly efficient regenerative shock absorber with​​semi-active and active controlsMethodology: Literature review and optimization of existing ARSA topology. Use​​dSPACE simulator to implement active and semi-active controls to prototype which will beintegrated in future multi-layer control. Simulation using stochastic road models will be used toguide design.2. Year Two - Active Regenerative Shock Absorber Experimentation​​ ​​ ​​Objective: Build ARSA and experiment with control parameters to optimize both active​​and semi-active logic.Methodology: Integrate the ARSA into the LabRAT to iterate the control parameters in​​each control strategy.3. Year Three - ARSA Integration, Controls Assimilation and Testing​ ​ ​​​Objective: To evaluate and improve robustness of control scheme which will result in an​​ ​ ​ ​ ​ ​ ​ARSA that is ready for integration to the SEV.Methodology: The ARSA and multi-layer control will be integrated to the SEV for​​experimentation. Accurate road experiments will be done to iterate to robust control. Robustnesswill be assessed by designing to International Organization for Standardization requirements.Broader Impact: With the anticipation that societal and economic growth will require increased​movement of people and things, we must ensure that our methods of transportation are clean andefficient. ARSAs are a step towards a better future where transportation is not only sustainable,but more intelligent. The SEV represents the most efficient vehicle topology and will benefitfrom the development of the ARSA because it will enable the in-wheel motor. Using thein-wheel motor will result in improved vehicle range by decreasing energy usage of thedrivetrain. The proposed control strategy is not constrained to passenger vehicles and can beadapted to all ground vehicle applications.The findings will be communicated in IEEE and SAE conferences and journals, and thetechnology will be demonstrated in solar car outreach activities, such as the EV Challenge, theScience Olympiad, and minority engineering summer transition programs to engage early collegeand high school students in automotive engineering research. SolarPack has already arranged toshow our SEV at future North Carolina Science & Engineering Fairs, which will be a great wayto inspire K-12 students to break barriers in the automotive industry through research. The NSFGraduate Research Fellowship will allow me to engage sustainable transportation research on adeeper level and focus on contributing unique insights to the automotive engineering field.References:1 ​Watts. A et al., SAE International, 9-10, 2010​ ​​​2 ​Anderson M. et al., Advanced Vehicle Control, 2-3, 2010​ ​3 ​Rojas. A.E. et al., SAE International, 14, 2010​ ​4 ​Shi D. et al., Smart Materials and Structures, 8-9, 2015​ ​5 ​Zuo L. et al., Smart Materials and Structures, 2010​ ​6 ​Sabzehgar R. et al., IEEE/ASME Transactions on Mechatronics, 2013,​ ​7 ​Huang K. et al., International Journey of Automotive Technology, 2011​ ​"
124.0,"Radiolytic Production of Gadolinium Nanoparticles for Cancer TherapyHypothesis: The average particle size of the gadolinium will decrease as total absorbed doseincreases within a nuclear reactor.Background and Introduction: In the United States, cancer is the second leading cause of deathand is a major public health problem worldwide [1], [2]. There were estimated to be 1,685,210new cancer cases and 595,690 cancer deaths in the U.S. alone in 2016 [2]. Current treatment forvarious cancers include chemotherapy, radiation therapy, hormone therapy, and surgery.Although survival rates have improved from these treatments, each one has its drawbacks andlimitations. Chemotherapy, for example, distributes the toxic therapeutic agents throughout theentire body, thus, damaging both cancerous and normal cells. This limits the amount of dose tothe cancer cells while causing adverse side effects to the patient including weakness, hair-loss,and organ dysfunction [1].An interest in nanoparticles (NPs) has increased over the last decade for researchersbecause of their ability to carry both drugs and imaging probes throughout the body [1].Additionally, they can be uniquely designed to target the molecules of diseased tissues, thus,having the potential to increase the dose to cancerous cells while decreasing the dose to healthytissues and organs [3].Gadolinium neutron capture therapy (GdNCT) isanother potential method for the treatment of cancer [4].GdNCT takes advantage of the energy released whenstable gadolinium-157 (157Gd) is bombarded by aneutron, producing an excited 158*Gd that decays bygamma emission, conversion electrons, and Augerelectrons (Figure 1) [4] [5]. 157Gd is appealing in NCTfor its extremely high neutron absorption cross sectionFigure 1: Gd decay scheme(255000 barn) and short path length in tissue, restrictingcell death to the gadolinium-containing regions only [5].The objective of this research proposal is to fabricate gadolinium nanoparticles forGdNCT applications by irradiation in a nuclear reactor. Average particle sizes of less than 100nm are desired so that they can pass through the body and localize around tumors. Once the NPshave gathered around the tumor, neutron irradiation can occur using either a nuclear reactor or aneutron accelerator, destroying the tumor with minimal damage to the surrounding healthytissues and organs.Research Plan: The first step for this research project will be to determine the likely materialcomponents. A form of the gadolinium precursor, a reducing agent, a particle capping agent, anda solvent to prevent excess agglomeration will need to be used to create the gadolinium solution[6]. The solution will be distributed into 8 labelled vials, with Sample 1 being used as the un-irradiated reference sample. Samples 2-8 will be irradiated in the High Flux Isotope Reactor at aconstant power (200kW) for times ranging from 30 to 1200 seconds (Table 1.)Table 1 – Irradiation TimesSample 2 3 4 5 6 7 8Irradiation30 60 180 300 600 900 1200Time (s)NSF Graduate Research Statement Mikayla MolnarI will complete dose calculations in order to determine the total absorbed dose for each sampleirradiated in the reactor. The samples will be subject to both incident neutrons and gammasradiation. Therefore, the dose rate D is given by Equation (1)t𝐷 = 𝐾 +𝐷 (1)𝑡 𝑛 𝛾Where K is the neutron kerma rate and Dγ is the gamma dose rate. These dose rates will bendetermined using a Monte Carlo N-Particle (MCNP) code simulation of the reactor.The samples will then be distributed onto a silicon wafer and left to dry. It is importantthat the radiation levels of the samples are safe and within NRC/reactor limits before removingthem from the reactor for analysis. I will then image each sample under a scanning electronmicroscope (SEM) to determine the particle size distribution. An Energy Dispersive X-raySpectroscopy (EDS) analysis will also be performed to verify the elemental composition of theparticles.Intellectual Merit: My background as a nuclear engineer is essential for the fulfillment of thisproject. It will combine my understanding of radiochemistry, reactor physics, and electronimaging with an engineering perspective. I completed a similar process for the production ofboron nanoparticles in my Reactor Laboratory II class at Missouri University of Science andTechnology, so I have first-hand experience in the process that needs to unfold. A much morecomprehensive and in-depth analysis will need to be taken, however. I plan to collaborate withmembers of Oakridge National Laboratory to complete the irradiation procedure and use myknowledge of MCNP and scanning electron microscopy to determine the total absorbed dose foreach irradiated sample.Broader Impact: GdNCT is becoming a safe and effective way to destroy cancer cells withminimal damage to surrounding healthy cells. If the results are successful, my research willprovide an efficient and valuable mean for creating gadolinium nanoparticles. This will makeGdNCT cheaper and more accessible for cancer patients, resulting in the potential savior ofcountless future lives.[1] K. T. Nguyen, ""Targeted Nanoparticles for cancer therapy: Promises and challenges,""Journal of Nanomedicine & Nanotechnology, vol. 02, no. 05, 2011.[2] R. L. Siegel, K. D. Miller, and A. Jemal, ""Cancer statistics, 2016,"" CA: A CancerJournal forClinicians, vol. 66, no. 1, pp. 7–30, Jan. 2016.[3] R. Subbiah, M. Veerapandian, and K. S. Yun, ""Nanoparticles: Functionalization andMultifunctional applications in biomedical sciences,"" Current Medicinal Chemistry, vol.17, no. 36, pp. 4559–4577, Dec. 2010.[4] G. A. Miller, N. E. Hertel, B. W. Wehring, and J. L. Horton, “Gadolinium NeutronCapture Therapy,” Nuclear Technology, vol. 103, no. 3, pp. 320–331, Sep. 1993.[5] C. Salt, A. J. Lennox, M. Takagaki, J. A. Maguire, and N. S. Hosmane, “Boron andgadolinium neutron capture therapy,” Russian Chemical Bulletin, International Edition,vol. 53, no. 9, pp. 1871–1888, Sep. 2004.[6] A. Abedini et al., “A review on radiation-induced nucleation and growth of colloidalmetallic nanoparticles,” Nanoscale Research Letters, vol. 8, 2013."
125.0,"Background literature. Introductory chemistry courses are often delivered lecture-style andassessed with multiple-choice exams in classes of hundreds of students, often lacking opportunityfor realistic scientific activity.1 Students often develop the notion that scientific knowledge maybe acquired from external authorities rather than viewing science as a sense-making endeavor2 andas such they may default to rote learning, as material seems removed from everyday experiences.3Often, students’ understandings of the nature of scientific knowledge, that is, their epistemologicalunderstandings of science, are not explicitly addressed in traditional curriculum, yieldingstudents, some who complete STEM degrees, who do not understand how science progresses.4Evidence suggests that undergraduate chemistry students possess significantly less sophisticatedepistemologies than practicing chemists but that sophistication of undergraduates’ epistemologiesare positively correlated with authentic experience. However, processes by which shifts in studentepistemologies occur remain unclear.5For instance, one authentic scientific activity identified by the National Research Council’sA Framework for K-12 Science Education, is that of scientific modeling.6 However, becausestudents often perceive scientific claims as “proven,” they may not consider the nature and purposeof scientific models or a models’ associated assumptions, known as metamodeling knowledge.7Students may have different metamodeling beliefs in different contexts.8 For example, studentshave demonstrated particular difficulty reasoning with mathematical models in meaningful ways.9In contrast, expert scientists create and use models purposefully, to explain and predict phenomena,and generally possess modeling epistemologies that are far more stable and contextuallyappropriate.8 Evidence suggests that incorporating authentic modeling activities into introductorycourses can support students’ development of expert-like epistemological ideas.10 Little is knownabout the mechanisms by which students’ epistemologies shift in response to engagement withmodeling activities, but understanding these mechanisms could inform practices for instruction onscientific modeling epistemology. I intend to identify the moments in which students’epistemological ideas are challenged, how and why students’ epistemological ideas change,and the factors that contribute to such realizations in a modeling-focused classroom setting.Research questions. 1) How do students rationalize their epistemological decisions whileengaging in collaborative modeling activities in introductory chemistry contexts? 2) How domodeling activities and instructor facilitation contribute to shifts in epistemological ideas?Methods. Because students are often unaware of their own epistemologies, it is not reasonable toask students to describe their epistemological ideas.11 Rather, it is logical to analyze studentdiscourse to deduce the ways in which students think about the nature of scientific knowledge.Furthermore, as I am interested in the process of students’ shifting epistemologies toward thoseappropriate in chemistry contexts rather than static knowledge states, microgenetic analysis, adetailed, moment-by-moment analysis of the processes which contribute to learning, is appropriatefor developing a nuanced understanding of change processes and the factors which contribute tothem, such as design features of classroom activities or instructor-student interaction.12My current graduate research is aimed at developing and testing modeling-focusedcollaborative learning activities that support students’ understanding of the nature and purpose ofmodels. As part of this project, I plan to examine pre- and post-intervention survey data to gain asense of the impact of the activities on students’ metamodeling knowledge (see PersonalStatement). Support from the GRFP would allow me to expand upon this work to conduct amicrogenetic analysis of classroom discourse as collaborative modeling activities take place,which would provide a finer-grained understanding of the mechanisms by which students’epistemological ideas shift toward more expert-like conceptions. Such a fine-grained account ofKatherine Lazenby | NSF GRFP Graduate Research Plan Statement 2how collaborative learning activities support students’ epistemologies of modeling would provideinsight for educators on how to orchestrate learning environments conducive for studentdevelopment of robust understanding of the nature of scientific inquiry. While common in themathematics education research community, few discourse analysis studies and fewer stillmicrogenetic studies in particular, exist in chemistry contexts that would provide the kind ofdetailed mechanistic understanding that would support instructor facilitation efforts.For this study, I will collect multiple sources of data including video recordings of wholeclass discussion and small group work during collaborative modeling-focused activities, andwritten work generated during the modeling activities. The collaborative nature of the modelingactivities will necessitate that students express their ideas about models to other group members,providing data about students’ thought processes. Since students will complete three modelingactivities over the course of a semester, these data will allow me to observe the changes in theways students discuss epistemological ideas about models over time.As an initial analytical framework for helping me to identify epistemological shifts inclassroom discourse, I will adapt Grünkorn et al.’s developmental progression of epistemologicalviews of modeling on five subscales (nature, purpose, and changeability of models, testing modelsand multiple models for a single phenomenon). Grünkorn et al.’s progression ranges from naïve-realistic interpretations of models as mere copies of phenomena, to constructivist views of modelsas the scientific products of developing explanations about the natural world, an idea whichstudents should ideally develop as they mature into individuals capable of contributing to science.This framework would allow for the characterization of the sophistication of student modelingepistemologies and for determining whether engaging in modeling activities supports shifts towardmore expert-like views of models.13In completing this project, I will draw on my experience analyzing qualitative data.Additionally, my adviser has experience in classroom discourse analysis and will serve as avaluable resource during the analysis for this study.14Summary of Intellectual Merit. The proposed research will provide insight about how studentsreason about the nature of models in chemistry. Since models are key tools used by scientists tocommunicate and explain the natural world, it is important that introductory courses can providestudents with opportunities to develop scientifically appropriate understanding of models’ natureand purpose. Additionally, microgenetic studies of chemistry learners are few; to my knowledge,this analytical technique has never been used in undergraduate chemistry contexts, but thesemethods are powerful for investigation of agents that contribute to shifts in student ideas.Summary of Broader Impacts. The proposed research will inform instruction on scienceepistemologies. Students who understand the nature of scientific inquiry are more likely to engagemeaningfully in subsequent coursework and experience academic success.15 Evidence-basedinstruction on epistemologies can support student success. Furthermore, students will be able toapply knowledge of the nature of scientific knowledge beyond classroom chemistry contexts tounderstand how scientists model globally-relevant phenomena such as climate change.(1) Smith, A. C.; Stewart, R.; Shields, P.; Hayes-Klosteridis, J.; Robinson, P.; Yuan, R. Cell Biol. Educ. 2005, 4 (2), 143–156. (2) Hofer, B.K. Contemp. Educ. Psychol. 2004, 29 (2), 129–163. (3) Songer, N. B.; Linn, M. C. J. Res. Sci. Teach. 1991, 28 (9), 761–784. (4) Clough, M.P. Sci. Educ. 2006, 15 (5), 463–494. (5) Samarapungavan, A.; Westby, E. L.; Bodner, G. M. Sci. Educ. 2006, 90 (3), 468–495. (6) NationalResearch Council. Washington, DC: The National Academies Press 2012. (7) Schwarz, C. 2002. Proceedings of Int. Conf. of Learning Sci.(8) Hammer, D.; Elby, A.; Scherr, R. E.; Redish, E. F. Transf. Learn. Mod. Multidiscip. Perspect. 2005, 89. (9) Brandriet, A.; Rupp, C.;Lazenby, K.; Becker, N. Chem. Educ. Res. Pract. (under review). (10) Schwartz, R. S.; Lederman, N. G.; Crawford, B. A. Sci. Educ. 2004,88 (4), 610–645. (11) Berland, L.; Crucet, K. Sci. Educ. 2016, 100 (1), 5–29. (12) Siegler, R. S. Handb. Child Psychol. 2006. (13) Grünkorn,J.; zu Belzen, A. U.; Krüger, D. Int. J. Sci. Educ. 2014, 36 (10), 1651–1684. (14) Becker, N.; Stanford, C.; Towns, M.; Cole, R. Chem. Educ.Res. Pract. 2015, 16 (4), 769–785. (15) Tsai, C.; Liu, S. Int. J. Sci. Educ. 2005, 27 (13), 1621–1638."
126.0,"One of the most important unknowns in high-z extragalactic astronomy is how reionizationoccurred; during the epoch of reionization (z≈10–6; EoR), neutral hydrogen (HI) dominatesthe intergalactic medium (IGM). HI attenuates radiation from early stellar populations,masking galaxies from detection. Understanding how and when reionization occurs can revealwhether or not these young galaxies provided the necessary ionizing radiation to completelyreionize the IGM by z(cid:39)6, one billion years after the Big Bang. However, due to the highredshift-space this implies, spectroscopic observations are limited as these galaxies are veryfaint, with their UV spectral features pushed out to near-infrared (NIR) wavelengths.My background in NIR spectroscopy and observational astronomy has prepared me toassist in addressing this question. I propose using Lyα and CIII] to investigate theproperties and ionization state of young galaxies using ground- and space-basedtelescopes, the structure and distribution of HI in the IGM and the circumgalac-tic medium (CGM) of certain galaxies, and implications for the evolution of theneutral fraction of the IGM throughout the EoR. The individual points proposed willbe summarized as follows: (i) small scale testing and building of an analysis technique, (ii)distribution of galaxies and evolution of neutral fraction, and (iii) metallicities of galaxies. Byunderstanding more about the IGM during the reionization era and of the galaxies within it,we can further constrain the properties of current galaxy evolution and reionization models.Small scale testing & building of analysis technique: In the search for galaxies during theEoR, Lyman-α (λ =1216˚A; Lyα) traditionally has been the best tracer both in photometric0surveys and spectroscopic follow-up. This is in part due to the increasing fraction of UVbright galaxies (with strong Lyα emission) with increasing redshift [1]. By measuring theescape fraction of Lyα many studies have inferred an increasingly neutral fraction of theIGM at z>6.5 [2]. One complication of Lyα is its attenuation due to HI, pushing emissionhundreds of km/s redwards of the galaxy’s systemic (or true) redshift. A recent methoduses a complementary spectroscopic tracer not attenuated by HI, with the UV metal lineCIII] (λ =1907,1909˚A) as the most robust according to mid-z (z(cid:39)2–3) analog surveys [1,3,4,5].0In my current work, I measure CIII] H-band emission of galaxies found via Lyα emissionusing Keck+MOSFIRE [6]. With both measurements, I compare the systemic (CIII]) andattenuated (Lyα) redshifts, shedding light on the structure and ionization of the CGMof these galaxies and surrounding IGM. From my previous work experience, I havedeveloped a proficiency in coding which enabled me to gain a close familiarity withthe MOSFIRE data reduction pipeline (DRP), having to dive into the sourcecode to fixbugs often encountered when working with incredibly faint emission lines and less commondithering patterns for standard star observations. I wrote code to optimally extract my 1Dspectra, adapted from Horne (1986), boosting the S/N of my detection. Using a marriage ofIRAF and Python, I developed code that can track the photometric variability of my datafrom a frame-to-frame basis – important when working with faint emission lines.Distribution of galaxies and evolution of neutral fraction: Using the foundation built from myprevious work, I will build a statistical sample of galaxies during the last half ofthe reionization era (z(cid:39)8–6.5) in order to track the evolution of the Lyα escapefraction as a function of redshift. Using my optimized extraction technique to improveTaylor A. Hutchison 2measurements, I will use this dataset to constrain the offset between these galaxies’ systemicand attenuated redshifts. This work will significantly increase the sample of high-z galaxieswith both Lyα and CIII] measurements. In addition, it will provide a more significantcomparison with z(cid:39)2–3 LAEs and LBGs, mid-z analogs commonly used in these analyses.A current complication for this project is the lack of a complete spectroscopic sample ofLAEs at z≥6.5 with even fewer galaxies with systemic measurements (via UV metal lines orthe [OIII] doublet; λ = 4959,5007˚A). This is partly due to these lines being redshifted to0NIR and mid-IR wavelengths; the latter is impossible to detect with ground-based telescopes– it is useful to note that during the EoR, both [OIII] and the UV metal lines fall in therange of NIRCam on JWST. As a first approach to resolving this, I will take the currentsample of confirmed LAEs at z(cid:39)6.5–8 and measure their CIII] emission, using myoptimized extraction technique to improve measurements. This has already been attemptedfor some galaxies [4], providing useful lower limits for determining exposure times andpotential telescopes for future observations, including JWST. We are planning proposals forthe first JWST cycles for this work. I will then take advantage of the deep multi-wavelengthimaging campaigns available to me, including the CANDELS datasets [7]. Moreover, I ampart of a proposal to increase the sample of z∼7 galaxies with Keck+MOSFIRE, with earlyindications that the proposal has so far been successful. Finally, as a scientific collaborator onan ERS JWST proposal, I will prepare for access to that data – understanding what spectraI will be looking for from running binary stellar population models (eg. BPASS), scaled tomatch expected bandpass magnitudes, through the JWST exposure time calculator.With a large, statistical sample of LAEs at z(cid:39)6.5–8 with both Lyα and CIII], I will beable to further constrain the amount of hard radiation emitted from these galaxies; as shownwith mid-z analogs, this is closely linked to the transmission of Lyα through the CGM [5].By tracking its evolution through the last half of the EoR, I can inform current reionizationmodels. Lastly, through gathering my sample I will map out the distribution of thesegalaxies, identifying whether galaxies with large escape fractions are tracing over-denseluminous regions, located within large ionized bubbles [3,8].Metallicities of galaxies: Using my high-z sample of galaxies with deep ground- and space-based spectroscopy, I will study the metallicity of galaxies in the EoR. From a ratio of thefluxes of the CIII] doublet, when measurable, I can infer an estimate of the electrondensity of the gas in the CGM. This is closely linked to the metallicity of the CGM,which directly affects the velocity offset of Lyα emission. Not only do recent studies indicatethat a neutral CGM attenuates Lyα photons, diminishing the effect the IGM will have, theyalso suggest (from mid-z analogs) a strong link between the profile of Lyα emission and theproperties of the gas within the CGM [5]. This can be incredibly important as some high-zgalaxies have been found to have more symmetric Lyα profiles, contrary to the archetypalasymmetric shape, thought to be indicative of high star formation and galactic winds [6].Understandingthe rateand distributionof reionization, including thefactors andprocessesresponsible for it, remains one of the most important unknowns in extragalactic astronomy.My work will aim to shed more light on this question, enabling more precise modeling ofthiserawiththeintentionofprobingeverfurtherbackintimetowardstheyoungestofgalaxies.References: [1] Stark et al. 2017 [2] Dijkstra 2014 [3] Stark et al. 2015ab,2016 [4] Matthee et al. 2017 [5] Erbet al. 2014 [6] Finkelstein et al. 2013 [7] Grogin et al. 2011 [8] Furlanetto et al. 2004"
127.0,"One of the most important unknowns in high-z extragalactic astronomy is how reionizationoccurred; during the epoch of reionization (z≈10–6; EoR), neutral hydrogen (HI) dominatesthe intergalactic medium (IGM). HI attenuates radiation from early stellar populations,masking galaxies from detection. Understanding how and when reionization occurs can revealwhether or not these young galaxies provided the necessary ionizing radiation to completelyreionize the IGM by z(cid:39)6, one billion years after the Big Bang. However, due to the highredshift-space this implies, spectroscopic observations are limited as these galaxies are veryfaint, with their UV spectral features pushed out to near-infrared (NIR) wavelengths.My background in NIR spectroscopy and observational astronomy has prepared me toassist in addressing this question. I propose using Lyα and CIII] to investigate theproperties and ionization state of young galaxies using ground- and space-basedtelescopes, the structure and distribution of HI in the IGM and the circumgalac-tic medium (CGM) of certain galaxies, and implications for the evolution of theneutral fraction of the IGM throughout the EoR. The individual points proposed willbe summarized as follows: (i) small scale testing and building of an analysis technique, (ii)distribution of galaxies and evolution of neutral fraction, and (iii) metallicities of galaxies. Byunderstanding more about the IGM during the reionization era and of the galaxies within it,we can further constrain the properties of current galaxy evolution and reionization models.Small scale testing & building of analysis technique: In the search for galaxies during theEoR, Lyman-α (λ =1216˚A; Lyα) traditionally has been the best tracer both in photometric0surveys and spectroscopic follow-up. This is in part due to the increasing fraction of UVbright galaxies (with strong Lyα emission) with increasing redshift [1]. By measuring theescape fraction of Lyα many studies have inferred an increasingly neutral fraction of theIGM at z>6.5 [2]. One complication of Lyα is its attenuation due to HI, pushing emissionhundreds of km/s redwards of the galaxy’s systemic (or true) redshift. A recent methoduses a complementary spectroscopic tracer not attenuated by HI, with the UV metal lineCIII] (λ =1907,1909˚A) as the most robust according to mid-z (z(cid:39)2–3) analog surveys [1,3,4,5].0In my current work, I measure CIII] H-band emission of galaxies found via Lyα emissionusing Keck+MOSFIRE [6]. With both measurements, I compare the systemic (CIII]) andattenuated (Lyα) redshifts, shedding light on the structure and ionization of the CGMof these galaxies and surrounding IGM. From my previous work experience, I havedeveloped a proficiency in coding which enabled me to gain a close familiarity withthe MOSFIRE data reduction pipeline (DRP), having to dive into the sourcecode to fixbugs often encountered when working with incredibly faint emission lines and less commondithering patterns for standard star observations. I wrote code to optimally extract my 1Dspectra, adapted from Horne (1986), boosting the S/N of my detection. Using a marriage ofIRAF and Python, I developed code that can track the photometric variability of my datafrom a frame-to-frame basis – important when working with faint emission lines.Distribution of galaxies and evolution of neutral fraction: Using the foundation built from myprevious work, I will build a statistical sample of galaxies during the last half ofthe reionization era (z(cid:39)8–6.5) in order to track the evolution of the Lyα escapefraction as a function of redshift. Using my optimized extraction technique to improveTaylor A. Hutchison 2measurements, I will use this dataset to constrain the offset between these galaxies’ systemicand attenuated redshifts. This work will significantly increase the sample of high-z galaxieswith both Lyα and CIII] measurements. In addition, it will provide a more significantcomparison with z(cid:39)2–3 LAEs and LBGs, mid-z analogs commonly used in these analyses.A current complication for this project is the lack of a complete spectroscopic sample ofLAEs at z≥6.5 with even fewer galaxies with systemic measurements (via UV metal lines orthe [OIII] doublet; λ = 4959,5007˚A). This is partly due to these lines being redshifted to0NIR and mid-IR wavelengths; the latter is impossible to detect with ground-based telescopes– it is useful to note that during the EoR, both [OIII] and the UV metal lines fall in therange of NIRCam on JWST. As a first approach to resolving this, I will take the currentsample of confirmed LAEs at z(cid:39)6.5–8 and measure their CIII] emission, using myoptimized extraction technique to improve measurements. This has already been attemptedfor some galaxies [4], providing useful lower limits for determining exposure times andpotential telescopes for future observations, including JWST. We are planning proposals forthe first JWST cycles for this work. I will then take advantage of the deep multi-wavelengthimaging campaigns available to me, including the CANDELS datasets [7]. Moreover, I ampart of a proposal to increase the sample of z∼7 galaxies with Keck+MOSFIRE, with earlyindications that the proposal has so far been successful. Finally, as a scientific collaborator onan ERS JWST proposal, I will prepare for access to that data – understanding what spectraI will be looking for from running binary stellar population models (eg. BPASS), scaled tomatch expected bandpass magnitudes, through the JWST exposure time calculator.With a large, statistical sample of LAEs at z(cid:39)6.5–8 with both Lyα and CIII], I will beable to further constrain the amount of hard radiation emitted from these galaxies; as shownwith mid-z analogs, this is closely linked to the transmission of Lyα through the CGM [5].By tracking its evolution through the last half of the EoR, I can inform current reionizationmodels. Lastly, through gathering my sample I will map out the distribution of thesegalaxies, identifying whether galaxies with large escape fractions are tracing over-denseluminous regions, located within large ionized bubbles [3,8].Metallicities of galaxies: Using my high-z sample of galaxies with deep ground- and space-based spectroscopy, I will study the metallicity of galaxies in the EoR. From a ratio of thefluxes of the CIII] doublet, when measurable, I can infer an estimate of the electrondensity of the gas in the CGM. This is closely linked to the metallicity of the CGM,which directly affects the velocity offset of Lyα emission. Not only do recent studies indicatethat a neutral CGM attenuates Lyα photons, diminishing the effect the IGM will have, theyalso suggest (from mid-z analogs) a strong link between the profile of Lyα emission and theproperties of the gas within the CGM [5]. This can be incredibly important as some high-zgalaxies have been found to have more symmetric Lyα profiles, contrary to the archetypalasymmetric shape, thought to be indicative of high star formation and galactic winds [6].Understandingthe rateand distributionof reionization, including thefactors andprocessesresponsible for it, remains one of the most important unknowns in extragalactic astronomy.My work will aim to shed more light on this question, enabling more precise modeling ofthiserawiththeintentionofprobingeverfurtherbackintimetowardstheyoungestofgalaxies.References: [1] Stark et al. 2017 [2] Dijkstra 2014 [3] Stark et al. 2015ab,2016 [4] Matthee et al. 2017 [5] Erbet al. 2014 [6] Finkelstein et al. 2013 [7] Grogin et al. 2011 [8] Furlanetto et al. 2004"
128.0,"vectors such as mosquitoes and ticks. Discovered in a screen of over 7,000 molecules, DEET wasdeveloped for the U.S. Army for application on human skin in 1946. Although DEET is the world’smost widely used insect repellent, the neurobiological mechanisms of how DEET mediatesavoidance remain controversial. Better understanding of the processes underlying DEET’seffectiveness would lead to the development of safer and more effective insect repellents.Background & preliminary data: Previous research shows that DEET’s mechanism of action ismultimodal1,2,3. It acts through mosquitoes’ sense of smell, evidenced byanimals lacking orco2, a necessary subunit of insect olfactory receptors,and through bitter-sensitive receptors in the labellum3 (Fig. A). Throughbehavioral assays and video analysis, we have shown that mosquitoes senseand are repelled by DEET on contact through their legs (tarsi)4 (Fig. A)Although the olfactory mechanisms of DEET are better understood, littleis known about how DEET repels on contact.Our results demonstrate that when mosquitotarsi come into contact with DEET, the mosquitoes willnot blood feed from that surface (Fig. C). Previous worksuggests that DEET avoidance acts through bitterreceptors in the labellum3 (Fig. A). We found that highconcentrations of bitters (such as quinine and lobeline),which are sufficient to prevent feeding when contactedby the labellum3, are ineffective at mediating avoidanceFigure | A. Female Aedes aegypti mosquitothrough tarsal contact when applied to human skin or feeding on a human arm. B. DEET-treated arman artificial surface (Fig. B & C). My preliminary work with 25mm circle of accessible skin. C. Blood-suggests that DEET repels mosquitoes on contact feeding with indicated compounds applied tothrough an avoidance pathway more strongly than or human arm.independent of bitter taste sensation, and that this deters them from blood-feeding. But nothing isknown about the cellular or molecular mechanisms by which the tarsi detect DEET.For my PhD thesis work, I propose to decipher this contact-mediated pathway to elucidatethe biological mechanism of action for DEET in mosquito tarsi. Using genetic tools recentlydeveloped in the mosquito, I will locate DEET-sensitive cells in the tarsi and identify receptor(s)that mediate DEET avoidance.Aim 1: Which neurons in Aedes aegypti tarsi respond to DEET? To investigate DEET contactrepellency further, I will use in vivo calcium imaging to compare neural activity responses todifferent chemical compounds in sensory cells within the mosquito tarsi. I will use an Ae. aegyptipan-neuronal promoter to express the genetically-encoded calcium sensor, GCaMP6s, in all tarsisensory neurons. Using a recent protocol from my lab5, I will present chemical solutions over intacttarsi while recording neural activity with a two-photon microscope and analyze the location andresponse dynamics of activated sensory cells. To determine if neurons in the tarsi are specializedto encode different chemical cues, I will compare responses within these tarsi sensory cells toDEET, sweet compounds, and bitter compounds. In behavioral assays, Aedes aegypti respond verydifferently to bitter, sweet, and DEET cues, therefore I hypothesize that chemosensory cells in thetarsi have different population response patterns to these different chemical cues. This may be inthe form of different cells reacting to different compounds, or discrimination of chemical cuesencoded through differences in population-level activity. This work will advance ourunderstanding of the peripheral sensory response that chemical cues elicit in Ae. aegypti tarsi.Aim 2: Is DEET-sensitivity conferred by different RNA expression patterns? In C. elegans, asubset of neurons express a G-protein coupled receptor, str-217, that is necessary for DEETbehavioral response6. To determine if sensory cells Ae. aegypti tarsi express a similar specializedreceptor, I will perform RNA expression analysis on separate populations of cells responsive toDEET, bitters, and sugars. Depending on the location and pattern of cells identified in Aim 1, Iwill develop methods for dissociating sensory cells from mosquito tarsi using either laser-capturemicrodissection (LCM) or fluorescent activated cell sorting (FACS) on photoactivatable GFP toprecisely isolate and harvest these separate chemosensitive cell populations. Collaborating withthe Rockefeller University genomics core, I will use single-cell RNA sequencing (sc-RNAseq) tocompare RNA expression patterns of DEET-responsive cell populations to tarsal cells responsiveto bitters and sweet compounds. I expect cell populations that respond to different tastants todifferentially express a number of proteins and receptors. Through this Aim, I will develop amethod for in-depth investigation of mosquito tarsal RNA expression while creating a list ofcandidate molecules that may be sufficient or necessary for DEET sensitivity.Aim 3: Can candidate genes for DEET-sensitivity be validated through genetic knock-out?To identify the functional relevance of genes identified in Aim 2, I will use CRISPR-Cas9-basedgene editing2 to create knock-out animals for candidate genes that may confer DEET-responsiveness. I will then use the behavioral screen in Figure B to determine if the mutant animalhas become DEET-insensitive, or partially insensitive. Ultimately, this work would result in thefirst identification of a receptor in mosquito tarsi that mediates avoidance behavior upon contact.Intellectual merit: This work has the potential to advance the field of chemosensation and solvea long-standing mystery in neurobiology. Although DEET is highly effective in repelling a widerange of evolutionarily divergent invertebrates, the mechanism of DEET avoidance is stillcontroversial 70 years after its discovery. Uncovering the mechanism of DEET avoidancepromises to elucidate new principles underlying how chemosensation is encoded and subsequentlytranslated into behavior.Broader impacts: Mosquitoes and ticks that blood-feed on human hosts can transmit pathogensthat cause a number of devastating diseases, threatening hundreds of millions of lives yearly.Identifying biological processes that mediate avoidance of blood-feeding, such as those underlyingthe mechanism of DEET, may lead to the development of more effective insect repellents thatcould last longer at lower doses and reduce the exposure of human populations to dangerousvector-borne diseases.In addition, because the general public has experience with insect repellents, DEETpresents itself as a very tractable example for public and youth engagement with the sciences. Iam excited to continue my efforts in science communication to inspire young potential scientistswith such an accessible topic. I will participate again this year in Rockefeller University’s ScienceSaturday, an annual science festival for over 1000 children in grades K–8 and their families, whereI will host a demonstration around DEET to illustrate basic principles of chemosensation. I willalso teach a class on chemosensation at the Rockefeller Summer Neuroscience Program, a graduatestudent-led course for disadvantaged high school students from New York City public schools. Iam eager to share my passion for sensory perception and chemosensation, through a topic thatchildren will already be familiar with. Using my research project on DEET, I hope to help studentsrealize that their personal observations can be of scientific value, potentially inspiring them topursue their own interests in science.References: 1. M. Ditzen, et al., Science 319, 1838-1842 (2008). 2. M. DeGennaro, et al., Nature 498, 487-491 (2013).3. Y. Lee, et al., Neuron 67, 555-561 (2010). ). 4. E.J. Dennis, O.V. Goldman, L.B. Vosshall, in revision at CurrentBiology. 5. B.J. Matthews, M.A. Younger, et al., bioRxiv (2018). 6. E.J. Dennis, et al., Nature 562, 119–123 (2018)."
129.0,"Introduction: Large carnivores are re-colonizing North America1,2 and parts of Europe3,following decades of systematic eradication4. The expansion of large carnivore populations iscreating novel and complex predator-prey interactions5. One well-known example is trophiccascades and associated declines in herbivore abundance6. Predator-prey interactions are amongthe most fundamental ecological processes and have been the focus of ecology since its origin6.They are integral processes that shape biological communities, affect coupled human-wildlifesystems, and drive conservation and management ecology7. Despite this, our understanding ofthe effect of predators on prey populations, especially in complex food-webs, is in its infancy5,7.Predator-prey theoretical and empirical research is dominated by single predator-singleprey systems like the Isle Royale wolf-moose system8. While useful, it is unclear if thesesimplified models are capable of predicting dynamics where multiple predators are interactingwith multiple prey species6,7. For example, the recent recovery of wolves, expansion of grizzlybear populations, and expanding range of mountain lions across the Western United States areincreasing the number and complexity of interactions between predator and prey species1,2,4.Mounting evidence that the growing number of interactions can cause previously unknownecological effects suggests that there is much left to be understood in multi-predator, multi-preyfood webs6,9,10. For example, these complex dynamics can spur changes in direct ecologicalinteractions, such as prey switching by predators in response to prey abundance9.A key conceptual way in which single predator-prey interactions differ from morerealistic, complex, multiple predator-prey food webs is the inclusion of competition in additionto direct predator-prey dynamics. For example, predator-prey dynamics can lead to indirectecological interactions, such as apparent competition, where one prey species supports predatorpopulations, thereby reducing alternative prey populations10. With various competitiveinteractions within a trophic level occurring, the complexity of competition must also beconsidered11. Ecology has long studied the tension between how the forces of predation andcompetition structure communities and population dynamics11. Unfortunately, the inherentcomplexity of such systems has often rendered purely statistical/empirical approaches limited intheir utility.Compared to laboratory studies and field experiments, mathematical models, such asmultiple predator-prey models (MPPMs) allow ecologists to study these dynamics12. Complexfood webs cannot be easily resolved with statistical/empirical approaches because of the largenumber of parameters to estimate and the scant data to do so with, as well as the challengespresented by some parameters and mechanisms that are impossible to estimate (e.g., carryingcapacity). MPPMs are also very powerful in evaluating the consequences of managementdecisions12. Commonly, natural resource agencies manage populations using independentmanagement strategies for each species; therefore they do not reflect the complexity of predator-prey population dynamics. By failing to incorporate food web interactions into speciesmanagement strategies and ignoring the role of multi-species predation and competition,agencies may be sub-optimally preserving and managing wildlife populations.I hypothesize that MPPMs which consider alternative interactions will explain empiricalsystems better than single-predator, single-prey models (SPPMs). I will address these majorquestions: a) Are MPPMs better at predicting population dynamics in real-world systems thanSPPMs? b) If so, are the main advantages of MPPMs in terms of predictive performance drivenby predation or inclusion of competitive interactions? c) What are the conditions (e.g.,environmental, stochastic) in which predation vs. competition drive food webs? With theseecological questions answered, I will finally address: d) How does management of one speciesaffect populations of other predators and prey within a food web?Research Approach: I will use wildlife agency-collected datasets from the Idaho Department ofFish and Game for predator and prey populations. Then, through funding from my NSF GRFPproposal, I will generalize my results to other high-profile multi-species predator-prey datasetsfrom Banff National Park, Yellowstone National Park, and Serengeti National Park, with thehelp of my Ph.D. supervisors who have connections to these 3 systems. First, I will gatherinformation about predator or prey population dynamics from previous studies to inform thestructure of my models12. Then, I will estimate functional and numerical responses for eachpredator-prey pair from across systems. I can then incorporate each predator and prey speciesinto a set of coupled equations, one for each species in the food web. If there are i predatorspecies and j prey species, the corresponding predator-prey equations can be written as such:𝑑𝑉 𝑑𝑃𝑗 𝑖[𝟏] = 𝑓(𝑉)−∑𝑓(𝑉,𝑃)−∑𝑓(𝑉) [𝟐] = ∑𝑓(𝑉,𝑃)−𝑓(𝑃)−∑𝑓(𝑃)𝑑𝑡 𝑗 𝑗 𝑖 𝑗 𝑑𝑡 𝑗 𝑖 𝑖 𝑖𝑖 𝑗 𝑗 𝑖where [1] describes the population growth rate for prey (1st term), reduced by the effects ofpredation (2nd term) and competitive interactions with other prey j (3rd term) and [2] representsthe population growth rate for predators (1st term), decremented by predator mortality (2nd term)and, when present, competition from other predators (3rd term). For example, V could represent1white-tailed deer, V elk, whereas P could represent wolves, P mountain lions, and so on. The2 1 2shape and dynamics of these functions, f (.), will be determined from field data.Intellectual Merit: I will address questions fundamental to predator-prey theory, and also morebroadly, the ecological theory about the role of competition vs. predation in driving populationdynamics. For example, I will investigate if functional and numerical responses, thought to beintegral to predator-prey theory7,9,13, are sufficient or even necessary to understand predator-preypopulation dynamics. By applying these models to a broad variety of ecosystems, I will identifygeneral properties that drive not only predator-prey systems, but other consumer-resourcerelationships14. Moreover, I will help natural resource agencies avoid mistakes stemming fromun-integrated management, which can be economically and ecologically costly12.Broader Impacts: Through an increased understanding of how management controls predator-prey population dynamics, wildlife agencies will be able to determine how human harveststrategies of one species will affect others in a food web. Additionally, I will work to establish anaccurate public image of large carnivores throughout local communities, and bridge the gapbetween ecologists-wildlife agencies-citizens. I will do so by giving talks at local high schools,writing articles for newspapers and online blogs, and partnering with local radio/TV programs,much of which I have done in the Falkland Islands (see Personal Statement). In sum, I envisionthat my work will develop ecological principles general enough to transcend ecosystems, butalso specific enough to assist management of the natural resources of local communities.Literature Cited: 1) Mech, L. (1995). Cons. Bio. 9(2):270-278. 2) LaRue, M. et al. (2012). J. Wild. Mgmt.76(6):1364-1369. 3) Chapron, G. (2014). Science. 346: 1517-1519. 4) Ripple, W. et al. (2011). Science. 343:151-162. 5) Berger, J. et al. (2001). Science. 291:1036-1039. 6) Shurin, J. et al. (2002). Ecol. Lett. 5(6): 785-791. 7)Abrams, P. & Ginzburg, L. (2000). TREE. 5(278): 535-541. 8) Messier, F. (1994). Ecol. 75(2):478-488. 9)Hebblewhite, M. (2013). Pop. Ecol. 55(4):511-522. 10) Holt, R. (1977). Theor.Pop.Bio. 12(2): 197-229. 11)Chesson & Kuang. (2008). Nature. 456: 235-238. 12) Serrouya, R. et al. (2015). Am. Natl. 185(5): 665-679. 13)Berryman, A. (1992). Ecol. 73(5):1530-1535. 14) Vucetich, J. et al. (2011). J. Anim. Ecol. 80(6):1236-1245."
130.0,"Keywords: coral reef; resilience; bleaching; climate change; ecosystem based managementIntroduction: Coral reefs shelter 25% of all marine species1 and provide food, protectcoastlines, and support economic opportunities for over 1 billion people worldwide.2 However,coral reefs face multiple threats. Chronic stressors, including overfishing, coastal development,pollution, and ocean acidification, slowly degrade coral reefs by undermining vital ecologicalprocesses, such as grazing by reef fish and coral growth.3 Coral reefs are also threatened by acutestressors, such as cyclones and coral bleaching events, that may severely damage or restructurecoral reef ecosystems.2,3 Climate change is predicted to compound these stressors and has alreadyincreased average ocean temperatures by 0.9°C globally.4 This increase has triggered three globalbleaching events to date, and most coral reefs are projected to face annual bleaching by the 2050s.4Adaptive and innovative management approaches are needed to ensure the longevity ofcoral reef communities in an era of global change.5 One potential approach supported by anemerging body of research3, 5-13 is resilience-based management (RBM).7 Under RBM, scientistsand coral reef managers use a variety of biotic and abiotic indicators to assess coral reef resilience,where resilience is defined as the capacity of an ecosystem to resist and recover from stress withoutshifting to a less desirable ecosystem state.6 However, several knowledge gaps related to coral reefresilience hinder application of RBM theory.5-12 Scientists have not reached consensus on whichbiotic and abiotic indicators are the strongest drivers of coral reef resilience.6, 8 Most assessmentsof coral reef resilience are predictive, and few studies exist that test the accuracy of thesepredictions following major stress events.6, 13 Furthermore, these assessments are conducted acrossa range of geographies using varying methodologies, 5-12 which makes it difficult determine ifobserved variability in resilience is due to context-specific factors or broad biogeographic patterns.In addition, assessments of coral reef resilience are still evolving to incorporate emerging scienceon ecosystem thresholds and phase shifts between coral- and algal-dominated states.3, 11, 13Proposed Research: The destructive 2014–2017 global bleaching event (Event), whichimpacted 51% of the world’s coral reefs,14 presents a unique opportunity to examine the impactsof major stress events on coral reef resilience. By evaluating changes in coral reef condition acrossan array of sites before, during, and after the Event, I will (1) assess the relative importance ofselect biotic and abiotic factors in determining coral reef resilience, (2) examine how theimportance of these factors varies spatially among reefs in the central Pacific, and (3) ground-truthexisting methods used to predict coral reef resilience.Experimental Design: An effective analysis of coral reef resistance to, and recovery fromthe Event will require extensive monitoring data that documents biotic and abiotic conditions oncoral reefs before, during, and after the Event. As a graduate researcher at the Scripps Institute ofOceanography (SIO), I will be well positioned to access comprehensive monitoring data from paststudies and collect data through current monitoring programs.To evaluate coral reef condition before the Event, I will analyze benthic and reef fishmonitoring data collected as part of an extensive SIO study that monitored coral reefs across 56islands in the central Pacific from 2002–2009.15 To assess coral reef resilience during and after theEvent, I will analyze photo surveys and fish transect data collected as part of the 100 IslandChallenge (Challenge), which is currently surveying 100 islands across a range of environmentaland anthropogenic gradients in the Pacific and Caribbean.16 Photo surveys collected as part of theChallenge are orthoprojected to generate comprehensive 3D models of the coral reef benthos thatdocument species composition and spatial arrangement to a resolution of 1cm2. The Challengesurveys sites (many of which were affected by the Event)14, 16 at regular intervals to documentecological changes, and has been monitoring numerous islands since 2013.I will select study sites by cross-referencing monitoring locations from the 2002–2009study15 with locations currently being monitored by the Challenge (I anticipate this will revealseveral dozen sites with sufficient monitoring data). I will evaluate the historic exposure of studysites to chronic stressors using the World Resources Institute’s Reefs at Risk spatial dataset ofanthropogenic impacts.9 Similarly, I will evaluate historic exposure to acute stressors before theEvent, and bleaching alert levels during the Event, using spatial data produced by NOAA’s CoralReef Watch. Based on this evaluation, I will classify sites into eight experimental groups (Fig. 1).I will build off existing meta-analyses of RBM studies6, 12 to identifypriority resilience indicators to measure, such as coral cover/diversity,herbivore biomass/diversity, coral recruitment, coral disease, macroalgaecover, bioerosion, substrate availability, and topographic complexity.3, 5-12I will monitor these indicators as a member of the Challenge research teamand extract relevant data from the 2002-2009 SIO monitoring dataset.15Using this data, I will generate site-level averages for each indicator beforethe Event to determine baseline conditions and analyze indicator varianceto assess pre-bleaching trends in ecosystem health. I will compare thesevalues to indicator averages and variance after the Event to identifyindicators with a statistically significant impact on coral reef resistance toand recovery from bleaching. I will also analyze spatial variability in siteresilience to detect regional or context specific patterns (i.e., whichindicators determine resilience and where), a knowledge gap prior studieshave not addressed. Lastly, I will examine areas of overlap and divergencebetween my findings and those of prior resilience assessments. Fig. 1: Sites will beAnticipated Results: I hypothesize that reef resilience will vary classed into 8 groupsbased on past exposure.depending on each site’s history of chronic and acute stress exposure. Inaddition, I anticipate that the accuracy of resilience predictions and the relative importance ofbiotic and abiotic drivers of resilience will exhibit spatial variability at regional and local scales.Intellectual Merit and Broader Impacts: This study will ground-truth RBM theory usingempirical data to analyze patterns of coral reef resilience before, during, and after a majorenvironmental disturbance. As a co-author of an RBM study,9 I recognize the potential of thisresearch to address knowledge gaps, and thereby enable scientists to further refine RBM methodsto reflect observed patterns of coral reef resilience. This continued refinement will be critical6 asreef managers, communities, and governments move to adopt RBM to inform marine protectedarea design, fisheries regulations, and other conservation measures7-10 that would have broadimpacts for millions of people who depend on coral reef ecosystems.2 In addition, the methodsoutlined in this study could be modified to test RBM assumptions for other ecosystems threatenedby climate change.7 As I conduct this research, I will use connections I have cultivated in themarine non-profit community by collaborating with researchers and practitioners, and draw frommy communications experience as an environmental blogger to widely disseminate my findings.References [1] Plaisance et al. 2011. PLoS one, 6(10): e25026. [2] Hoegh-Guldberg et al. 2007. Science,318.5857: 1737-1742. [3] Anthony et al. 2014. Glob Change Biol, 21: 48–61. [4] Van Hooidonk et al. 2016. ScientificReports, 6: 39666. [5] Nyström et al. 2008. Coral Reefs, 27: 795–809. [6] McClanahan et al. 2012. PloS one, 7.8:e42884. [7] Maynard et al. 2015. Biological Conserv, 192: 109-119. [8] Maynard et al. 2010. Coral Reefs, 29.2: 381-391. [9] Harris et al. 2017. Aquatic Conserv, 27.S1: 65-77. [10] Weeks & Jupiter. 2013. Conserv Biol, 27.6: 1234-1244. [11] Mumby et al. 2013. Conserv Letters, 7.3: 176-187. [12] Lam et al. 2017. PloS one, 12.2: e0172064. [13]Jouffray et al. 2014. Philosph Trans B, 370.1659: 20130268. [14] Eakin et al. 2017. Reef Encounter, 32(1): 33-38.[15] Smith et al. 2016. Proc R Soc B, 283(1822): 20151985. [17] 100islandchallenge.org/study-design/"
131.0,"One of the most important unknowns in high-z extragalactic astronomy is how reionizationoccurred; during the epoch of reionization (z≈10–6; EoR), neutral hydrogen (HI) dominatesthe intergalactic medium (IGM). HI attenuates radiation from early stellar populations,masking galaxies from detection. Understanding how and when reionization occurs can revealwhether or not these young galaxies provided the necessary ionizing radiation to completelyreionize the IGM by z(cid:39)6, one billion years after the Big Bang. However, due to the highredshift-space this implies, spectroscopic observations are limited as these galaxies are veryfaint, with their UV spectral features pushed out to near-infrared (NIR) wavelengths.My background in NIR spectroscopy and observational astronomy has prepared me toassist in addressing this question. I propose using Lyα and CIII] to investigate theproperties and ionization state of young galaxies using ground- and space-basedtelescopes, the structure and distribution of HI in the IGM and the circumgalac-tic medium (CGM) of certain galaxies, and implications for the evolution of theneutral fraction of the IGM throughout the EoR. The individual points proposed willbe summarized as follows: (i) small scale testing and building of an analysis technique, (ii)distribution of galaxies and evolution of neutral fraction, and (iii) metallicities of galaxies. Byunderstanding more about the IGM during the reionization era and of the galaxies within it,we can further constrain the properties of current galaxy evolution and reionization models.Small scale testing & building of analysis technique: In the search for galaxies during theEoR, Lyman-α (λ =1216˚A; Lyα) traditionally has been the best tracer both in photometric0surveys and spectroscopic follow-up. This is in part due to the increasing fraction of UVbright galaxies (with strong Lyα emission) with increasing redshift [1]. By measuring theescape fraction of Lyα many studies have inferred an increasingly neutral fraction of theIGM at z>6.5 [2]. One complication of Lyα is its attenuation due to HI, pushing emissionhundreds of km/s redwards of the galaxy’s systemic (or true) redshift. A recent methoduses a complementary spectroscopic tracer not attenuated by HI, with the UV metal lineCIII] (λ =1907,1909˚A) as the most robust according to mid-z (z(cid:39)2–3) analog surveys [1,3,4,5].0In my current work, I measure CIII] H-band emission of galaxies found via Lyα emissionusing Keck+MOSFIRE [6]. With both measurements, I compare the systemic (CIII]) andattenuated (Lyα) redshifts, shedding light on the structure and ionization of the CGMof these galaxies and surrounding IGM. From my previous work experience, I havedeveloped a proficiency in coding which enabled me to gain a close familiarity withthe MOSFIRE data reduction pipeline (DRP), having to dive into the sourcecode to fixbugs often encountered when working with incredibly faint emission lines and less commondithering patterns for standard star observations. I wrote code to optimally extract my 1Dspectra, adapted from Horne (1986), boosting the S/N of my detection. Using a marriage ofIRAF and Python, I developed code that can track the photometric variability of my datafrom a frame-to-frame basis – important when working with faint emission lines.Distribution of galaxies and evolution of neutral fraction: Using the foundation built from myprevious work, I will build a statistical sample of galaxies during the last half ofthe reionization era (z(cid:39)8–6.5) in order to track the evolution of the Lyα escapefraction as a function of redshift. Using my optimized extraction technique to improveTaylor A. Hutchison 2measurements, I will use this dataset to constrain the offset between these galaxies’ systemicand attenuated redshifts. This work will significantly increase the sample of high-z galaxieswith both Lyα and CIII] measurements. In addition, it will provide a more significantcomparison with z(cid:39)2–3 LAEs and LBGs, mid-z analogs commonly used in these analyses.A current complication for this project is the lack of a complete spectroscopic sample ofLAEs at z≥6.5 with even fewer galaxies with systemic measurements (via UV metal lines orthe [OIII] doublet; λ = 4959,5007˚A). This is partly due to these lines being redshifted to0NIR and mid-IR wavelengths; the latter is impossible to detect with ground-based telescopes– it is useful to note that during the EoR, both [OIII] and the UV metal lines fall in therange of NIRCam on JWST. As a first approach to resolving this, I will take the currentsample of confirmed LAEs at z(cid:39)6.5–8 and measure their CIII] emission, using myoptimized extraction technique to improve measurements. This has already been attemptedfor some galaxies [4], providing useful lower limits for determining exposure times andpotential telescopes for future observations, including JWST. We are planning proposals forthe first JWST cycles for this work. I will then take advantage of the deep multi-wavelengthimaging campaigns available to me, including the CANDELS datasets [7]. Moreover, I ampart of a proposal to increase the sample of z∼7 galaxies with Keck+MOSFIRE, with earlyindications that the proposal has so far been successful. Finally, as a scientific collaborator onan ERS JWST proposal, I will prepare for access to that data – understanding what spectraI will be looking for from running binary stellar population models (eg. BPASS), scaled tomatch expected bandpass magnitudes, through the JWST exposure time calculator.With a large, statistical sample of LAEs at z(cid:39)6.5–8 with both Lyα and CIII], I will beable to further constrain the amount of hard radiation emitted from these galaxies; as shownwith mid-z analogs, this is closely linked to the transmission of Lyα through the CGM [5].By tracking its evolution through the last half of the EoR, I can inform current reionizationmodels. Lastly, through gathering my sample I will map out the distribution of thesegalaxies, identifying whether galaxies with large escape fractions are tracing over-denseluminous regions, located within large ionized bubbles [3,8].Metallicities of galaxies: Using my high-z sample of galaxies with deep ground- and space-based spectroscopy, I will study the metallicity of galaxies in the EoR. From a ratio of thefluxes of the CIII] doublet, when measurable, I can infer an estimate of the electrondensity of the gas in the CGM. This is closely linked to the metallicity of the CGM,which directly affects the velocity offset of Lyα emission. Not only do recent studies indicatethat a neutral CGM attenuates Lyα photons, diminishing the effect the IGM will have, theyalso suggest (from mid-z analogs) a strong link between the profile of Lyα emission and theproperties of the gas within the CGM [5]. This can be incredibly important as some high-zgalaxies have been found to have more symmetric Lyα profiles, contrary to the archetypalasymmetric shape, thought to be indicative of high star formation and galactic winds [6].Understandingthe rateand distributionof reionization, including thefactors andprocessesresponsible for it, remains one of the most important unknowns in extragalactic astronomy.My work will aim to shed more light on this question, enabling more precise modeling ofthiserawiththeintentionofprobingeverfurtherbackintimetowardstheyoungestofgalaxies.References: [1] Stark et al. 2017 [2] Dijkstra 2014 [3] Stark et al. 2015ab,2016 [4] Matthee et al. 2017 [5] Erbet al. 2014 [6] Finkelstein et al. 2013 [7] Grogin et al. 2011 [8] Furlanetto et al. 2004"
132.0,"The Eccentricity Distribution of Long-Period Brown Dwarf CompanionsKeywords: brown dwarfs, direct imaging, radial velocityAbstract:I propose to measure the eccentricity distribution of long-period (1-500 yr) browndwarfs. I will accomplish this measurement by modifying the Orbits for the Impatientalgorithm and applying it to calculating posterior eccentricity probability densityfunctions (PDFs) for a statistically large sample of long-period brown dwarfs. I will thenaggregate these PDFs to determine the underlying eccentricity distribution of long-periodbrown dwarf companions. These results will allow direct comparison with the empiricaldistribution of exoplanets discovered by radial velocity and direct imaging, allowinginsights about planetary formation, and will provide opportunities for statisticalinferences about individual systems.Background and Motivation:Whether brown dwarfs form like large planets or small stars is key tounderstanding the process of exoplanet formation. Brown dwarf eccentricities canprovide insight into formation scenarios, since brown dwarfs with high eccentricities arelikely to have experienced close encounters with other orbiting objects early in theirlifetimes (Morbidelli 2014), but in spite of this, little analysis has been done tocharacterize the eccentricities of individual brown dwarfs, let alone the population ofbrown dwarfs at a wide range of orbital separations. In order to study the formationscenarios of brown dwarfs and make statistical inferences about the population of browndwarfs with respect to the population of giant exoplanets, it is therefore necessary to haveaccurate eccentricity measurements from a large sample of brown dwarfs orbiting stars.Fortunately, several long-period brown dwarfs have already been observed withboth the radial velocity and direct imaging methods, but few orbital fits intended tocharacterize their orbital eccentricities have been attempted, in many cases due to theirlong orbital periods, for which only short orbital arcs have been observed. In order toprovide these empirical constraints, I propose to use the NSF Graduate ResearchFellowship to compute eccentricity PDFs for each of a statistically large sample of long-period brown dwarfs using our novel Bayesian technique, Orbits for the Impatient (OFTI;Blunt et al 2016). Since many systems will only have observations covering a fraction ofa full orbital period, the uncertainty on the eccentricity of any given system will berelatively large, but with a large sample of systems, the underlying eccentricitydistribution of the population can be measured to much higher precision than for any oneobject. I will combine the eccentricity PDFs to compute the physical distribution of theeccentricities of brown dwarfs, and determine whether this distribution is consistent withor qualitatively different from that for long-period giant planets.Methods:Combining data from radial velocity and direct imaging measurements can resultin precise determinations of orbital eccentricities (Nielsen et al 2016), so the first step inmy analysis will be to modify the OFTI algorithm, which produces orbital element PDFsfrom direct imaging data, to fit orbits to data sets composed of both radial velocity anddirect imaging measurements. Once I’m prepared with this necessary tool, I will compileNSF Research Statement Sarah Bluntradial velocity and direct imaging data on >40 brown dwarf companions from theliterature, and supplement these by reducing and analyzing unpublished data. Stanford isideally suited for accomplishing this work, since there are many individuals at Stanfordand in the Gemini Planet Imager Collaboration (including GPI PI Bruce Macintosh, andcollaboration members at Stanford and nearby institutions Eric Nielsen, James Graham,Robert De Rosa, and Jason Wang) who are experienced with reduction of both radialvelocity and direct imaging data, and since Stanford has access to the high-performancecomputing resources necessary for robust and efficient data reduction.Once I have compiled reduced direct imaging and radial velocity data for asufficient number of brown dwarfs, I will run the modified version of OFTI on each dataset to produce a posterior PDF in eccentricity for each brown dwarf. I will then aggregatethese posterior PDFs to obtain the physical probability distribution of long-period browndwarfs, testing the effectiveness of several functional models at reproducing thisdistribution, and so determine for the first time the functional form of the long-periodbrown dwarf eccentricity distribution.Anticipated Results:The most direct application of the calculation of the physical eccentricitydistribution of long-period brown dwarfs will be a comparison with the eccentricitydistribution of exoplanets detected by the radial velocity method (Nielsen et al 2010), andcorresponding analysis to determine the probability that the two empirically determineddistributions are the same. Additionally, the orbit fits to the selected brown dwarfs will inmany cases be the first measurements of eccentricity, semi-major axis, and relativeinclinations of these systems, which will be useful for understanding interactions betweenthe substellar companions and circumstellar disks (e.g. Rameau et al. 2016). Orbit fits canalso be used to calculate the probabilities of the existence or absence of additional boundexoplanets or brown dwarfs orbiting a given star (e.g. Bryan et al 2016), and guide futureobservations of these systems.Proposed Timeline:Year 1: Modify OFTI and compile brown dwarf astrometric and RV data.Year 2: Publish early results for individual systems and finish fitting orbits toremaining systems.Year 3: Produce eccentricity distribution of long-period brown dwarfs, publishcomparison to planet population.References:Blunt, S., Nielsen, E. L., De Rosa, R. J., et al. 2016, ApJ (submitted)Bryan, Bowler, Knutson, Kraus, Hinkley, Mawet, Nielsen, Blunt (2016). ApJ,827, 100Morbidelli, 2014, Phil. Trans., DOI: http://dx.doi.org/10.1098/rsta.2013.0072Nielsen, E. L. & Close, L. M. 2010, ApJ, 717, 878Nielsen, E. L., De Rosa, R. J., Wang, J., et al. 2016, AJ, eprint arXiv: 1609.09095Rameau, J., Nielsen, E. L., De Rosa, R. J., et al. 2016, ApJL, 822, 2"
133.0,"Keywords: Chlamydomonas reinhardtii, flagella assembly, kinase, length regulationIntroduction: Recent discoveries concerning cilia assembly suggest complex signalingpathways play a prominent role in cilia length regulation and function.1 Far less is known aboutthe about the kinases that regulate these pathways. The proposed research will attempt touncover the signaling pathways responsible for growth and regulation by establishing whichkinases and mechanisms are responsible for the regulation of cilia length.Background and Rationale: Cilia and flagella are found on almost every cell in the humanbody and consist of microtubules that extend from the cell surface. Cilia are typically dividedinto two types, primary and motile, which both sense extracellular signals. Primary cilia, foundon the majority of cells in the human body are immobile. Motile cilia, found on the majority ofepithelial cell surfaces, create wave-like patterns to propagate fluid. As flagella and motile ciliahave identical structures, the words cilia and flagella are used interchangeably.The process of assembling cilia, ciliogenesis, is highly regulated as the centrioles that nucleatecilia are also required for cell division. The mechanisms regulating ciliogenesis, includinginitiation, assembly and resorption, are poorly understood. Learning more about these mechanismswill facilitate the study and treatment of diseases involving ciliary dysfunction.Flagella of the unicellular green alga Chlamydomonas reihardtii are essentially identical tocilia of vertebrate cells and provide an excellent modelto study ciliogenesis. Chemical studies inChlamydomonas have demonstrated length-regulatingroles for G-protein coupled receptors2. Similarly,flagella assemble in a length-dependent manner, withrapid early assembly and very slow assembly as theyapproach their steady-state length. The rate ofdisassembly is length independent and the length atwhich assembly and disassembly are in equilibrium isFigure 1. Preliminary kinase inhibitors withknown as the balance point3. To identify kinaseincreased rate of assembly during regeneration.pathways that affect flagellar assembly, we performeda small-molecule screen using a kinase inhibitor library. Preliminary data show inhibiting ProteinKinase A and G causes an increased rate of flagellar assembly during regeneration over of 2 hoursas compared to wild type. Also, inhibiting Protein Kinase C causes a slower rate of assemblyduring regeneration at 1 hour as compared to wild type (Figs. 1,2). We hypothesize these inhibitorstarget regulators that control the switch from rapid to slow assembly rates. Reversing this switchhas the potential to rescue defects caused by slow or impaired assembly.Aim 1: Validate Targets and Phenotypes with NovelInhibitors and Activators: To confirm phenotypes andidentify the kinases responsible for the observedphenotypes, we will use different inhibitors of the sametargets. In contrast to the kinase inhibitors, the activation ofthese kinases should show us the opposite effects,confirming the targets and phenotypes previously identified(Figs. 1,2). Following pH shock to induce flagellar loss andregrowth, we will treat Chlamydomonas cells (CC125) withinhibitors and activators of protein kinase A, G, C andFigure 2. Preliminary kinase inhibitorstyrosine kinases (Table 1). Flagella will be imaged using with decreased rate of assembly duringregeneration.automated phase contrast microscopy and flagellar length Table 1. Inhibitors and Activators ofmeasurements will be performed using ImageJ software. With proposed targets to be used in Aim 1these experiments, we expect to confirm the data seen inFigures 1 and 2 while helping us to further confirm thesekinases as regulators of the switch from rapid to slowassembly.Aim 2: Identify Regulatory Pathways for FlagellarAssembly: As many of the kinases identified in thepreliminary screen have both cytoplasmic and nucleardownstream targets, we will identify which subset of targetsare responsible for the flagellar assembly phenotype. Todiscriminate between the targets, we will use inhibitors fromthe preliminary screen simultaneously with cyclohexamide, a protein synthesis inhibitor that willprevent gene expression in downstream transcription factors (Table 2). Next, we will perform anepistasis experiment by inhibiting or activating a preliminary target as well as a potentialdownstream targets to see if they are in the same pathway. The process of pH shock and flagellarlength measurement will be followed according to the steps described in Aim 1. Theseexperiments will narrow down the pathway components regulating the switch from rapid toslower assembly rates.Aim 3: Determine the Role of Identified Kinases in Trafficking of Flagellar Cargo: We willuse total internal reflection fluorescence (TIRF) microscopy toTable 2. Cytoplasmic anddetermine the role of kinases in trafficking of flagellar cargo byNuclear compounds to be usedassessing the preliminary targets’ effect on transportation of tagged for experiments in Aim 2.proteins in regenerating flagella. We will treat the cells with thekinase inhibitors during flagellar regeneration and use TIRF imagingto compare the amount of cargo traveling from the base to the tip ofthe regenerating flagella by quantifying fluorescence intensity oftagged cargo.4,5 Results from this visualization and quantification of tagged cargo will identify themechanism with which identified pathways regulate flagellar assembly.Intellectual Merit/Broader Impacts: My familiarity with the culture conditions and flagellarphenotyping of the model organism Chlamydomonas reinhardtii will facilitate the proposedexperiments. I will gain the necessary skills to perform TIRF microscopy through futurementoring from Dr. Avasthi. The initial microscopy work in the outlined project, allowsRockhust University undergraduate students participating in research at the University of KansasMedical Center to be trained on microscopy. The findings from these experiments impact thescience community through the identification of fundamental principles of ciliary regulation.Society is influenced by these findings as they will provide the foundation for the treatment ofdiseases of ciliary dysfunction. Results will be shared in relevant conferences, preprints andpublications. Also, the proposed experiments and results, will be shared with undergraduatestudents at Rockhurst University with the intention of using relevant basic science research toengage future students. This will capture their attention and spark their interest for researchopportunities at the University of Kansas Medical Center. Support from the NSF through theGraduate Fellowship Research Program will promote my success as a future scientist byfacilitating research during my graduate career, but will also benefit society by providing a moreapproachable path to science careers for women.[1] Nachury,Maxence V.(2014) Philosophical Transactions of the Royal Society B: Biological Sciences 369.1650[2] Avasthi, Prachee et al. (2012). ACS Chemical Biology 7.5 [3] Marshall, Wallace F. et al. 2005.Molecular Biologyof the Cell 16.1 [4] Engel, Benjamin D. (2009) Method Cell Biol.93 [5] Avasthi, Prachee et al. (2014).Curr Biol. 24."
134.0,"Understanding the Role of the Cytoskeleton on Intracellular Particle DynamicsIntroduction – Intellectual Merit:The dynamics of the cytoplasm, which includes the cell chromosome and other intracellularparticles is relevant to many biological processes, including cell replication and genomic control.However, these systems exist out of equilibrium and show complex dynamic behavior, not easilyexplained by classic dynamic theory.Recently, new fluorescent labeling techniques have allowed intracellular particles to betracked as they move though the cell1,2. These experiments, done on E. coli, have shown that thatthese particles show sub-diffusive behavior. It seems that the cell environment confines themovement of these particles, and blocks them from fully exploring their surroundings.Various theories have been proposed to explain this behavior.3,4. These depend mostly onstudying polymer models for the chromosomes and treating the cytoplasm as a viscoelasticmedium with a simple memory kernel. This continuum approach has shown some success inreproducing the sub-diffusive behavior of particles.However, there is no need to introduce an artificial memory kernel, the cytoplasm can bemodeled explicitly using colloidal models. Then, the particles are treated as colloids moving in aNewtonian medium (water). Then the constraints that induce the caging on these particles and leadto sub-diffusive behavior can be inserted explicitly.There are two factors that could lead to this diffusive behavior. The first is the fact that theparticles are confined in the cell. This confinement could lead to a reduced ability to explore certainparts of the cell. Additionally, the cell cytoskeleton would induce an additional major hindranceto their movement.The existence of the bacterial cytoskeleton has only recently been recognized5. However,by now it is well understood that prokaryotes have analogues to most components of the eukaryoticcytoskeleton. These help give the cell it’s structure, and connect different parts of the cell witheach other. However, they are also major sources of hindrance in the movement of the cellparticles.It is appropriate to use a colloidal model of the cytoplasm, since many large biomoleculeseasily fall in the colloidal size regime. The hindered diffusive behavior is analogous to that seenin classic colloidal glassing6, and could be explored using the same fundamental theory.Goal:We wish to develop a simple colloidal model to study particle dynamics within a cell,including the role of confinement and the cytoskeleton. This model will demonstrate that thisconfinement, along with the additional interference of the cell cytoskeleton leads to the sub-diffusive behavior shown in experiments.To achieve this, we will first use existing polymer models to properly study the behaviorof the bacterial cytoskeleton. Then Brownian Dynamics studies of a simple cell model would berealized, and the confined movement of the particles in the model cell would be studied. Finally,the role of hydrodynamics would be explored, using newly developed theory and computationalmethods.Objective 1: Match Cytoskeleton Dynamics to Polymer Models:The first step is to develop a good model for the cytoskeleton, which is a complex networkof polymer chains that connect different parts of the cell. A convenient way to model the behaviorof these polymers is to use the shearable stretchable Worm Like Chain (ssWLC) model developedby the Spakowitz Group to study general semi-flexible polymers7.This general model allows one to study a wide range of polymers at many timescales. Usingtheir methodology7 to match the known chemical structure of the components of the bacterialcytoplasm5, we can obtain a simple polymer model applicable for Brownian Dynamics, which wewill use in the following simulations.Objective 2: Study Particle Diffusion in Cellular Environment:The cell can be modeled as a sphere, and the cytoplasm can be modeled as a colloidalsolution inside this sphere. The sphere would have polymers, whose dynamics follow the ssWLCmodel in a network analogous to the bacterial cytoskeleton5. Then the dynamics of the colloidalsolution would be explored using Brownian Dynamics, a classic simulation methodology incolloidal physics.Various factors can affect the overall dynamics of the solution. The first is theconcentration, which would be kept neat to cellular concentrations. Additionally, the exactstructure of the cytoskeleton is likely to be very relevant. Various randomized structures would beused to study this effect. Finally, a single particle would be used as a probe, and its movementthough the cell would be studied to determine if it shows sub-diffusive behavior.Objective 3: Explore the Role of Hydrodynamics:An important factor in the dynamics of a colloidal system is hydrodynamics. These can beincluded in the Brownian Dynamics simulation through the use of the Accelerated StokesianDynamic methodology8. This methodology includes the full effects of hydrodynamics.A challenge is exploring the role of the confinement in the hydrodynamics. Fortunately,the relevant mobility functions have recently been published9.. These would be used along theclassic particle-particle mobility, which are well known8, and can be extended to the polymermodel10. Since these computations are likely to require significant computational power, theywould be parallelized using newly developed methods11.Broader Impacts:Understanding the dynamics of the intracellular environment could lead to increasedunderstanding of genome expression. This in turn could lead to new understanding of many geneticdiseases and their mechanism of action.Every effort would be undertaken to undergraduate students in this project. Several parts,including the managing of simulations, can be easily performed by a student new to the field, andcould serve as a great learning opportunity. This would be done through REU and other programsfor underrepresented students.All papers published from this project will be made available to the wider public usingOpen-Access publication models.References:1. Weber, S. C. et al. 2010. Physical Review Letters 104, 238102.2. Kuwada, N. J. et al. 2013. Nucleic Acids Research 41 (15).3. Lampo, T. J. et al 2015. Biophysical Journal. 108.4. Tampo, T. J. et al 2016. Biophysical Journal 110.5. Cabeen, M. T. et al. 2010. Annual Reviews of Genetics 44.6. Parry, B. R. et al. 2014. Cell 156 (1-2)7. Koslover, E. F. 2013. Soft Matter. 9, 70168. Banchio, A. J. et al. 2003. The Journal of Chemical Physics. 118 (10323)9. Aponte-Rivera, C. et al. 2016. Physical Review Fluids 1 (2).10. Nieves-Rosado, L. et al 2016. Unpublished Work11. Bülow, F. et al. 2016. Computer Physics Communitcation. 204."
135.0,"duplicate or reproduce without permission. www.rachelcsmith.comSeasonal Migration Within Aseasonal Tropical Rainforests:A Phenomenon With Immense ImplicationsINTRODUCTION: Tropical rainforests (TRF) are often considered aseasonal, however every TRFstudied shows seasonal phenological variations corresponding to precipitation and solarirradiance1. Flushing, flowering, fruiting, and invertebrate biomass have general community-wide peaks during a region’s wet season, with large-fruited trees exhibiting the strongestphenological clumping1,2. Due to local precipitation regimes, phenology peaks vary in differentgeographical locations, creating spatio-temporal resource shifts1,3,4. Migration, the large-scaleseasonal range shifts that occur in response to disparities in regional resources, has not beenstudied as a faunal survival adaptation within tropical rainforests1.Uncovering how animals move in response to seasonal resource shifts is critical to theconservation of migrating species and the ecological processes they perform5,6,7,8. Furthermore,species dependent on variable resources are the first to face local extinction after forestfragmentation. Moreover, migrating species are particularly threatened by current global climaticchanges5,6. I will create a spatio-temporal model of fruiting shifts in SE Asia, then track hornbillmovements to test my hypothesis that migration exists in TRF to follow resource shifts.BACKGROUND: Current research on migration as a response to seasonal resource shifts isfocused on temperate and highly seasonal tropical regions5. While altitudinal migration thatfollows seasonal phenological changes does exist in TRF, large-scale seasonal migration thatfollows regional climatic differences is completely unreported2,6,7. Newton’s comprehensivetextbook on migration argues that the increased movements required to cross climatic gradientsand the limited resource inequalities between TRF negate the returns for intra-TRF migration7.However, highly mobile TRF frugivores like hornbills can traverse hundreds of kilometers perweek, and in SE Asia, seasonality is sufficient to create resource disparities4,8,9.SE Asia is the optimal location to test for migration because monsoons create localizedweather patterns in lowland TRF. Variations in wet seasons form a matrix of adjacent landscapeswith offset phenologies1,4. Consumers depend on these spatio-temporal rhythms in the foodsupply1,2,3,8. Local seasonal resource disparities are extreme, exceeding six fold increases infruiting species during months of peak rainfall. This provides incentive for migration6.Hornbills are large frugivorous birds that are highly mobile and capable of migration. Theyfavor large, ripe, oily fruits in rare canopy/emergent tree species that fruit seasonally2,3,8,10.Hornbills are keystone seed dispersers and the SE Asian equivalent of toucans8,9. Hornbills trackresources throughout their home ranges and juveniles are known to roam until they obtainterritories, however hornbills are not known to migrate8.A seasonal flock of 3000+ plain pouched hornbills, Aceros subruficollis, has recently beendiscovered around Lake Tasek Temengor in Peninsular Malaysia11. The hornbills fly north afterstaying in the region during the two month period of peak rainfall and fruiting3,11. Thedestination of A. subruficollis is unknown, however, it has never been recorded as a breeding inMalaysia8,11. The seasonal presence of this flock in Malaysia for purposes other than breedingsuggests that A. subruficollis is migrating outside of Malaysia, most likely into Thailand.If A. subruficollis is migrating, it would constitute the first documented migration by aTRF species7. Altitudinal migration can be refuted because A. subruficollis vacates from theLake Tasek Temengor region where elevation changes exceed 1000m within a 30km zone11. A.subruficollisis is currently listed as a vulnerable species due to the rapid decline in small totalpopulation. In addition, the details of its range, life history and ecology are unknown8,12.NSF Proposed Research 2010 All Rights Reserved to original author. Do notduplicate or reproduce without permission. www.rachelcsmith.comHYPOTHESIS: i) Rainfall-driven local phenology differences have resulted in significant seasonalresource disparities across space within TRF. ii) A. subruficollis will migrate in order to exploitseasonal resources. Null: i) Resources are homogeneously distributed in time and ii) A.subruficollis movements do not correlate with resource abundance.OBJECTIVE 1: Create a spatio-temporal resource model using GIS mapping techniques to test therelationship between rainfall and phenology of fruiting trees. Then, model optimal migrationpaths for A. subruficollis based on distance and temporal resource abundances.METHODs: 1) Create regional monthly rainfall/fruiting species database. Precipitation data isavailable from the Malaysian and Thai Hydrological departments, phenological data is availablefrom the literature1. 2) Model month-by-month rainfall and fruit abundance by region in ArcGIS.3) Use large-scale layered models to quantify resource disparities across time and space. 4)Model A. subruficollis optimal movements to exploit spatio-temporal resource peaks.OBJECTIVE 2: Test if A. subruficollis migrates to exploit spatio-temporal resource abundances.METHODS: 1) Radio-track 15 A. subruficollis individuals for two years9. Capture birds withpulley-mounted canopy mist-nets at roost in Malaysia and attach satellite-transmitters at the baseof the tail feathers9. Monitor their movements with a receiver9. 2) Input A. subruficollismovement data into a GIS spatio-temporal resource model. 3) Determine if there is causalrelationship (using spatial auto-correlation) between movements and spatio-temporal resources.CONSEQUENCES: Migrants and species dependent on seasonal resources are particularlyvulnerable to climatic changes and forest fragmentation5,7,8. Moreover, concerns about climatechange stress the importance of keystone seed dispersers, like hornbills, to help move the trees tomore suitable climates8,9. A positive feedback response could develop where keystone migrantsdisappear from disturbed forests, decreasing ecosystem functioning and future forest resilience.TRF migration also directly challenges Rapaport’s Rule of decreasing animal range size withlatitude, a theory based on decreased resource variability in the tropics. The seasonal resourcemodels I will create will bring the degree of variability into question. Migrating frugivores alsoprovide rapid long-range seed dispersal along distinctive corridors and back to roosts, shapingthe spatial regeneration patterns and diversity of forest trees3,10.BROADER IMPACTS: I will partner with the Forestry Research Institute of Malaysia (FRIM).Malaysian researchers will aid in all aspects of this project including anticipated co-authorshipson publications, and becoming fully trained in the methods and analyses. FRIM helps to manageMalaysia’s natural resources, making it optimal to immediately bridge my research with policyand action. Additionally, this research will locate movement corridors that are critical toconservation efforts for this vulnerable species, which benefits future human generations of allnations12. A. subruficollis is also a charismatic species and important tourism draw in the region8.Finally, Dr. Poonswad at the Mahidol University in Bangkok has enlisted master’s studentsworking on Thailand Hornbill Project (THP) to help track A. subruficollis in Thailand. Workingwith FRIM and THP will bring together an international team and facilitate the local and broaddissemination of results in English, Malay and Thai.BIBLIOGRAPHY: [1]van Schaik, C.P.,Terborgh, J.W. and Wright, J.S. 1993. Annun. Rev. Ecol. Syst. 24;[2]Walker, J.S. 2006.Biol. Conserv.130; [3]Medway, F.L.S. 1972.Biol. J. Linn. Soc. 4 [4]Kumagai, T. etal. 2009.Water Resources 45; [5]Both, C., et al. 2006. Nature 441; [6]Levey, D.J. 1994. The Auk 111;[7]Newton, I. 2008. Academic Press,London; [8]Kinnaird, M. F. & T. G. O'Brien. 2007. [9]Holbrook, K.M.& T.B. Smith. 2000. Oecologia125; [10] Hardesty, B.D., Hubbell, S.P., et al 2006. Ecology Letters 9.[11]Chew, H.H., & S. Supari. 2000. Forktail 16; Univ. Chicago Press; [12]IUCN 2009. Version 2009.1;"
136.0,"www.rachelcsmith.com *All Rights Reserved to Original Author 2010 GRFP Research ProposalNative Bee Reproductive Success in Restored HabitatsIntroduction: Ecological restoration can rehabilitate ecosystem services, but its success dependsupon the ability of the restored site to sustain functional populations.1 Restoration has beenproposed as a way to promote conservation of native bee populations that have declined due tohabitat loss and fragmentation.2 Native bees are effective pollinators of many economicallyimportant crops,3 and drastic crashes in managed, non-native honey bee populations due tocolony collapse disorder have highlighted systemic vulnerability, as well as the need to diversifyon-farm pollinator communities. Within agricultural systems, hedgerows (linear strips of nativeflowering shrubs planted in fallow field margins) are the preferred restoration method: In 2007,Congress passed the Pollinator Habitat Protection Act (S.1496), incentivizing the creation ofpollinator-friendly hedgerows. However, agricultural landscapes have become increasinglysimplified due to intensive farming practices, and potential source habitat may be too distant toprovide reliable immigration to hedgerows.4 In addition, recent research5 suggests thathedgerows may be sink habitat, where the death rate is greater than the birth rate.6 This researchused species richness as a proxy for reproductive success, which is problematic because it givesno indication of long-term population viability within sites. If hedgerows are sinks, pollinationservices could be threatened.3 Therefore, I propose to directly measure native bee reproductivesuccess in order to assess the sink hypothesis and the conservation potential of hedgerows.Background: Native solitary bees typically have one generation per year, therefore there are twomain components that influence reproductive success: per female fecundity and offspringsurvival. Fecundity may be influenced by proportion of forage (pollen) available for provisioningof brood cells7 at both the local and landscape level.8 Hedgerows often contain low plantdiversity (usually between 8 - 15 species); if these resources are inadequate, bees may need toforage in the surrounding landscape to obtain sufficient pollen to meet larval needs.4,8 Limited orpatchy landscape resources could reduce success as fewer nests could be created.Larval mortality can be heightened by increased parasitism, and cleptoparasite and parasitoidabundance is often greater in restored sites than in natural areas.10 Additionally, parasitism rateshave been correlated with resource availability: in resource-poor environments, bees compensatefor floral scarcity by increasing search time, broadening the window for successful parasitism.11While exposure to herbicides12 and abiotic factors, such as high in-nest moisture and temperaturelevels,13 can also be fatal to larvae, their effects are difficult to measure; therefore, I will dividecauses of mortality into two categories: parasitism and unknown.10In order to demonstrate the occurrence of source-sink dynamics it is necessary to comparepopulation demographics in multiple habitats.14 Thus, treatments will be in two habitat types,restored (hedgerow), and un-restored (fallow field margins), situated in either complex(heterogeneous) or simple (homogenous) landscapes (n = 18). Additionally, in order to havebaseline data against which gauge the success of the restored sites, fecundity and offspringsurvival will be recorded in natural habitats (n = 4).I will use trap-nesting bees (cavity-nesters) as my study taxon because ninety percent of thenative bee species managed for agriculture are trap-nesters, and they readily occupy artificial“trap-nests,” bundles of hollow reeds, that can be lined with removable straw inserts to facilitatemonitoring of nest progress.8Hypotheses: In order to examine the capacity of hedgerows to sustain viable populations of trap-nesting bees, I will measure fecundity and parasitism in two landscape contexts:1. Fecundity of trap-nesting bees will decline with decreased resources. I hypothesize thatlandscape complexity will be more important to fecundity than local-level resources. In simpleNative Bee Reproductive Success *Do not Reproduce without Permissionwww.rachelcsmith.com *All Rights Reserved to Original Author 2010landscapes, I do not expect to find significant differences in fecundity between hedgerows andfallow field margins. In contrast, I predict that in complex landscapes fecundity will in higher inboth treatment types, approaching observed levels in natural habitat. However, if fecundity inhedgerows in simple landscapes is higher than in fallow field margins, it would indicate that thelocal resources they provide are sufficient, bolstering claims that they are an appropriaterestoration method in homogenous landscapes.2. Parasite pressure on larvae will increase with decreasing resources, negatively impactingreproductive success. In simple landscapes, I expect to observe spikes in parasitism levels inboth habitat types. I predict that the additional resources provided in heterogeneous landscapeswill buffer larvae against heightened parasitism in hedgerows but not in fallow-field margins.Further, I predict that offspring survival in hedgerows and field margins in both landscapes typeswill be significantly lower than in natural habitat, signifying that disturbed landscapes subjectlarvae to increased threats from parasitism and other factors shown to increase mortality.Methods: Study Location: This study will take place in Yolo County, an agricultural region inCalifornia’s Central Valley. In the study region, complex landscape is a mosaic of naturalhabitat, riparian corridors, organic farms, and conventional agriculture; simple landscapes aredominated by intensive agriculture (> 80%). Landscape features will be categorized using GISlandsat data. Each site will contain a 300 m transect with a trap-nest in the center, and will be atleast 2 km apart to ensure isolation.15Floral Resources: Vegetation sampling will commence with nest initiation and terminate whennesting ceases. I will record flowering species and number of inflorescence in 1 m2 quadratsalong transects. To determine the proportion of local and landscape resources used, I will collectvoucher pollen from all flowering plants within a 1500 m radius of trap-nests, and compare itwith sub-samples of pollen from nests.8Parasitism: Once nests are completed, I will x-ray larvae in the lab to ascertain which areparasitized;8 parasitoids will be identified after emergence by Dr. Robbin Thorp, of the UC DavisBee Biology Lab. Unparasitized pupae will be stored in optimal conditions at the UC Berkeleyinsectary and monitored for emergence of cleptoparasites.Broader Impacts: Due to the persistent, damaging effects of colony collapse disorder,restoration of native bees is essential for the maintenance of pollination services in agriculturalareas.3 These findings could validate hedgerows as an effective restoration method, or illuminateits short-comings. Worldwide, native bees are the most important pollinators in natural systems,and are therefore necessary for preservation of biodiversity.3,16 The result of this study will helpidentify factors that could contribute to the success of pollinator restoration at larger scales. I willsubmit papers to scientific journals, present at conferences, and share my results with farmers atannual workshops put on by the Xerces Society, a non-profit dedicated to insect conservation.References: 1. Ormerod, SJ. J. of Applied Ecology 40 (Dec 2003) 2. Dixon, KW. Science 325 (Jul 2009)3. Kearns, CW. et al. Ann. Review of Ecology and Systematics 29 (1998) 4. Ricketts, TH, et al. EcologyLetters 11 (May 2008) 5. Ockinger, E, HG Smith. J. of Applied Ecology 44 (Feb 2007) 6. Pulliam, HR.American Naturalist 132 (Nov 1988) 7. Muller, A, et al. Biological Conservation 130 (Jul 2006)8. Williams, NM, C Kremen. Ecological Applications 13 (Apr 2007) 9. Steffan-Dewenter, I. EcologicalEntomology 27 (Oct 2002) 10. Exeler, N, et al. J. of Applied Ecology 46 (Oct 2009) 11. Goodell, K.Oecologia 134 (Mar 2003) 12. Freemark, K, C Boutin, Agriculture Ecosystems & Environment 52 (Feb1995) 13. Hranitz, JM, et al. Environmental Entomology 38 (Apr 2009) 14. Watkinson, AR, WJSutherland, J. of Animal ecology 64 (Jan 1995) 15. Gathmann, A, T Tscharntke. J. of Animal Ecology 71(Sept 2002) 16. Allen-Wardell, G, et al. Conservation Biology 12 (Feb 1998)"
137.0,"Deriving Language Signatures for Bilingual Code-SwitchingKeywords: Code-Switching, Probabilistic Language Models, Sociolinguistics​Research Question: How do bilingual speakers of the same language pairings code-switchbetween them differently? More specifically, what components can be extracted from bilingualdata to differentiate speakers of the same languages?Background: Linguistic scholars have observed that there is wide variation in code-switching(CS) due to social differences (Gardner-Chloros, 2009). For example, Post (2015) observedvariations in frequency and type of CS as a function of gender among Arabic-French speakers inMorocco. Unfortunately, findings like these have been restricted to specific languages and smalldatasets and until recently, there have been no tools to classify CS at the level of large corpora(Gambäck & Das, 2016). Furthermore, there have been no attempts to distinguish the unique CSpatterns presented by speakers, i.e., individual language signatures. The key problem is that CScan include small word-level insertions of single lexical items or long stretches of dialogueacross several speakers, which make its study difficult as speakers can vary their patterns ofspeech considerably from one utterance to another.I propose to address these gaps in the study of CS by applying statistical models toextract and extrapolate patterns from bilingual corpora. The crux of my approach is to look at CSas a sequence of language spans, in which a speaker remains in one language before switching toanother. Solorio and Liu (2008) have previously exploited this idea to predict switch points andto tag for Part-Of-Speech, yet their approach made no attempt to distinguish or identify differentpatterns. Outside of current analyses at the level of corpora I do not know of any statisticalapproach to studying bilingual CS across speakers that exploits this idea of language spans. Byadapting this concept to the alternation of language at the individual level and not corpora, Ibelieve that it is possible to distinguish the CS of one bilingual speaker from others to produce adistinctive language signature, regardless of small changes in speech.Hypothesis/expected findings: Based on my previous work with the Killer Crónicas, Yo-Yo​ ​ ​Boing!, and Bon Cop, Bad Cop datasets, I hypothesize that CS can uniquely characterize​ ​individual speakers and that the relative frequencies of language spans across speakers aredistributed differently, with some speakers preferring spans of one length to another. I expectthat speakers of the same language pairings vary enough in the length of languages spans thatthere are statistically significant differences in the speech of two bilingual individuals. Ianticipate that there are also several variables contributing to these differences such as region,attention paid to speech, and social factors. My methods to extract different features of CS andprovide unique signatures of CS across bilingual speakers will be language-neutral andapplicable across different language pairings.Approach and Methods: The first component of this project will be the gathering of a largenumber of bilingual corpora involving CS in order to introduce as much variation as possible.Given my previous work in language annotation, I am free to work with larger, untagged datasetsso long as enough training data exists. By far the largest collection of such datasets is theLinguistic Data Consortium (LDC), which charges a fee for unlimited use and access. Theremaining resources are access to powerful computing resources (or XSEDE access) and theexpertise of faculty members working on CS and statistical language models.After preliminary analysis of the datasets, I expect distinct patterns of CS to emergeacross speakers such as switching differently around breaks in speech, which will lead todiffering patterns in the corresponding language signatures. At this point, I will work to examineGualberto A. Guzman Graduate Research Plan Statement NSFGRF 2016bilingual CS with statistical models by looking at the distribution of language spans per speakerand by examining the probability of switching in a discourse as a function of time, both of whichnecessitate large datasets.Assuming the simplest case, the distribution of language spans of a speaker can bemodeled as a stochastic exponential decay after normalization for length of text. I expect thatdifferent speakers will present different rates of decay in their language, resulting from varieduse of language spans. In addition, by looking at bilingual text as a series of switches betweenmonolingual spans, I will model CS as a Poisson process and find the most apt parameters forindividual speakers by working backwards from their speech. I will tune different stochasticmodels to speakers in order to find statistically significant differences in speech patterns and Iplan to subject the data to a rigorous analysis of different stochastic models to test myhypotheses. I will also perform a regression analysis to find correlations between the social andenvironmental factors mentioned above and any differences from the models.Intellectual Merit/Broader impacts: A Graduate Research Fellowship will allow me to​promote further research between the fields of Linguistics and Mathematics. My work willinspire the development of a general framework with which to examine cases of switchingphenomena within Linguistics. It will have broad impacts in computational linguistics,sociolinguistics, and bilingualism both as a tool and as a theoretical construct. My model willcontribute a new, language-neutral approach to examining bilingual CS, freeing researchers frombeing constrained by the availability of data in dominant languages like English. In addition, myproposal has potential contributions to the fields of linguistic methodology and linguisticanthropology. Its development may lead to the possibility of deconstructing seeminglyhomogenous language or CS use into discrete subgroups by geography, ancestry, or culture.Finally, it must be noted that the development of my model need not be restricted to thestudy of switching between two languages. My ambition is to generalize my model to work withas many languages as needed. In addition, a refined version of my proposed model would be ableto uniquely identify changes in style, dialect, or register given enough training data. As anexample, learners of a second language could apply the principles of my model to pinpointexactly where their usage differs from that of a native speaker, which provides a new possibilityfor accelerated language learning and for the study of second-language acquisition.Björn Gambäck and Amitava Das. 2016. Comparing the level of code-switching in corpora. Proceedings of theTenth International Conference on Language Resources and Evaluation (LREC 2016), pages 1850–1855.Penelope Gardner-Chloros. 2009. Sociolinguistic factors in code-switching. In Barbara E. Bullock and AlmeidaJacqueline Toribio, editors, The Cambridge handbook of linguistic code-switching , pages 97–113. CambridgeUniversity Press, Cambridge, UK.Thamar Solorio and Yang Liu. 2008. Learning to predict code-switching points. In Proceedings of the Conferenceon Empirical Methods in Natural Language Processing, pages 973–981. Association for ComputationalLinguistics.Thamar Solorio and Yang Liu. 2008. Part-of-speech tagging for English-Spanish code-switched text. In Proceedingsof the Conference on Empirical Methods in Natural Language Processing, pages 1051-1060. Association forComputational Linguistics.Rebekah Elizabeth Post. 2015. The impact of social factors on the use of Arabic-French code-switching in speechand IM in Morocco. Ph.D. thesis, University of Texas at Austin."
138.0,"Interferometric Reflectance-Based Nanoparticle Imaging with Patterned IlluminationIntroduction: A significant issue in current medical standard-of-care is the accurate detection ofinfectious diseases. Viruses, bacteria, parasites, and other microorganisms causing these diseasesare difficult to detect directly due to their micro- and nanometer length scales. Existingdiagnostic techniques typically rely on indirect detection through monitoring bulk tissue changesin a patient, analyzing biological samples in vitro, or determining an infection based on thepatient’s symptoms and immune response. While these techniques are effective in certain cases,indirect detection methods increase the difficulty of achieving a proper diagnosis which can leadto harmful consequences for patients [1].One such primary diagnostic tool experiencing this limitation is the optical microscope.New optical technology has improved microscopy’s capabilities in imaging small-scale objects,but many modern systems have become diffraction limited. Diffraction limits occur when theparticles of interest are smaller than the imaging wavelength of light. This sizing issue results inlight scattering that prevents nanoparticles from being resolved with conventional microscopytechniques. This limit has been bypassed previously using methods such as fluorescencemicroscopy, where the particle of interest is indirectly detected by imaging a fluorescent dye thathas been bound to the particle. Such techniques are successful, but they have significantdrawbacks including the need for extensive sample preparation, augmentations to the sampleprior to analysis, and expensive imaging hardware [2]. These factors create significant barriers ofentry for these modalities from becoming common disease diagnosis platforms in developing anddeveloped countries. Thus, a substantial need exists for an affordable diagnostic platformcapable of nonspecifically detecting nanoscale biological particles.Proposal: I propose a new microscope design combining the imaging modalities of Single-Particle Interferometric Reflectance Imaging Sensors (SP-IRIS) and Fourier Ptychography (FP)Microscopy for high resolution, high throughput imaging of biological nanoparticles.SP-IRIS, developed in Dr. Selim Unlu’s labat Boston University, utilizes wide-fieldinterferometric imaging techniques to acquire weakscattered light signals from nanoparticles over alarge sample region. These signals provideinformation regarding nanoparticle geometry andhave been used for label-free detection of viruses atattomolar concentrations (Figure 1). These factorsmake SP-IRIS a desirable option for both largesample virus diagnostics and biologicalnanoparticle characterization applications.However, drawbacks including the requirement ofmechanical sample scanning and device limitationsin detecting differences between floating and Figure 1: Label-Free Figure 2: Standardadhered nanoparticles limit the system’s current Virus Particle Microscope (Top) andabilities as a diagnostic tool [1]. Visualization with SP- FP-ReconstructedIRIS Microscope [1] (Bottom) Image [3]Fourier Ptychography techniques couldremove these existing issues in SP-IRIS technology. FP is a computational microscopy approachwherein different angled illumination patterns are projected on the sample via an LED array toobtain low-resolution image sets. These images can be recombined to create images with higherresolution and wider field-of-view than standard microscope techniques (Figure 2). These angledNSF Research Statement Alex Matlockillumination measurements also enable tomographic and 3-D reconstruction of the imagedsample. With the capabilities of FP in achieving near real-time imaging while providing high-resolution images, the synthesis of FP with SP-IRIS could create a highly sensitive and specificnanoparticle detection platform with volumetric information regarding each particle [3]. Theseadditions would remove the need for depth sectioning in the SP-IRIS system and would allowthe user to differentiate between floating and static particles as well as provide additionalinformation for nanoparticle characterization.Year 1: Proof-Of-Concept Prototype The first year will focus on proof-of-concept researchillustrating the successful combination of SP-IRIS and FP. I have already constructed an SP-IRISbench-top microscope and will be validating the instrument’s operation prior to adding FP. Thismodification will require the addition of a programmable LED array for angled illumination,adapting FP algorithms for reflection microscope geometries, changing SP-IRIS forwardmodeling to use FP images, and determining whether volumetric FP results are viable with SP-IRIS imaging methods. This year’s goals will be achieved when floating and static customizedcarbon nanotubes can be identified with the system and an improvement in particle visualizationis achieved with the combined system over SP-IRIS alone.Year 2: System Design and Speed Improvement: The primary work in this phase will focus onachieving real-time imaging using the combined software platforms from both modalities.Additional hardware and software modifications will likely be necessary to determine whetherdifferent illumination patterns, LED arrays, lens setups, or other aspects of the system canimprove the imaging quality or speed. This year’s success criteria will be satisfied once real-timeimaging of floating carbon nanotubes in a microfluidic channel is achieved. This phase can beextended into Year 3 if additional time is required for real-time imaging with the system.Year 3: System Validation in Biological Particles: The third year will investigate the device’sapplications in biological imaging. The system will be tested for its sensitivity to biologicalparticle detection and characterization of different nanoparticles. The throughput and speed ofthis system will also be tested by analyzing samples with increasing particle counts underdifferent fluid flow conditions. Should this device exhibit reliable results in identifying andcharacterizing biological samples, the use of this device in clinical trials at Boston University’smedical hospital will be explored.Intellectual Merit: Achieving high-resolution, high throughput imaging of nanoparticles wouldopen opportunities for nanoparticle imaging in many other scientific fields including thesemiconductor industry. This technology also uses relatively low-cost optical componentsallowing other research facilities to build their own systems. This research will be published inresearch journals and presented at conferences.Broader Impacts: This technology would be viable as a low-cost, high sensitivity andspecificity diagnostic platform for infectious diseases. The high throughput capabilities of thisproposed device would be significant for detecting diseases with low concentrations of biologicalmarkers in the body. The results from this project will also be published in multiple journalarticles and presented at optics-focused and biological research-related conferences.[1] Avci, O., Ünlü, N. L., Özkumur, A. Y., & Ünlü, M. S. (2015). Interferometric Reflectance Imaging Sensor(IRIS)--A Platform Technology for Multiplexed Diagnostics and Digital Detection. Sensors (Basel, Switzerland),15(7), 17649–65. http://doi.org/10.3390/s150717649[2] Jesus, D. M.; Moussatche, N.; McFadden, B. B. D.; Nielsen, C. P.; D’Costa, S. M.; Condit, R. C. Vaccinia VirusProtein A3 Is Required for the Production of Normal Immature Virions and for the Encapsidation of theNucleocapsid Protein L4. Virology 2015, 481, 1−12.[3] Tian, L., Liu, Z., Yeh, L.-H., Chen, M., Zhong, J., & Waller, L. (2015). Computational illumination for high-speed in vitro Fourier ptychographic microscopy. Optica, 2(10), 904. http://doi.org/10.1364/OPTICA.2.000904"
139.0,"Introduction: Understanding the atmospheric questions about the fate of ISOPO in differing2oxidation of organic compounds is important NO regimes.xfor predicting the production of tropospheric To combat this, I aided in the developmentozone and organic aerosols, both of which im- of a field-hardened high resolution time-of-pact our health and climate. Though the for- flight CF O- CIMS coupled with a low pressure3mation of these two constituents involves many gas chromatograph (GC-HR-ToF) that is capa-compounds, isoprene plays a dominant role due ble of observing isomer distributions of variousto its large biogenic emissions and rich oxida- oxidation products in ambient air. An initialtive chemistry. However, it is the complexity of field test has provided promising preliminaryits oxidation scheme that serves as a major chromatograms of several isoprene productssource of uncertainty when making predictions, and my plans to continue the development ofgenerating chemical models that fall short of this instrument will allow it to serve as an inval-replicating ambient observations especially near uable analytical tool, allowing for an increasedisoprene-dominated environments1. understanding of ISOPO chemistry and its ef-2One reason for this uncertainty is due to its fects on global air quality.peroxy radical (ISOPO ), formed predomi-2nantly through the oxidation of isoprene withOH. ISOPO is known to undergo three individ-2ual reaction pathways, with the likelihood ofeach strongly dependent on the availability ofNO . In areas where NO levels are decreasingx x(e.g., the United States), the isoprene chemistryis being shifted towards a system dominant inautoxidation and HO reactions, resulting in the2production of species such as isoprene epoxides Figure 1: Instrument schematic of GC-HR-ToF. Greenboxes represent mass flow controllers; blue circles repre-(IEPOX), which contribute to the formation ofsent valves; arrows indicate direction of analytical flow.secondary organic aerosols2. Analogously, as(A) GC column; (B) Heating/cooling unit; (C) Radioac-NO x emissions increase in more pristine areas tive ionizer; (D) Glass flowtube; (E) ToF mass analyzer.(e.g., the tropics) ISOPO 2 begins to favor its re- Instrument Description: The GC-HR-ToFaction with NO, either increasing the ozone pro- uses a 1-meter column with its resulting effluentduction potential of the area or forming reser- sampled directly into the CIMS. During collec-voirs, like isoprene nitrates (ISOPN), that can tion, the sample is cryofocused near the en-transport NO x elsewhere with unknown effects. trance of the column via a custom-built heat-Observations of ISOPO 2 products in the at- ing/cooling unit and the temperature of the coldmosphere can shed light on the relative im- trap is controlled through alternating CO cool-2portance of the reaction pathways that produce ing and resistive heating. Furthermore, duringthem. The utilization of clustering ion chemistry the trapping phase, ambient air is also simulta-in conjunction with chemical ionization mass neously analyzed by the CIMS, allowing for di-spectrometry (e.g., CF 3O- CIMS) has allowed rect comparison between the GC sample andlow fragmentation sampling of important multi- traditional measurements. The overall instru-functional isoprene products considered too ment schematic is shown in Figure 1, with a fo-fragile to be detected otherwise3. However, be- cus on the GC components I constructed.cause isoprene oxidation results in eight Preliminary Results: Our first field test oc-ISOPO 2 isomers, CIMS cannot distinguish be- curred during PROPHET 2016, a campaign heldtween the isomeric products, causing ambiguity at the University of Michigan Biological Sta-in the data provided and leaving unanswered tion. Sitting on the PROPHET tower 30 metersNSF GRFP 2017 1Krystal Vasquez Graduate Research Plan Statement6 10 14Retention Time [min]Figure 2: (A) Peak assignment of ISOPOOH/IEPOX (blue) and ISOPN (red, signal x3) for data collected on 23 July,10:00 EDT; (B) Sample of peak identification of ISOPOOH/IEPOX (black) using known product ions (red & blue,signal x2) from data collected on 23 July, 14:00 EDTabove ground, the GC-HR-ToF sampled above be able to obtain isomer-specific measurementsthe tree canopy obtaining flux measurements of of isoprene products in areas with a spectrum ofvarious compounds. Even more, in situ isomer NO concentrations. This will be key in under-xdistributions of isoprene products (e.g. isoprene standing both the favorability of ISOPO path-2hydroxy hydroperoxides (ISOPOOH), IEPOX ways and its subsequent effects on air quality,and ISOPN) were observed for the first time in particularly in areas where VOC/NO ratios canxambient data. I have performed preliminary be effected by increasing emissions, thepeak assignment using known product ions2 to transport of NO or air quality regulations.xidentify the compounds (Figure 2). The isomer Conclusion & Broader Impacts: The data Idistributions determined by this data set will will obtain using the GC-HR-ToF will provideprovide information regarding the fate of a critical test of our current grasp of isopreneISOPO in a Northern Michigan forest influ- chemistry, adding to the current kinetics used in2enced by both pristine air from the north and models to improve predictions. In addition, itshigh-NO pollution from nearby urban centers. use by several atmospheric groups at Caltech, asxResearch Plan: Though overall successful in well as collaborators, will extend the use of thisthe field, I plan to further improve the GC cry- new technique beyond our initial focus, demon-otrapping system. Despite the fact that the col- strating both its versatility and benefit to the sci-umn separated the product isomers, the high hu- entific community.midity levels seen in Michigan served as a ma- Lastly, as this instrument aims to better un-jor obstacle during sample collection; trapped derstand some of the fundamental science be-water easily degrades the chromatography by hind isoprene chemistry, it provides an oppor-hydrolyzing isomers and overshadowing the tunity for me to enhance my science communi-visibility of early eluting peaks. Though I per- cation skills. By using my blogging platform, Iformed constant on-site adjustment to minimize plan to discuss the various aspects of atmos-this effect in the field, improvement of the tem- pheric chemistry and atmosphere-biosphere in-perature control and automating its adjustment teractions in order to teach a demographic com-with ambient humidity will make the GC system posed of young students and future scientistsmore robust in the field. about a field they may have otherwise neverAfterwards, I propose to commission the in- been introduced to. Additionally, social mediastrument to continuously sample ambient air on has been and will continue to be utilized whenCaltech campus (an urban high NO environ- out in the field to give my readers a peak intoxment) while also preparing for a summer collab- the day to day workings of an atmosphericoration at Indiana University (a rural low NO x chemist. References: (1) Horowitz, L. W. et al. JGR:regime). During both field experiments, as well Atmos. 112, 13 (2007). (2) Bates, K. H. et al. JPCA 118,as with future campaigns, the GC-HR-ToF will 1237-1246 (2014). (3) Crounse, J. D. et al. Anal. Chem.78, 6726-6732 (2006).NSF GRFP 2017 2langiSyrartibrA10.50"
140.0,"Introduction: The Channeled Scablands is a striking landscape that captures a remarkablemoment in Earth’s history when enormous quantities of glacial meltwater poured across the region.These glacial floods carved deep canyons, referred to as coulees, into basalt bedrock within theotherwise subdued topography of the Columbia Plateau. The most impressive of these, GrandCoulee, is the largest flood-carved canyon on Earth at 200 m deep and nearly 100 km long. Oncethought to be glacially-carved, the recognition that Grand Coulee formed due to the upstreamerosion of what must have been one of the largest known waterfalls on Earth [1] brought about arevolution in geological thinking by proposing that catastrophic events—rather than slow,uniformitarian processes—can dominate the evolution of Earth’s surface. Though a catastrophicflood origin of the Grand Coulee is now accepted, many questions still remain regarding the sizeand number of floods that carved it [1]. I propose to use cosmogenic nuclide exposure dating tomeasure the retreat rate of the Grand Coulee waterfall, and to combine field evidence ofsediment transport with numerical flood models to constrain the discharge of the outburstfloods that carved Grand Coulee. This approach will address longstanding questions concerningthe role of catastrophic events in shaping Earth’s surface, make inferences about the hydrology ofearly Mars (which contains canyons similar in form to Grand Coulee). Additionally, my projectwill highlight the process of scientific discovery to the public via Grand Coulee’s status as aNational Natural Landmark and a key feature on the Ice Age Floods National Geologic Trail.Questions: The project will address two fundamental questions regarding the role of catastrophicfloods in eroding Grand Coulee. Question 1: Did Grand Coulee form geologically instantaneouslyduring a single flood, or by flooding throughout the last ice age or even earlier glaciations?Question 2: What was the magnitude of the flood(s) that carved Grand Coulee and how did floodvolume change as the landscape evolved via canyon incision?Research Plan: I propose to integrate field, geochronological, and numerical modeling methodsto unravel the geomorphic history of the Upper Grand Coulee, under the advisement of Dr. IsaacLarsen at the University of Massachusetts. Question 1 will be addressed using primarilygeochronological methods. Determining exposure ages along the length of the canyon rim ofUpper Grand Coulee will constrain the location of the waterfall as it retreated upstream. I havecollected samples of fluvially-transported granite boulders and flood-carved basalt surfaces fromthe study area for exposure dating [2]. Granites will be processed for 10Be dating in the UMassCosmogenic Nuclide Laboratory, and basalts will be dated using 3He in labs of collaborators. Ifthe waterfall experienced gradual retreat in response to multiple floods, we expect to find adecrease in exposure ages of flooded basalt surfaces with distance upstream. Alternatively, similarages of flooded basalt along the rim of Upper Grand Coulee would support a more rapid landscaperesponse driven by a single flood or several floods occurring in rapid succession. Question 2 willbe addressed by field and numerical methods. I will use a 2D, depth-averaged shallow waterhydraulic script to numerically simulate floods of varying magnitudes in Grand Coulee, withdischarges ranging from the minimum required to barely inundate the canyon floor, to that whichfills the canyon to the brim. This script will be run on the Massachusetts Green High PerformanceComputing Center, a supercomputer accessible from UMass. Field measurements will be used todetermine which of these modeled discharges is most consistent with the geochronologicalevidence. I measured boulder dimensions on depositional bars in Grand Coulee, and will use theseto constrain the threshold bed stresses and flood discharges required for their transport. Similarly,field measurements of basalt columns and physics-based estimates of bed stresses required to erodethe bedrock channel floor will be used to constrain the canyon-forming discharge [3]. Thesedischarge constraints will allow me to assess whether Grand Coulee was filled to the brim byfloods, as is often assumed in flood reconstructions, or whether smaller, but still exceptional,floods carved the canyon. Moreover, the geochronology will allow me to independently assess thepredictions of my modeling, as the dating will indicate whether the appropriate paradigm ofincision requires huge, brim-full floods or smaller floods.Intellectual Merit: The evidence to support extensive flooding in the Channeled Scablands isoverwhelming, but it remains a challenge to quantitatively constrain the pace and timing of theevolution of the bedrock landscape and the coevolution of flooding and canyon incision [3]. Ourunderstanding and interpretation of the roles that floods of varying magnitudes may have playedin generating the topography of the Channeled Scablands therefore remains far from complete. Byaddressing the magnitude of the floods that carved Grand Coulee, my work will address long-standing questions regarding the balance between catastrophic and gradual processes in shapingtopography. There is great value in constraining the discharge of megafloods: large freshwaterreleases can alter ocean circulation and trigger abrupt climate change [4], so understanding themagnitude of paleo-floods is key to understanding Earth’s past climate and sensitivity for futureclimate change, given current ice melting in polar regions. Additionally, understanding theprocesses and formation rates of Grand Coulee can yield insight into the evolution of the muchlarger Martian Outflow Channels and contribute to a clearer picture of the volume of water thatflowed on the surface of early Mars, where direct dating is not yet possible.Broader Impacts: The story of the megafloods is exciting, coherent, and illustrative of the natureof scientific research, and outreach on this topic can motivate the next generation of scientists. Infact, watching a documentary on the Channeled Scablands played a major role in my own decisionto pursue graduate research. Outreach will therefore be a significant broader impact of this work.I participate in UMass’ Graduate Women In STEM’s Science Café, and already have multipleChanneled Scablands presentations scheduled at a local middle school, through which I hope toignite interest in science and make research relatable. I will also work with Eureka!, a branch ofGirls, Inc., which runs summer programs at UMass for pre-college girls from an underservedcommunity. I will play a leading role in developing a series of local discovery-based field trips tointroduce girls to earth science, which is largely absent in the standardized state curriculum. Floodsfrom ice and landslide dam failures are hazards worldwide, and the quantitative methods forestimating flood discharge developed in my work can be directly transferred to smaller floods, andthereby used to assess geohazards using paleoflood evidence and to predict risks from futureflooding scenarios. As the usefulness of scientific research is limited until it is communicated topolicymakers and members of the public, I will post project updates to my field blog to convey theresearch process, discuss my findings, and provide a personal perspective of geoscience. I alsointend to collaborate with other researchers to develop a field trip to the Scablands at a nationalconference to showcase current research on the megafloods, and will work with state parks in theGrand Coulee area to develop interpretive displays to communicate the story of the Scablands’dynamic past to the public.References [1] Bretz, J. 1932. American Geog. Soc. 15. [2] Lal, D. 1991. Earth and Plan. Sci. Letters. 104, 424-439.[3] Larsen, I. and Lamb, M. 2016. Nature. 538, 229-232. [4] Barber, D.C., et al. 1999. Nature. 400, 344-348."
142.0,"The evolution of similar traits in distantly related species is one of nature’s great surprises.Convergent evolution of traits has been widely observed throughout the animal kingdom;however, it is often unclear whether this phenotypic convergence results from convergentevolution of genes (Stern, Nat Rev Genet 2013). On a molecular level, convergent evolutionoccurs when the amino acids of a specific protein preferentially undergo mutations that producesimilar or even identical amino acid sequences within distinct evolutionary lineages. A high levelof adaptive convergent evolution – that is, convergence due to positive selection of beneficialmutations – would suggest that some genes have “optimal configurations,” which evolution usesand reuses across species. If such genes exist, then evolution is somewhat predictable,proceeding by one of a small number of possible paths (Stern & Orgogozo, Science 2008). Incontrast, a complete absence of adaptive convergence would indicate that protein configurationsbeneficial to one species are seldom optimal within other species, and that evolution mayproceed by a much wider set of paths. Thus, two fundamental questions in evolutionarymolecular biology are 1) how often and in which genes convergent molecular evolutionoccurs and 2) whether molecular convergence is a primary driver of phenotypicconvergence. Most analyses of convergent evolution have been limited to single genes (Li et al.,Curr Biol 2010) or small taxa (Bazykin et al., Biol Direct 2007); to date, no genome-wideanalysis involving a wide variety of species has been completed. Recently, the advent of whole-genome sequencing has opened new opportunities for exploring molecular convergence.Published genomes now exist for over 100 animal species, and 177 more are currently underway(Koepfli et al., Annu Rev Anim Biosci 2015). Thus, a genome-wide search for convergentmutations across multiple species is now possible, and might reveal new evidence of adaptivemolecular convergence.I plan to develop and apply a novel computational framework to test for convergentevolution among 61 sequenced mammalian species. I hypothesize that convergentmolecular evolution occurs at a higher rate than has been previously observed, and thatthis genetic convergence drives convergence of observable traits. This framework will extendthe boundaries of biological knowledge by quantifying the frequency of convergent evolution,and will augment existing phylogenetic methods in a broadly applicable framework that can beextended to other genomes in the future.Aim 1: Develop a novel computational framework for identifying convergent evolutionbetween genomes. My framework will be generalizable to any data set with the followinginputs: 1) a phylogenetic tree for a set of species, and 2) the pairwise sequence alignments of allproteins in those species. I will limit my analysis to genes unambiguously alignable to a one-to-one human ortholog in at least 80% of mammalian genomes. I have verified that even afterfiltering on these criteria, >50% of all human genes are retained. My analysis will integrate thesedata as follows: Step 1: Infer ancestral sequences. For every amino acid in every sequence, I will computeamino acid sequences at each ancestral node in the phylogeny using the linear-timemaximum parsimony method implemented in PAML 4 (Yang, Mol Biol Evol 2007). Step 2: Infer patterns of adaptive convergent evolution between species pairs. For every pairof species within our analysis, for each gene, I will identify the set of amino acids thatconverged in that pair of species with probability >0.9, as well as those that diverged withprobability >0.9, based on the ancestral sequences inferred in Step 1. I will report aconvergence score for the gene in this pair of species: the ratio of convergent mutations todivergent mutations. Thus, genes with high rates of both divergent and convergent mutations(such as rapidly evolving immune genes) will score lower than those with relatively higherrates of convergent mutations. After computing the full distribution of convergence scoresfor every gene in every species pair, I will denote the upper outliers as convergence events. Step 3: Evaluate model performance on simulated data. I will simulate evolution of proteinsequences in which a small fraction of the sequences evolve under a non-neutral convergencepattern and the rest evolve neutrally. I will measure my framework’s precision and recall ininferring which sequences evolved under the convergent model. If my framework is able todetect convergence events in the simulated data at a low false discovery rate, but observes noconvergence events in the biological data, then these results will cast doubt on the hypothesisthat adaptive convergence is a significant driving force in molecular evolution.Aim 2: Quantify the levels of convergent evolution within mammalian genomes, andidentify functions enriched within genes evolving in convergence. Step 1: Identify specific genes that have evolved in convergence across species. Using publicalignment tools (Kent et al., PNAS 2003), my collaborators in the Bejerano Lab at Stanfordhave provided cross-species sequence alignments and a phylogenetic tree for 61 mammalianspecies. I will apply my framework from Aim 1 to all pairs of sufficiently divergedmammalian species and identify genes within each species-species pairing that exhibit non-neutral convergence. I hypothesize that I will find evidence of adaptive convergentevolution within many genes and within almost all species-species pairings. Step 2: Identify convergent genotypes potentially responsible for known convergentphenotypes. If evolutionary parallelism is truly adaptive, this would suggest that genesconverge when they undergo similar selective pressures within different species (Castoe etal., PNAS 2009). Therefore, I hypothesize that genes facing similar pressures withinindependent species will be more likely to evolve in convergence within those species.For example, in aquatic mammals such as dolphins and manatees, we might expect highconvergence of skin-expressed genes involved in thermoregulation. Indeed, my preliminaryanalysis has identified 4 convergent mutations in the gene TGM1 in dolphins and manatees, asignificantly greater number than expected by chance. Human mutations in this gene cause askin disease called ichthyosis, characterized by fish-like, scaly skin (Laiho et al., AJHG1997). In order to find similar cases, I have identified a set of 20 convergent phenotypes thatarose independently in mammals, such as adaptation to high altitudes or dry environments.For each of these phenotypes, I will identify genetic convergence events that may beresponsible for the phenotype in question. If my hypothesis is correct, this analysis willsuggest functions for which similar selective pressures across species have necessitatedsimilar courses of protein evolution across these species. The specific amino acidsubstitutions that I identify will then be prime targets for further examination in functionalassays, as described by Liu et al. (Mol Biol Evol 2014).Broader Impacts: This project will help us to understand whether phenotypic convergence is adirect result of genotypic convergence. I will create a publicly available, user-friendlyvisualization for the UCSC Genome Browser that highlights hotspots of convergent evolution.This tool will allow biologists to visually explore instances of adaptive molecular convergenceand to ask even deeper questions about the specific functional roles and phenotypic effects ofthese convergent mutations."
144.0,"permission.Investigating Informal E-Waste Recycling Methods and Associated Soil PollutionKey words: environmental pollution, heavy metals, e-waste, recycling, informal, DelhiWhere does your computer go to die? Electric and electronic waste (e-waste) containshazardous materials and much of it is processed with few environmental controls. Annually, anestimated 20 to 50 million tons of e-waste is produced worldwide1 and due to the substantialamount of labor involved in the recycling of electronic devices, many e-waste dealers turn todeveloping economies for processing2. Policies designed to address the movement of e-wasterecycling increasingly require robust scientific evidence of toxic leaching and the nascent bodyof evidence describing the environmental effects of unregulated or informal e-waste recycling islargely anecdotal3, 4. The few empirical studies have operated at an inappropriate scale to makeassociations between processing categories and associated levels of pollution5; have analyzedpolicy at a more global scale2, 6; or have focused on pollutant leaching in a laboratory setting as aproxy for environmental leaching7. The recent US Government Accountability Office report(GAO-08-1044, August 2008) criticizing the US EPA’s handling of e-waste highlights therelevance of this research. My study will make a significant contribution to both research andpolicy by addressing this gap in scale and context and by testing for robust associations betweenquantified pollutant levels and specific e-waste industrial processes in the field environment.This investigation will classify and map e-waste recycling operations and quantifyassociated pollutant levels in the soil. Hypothesis: the concentrations of key pollutants in the soilwill increase in association with more destructive recycling processes (e.g. repair and resale willbe associated with lower toxin concentrations as compared with smashing cathode ray tubes forthe copper yokes).Methods: My proposed field site is Delhi, India, due to the city’s established e-wasterecycling industry and well-documented specialized processing areas4, 8. I will collaborate withthe following non-governmental organizations in the United States and on-site in India: SiliconValley Toxics Coalition; Toxics Link, Delhi, India; and Chintan Environmental Research andAction Group, Delhi, India. Base maps of Delhi will be collected from map archives, universitydepartments, and government offices. These will include streets and historical land use to assistin navigation and pollutant baseline controls; elevation for surface/hydrological modeling; andgeology, soils, and streams for environmental controls. Additional information will be gatheredfrom public records if historical maps are not available. All data will be translated intogeographic space, and digitized in a Geographic Information System, with coordinate systemsdefined, projected and transformed as necessary. Following this, key individuals from localNGOs, government offices, and universities will be interviewed to provide qualitative data forthree critical components: types of e-waste recycling operations in Delhi, site locations, andhistorical land use not captured in the base map construction.Combining the results of these interviews with published literature on recyclingprocesses8, 9, a series of recycling operation categories will be categorized (e.g. one code for goldextraction from printed circuit boards using acid-baths versus another code for cell-phonerefurbishment), resulting in approximately 3-5 analytical codes. Information gained in theinterviews will be verified and geo-located in the field by surveys assisted by a differentiallycorrected geographic positioning system (GPS). Using the population of coded recyclingoperations, a stratified simple random sample of individual recycling sites within each code willbe selected. Soil analysis will primarily be performed with a field-portable x-ray fluorescenceanalyzer (fp-XRF), supplied by Ron Amundson’s lab, based in the Department of EnvironmentalScience, Policy and Management at UC Berkeley. The fp-XRF will be calibrated for lead,Copyright 2008. All rights reserved to original author.Copyright 2008 All rights reserved to original author. Do not duplicate or use in any way withoutpermission.arsenic, cadmium, bromine, mercury, and chromium, toxic elements most commonly associatedwith e-waste2. All samples collected and fp-XRF readings will be catalogued with geographiccoordinates using GPS.The first sampling phase will define pollutant plumes and concentration strata usingtransect sampling with the fp-XRF. Systematic random sampling will assign sampling locationswithin each plume strata. In situ soil readings and ex situ samples will be collected during thesecond phase. To aid in precision and bias control, two methods will be employed: 1) onerandomly selected site will provide field calibration values by double sampling: ex situ soilsamples and in situ readings 2) 20% of all in situ readings will be accompanied by ex situsamples at remaining sites as a further control for environmental variations10.Potential sources of error include sampling design insensitivity to local variations,sampling obstructions at individual sites, non-soil ground-cover (mitigated by alternatecollection protocol for dust using thin-sample), dynamic environmental conditions (mitigated byhydrologic modeling or averaging multiple series), and changing land use at observation sites(mitigated by a study design with more sampling sites than necessary).After ex situ soil samples have been laboratory tested, all soil data will be digitized andgeo-referenced. In situ readings will be calibrated against quantitative laboratory resultsproducing a measure of estimated bias. Multivariate Analysis of Variance (MANOVA) will beused to assess the combination of toxin concentrations against the categories of recyclingprocesses. Additional variables will be tested for inclusion in the model such as historical landuse and environmental features such as slope and soil type. Weights will be applied in the modelfor the concentration strata and to control for spatial autocorrelation. Covariance will beaddressed in the MANOVA model.Anticipated Results: As the recycling process becomes more destructive, theconcentrations of key soil pollutants are expected to increase. The results of this study can aidmore precise targeting of particular waste-handling practices for environmental controls, thusfacilitating a more nuanced approach to improving e-waste recycling operations. Methods usedin this project could also be replicated in other locations to examine environmentalcontamination associated with formal and informal e-waste recycling.Support: My advisor, Rachel Morello-Frosch (study design and environmentalpollution); Ron Amundson (soil sampling methodology); John Radke (spatial analysis andsampling techniques); Alan Hubbard (statistical analysis); and Alastair Iles and Kate O’Neill(hazardous and e-waste trading). Oladele Ogunseitan at UC Irvine, and Jaco Huisman with theUN’s StEP Initiative (e-waste toxicity and recycling processes).1. Schwarzer, S., et al. in Env Alert Bulletin 4 (UNEP, 2005). 2. Widmer, R., et al. Globalperspectives on e-waste. Env Impact Assess Rev 25, 436-458 (2005). 3. Puckett, J., et al. (BasalAction Network, 2005). 4. Puckett, J. B. et al. (Basal Action Network & Silicon Valley ToxicsCoalition, 2002). 5. Wong, C. S. C., et al. Evidence of excessive releases of metals fromprimitive e-waste processing in Guiyu, China. Env Pollution 148, 62-72 (2007). 6. Iles, A.Mapping Environmental Justice in Technology Flows: Computer Waste Impacts in Asia. GlobalEnv Politics 4, 76-107 (2004). 7. Lincoln, J. D., et al. Leaching Assessments of HazardousMaterials in Cellular Telephones. Env Sci & Tech 41, 2572-2578 (2007). 8. Agarwal, R., et al.1-57 (Toxics Link, 2003). 9. Streicher-Porte, M. et al. Key drivers of the e-waste recyclingsystem: Assessing and modelling e-waste processing in the informal sector in Delhi. Env ImpactAssess Rev 25, 472-491 (2005). 10. Kalnicky, D. J. & Singhvi, R. Field portable XRF analysisof environmental samples. J of Haz Materials 83, 93-122 (2001).Copyright 2008. All rights reserved to original author."
146.0,"Catherine Alves | October 2016Keywords: Coral reefs, conservation, community-based fisheries, sustainability, survey analysisProposed Research: Does community-based fisheries management restore ecological functionand improve the livelihood of fishers in Belize?Background: Overfishing is a significant threat to the world’s ocean ecosystems (1) that hascaused an 80-95% reduction in large predatory fish biomass (2). This not only disruptsecosystem functioning but threatens invaluable commercial and subsistence fisheries that providelivelihoods and fish protein to nearly 3 billion people annually (3). Marine reserves are one tooldesigned to mitigate these impacts and to meet both biodiversity conservation and fisheriesmanagement goals. Marine reserves function by restricting fishing access with the intention ofincreasing fish abundances and diversity within no-take zones, ideally with fish spilling over intoadjacent non-protected areas (4). However, poaching, lack of enforcement, and limited spilloveroften limit the broader success of marine reserves (5).An emerging approach is to more directly involve and incentivize local communities inthe restoration and management of overfished stocks. Such “TURFs” (“Territorial User Rightsfor Fishing”) assign local fishers the rights to fish in designated areas in exchange for reportingtheir catch. These initiatives encourage environmental stewardship in coastal communities byproviding effective ownership of fish stocks, further incentivizing sustainable fishing practices(6, 7). TURFs have been implemented worldwide by the Environmental Defense Fund (EDF),but little is known about their effectiveness, particularly in the tropics where implementation isonly beginning (6). Research to examine the impact of TURFs from ecological and socialperspectives is limited (6, 7), despite catch improvements reported by fishers participating in theprogram. TURFs have been designed to prevent the “race to fish” oftentimes accompanyingsmall-scale fisheries because they assign catch shares to fishers. Furthermore, by assigningfishers locations to fish, poaching decreases in restricted areas, enabling fish populations torecover (6, 7).In 2011, the first TURFs in the Caribbean were established by the Belize FisheriesDepartment and they incorporated The Port Honduras Marine Reserve (est. 2000) and theGlover’s Reef Marine Reserve (est. 1993) (7). The Belize Fisheries Department is currently inthe process of implementing a nation-wide TURF system, adding seven additional TURFs to pre-existing marine reserves (7, www.fisheries.gov/bz/#). The purpose of my study is to quantifythe efficacy of Belize’s newly implemented TURFs in restoring overfished stocks, generalbiodiversity, and ecosystem functioning as well as in improving the livelihood of fishers.Specifically, I will test the following hypotheses:H : Fish species richness, density and biomass will be greatest in locations with TURF1implementation and lowest in unmanaged control sites.H : TURF implementation will improve the perception, livelihood, and catch per unit2effort (CPUE) of fishers who participate in the TURF program versus those who do not.Study Design: Visual fish surveys will be performed in the nine TURF locations plus nineunmanaged control sites (7, www.fisheries.gov/bz/#). Fish species richness, density and biomasswill be quantified via underwater transect surveys using SCUBA. At all sites, I will quantify1ecological factors that could influence coral reef community structure and potentiallycompromise co-management efforts – such as reef structural complexity, temperature,chlorophyll, macroalgal cover and human population density (Cox et al., in review).The quantitative social science surveys will consist of structured interviews of 100individuals randomly selected from four stakeholder groups: fishers participating in the TURFprogram, fishers not participating in TURFs, natural resource managers, and scientists (8).Closed-ended questions will be asked of all survey respondents to collect socio-economic,demographic and perceptions data including income, number of years in profession, gender, andperceived goals of the TURF program. Specifically, fishers will be asked to identify fishinglocations on a map, provide CPUE, and share the percent of their income that comes fromfishing. I will use the multilevel, nested framework of studying social-ecological systems (9) tobuild Bayesian hierarchical models to quantify the relationship between covariates. It is crucialto include fishers in management decisions because they become resources of change in theircommunities (5, 6, 7).A key component to the success of this project will be my partnership with the BelizeFisheries Department, the University of Belize, and local non-profits like Belize Healthy Reefs –all of whom are currently collecting CPUE data at locations where fishers sell their catch tovendors. During a research trip to Belize this past summer, I began to make connections withindividuals at all of these institutions, with intentions to collaborate in the future. My partnershipwith local contacts is essential for establishing trust among the community because it willincrease the likelihood that the fishers, managers, and scientists will consent to the study (5, 9).This collaboration will also enable the survey questionnaire to be implemented in the locallanguages of English, Spanish, and Belizean Kriol, therefore reaching different communities inBelize. In addition, I will draw upon data collected by my PhD advisor, Dr. John Bruno, who hasconducted long-term monitoring research in Belize across 16 sites with varying levels of marineprotection.Broader Impacts: This study will advance the field of community-based fisheries managementby providing natural resource managers and fishing associations with insights into the efficacy ofthe TURF program in Belize from social and ecological perspectives. Information gleaned fromthis study has the potential to maintain livelihoods of the commercial and subsistence fishers inBelize while preserving coral reef fish biodiversity. I will also incorporate public outreach andeducation to increase scientific literacy and engagement of the public, both among the public inBelize and in my local community in North Carolina. I will collaborate with local institutions toco-organize public forums, workdays and outreach events for citizens of Belize to educate themabout their local marine ecosystems. For outreach within my community in North Carolina, Ihave already developed a lesson plan for grades 8-12 on marine food webs for the ScientificResearch and Education Network (SciREN). I hope to incorporate the findings of this study intoa different lesson plan that focuses on marine resource management decision making. Both ofthese outreach programs will show the public the importance of interdisciplinary conservationscience, and encourage environmental stewardship among the next generation. Community-based environmental management techniques are emerging across the globe as some of the mostpromising ways to combat anthropogenic threats to ecosystems, and I look forward to becominga part of that endeavor.References: 1. Jackson, J.B.C., et al. Science 293:629-638 (2001). 2. Valdivia, A., et al. PeerJ PrePrints 3:e805v1(2015). 3. FAO. The State of World Fisheries and Aquaculture: Opportunities and Challenges p. 243 (2014). 4.2Gaines, S.D., et al. Proceedings on the National Academy of Sciences 107(43):18286-18293 (2010). 5 Valdés-Pizzini, M., et al. Caribbean Studies 40(2):95-128 (2012). 6. Barner, A.K., et al. Oceanography 28(2):252–263(2015). 7. Foley, J.R. Proceedings of the 12th International Coral Reef Symposium: Evaluating ManagementSuccess (2012). 8. Bernard, H.R. Research Methods in Cultural Anthropology ch. 9 (1988). 9. Ostrom, E. Science325:419-422 (2009).3"
148.0,"OPTIMIZING THE SYNTHESIS OF METAL ORGANIC FRAMEWORKSUSING SEGMENTED FLOW TUBULAR REACTOR TECHNOLOGYKeywords: metal organic framework, scale up, continuous flow processesI. BACKGROUNDThe segmented flow tubular reactor (SFTR) is an exciting breakthrough in the realm of nano-scaletechnology. I first encountered this reactor during my research at Sandia National Labs (see personalstatement), where it showed much promise in scaling up the synthesis of titania nanowires. Due tothe limitations of reactor size, high chemical costs, and uncontrollable side effects of chemicalimpurities, mass production of nanoparticles remains an ever increasing challenge of engineerstoday. The expansion of a typical batch process will often lead to low quality synthesis due to theinability to control particle size and morphology under heterogeneous conditions. This samechallenge is also paralleled within the metal organic framework (MOF) industry. How can MOFS,having synthesis routes and material properties that depend on nucleation at a reaction surface, beproduced at a large scale where quality isoften sacrificed for quantity? Fortunately,the SFTR is able to address this issue inmuch the same way as it did fornanomaterials. The key principle behindthe design is the segmentation of thereactants into micro-reactors in acontinuous tubular process. Eachmicrovolume is separated by animmiscible fluid or gas as shown inFigure 1. Within this arrangement,borrowing from the concept of ‘plugs’ inplug flow reactors, reagents are perfectlymixed in the radial direction but not in theaxial direction, thus removing the possibility of axialFig. 1. Schematic Representation of SFTR [1].back-mixing, and ensuring that all reactants areendure a similar history (residence time and heat exchange). This process allows the synthesis ofhomogeneous products with narrow particle size distributions, enhanced control of particlemorphology, polymorph selectivity and better stoichiometry control.II. MOTIVATIONCurrent literature demonstrates that continuous MOF synthesis is possible, even at the scale ofseveral kilograms per day [2]. The largest MOF manufacturing company, BASF, whose pilot plant islocated in Germany, can produce MOFs on order of several kilograms per batch using thesolvothermal method. What will be done as the demand for these hydrogen-capturing materialsincreases, especially as the United States is becoming an increasingly hydrogen-based economy [3]?NSF GRFP Research ProposalIII. RESEARCH PLANa. Year I –Determine Optimal Reacting Conditions for Common MOF CompoundsIt is desirable to know exactly what operating conditions the SFTR is expected to perform underbefore a prototype reactor can be prepared, and thus its effectivity in optimization tested. Therespective MOF compounds under analysis include, Mn3[(Mn4Cl)3(BTT)8]2, Zn4O(BDC)3,Cu3(BTC)2(H2O)3. These should all be explored due to their ability to their differing levels ofhydrogen storage capacity and differing size and geometry. The optimal reacting conditions will alsobe depend on what pore size is desired for the respective MOFs and what substrate is being used insynthesis.b. Year II- Determine Optimal Reactor Conditions for the MOF SynthesisWhereas year I focused exclusively on the chemistry of the MOFs to be prepared and demonstratingthat specific reaction conditions generate material with the desired properties, year II will be one ofmatching those conditions to that of a SFTR. Here, I will be sizing an SFTR that meets all of therequirements given the reaction conditions.c. Year III- Design a Bench Scale Model and Test PerformanceAt this point in research, it is expected that the prototype reactor can be developed as as bench scalemodel. Necessary parameters such as tube size, material construction, volume, pumping efficiencyand the need for a cooling or heating bath have been determined based on analysis in years I and II.The performance will have to become compared against traditional MOF synthesis routes such as labscale layer-by-layer deposition, and microwave synthesis.IV. ANTICIPATED RESULTSJust as the segmented flow tubular reactor has shown much promise in optimization of calciumcarbonate nanomaterial production [1], it is expected that, it will also be successful regardingsynthesis of the three chosen MOF compounds. The many similarities between MOF synthesis andnanoparticle synthesis is what will be exploited in this study, to hopefully achieve similar results.Solvothermal synthesis is useful for growing crystals suitable to structure determination, becausecrystals grow over the course of hours to days. It is expected that by optimizing the SFTRs models toeach respective MOF mechanism, a continuous production of uniform and low–defect material canbe achieved over this same length of time or even a shorter duration.V. INTELLECTUAL MERIT & BROADER IMPACTSThe implications of this research project are far reaching, even beyond its potential to mass produceMOFs and thus meet the demand of our growing hydrogen economy. It has the potential to introducean energy efficient way of producing compounds designed for energy efficient applications to beginwith. Double threat! This projects represents the cross between the chemistry and chemicalengineering discipline to address the issues in sustainability that plague our nation. The scale-up ofMOFs is not an area that has not been widely studied, and thus this research study represents a muchneeded contribution to the world of sustainable chemistry.NSF GRFP Research ProposalReferences:[1] “Precipitation of nanosized and nanostructured powders: process intensification using SFTR”, applied toBaTiO3, CaCO3 and ZnO - Chem. Eng. & Techn., 34(3) 344-352 (2011).[2] “BASF Develops Method for Industrial-Scale MOF Synthesis; Trials Underway in Natural Gas Vehicle Tanks.”Green Car Congress. 5 October 2010.[3] ""Global Hydrogen Fuel Cell Electric Vehicle Market Buoyed as OEMs Will Launch 17 Vehicle Models by 2027,IHS Says"". IHS Inc. 4 May 2016. Retrieved 13 May 2016."
149.0,"cues on relationship perception and intent biasesMen are more likely to perceive a woman’s friendliness as sexual interest, and thispattern holds up across surveys, actual behaviors, and beyond lab conditions [1-3]. Althoughcommunication about sexual interest have always been complicated, they recently have becomelegal and societal issues. A more complete understanding of how individuals communicate aboutsex is necessary, especially when 23.1% of college women experience sexual assault [4].Intellectual MeritError management theory (EMT) explains this “sexual overperception” effect in men as astrategic bias favoring specific types of judgment errors over other types of errors. Differentialparental investment theory [5] states that male mammals are less physically obligated to invest inoffspring, so they tend to be more willing to engage in sexual activity, whereas females are moreselective about potentially costly sexual activity. For males, the error of “missing” an interestedfemale is costlier than the “false alarm” error of judging an uninterested female as interested,resulting in a pattern of decisions that adaptively reduces costs and increases benefits, even as itfails to minimize errors overall.EMT is, at its core, Signal Detection Theory (SDT) applied to intersexual relationships[6], using differential parental investment to model the costs and benefits of relationshipdecisions. SDT is a way to describe how observers judge the presence or absence of a “signal”when the given stimuli have some level of ambiguity (“signal + noise”) [7]. The division ofEMT from SDT has resulted in an unnecessarily restricted analysis of data that couldpresent a fuller explanation of behavior if analyzed using signal detection models. AlthoughEMT, like SDT, considers different judgments and possible outcomes, it ignores severalextensions and implications which a full SDT analysis can provide. For instance, EMT does notconsider the base rates of signals compared to noise (that is, the frequencies with which signalsand noise occur in the environment), and how that influences judgments. Very common truesignals, with rare non-signals, will encourage signal-present judgments in ambiguous situations(known as a liberal bias). Conversely, a low signal rate and common non-signals will encourageno-signal judgments (known as a conservative bias). Additionally, SDT provides a measure(sensitivity) of how well people distinguish signals from noise.One benefit of this approach is that concepts already developed within SDT cantransfer to EMT contexts. At the theoretical level, SDT specifies situations in which both menand women should have systematically different signal detection strategy profiles. Individualswith faster (v. slower) life history strategies, more unrestricted (v. restricted) sociosexuality, andmore short-term (v. long-term) mating orientation should show more liberal biases (Hypotheses1-3). Similarly, people high in mate value should show a liberal bias because their experience isof a higher signal base rate (H 4), which EMT cannot predict as it does not take signal/noise ratiointo account. It also is possible to manipulate aspects of the social situation, and thus the value ofdecision outcomes, by manipulating the attractiveness of the stimuli used as signals (H 5) and bychanging the signals-to-noise base rates through exposure to different sex ratios of stimuli (H 6).Additionally, methods and analyses from SDT research can be used to more fullyunderstand and analyze existing EMT results. For preliminary results, I analyzed the data fromPerilloux, et al. [8] using SDT. This confirmed that men are more liberally biased in perceivingsexual interest, but also yielded unanticipated insights: Women are more sensitive to thedifference between sexual interest versus non-interest (d’ in Figure 1), and -surprisingly- bothmen and women in this study are conservatively biased in perceptions of sexual interest (c inFigure 1). Differential parental investment theory predicts why men have a lower sensitivity thanwomen, as females may conceal their signals of sexual interest, making it more difficult for mento differentiate signal from noise. This also may explain why men are more liberally biased thanwomen, since they need to compensate for their lower sensitivity to maintain the same level ofoptimality at detecting sexual interest. This difference in sensitivity led to an additional hypoth-esis that men’s sensitivity will increase as the woman’s sexual cues become more overt (H 7).Methodological Approach – My stimuli will include 96video clips showing heterosexual pairs engaging in conver-sations. Each videotaped person will rate their sexual interest intheir conversation partner, then complete questionnaires toevaluate individual differences (described above). Method:Studies will involve participants watching the muted clips andrating each actor regarding their levels of sexual interest in theirconversation partner. Multiple study variations will look atinfluences of the observers’ life history strategy (H 1), socio-sexual orientation (H 2), mating strategy (H 3), and mate value(H 4). Additionally, experimentally manipulated sets of clipswill be shown to evaluate the causal effects of skewed ratios ofattractiveness of each conversant (H 5) in the video clips, priorexposure of participants to skewed sex ratios (H 6), andexposure to overt sexual cueing (H 7). Analysis will use bothEMT and SDT methods, utilizing multilevel probit regressionto determine c and d’ for this repeated measures design. [9]Broader ImpactsUnderrepresented Minorities in STEM: Efforts will be madeto recruit underrepresented and first-generation undergraduatesas research assistants, who will be encouraged to learn about the research process, present resultsat conferences, and participate in authorship of publications. Increasing Scientific Literacy andPublic Engagement with STEM: Research about romantic relationships often gets publicmedia attention, which will be used to broadly communicate the results of this research and bringattention to current directions in psychological science. This research will also be presented atregional and national conferences. Improving Individual Well-Being: This SDT approach willincrease knowledge about the abilities and biases different people have about sexualcommunication, empowering individuals to make informed, healthy decisions about their sexualand relationship behaviors. Identification of individuals and situations where sexual interest andintents are often misinterpreted will aid in locating at-risk populations, improving sexual assaultprevention policies, and inhibiting interference with the right to receive an education free fromdiscrimination through sexual harassment and sexual violence (per Title IX of the EducationAmendments of 1972).References: [1] A. Abbey, J. Pers. Soc. Psychol.42, 830-838 (1982). [2] A. Abbey, Psychol. Women Quat 11, 173-194 (1987). [3] M. G. Haselton, J. Res. Pers. 37, 34-47 (2003). [4] The Association of American Universities,Report on the AAU Campus Climate Survey on Sexual Assault and Sexual Misconduct (Westat, Rockville, MD, ed.2, 2015). [5] R. L. Trivers in Sexual Selection and the Descent of Man, B. Campbell Ed. (Aldine, Chicago, IL.1972), 136–179. [6] D. Nettle in Evolution and the Mechanisms of Decision Making, P. Hammerstein, J. R. StevensEds. (MIT Press, Cambridge, MA, 2012), 69-79. [7] D. M. Green, J. A. Swets, Signal Detection Theory andPsychophysics, (Wiley, New York, NY, 1966. [8] C. Perilloux, J. A. Easton, D. M. Buss, Psychol. Sci. 23, 146-151(2012). [9] L. T. DeCarlo, Psychol. Methods 3, 186-205 (1998)."
150.0,"studies of the RAG complex led to my interest in the evolutionary origins of adaptive immunity.V(D)J recombination is the process responsible for generating the massive diversity of antigenreceptors that characterizes the vertebrate immune system. RAG1 and RAG2, the protein prod-ucts of recombination activating genes 1 and 2, cooperate to initiate V(D)J recombination inlymphoid cells by making double-stranded breaks at recombination signal sequences (RSSs)(1).The recombinational DNA rearrangements catalyzed by RAG have long been biochemically lik-ened to the cleavage reactions effected by transposases (TPs)(1). In 1998, the demonstration thatRAG displays transposition activity in vitro strongly suggested that this likeness can be ex-plained by homology and that RAG is a descendant of an ancient transposable element(1). Due toextensive sequence divergence, a close homolog of RAG within the modern diversity of TPsevaded detection until targeted PSI-BLAST searches linked the RAG1 core to the Transib familyof TPs(2). Subsequent biochemical analysis of Hztransib, a Transib transposon active in the ge-nome of the corn earworm, revealed that, like RAG, Hztransib TP cleaves DNA through nickingand hairpinning steps that produce blunt transposon ends and hairpinned flanking ends(3) (Fig. 1).Additionally, insertion events create CG-rich 5-bp target-site duplications, as is typical forRAG(3). These results conform to expectations of a RAG-like TP, but it is reasonable to supposethat some of RAG’s properties are specific to V(D)J recombination and do not describe an ances-tral TP. I propose to conduct an exhaustive biochemical analysis of the Transib transposon in theYale Department of Molecular Biophysics & Biochemistry, in the laboratory of David Schatz,who discovered and biochemically characterized RAG1 and RAG2. Biochemical similarities be-tween RAG and Transib can lend further support to their homology. Biochemical differences cansuggest which functional aspects of RAG are evolutionarily recent recombinase-specific innova-tions, perhaps due to association of RAG1with other factors (e.g. RAG2) or perhapsdue to structural changes within theendonuclease itself.Aim 1: Determine the substrate requirements for Hztransib TP activity. Each RSScomprises a conserved heptamer and nonamer separated by a nonconserved spacer of either 12 or23 bp(1). RAG’s activity is governed by the 12/23 rule: cleavage can only occur if both a 12- anda 23-RSS are present(1). Hztransib TP has already been demonstrated to cleave at paired 12/23RSSs (unpublished data in the Schatz lab), but other RSS combinations have not been tested. Toevaluate Hztransib TP’s adherence to the 12/23 rule, I will incubate purified Hztransib TP pro-tein with DNA substrates containing various combinations of 12- and 23-RSSs, and I will deter-mine the efficiency of cleavage by visualizing and characterizing radiolabeled DNA products ona denaturing polyacrylamide gel. In this and all other described experiments, a negative controlreaction will contain no endonuclease, and a positive control reaction will use RAG as the endo-nuclease. RAG activity is highly dependent on conservation of the first 3 bp of the heptamer(CAC), while flanking sequences have little effect on cleavage efficiency(1). I will investigate theprecise sequence requirements of Hztransib TP by quantifying cleavage of DNA substrates withvarious point mutations in the RSSs and their flanking DNA. The sequences with greatest cleav-age efficiency will likely approximate Hztransib’s own terminal inverted repeats (TIRs), whichresemble RSSs and begin with the same CAC sequence. Accordingly, for all describedexperiments, I will compare reactions that use RSS-containing substrates to reactions using TIR-containing substrates to determine the sequence dependence of any effects I observe.Aim 2: Determine structural characteristics of Hztransib TP’s catalytic state. RAG can nickindividual RSSs, but completion of cleavage via hairpin formation can only occur in a synapticcomplex containing a 12- and a 23-RSS(1). To assay Hztransib TP for nicking and hairpinningactivity in the absence of synapsis, I will immobilize low concentrations of biotinylated DNAsubstrates containing a single 12- or 23-RSS on streptavidin agarose beads, and I will character-ize products after addition of TP. I will then add free DNA substrates to the slurry to assay forcleavage activity with specific synaptic pairings. RAG’s cleavage efficiency is greatly enhancedby the DNA-bending high-mobility-group protein HMGB1 because cleavage requires DNA dis-tortion(1). I will add HMGB1 to standard Hztransib TP cleavage reactions and observe its effecton cleavage efficiency. Following RAG cleavage, the four newly created DNA ends remain syn-apsed in a postcleavage complex(1). To probe for an Hztransib postcleavage complex, I will bi-otinylate specific DNA ends, pull down biotinylated cleavage products with streptavidin agarosebeads, and characterize any unbiotinylated DNA species that are also pulled down.Aim 3: Determine secondary nuclease activities of Hztransib TP. In vitro, RAG exhibits vari-ous nuclease activities besides cleavage at RSSs: it cleaves single-stranded heptamers, it cuts off5’-ended overhangs on duplex DNA, and it removes 3’-terminated single-stranded flaps(1). Byincubating Hztransib TP with representative radiolabeled substrates and characterizing products,I can determine whether Hztransib TP also exhibits these activities.Aim 4: Suggest catalytic and regulatory roles for RAG2. While RAG1 requires RAG2 foractivity(1), Hztransib TP bears sequence similarity only to RAG1(2) and is able to effect cleavagewithout supplementary protein factors(3). To elucidate RAG2’s role in V(D)J recombination, Iwill include in each of the previously described experiments an additional reaction containingboth Hztransib TP and RAG2. If RAG2 enhances a RAG-like biochemical property of HztransibTP, that property may have evolved due to recombinase-specific selection pressures.Challenges: As of yet, cleavage activity in low-purity Hztransib TP preparations from anotherlab has been observed only after addition of Mn2+ (2), which deregulates RAG endonuclease ac-tivity when substituted for the physiological electrophile Mg2+ (1). The Schatz lab has ample ex-perience developing expression constructs and purification/reaction protocols for RAG, expertisethat can now be applied to Hztransib TP to increase purity and, I predict, allow cleavage withMg2+. Hztransib may not represent the entire Transib family in all details; whereas several otherTransib transposons contain V(D)J-like asymmetric TIRs(2), Hztransib has symmetric TIRs. Iwill use my background in computational sequence analysis to identify and conduct experimentswith an active Transib transposon bearing asymmetric TIRs, allowing requirements of asymmet-ric synapsis to be evaluated both with RSSs and with the transposon’s own TIRs.Broader Impacts: I will recruit undergraduate mentees from my classes and from oSTEM to getinvolved in this work, capitalizing on the multifaceted nature of the project to teach them to ap-proach problems from various angles. Additionally, because the USA currently falls far behindother scientifically advanced nations in popular acceptance of evolutionary theory, I will presentthe exciting history of this tamed transposon at high school teacher conferences to encourageDNA-level approaches to evolution pedagogy, obviating higher-order misinterpretations.Intellectual Merit: Because V(D)J recombination is an essential step in the development of an-tigen-specific lymphocytes, a complete functional comparison between Transib TP and the RAGcomplex would strengthen the current model for adaptive immune system development. It wouldalso offer clues as to how early organisms acquired pathogen defense capabilities, a significantevolutionary hurdle that, once cleared, initiated a dramatic increase in organismal complexity.References: (1) Gellert M. 2002. Annu Rev Biochem 71: 101-32. (2) Kapitonov VV, Jurka J.2005. PloS Biol 3: e181. (3) Hencken CG, Li X, Craig NL. 2012. Nat Struct Mol Biol 19: 834-6."
151.0,"Motivation and Background: Mammalian white adipose tissue (WAT) distribution andexpansion is sex-dependent, with males preferentially accumulating visceral WAT (VWAT) andfemales exhibiting a subcutaneous WAT (SWAT) accumulation bias. Interestingly, females switchto a male-like pattern of WAT distribution after menopause when estrogen levels decline,indicating sex hormones play a role in the distribution of subcutaneous and visceral WAT mass,yet the molecular mechanisms governing these processes in vivo are not well understood. WATdistribution is strongly correlated with the development of pathologies related to obesity, withaccumulation of VWAT being more detrimental for metabolic health than accumulation of SWAT,which may confer protection against these pathologies. Our lab has shown that there is a sexuallydimorphic pattern of adipocyte precursor (AP) activation in mice in response to high fat diet, withmales having robust AP activation in the VWAT but not SWAT and females having activation inboth VWAT and SWAT.1 Once APs are activated they commit to differentiating into matureadipocytes and thus contribute to WAT mass. Interestingly, the sex-specific AP activation patternobserved occurs in an estrogen-dependent manner. Therefore, estrogen levels appear to be crucialfor AP activation and expansion of SWAT but not VWAT. Herein I propose to identify the roleof estrogen signaling in sexually dimorphic WAT expansion and elucidate the mechanismscontrolling differential AP activation in male and female mice. Hypothesis: Estrogen receptoralpha (ERα) is required for AP activation and expansion of SWAT and there are distinct molecularmechanisms driving WAT expansion in VWAT and SWAT, with VWAT expansion beingindependent of ERα activity.Aim1: Characterize the requirement of ERα in the activation of adipocyte precursors inSWAT. For this aim, we will knockout the Esr1 gene in APs using an inducible Cre-recombinasesystem driven by the AP-specific promoter PdgfRα (Figure 1).2 This will enable us to ablate ERαexpression postnatally to avoid any developmental phenotypes. We will then test the proliferationof APs via incorporation of BrdU, a nucleoside analog, inthese ERα-APKO mice upon high-fat diet (HFD) orstandard diet feeding (SD). After the HFD-induced APproliferation phase, incorporation of BrdU will be assessedin APs via flow cytometry. If ERα is required for APproliferation in female SWAT, we expect to see a decreasein BrdU positive cells when challenged with HFD only inthis depot. If ERα is also important for AP proliferation inmale SWAT, we expect to see an even lower percentage ofBrdU+ cells than wildtype (WT) littermates. We do notexpect to see an impairment in AP proliferation in visceralfat in males or females.Aim2. Identify differences in WAT depot estrogenFigure 1. Adipocytes are derived from PdgfRa+levels. Even though WAT can produce estrogen locally, ourprecursor cells. Fat from mouse strain withfindings suggest that circulating levels of estrogen are fluorescent-membrane dTomato/ membrane eGFPrequired for SWAT AP activation but not VWAT AP (mT/mG) Cre reporter. Cre excision is marked bya switch from tdTomato expression to eGFPactivation in both males and females.1 Therefore, Iexpression. PdgfRa-Cre labels all maturehypothesize that circulating levels of estrogen influence adipocytes in WAT but PdgfRa is not expressed inestrogen levels in SWAT but not VWAT to drive mature adipocytes, thus the GFP expressionobserved in adipocytes of PdgfRa-Cre:mT/mGadipogenesis upon periods of HFD. To test this, I willmice is due to lineage tracing.2measure estradiol levels in the WAT depots of WT female and male mice on days 1, 3, and 5 ofHFD or SD. Our lab has shown that activation of APs initiates on day 1 of HFD, with a peak onday 3, and returns to SD levels by day 5.3 Hormone extraction from WAT will be performed andlevels of estradiol and estrone will be quantified by liquid chromatography tandem-massspectrometry. I expect to see increased levels of estrogen in SWAT of WT female mice on day 3of HFD compared to VWAT. Because WT males do not have significant circulating levels ofestrogen, I do not expect to see a difference in VWAT and SWAT levels. I can also perform thesame experiment in ovariectomized (Ovx) females and estrogen-treated males, where circulatinglevels of estrogen are diminished/increased respectively as compared to WT mice. If I see adecrease in estrogen levels in SWAT of Ovx females and an increase in SWAT of estrogen-treatedmales on day 3 of HFD as compared to WT, then circulating levels of estrogen influence SWATlevels of estrogen upon HFD and promote WAT expansion through estrogen signaling in thisdepot.Aim3: Elucidate distinct molecular mechanisms of adipogenesis in VWAT and SWAT. Ourlab recently identified FOXM1, a nuclear fork box protein, as an important gene in male visceralAP activation (unpublished). Interestingly, FOXM1 has been shown to work with ERα to promotegene expression in a breast cancer model.5 Furthermore, when in the presence of activated ERα,FOXM1 drives the expression of a different gene program than when in absence of ERα.5Therefore, we hypothesize that FOXM1 is important in adipocyte hyperplasia in both males andfemales but it acts through distinct molecular mechanisms depending on the presence of estrogen.To test this, we will perform RNAseq on isolated APs from both fat depots under HFD and SDconditions on WT and Ovx female mice. If FOXM1 is working with ERα to promote AP activationin SWAT, we expect to see an increase in gene expression in FOXM1-ERα targets only insubcutaneous fat of WT females. If we do not see this same pattern in the subcutaneous fat of Ovxfemales, but we do find increased gene expression of FOXM1 targets in the visceral fat, we canconclude that in the presence of estrogen, FOXM1 and ERα promote the activation of APs andexpansion of subcutaneous WAT and in the absence of estrogen, FOXM1 alone promotesactivation of APs and expansion of visceral WAT. To further confirm this, I will perform co-immunoprecipitation (co-IP) on isolated APs from both depots from SD and HFD-fed mice toassess if FOXM1 partners with ERα in SWAT but not VWAT of WT females.Intellectual Merit and Broader Impact: This study will clarify for the first time the mechanisticrole of estrogen signaling in WAT and will significantly impact the field of adipose tissue biology.We will also set precedent on elucidating distinct sex-dependent molecular pathways governingWAT mass expansion. As a hispanic woman in science, my goal is to inspire others to pursuecareers in science and become advocates for minorities in STEM. By sharing my research findingsin activities coordinated by Yale organizations and minority-focused science conferences I plan tomotivate not only undergraduate women and minorities to pursue careers in science, but I will alsoeducate the greater community and general public about the importance of science education inorder to advance knowledge beyond an academic environment.IACUC Approval: We have clearances and training for all handling and proposed mouseprocedure (Yale IACUC protocol 2012-11249). The University’s Assurance number with theOffice of Laboratory Animal Welfare is #A3230-01, approval through 5/31/19. IACUC overseesthe University’s centralized, AAALAC-accredited animal resource, the Yale Animal ResourcesCenter (YARC). References: 1Jeffery, E., et. al. (2016). Cell Metabolism, 24(1):142-50. 2Berry, R.,Rodeheffer, M. (2013). Nature Cell Biology, 15(3): 302-308. 3Jeffery, E., et. al. (2015). Nature CellBiology, 17(4): 376-385. 4Falk, R. T., et. al. (2008). Cancer Epidemiology, Biomarkers, and Prevention,17(8): 1891–1895. 5Sanders, D., et. al. (2013). Genome Biology, 14:R6."
152.0,"Assessing Heterogeneity in Organic Municipal Solid Waste Across City-Scales forOptimized Urban Biogas ProductionKeywords: biogas, sustainable development, urbanization, waste management, OFMSWHypothesis: Biogas projects have found success in supplying renewable energy for nichemarkets with homogenous waste streams, but are limited by heterogeneous waste streams atthe urban scale. Disaggregating waste streams to homogenize anaerobic digestion feedstockswill aid stability of biogas production at the urban scale.Introduction: Bangkok currently produces one of the highest municipal solid wastegeneration rates of megacities within the developing world, at over 11,000 tons per day1. Themajority of Bangkok’s organic fraction of municipal solid waste (OFMSW) is landfilled, withadverse impacts on both public health and the environment through degradation of waterresources and large releases of the potent greenhouse gas methane. One commonly acceptedmethod for management of the OFMSW is anaerobic digestion (AD). Anaerobic digestion ofOFMSW has numerous benefits: voluminous production of biogas (a biogenic gas that maybe combusted for electricity and heat production), reduction of landfilled waste volume,reduction of methane emissions, and production of a high-quality organic fertilizer by-product2. However, variations in biochemical composition of organic waste streams largelydictate the stability of biogas production, as heterogeneities in feedstocks can cause inhibitionof the microbiological processes that produce biogas3,4. For example, significant differencesin moisture content between two areas may necessitate the implementation of different ADtechnologies, such as wet, dry, or a wet-dry combination of AD. Additionally, OFMSWcollection infrastructures can be complicated and expensive due to waste originating fromnumerous sources over large spatial areas. Understanding how generation of OFMSW variesover urban to exurban spatial scales will better inform strategic homogenization of ADfeedstock waste streams, more effective collection infrastructure, and appropriate siting offuture biogas production plants for the sustainable management of OFMSW.Research Plan: My intended research will fundamentally address the following questions:1. Do urban “pockets” exist in which municipal solid waste is predominantly composedof organic, digestible waste?2. Can waste collection infrastructure and waste facility siting be restructured to betterreflect spatial variations in OFMSW generation?Methods: I will combine spatial mapping, waste-transport charts, and waste sampling toassess how generation of organic waste is distributed over Bangkok’s urban environment.1. Delineate urban, suburban, and rural-urban fringe (RUF) zones. I will useGeographic Information Systems (GIS) to demarcate urban, suburban, and RUF zonesof Bangkok based on census data, land use maps, and aerial photography5. Thedemarcation of the three urban zones will inform my in-field waste sampling duringthe summer of 2015.2. Identify waste management plants/landfills that collect waste within each of theabove-listed zones, and sample waste from May – August, 2015. Municipal solidwaste in Bangkok is not source separated, thus I will conduct a waste compositionstudy under ISO 14001 standard6. Depending on the waste center, I will either collectsamples from waste screens and grinding operations, or will hand sort the waste tocollect samples of the organic fraction. I will then assess the waste sample formoisture content and biochemical composition through local university facilities7. IGraduate Research Proposal NSF GRFPwill collect waste samples two times per day from ten replicates within each urbanzone to best account for expected high variability in waste structure.3. Identify appropriate sites for siting of future AD facilities. By comparing samples oforganic waste with existing waste collection routes, inferences can be made as towhether or not organization of waste management facilities are appropriate for thewaste composition originating from Bangkok. I expect that city areas with highdensities of malls (often with large food courts) and food markets will havedisproportionately high food waste suitable for AD.4. Model the potential biogas production based on computer simulation of biogasproduction, and scale the waste streams for their representative urban areas to thecity scale. I will input the elemental compositions of organic wastes into theAnaerobic Digestion Model 1 (ADM1) computer simulation to gain rough estimatesof biogas productions8. I will then scale the production rates from each urban areatype to its full city-wide extent to estimate Bangkok’s biogas production potential.5. Model future urban development and its implications for organic waste based on theBangkok Development Plan released in 2013. Similar to step 4, I will use projectionsof future shifts in urban environment (e.g., from suburban to urban) to model futuregrowth in urban waste/biogas.Research collaborations: Through Yale University’s Urban Resources Initiative (URI), Iwill conduct a pilot project to assess neighborhood-wide waste streams during the springsemester of 2015. Working with URI will give me valuable experience and insight intopotential pitfalls that may arise during my summer data collection, and will allow me toextend my research to New Haven’s local community. Additionally, my previous researchcollaborations through the Joint Graduate School of Energy and Environment in Bangkokwill afford me access to university facilities for biochemical analyses and support from Thaiprofessors currently involved with waste-to-energy projects.Intellectual merit: My proposed research aims to bridge the gap between the use of ADtechnology in the developed and the developing world. Understanding how waste-streamsrespond to urban growth will allow city planners to best implement future waste managementplans for developing urban environments in both the developing and developed world – suchas the U.S. My intended research will contribute to the broader knowledge on wastemanagement through the goal of a peer-reviewed publication by the end of my second year,as well as presentations of findings at university-based and international conferences.Broader impacts: Capitalizing on OFMSW for production of biogas is a comprehensivesustainable development strategy that tackles the increasing challenges of managing waste,providing stable electricity, and mitigating greenhouse gas emissions. The findings of theresearch will be particularly valuable in developing urban environments, for example those inIndia or sub-Saharan Africa, in which putrefying organic waste directly contributes to publichealth concerns and ecological damage. Furthermore, generation of electricity from biogasmay become significant for assisting intermittent renewable energies, such as wind and solarphotovoltaics, in future provisioning of base load electricity supply. This work will directlyaid local professors, students and urban planners, as few comprehensive waste-structurestudies of Bangkok currently exist in the literature.References: 1 Udomsri et al. 2011. Energy for Sustainable Development 15: 355-364. 2 Wellinger, A. et al.2013. The Biogas Handbook. 3 Curry and Pillay. 2012. Renewable Energy. 41: 200-209. 4 Browne, J.D. et al.2013. Applied Energy 128: 307-314. 5 Pryor, R.J. 1969. Geografiska Annaler. Series B, Human Geography.51:33-38. 6 ISO 14001. 2004. Environmental Management. 7 Zhang, R. et al. 2007. Bioresource Technology 98:929-935. 8 Batstone, D.J. et al. 2002. Water Science Technology 45: 65-73."
153.0,"global coral reef mortality. These stressors may reduce reef resilience by stimulating macroalgalgrowth and competition [1]. Parrotfish control macroalgae through herbivory but often predatecorals to supplement their diets. This causes some coral tissue damage in the form of individuallesions, but rarely causes total colony mortality [2]. However, Zaneveld [1] surprisingly foundthat in waters enriched with nitrogen and phosphorous, colony mortality increased from zero to~65% in Porites colonies after parrotfish predation, but why this occurred was unknown. For mydissertation project I aim to study if and how the combined stressors of predation and nutrientenrichment disrupt coral physiology and/or their microbiomes to cause this increase in mortality.The coral holobiont is a dynamic assemblage of the coral animal and its associatedmicroorganisms such as bacteria and algae which collectively make up the microbiome. Elevatednutrients can alter the abundance and types of coral-associated mutualistic algae in the genusSymbiodinium [3]. Environmental stressors cause shifts in healthy coral-associated bacteria [4],that may provide antibiotic activity against invasive microbes and pathogens [5]. Zaneveld [1]found that the combination of predation and nutrient enrichment increased the amount ofpotentially opportunistic bacteria when compared to proposed coral mutualists. My project willdetermine if parrotfish are a vector for bacterial opportunism and/or if nutrients drive an increasein host susceptibility to infection following wounding by predation.Hypothesis: I hypothesize that nutrient enrichment and predation interact to cause two majorchanges to the coral holobiont that result in coral death: reduced host immunity and theproliferation of pathogens. My work will focus on the following questions:Q1. How do bacteria in the coral mucus protect against predation-mediated mortality inwater with ambient nutrient levels? I hypothesize that coral mucus already possess specializedmicrobiota that protect corals from pathogens via several testable mechanisms such as antibioticproduction, competitive exclusion, or predation.Q2. How do nitrogen and phosphorous alter coral and algal symbiont physiology and themicrobiome? I hypothesize that a decrease in host immunity and destabilization of theSymbiodinium community will combine to reduce the holobiont’s ability to regulate itsmicrobiota. I also predict that the microbiota with anti-pathogen activity identified in Q1 will bereduced and opportunistic bacteria will increase in nutrient enriched treatments.Q3. Is the microbiome-dependent route to coral death driven by physical wounding orpredator specific corallivory in nutrient enriched waters? I hypothesize that parrotfish serveas vectors for the proliferation of pathogens in the mucus around the wound site. Alternatively, Ihypothesize that any wounding in the presence of elevated nitrogen and phosphorus provides aroute to enhanced bacterial infection.Research Plan: These questions will be addressed at the Gump South Pacific Research Stationon Moorea, French Polynesia, through two complementary experiments: on the reef and incontrolled tanks. While I expect to see similar changes in microbial communities and host healthbetween the two experiments, each will provide a specific component to my investigation. UsingSCUBA, individual Pocillopora colonies will be transplanted to saltwater mesocosm tanks. Inthe tanks, I will pre-expose corals to an antibiotic mix [6] to deplete the bacterial community.The types, concentrations, and exposure length will be determined the year prior to theexperiment. Then I will move the treated and untreated corals to new tanks with natural seawateror to the field for monitoring. I will simulate predation in the tanks by physically wounding thecoral and track host immunity to determine if the host alone is capable of preventing mortality orif associated microbiota are necessary for defense and recovery (Q1). On the reef, a subset ofcorals will be exposed to parrotfish predation while others will be shielded from predation withherbivore exclosures (Q3). A subset of the colonies in both experiments will be maintained atambient nutrient levels while others will be enriched using slow-release fertilizer diffusers (Q2).N and P concentrations will be comparable to those on reefs impacted by nutrient pollution [1].Phase 1. Simulate the effects of predation, nutrient loading, or a combination of these stressorswith manipulative experiments on the reef and in tanks. At regular intervals, 1) photographicallymonitor coral tissue growth/loss and coral mortality, 2) record dissolved organic nitrogen andsoluble reactive phosphorus concentrations via autoanalyzer, 3) measure Symbiodinium densitywith Pulse Amplitude Modulation, 4) measure bacterial respiration with oxygen probes, 5) countmucus associated bacteria with epifluorescence microscopy, and 6) sample coral tissues forDNA/RNA, taking care to minimize any serious damage to the coral. Phase 2. Track changes inthe holobiont. For bacterial community dynamics, extract DNA from mucus to generatemicrobial 16S amplicon libraries [1] and metagenomes [4] for bacterial functional analysis. ForSymbiodinium and host gene expression changes, extract RNA and DNA from tissue for RNAseqas well as for ITS-2 amplicon libraries [3]. Phase 3. Sequence the libraries on Illumina platformsat OSU’s Center for Genome Research. Phase 4. Use bioinformatics (e.g. QIIME [7], Shotmap[8]) and statistical pipelines (e.g. STAMP [9]) to analyze changes in structure and function ofmicrobial communities and in gene expression patterns of innate holobiont immune responses.Predictions: Antibiotic producing bacteria, not host immunity, will be the primary defenseagainst coral tissue loss or mortality from predation or wounding. Nutrient enrichment incombination with predation or wounding will lead to coral mortality. Coral mucus will exhibit anincrease of one or more pathogenic strains, either found in low abundance in the communities ofcontrol colonies or absent from control colonies and therefore introduced by parrotfish predation.Coral mucus will also exhibit a decrease of one or more strains with antibiotic capabilities. I willidentify the proliferated pathogenic strain(s) and the reduced defensive strain(s) therebyidentifying the microbial route to colony mortality.Intellectual Merit: The Zaneveld study [1] is the first to document increases in predator-mediated mortality in the presence of elevated nutrients. Parrotfish herbivory is accepted asbeneficial to coral reefs, and parrotfish predation is accepted as normally benign. My study willpin down the mechanism(s) in which these herbivores become agents of mortality and willtransform how we approach the conservation of coral reefs, and more specifically, trophicinteractions on a reef. Restoration of parrotfish populations may have negative consequences forcoral health if efforts are not simultaneously made to combat water quality issues.Broader Impacts: During the field season in Moorea, I will design and conduct interactiveteaching workshops for the local community similar to my outreach as an undergraduate. Usingresources at the Gump Station and connections with the Atitia Center for outreach, I will print 2-D reef replicas of my nutrient-enriched and ambient level in situ corals over time for use incitizen science training. Local schoolchildren and adults will use the photos along with quadrats,transect tape, identification guides, and whiteboards to ‘become’ a marine biologist for a day. Iwill guide participants in using quadrats to quantify metrics of reef change, such as percent livecoral cover. Children and adults will experientially observe how nutrients such as fertilizersaffect the health of marine species. Through this citizen science initiative, I hope to transformhow local communities understand and interact with their coral reefs.Citations [1] Zaneveld et al. (2016) Nat Commun, [2] Rotjan & Lewis (2008) Mar Ecol Prog Ser, [3] Correa et al.(2009) Coral Reefs, [4] Vega Thurber et al. (2009) Environ Microbiol, [5] Ritchie (2006) Mar Ecol Prog Ser, [6]Glasl et al. (2016) The ISME Journal, [7] Caporaso et al. (2010) Nat Methods, [8] Nayfatch et al. (2015) PLoSComput Biol, [9] Parks et al. (2014) Bioinformatics."
156.0,"extreme hydrodynamic and aerodynamic loads on offshore wind turbines (OWTs),specifically wave and wind loads during hurricanes. To this end, I propose to numericallysimulate OWTs subjected to extreme wind and waves using computational fluid dynamics(CFD). This research aims to advance basic understanding of OWT loads by answeringthe questions:1. How do extreme hydrodynamic and aerodynamic loads on OWTs vary for differentsupport structures and hurricane characteristics?2. How do OWTs (especially floating OWTs) respond to hurricane wind and waves?Motivation: To meet the federal goal of 20% electricity from wind energy by 2030,the U.S. wind industry must expand to include offshore wind development. Offshore windoffers several advantages over onshore wind, including the mitigation of aesthetic and landuse issues, as well as the utilization of abundant, high-quality offshore wind resources inproximity to population centers [1]. However, wind farms off the eastern and southern U.S.coast could be destroyed by hurricanes, unless their support structures are designed withsuch extreme loads in mind [2]. These designs require accurate load data, butexperimental data is mostly unavailable due to the lack of OWTs in hurricane-prone areas.So, current OWT simulations find hydrodynamic and aerodynamic loads using simpleempirical models, which are much less accurate than CFD [3]. This inaccuracy iscatastrophic when designing OWTs to withstand hurricanes, so using CFD to betterpredict extreme loads will inform more robust OWT designs.Methods: To generate hydrodynamic and aerodynamic loads typical of hurricanes, Iwill numerically simulate OWTs subjected to extreme, hurricane-like wind and waves.These simulations will be done in the CFD software Converge from Convergent Science.Unlike most CFD software, Converge doesn’t require user-made meshes, which meansresearchers can complete simulations faster. Converge’s adaptive automatic meshing alsoimproves solution accuracy for moving objects like floating OWTs, since the gridresolution adapts where necessary. Converge could also fix stability issues found whenmodeling floating OWTs in other CFD software like OpenFOAM [4].I will first identify hurricane parameters characteristic of the U.S. coast, focusing onareas where OWT development is likely. I will then validate my predicted hydrodynamicand aerodynamic loads against experimental and numerical data: CFD-based numericaldata for non-extreme waves is available from Benitz [4], while proprietary experimentaldata for loads from Hurricane Irene is available from industry collaborators. Aerodynamicloads will be validated against the open literature for onshore wind turbines. Finally, I willcreate databases of hydrodynamic and aerodynamic loads corresponding to varioushurricane parameters for several support structure types.The predicted non-hurricane hydrodynamic loads will be validated for some OWTstructures prior to the beginning of the proposed project: the proposed team (detailedbelow) is currently collaborating on a 1-year project on OWTs in breaking waves, whichincludes validating the predicted hydrodynamic loads on non-floating structures againstnumerical data and experimental data from industry partners.Deliverables: The main deliverables of the project and their estimated times ofcompletion are:1. Identify representative hurricane characteristics for the U.S. coast (2 months),2. Validate aerodynamic loads against experimental data (3 months),3. Validate hydrodynamic loads against experimental and numerical data (5 months),4. Generate hydrodynamic and aerodynamic load databases for various hurricaneparameters for non-floating structures (12 months) and floating structures (14months).Collaborations: This work will involve collaboration between University ofMassachusetts faculty from two departments, as well as collaboration with industrypartners (Convergent Science and others in development). Dr. David Schmidt and Dr.Matt Lackner (Mechanical Engineering) have previously studied hydrodynamic loads onOWTs [3,4], and have access to the computing resources necessary for CFD. Dr. Schmidtalso worked in Converge on other applications, and his long relationship with ConvergentScience enables their collaboration and assistance in introducing hydrodynamics andaerodynamics as new applications. Dr. Sanjay Arwade (Civil Engineering) brings expertisein OWT support structures and hurricanes’ impacts on OWTs.Intellectual merit: The proposed project furthers basic scientific understanding ofOWT loads, introduces better software for OWT modeling, and provides better data forstructural models of OWTs. First, using CFD to study extreme hydrodynamic andaerodynamic loads on OWTs will improve fundamental understanding of how OWTsupport structures behave during hurricanes, which is currently hindered by overly simplemodels and a lack of experimental data. Second, this project will validate a faster, moreaccurate CFD software for OWTs and other ocean engineering applications. Third, thisresearch will provide more accurate loads used in OWT structural analysis, like that doneby civil engineers. These results will be distributed at wind energy and CFD conferences,in journal articles, and in my PhD dissertation.Broader impacts: By providing more accurate hydrodynamic and aerodynamichurricane loads for use in structural OWT models, the proposed project allows for betterdesigns of OWTs that can withstand hurricanes. Hurricane-resistant OWTs lower the risksof offshore wind, encouraging the widespread development of offshore wind energy in theU.S. and other hurricane-prone countries. In this way, the proposed research contributes tothe growth of renewable energy on the national and global scale.References1 Musial, W., and Ram, B. 2010. Large-scale offshore wind power in the United States:Assessment of opportunities and barriers. Technical Report NREL/TP-500-40745, U.S. Dept.of Energy, 1–221.2 Wei, K., Arwade, S.R., Myers, and A.T. 2014. Incremental wind-wave analysis of thestructural capacity of offshore wind turbine support structures under extreme loading.Engineering Structures 79, 58-69.3 Benitz, M.A., Lackner, M.A., and Schmidt, D.P. 2015. Hydrodynamics of offshore structureswith specific focus on wind energy applications. Renewable and Sustainable Energy Reviews44, 692-716.4 Benitz, M.A. 2016. Simulating the hydrodynamics of offshore floating wind turbine platformsin a finite volume framework. PhD thesis, University of Massachusetts - Amherst."
157.0,"Starsexplode. Supernovae(SNe), orstellarexplosions, canoccurthroughtheignitionofadegenerate white dwarf (WD) star, a star that is supported by quantum electron degeneracypressure, orbythecorecollapseofamassivestar. Recenttransientsurveys, suchasTheDarkEnergy Survey have discovered and imaged thousands of supernovae since 2013 includingthe anomalous SNe DES13S2cmm. The forthcoming Large Synoptic Survey Telescope willfurther these efforts utilizing a three billion pixel digital camera to cover more than 20,000deg2 of the night sky. However, even with this wealth of observational data, many aspectsof the evolution and subsequent explosion of massive stars remain unknown.My background in theoretical astrophysics has prepared me to aide in the advancement oftheseefforts. I propose to investigate the stellar structure and evolution of massivestars, core collapse supernovae explosion (CCSNe) mechanisms, and implicationsfor cosmic chemical evolution and gravitational wave radiation. The confluence ofadvancements in multiple fields will provide the empirical basis needed to accomplish thesegoals. The focused efforts proposed are summarized as follows: (i) getting the progenitorright, (ii) supernova explosion mechanisms, and (iii) nucleosynthetic yields and gravitationalwave bursts. Advancement in our understanding of massive stars can lead to furtheringour knowledge of the cosmic chemical evolution of the Universe and provide direct tests ofEinstein’s General Theory of Relativity (GR).Getting the progenitor right. The star that will eventually explode as a CCSNe is oftenreferred to as the progenitor. Computational modeling of the progenitor star can lead tothe insight of how a star will end its life, or allow one to infer the initial progenitor of anobserved supernova. Recent 3D hydrodynamic simulations of radiation dominated envelopesin massive stars and internal magnetic field strengths of order ∼105 Gauss, suggest theneed for further investigation [4]. I will investigate the uncertainties associated withthe structure and evolutionary properties of massive stars that will end theirlives as CCSNe explosions. Using a state of the art stellar evolution code, Modules forExperiments in Stellar Astrophysics, I will focus on uncertainties due to the nuclear reactionrates, compositional mixing, and the effects of rotation and induced magnetic dynamos.Specific steps include the sampling of new Monte Carlo nuclear reaction rate distributionsfor key nuclear reactions using the recently constructed rate library, STARLIB [5], andperforming a quantitative assessment of the effect of varying strengths of compositionalmixing and rotational values. The utilization of new measurements of nuclear reaction ratesat astrophysically relevant energies forthcoming from the Facility for Rare Isotopes Beamswillalsobeparamountinthiseffort. My background in stellar astrophysics, especiallymy past published work on modeling super asymptotic giant branch stars [2],will allow me to play a productive role towards modeling more physically accurate stellarmodels that can address fundamental questions in stellar and galactic evolution.Supernova explosion mechanisms. Collapse of the iron core within a massive star initiatesthe CCSNe explosion. The inner core is then halted once densities exceed that of nuclearmatter, resulting in core bounce launching a shock towards the still collapsing outer core.However,theshockisnotstrongenoughtoblowupthestarandisusuallyhalted. Thisstalledshock has led to the so-called ‘failed supernovae’ problem and has left many scientist tryingto determine the mechanism which allows for the efficient explosion of CCSNe observed.Contemporary approaches favor neutrino transport as an efficient means of reheating, oraddingenergyto, thestalledshockallowingforasuccessfulexplosion. Recentstudiessuggesta correlation between the local neutrino heating rate and successful explosion [1].I propose to continue this effort by investigating various explosion mechanismsof CCSNe and addressing uncertainties therein. My primary numerical instrumentwill be the 3D adaptive mesh hydrodynamic code, FLASH. The computational resourcesavailable at my proposed graduate institution, California Institute for Technology, will maketheseeffortsfeasible,whiletheexpertiseofthegroupIwishtojoinwillprovidetheneccessarysupport to successfully address these scientific questions.Nucleosynthetic yields and gravitational wave bursts. Successful CCSNe explosions arealso known to produce iron-group elements and experience bursts of gravitational waveradiation. I propose to investigate gravitational wave bursts caused by CCSNe aswell as the associated nucleosynthetic yields.Minutes after the Big Bang, the Universe began to synthesize light isotopes such as 1Hand 4He. However, uncertainties still lie within the steps taken to arrive at the m´elangeof isotopes in our interstellar medium today. The next step towards understanding thecosmic chemical evolution of our Universe is to move towards a deeper understanding of thenucleosynthetic yields of CCSNe. My current NSF-supported work with Dr. FrankTimmes at Arizona State University on nucleosynthetic yields in WDs [3] ispreparing me to address aspects of forging the elements during my graduate work.Furthermore, with the recent upgrade of The Laser Interferometer Gravitational-WaveObservatory (LIGO) complete, direct detection of gravitational waves (GWs) is imminent.These ripples in spacetime can occur during asymmetric collapse to a black hole of CCSNeand provide direct tests of GR. A new field of astrophysics is upon us and requires necessaryinterplay between astronomy and theoretical physics. While participating in the NSFLIGO summer research program I simulated GWs emitted by compact binarysystems in an effort to test the strong-field dynamics of General Relativity andthis experience has prepared me to play a large role in this effort.Here I present a framework for maintaining successful completion of these efforts. In years1-2 of my graduate studies, I will work on focused effort, Getting the progenitor right, withsuccessful completion corresponding to a peer-reviewed journal publication. Years 3-4 willfocus on Supernova explosion mechanisms, again with successful completion correspondingto a peer-reviewed journal publication. Lastly, I will spend my final year considering Nucle-osynthetic yields and gravitational wave bursts, with the culmination of this project resultingin a publication and successful completion of my Ph.D.The focused efforts presented here would result in the advancement of our understandingof the evolution and subsequent explosion of massive stars, leading to advancements in thefields of cosmology, astronomy, and theoretical physics. These are immense, broad questionsthat require expertise in multiple backgrounds as well as interdisciplinary collaborative ef-forts. Being supported by the NSF through the GRFP would accelerate my goals by allowingme to begin research my first year and be invaluable in preparing me for a successful career.[1] Couch, S. M., & Ott, C. D. 2015, The Astrophysical Journal, 799, 5[2] Farmer, R., Fields, C. E., & Timmes, F. X. 2015, The Astrophysical Journal, 807, 184[3] Fields et al. 2016, The Astrophysical Journal, in prep.[4] Fuller, J., Cantiello, M., Stello, D., Garcia, R. A., & Bildsten, L. 2015, Science, 350, 423[5] Sallaska, A. L., Iliadis, C., Champange, A. E., et al. 2013, ApJS, 207, 18"
160.0,"Modeling the FeMoco Cluster of Nitrogenase: Synthesis of a μ -Carbide Metal Cluster3Ammonia is the second-largest syntheticchemical product worldwide, with 1.68 × 108tons produced annually.1 Typically, ammoniais synthesized via the Haber-Bosch process,where a heterogeneous iron oxide catalyzes theFigure 1. (left) Structure of the FeMo cluster of nitro-reaction between hydrogen and nitrogen.1,2genase. The terminal iron is bound to cysteine; the ter-About 85% of ammonia produced is used to-minal molybdenum is bound to histidine and chelatedwards crop fertilization; large-scale ammonia by homocitrate. (right) Proposed synthetic target, corre-production has been credited for the quadru- sponding to the left cubane of FeMoco.pling of the world’s population from 1.8 to 7.4 studies have attempted to calculate stable nitro-billion in the last 100 years.2 The process is typ- gen binding sites of FeMoco and possible inter-ically performed in excess of 400°C at 200 atm, mediates of the reduction.5,6 However, in orderand is highly energy-intensive, consuming to determine the true mechanism, experimentsabout 3–5% of the world’s yearly natural gas on a structural model are necessary.production and 1–2% of the global energy pro- Due to the high complexity of FeMoco, aduced. These are consequences of nitrogen’s synthetic model adequate for detailed struc-high stability: the N–N triple bond of N is one ture-function studies has proven elusive thus2of the strongest covalent bonds known, with a far; as of yet, no models incorporate the inter-dissociation energy of 226 kcal/mol.3 stitial carbon atom. I propose to develop a syn-Despite the stability of nitrogen gas, many thesis of a novel cubane cluster structurally rel-classes of bacteria and archaea have evolved evant to FeMoco (Figure 1). This tetrametallicthe ability to catalytically fix nitrogen via the cluster contains an unusual bridging carbideenzyme nitrogenase, which couples the reduc- ligand coordinated to three iron centers.tion of nitrogen to the hydrolysis of ATP over Trimetallic bridging carbide clusters are8 single-electron transfer events (Scheme 1). known for various metals, including Ti,7 Co,8Remarkably, nitrogenase is capable of fixing Ru,9 and Os.10 However, these isolated com-nitrogen at ambient temperatures and pressures, plexes all contain strong-field ligands such asa feat that humans have yet to mimic. CO and cyclopentadienide; μ 3-carbides are ex-tremely rare for complexes containing low-field ligands such as sulfides, making the syn-thesis of a [4Fe-3S-C] cluster such as this a for-Scheme 1. Balanced half-reaction for nitrogenase-mediated nitrogen fixation. P = inorganic phosphate. midable challenge.iNitrogenase contains three types of metal Lee and coworkers have previously synthe-cluster cofactors: the most complex of these is sized a [4Fe-3S-N] cluster containing a μ -im-3the FeMo cluster (FeMoco), where nitrogen is ido ligand, analogous to the proposed μ -car-3bound and reduced (Figure 1). FeMoco is com- bide, from a [4Fe-4S] cluster and a nitride-prised of 8 metal centers encapsulating a small carrying bimetallic species.11 I will use thisinterstitial atom. The interstitial atom’s identity route as a model synthetic strategy (Scheme 2).has been long debated as either C, N, or O; re- The μ -imido nitrogen in Lee’s system is de-3cent research has provided strong evidence for rived from an amine; an isoelectronic reagentthe identification of this atom as carbon.4 such as an organolithium reagent could reactMuch is still unknown about the mechanism similarly. A carbene equivalent such as a diazothrough which FeMoco reduces nitrogen, in- species could also serve as a carbon precursor.cluding the precise N binding site, the elec- An alternative synthesis draws from the2tronics of the cluster during reduction, and the work of Holm and coworkers, who synthesizedrole of the interstitial carbon. Computational pentametallic cuboidal clusters containing aNSF Graduate Research Fellowship Program 1Graduate Research Plan Statement Jeremy C. TranScheme 2. Two proposed syntheses of the target cubane clusters, inspired by Lee (top) and Holm (bottom).[4Fe-3S] moiety capped by a fifth metal gating the clusters together, a true analog ofthrough sulfide linkages.12 By using a small FeMoco could be synthesized. This full modelphosphine such as PMe as L and a bulky phos- could be used in structure-function studies and3phine such as P(tBu) as L', the sulfides capping would prove invaluable in determining the pre-3the cuboidal face could potentially be more ac- cise mechanism of nitrogenase.cessible. This would allow for selective re- INTELLECTUAL MERIT, BROADER IMPACTSmoval of the capping sulfides with a thiophilic The proposed research would provide a syn-reagent such as mercury, opening up a vertex thetic route to low-field μ -carbide metal clus-3for carbide insertion. ters, which are very uncommon and not wellAlthough 13C NMR spectroscopy could po- understood. This research would also fill atentially be used to check for incorporation of wide gap in our knowledge about the mecha-the carbide, the paramagnetism of iron clusters nism of nitrogen reduction via FeMoco. Know-diminishes the usefulness of NMR spectros- ing the mechanism through which biologicalcopy as a characterization tool. Instead, product systems fix nitrogen could lead to the develop-characterization will focus heavily on mass ment of new manmade nitrogen fixation meth-spectrometry and X-ray crystallography, to de- ods, boosting the production of ammonia whiletermine whether the synthesis was successful. I simultaneously reducing energy inputs.will also use Mössbauer spectroscopy to deter- The primary use of ammonia is as a fertilizer;mine the oxidation states of the iron centers. a more efficient means of ammonia productionUpon successful synthesis of the target, fur- would correspond to a potential increase in ag-ther experiments will be performed to fully ricultural productivity, helping to sustain thecharacterize the cluster. Cyclic voltammetry ever-growing global population. Although thiswill be utilized to test the redox properties of is not likely to outcompete the Haber-Boschthe clusters. The ability of these clusters to bind process, a small-scale source of readily obtain-N will also be examined, both under redox- able ammonia would be incredibly useful for2neutral and reducing conditions. In the event remote regions where fertilizer is scarce.that N successfully binds, characterization to References: (1) Ullmann’s Encyclopedia of2determine the binding site(s) will be carried out Industrial Chemistry; 7th ed. 647–698. (2) Nature 1999,400, 415. (3) Comprehensive Handbook of Chemicalvia X-ray crystallography. The reactivity of aBond Energies; 1st ed. (4) Science 2011, 334, 940–940.nitrogen-binding species towards various nu-(5) J. Am. Chem. Soc. 2003, 125, 15772–15778. (6) Annu.cleophiles and reductants will also be explored. Rev. Biochem. 2009, 78, 701. (7) Organometallics 1994,Future directions include using this carbide- 13, 2159–2163. (8) J. Am. Chem. Soc. 1958, 80, 6529–6533. (9) J. Organomet. Chem. 2001, 633, 51–65. (10)containing cluster as a stepping stone towardsInorg. Chem. 1996, 35, 1405–1407. (11) Inorg. Chem.the full synthesis of a FeMoco-like cluster. By2012, 51, 12891–12904. (12) J. Am. Chem. Soc. 1993,constructing the other half of the cluster and li- 115, 5549–5558.NSF Graduate Research Fellowship Program 2"
161.0,"Motivation: Functional magnetic resonance imaging (fMRI) allows non-invasive measurementof real-time brain activity in humans. The success of this technology has been evidenced by itsrapid growth in popularity in the 25 years of its existence, resulting in nearly 40,000 researchpapers1. A large portion of these studies investigates the correlational structure of the brainsignal, known as functional connectivity (FC). FC studies are most often implemented in restingstate fMRI (RS-fMRI). Historically RS-fMRI has been especially useful in clinical anddevelopmental imaging because it requires no task demands, avoids performance confounds andmeasures network connectivity in largely the same way that task fMRI does2. These methodshave led to many groundbreaking findings in brain science that were previously inaccessible.Recent evidence3 has shown that many of these findings may be spurious and insidiouslyriddled with artifactual patterns of connectivity created by head motion. This is most oftenevident in clinical and developmental populations because head motion is confounded with thegroup effect of interest. Even small movements, on the scale of .1 mm, have been shown to causestructured patterns of spurious variance, enhancing short-range connectivity and decreasing long-range connectivity3. These findings have caused many groups to entirely reevaluate previous FCfindings3 and attempt to develop ways of overcoming this major problem.Current motion correction methods summarize head motion as a rigid body transformwith 6 parameters (motion in the 3 spatial dimensions as well as rotations along each of theseaxes). The amount of motion at any single time point can be estimated by the change in each ofthese 6 motion parameters from the previous time point. Many methods have been developed tocharacterize and correct for motion-related signal. Common motion correction pipelines modelthe relationship between each direction of motion and fMRI signal changes linearly in confoundregression. However, this linear assumption may be inadequate4. Higher order expansions of thismodel4 that allow for temporal offset and nonlinear relationships between motion and fMRIsignals have been shown to perform better than standard methods in high motion populations,however, these models still fail to entirely remove motion related signal. To remove theremaining nuisance signal it is common practice to censor the problematic timepoints5. Whilethis method works, it requires removal of valuable time points and often removal of entiresubjects from an analysis. Regularly these removed subjects are patients whose data collectioncost thousands of dollars and many person-hours. This leaves the field in a tenuous position inwhich previous findings require reevaluation and future studies must employ burdensomecensoring techniques. If lasting, valid progress will be made with FC-fMRI a thoroughunderstanding of motion and better motion correction techniques are required. The proposedresearch will apply established methodologies to a unique dataset, which will shine light on thisimportant issue in fMRI.Aim 1: Characterize and model head motion artifacts in a single highly sampled subject.The proposed project will begin by thoroughly characterizing motion related signal changes inthe MyConnectome dataset6. This publicly available dataset consists of 88 ten minute RS-fMRIscans of a single healthy adult male, resulting in over 45,000 whole brain images. Originallycollected to establish the reliability of FC-fMRI methods, this dataset provides a uniqueopportunity to understand fMRI signals related to motion, an endeavor previously overlooked.Compared to a typical RS-fMRI dataset this sample has no variance related to individualdifferences or sex effects, and minimal variance related to age, brain size, or vasculature.From the wealth of time points in this dataset, I will construct smaller datasets out of timepoints that have motion primarily in a single direction and/or magnitude. Each will be the size ofa typical RS-fMRI analysis. I will then apply previously described methods5 to characterize theinfluence of this highly controlled motion on fMRI signal change and FC. The unique flexibilityof the MyConnectome dataset will allow me to further describe the nonlinearity andheterogeneity of motion related signal changes. To do this I will use established multipleregression methods 4, testing models of the linear and nonlinear effects of motion on the fMRIsignal and time-course while penalizing for model complexity to avoid overfitting. I hypothesizethat this approach will allow a precise description of the influence of directionality, magnitudeand the time-course of head motion on fMRI signal and connectivity that will surpass currentmodels in the amount of motion related variance explained.Aim 2: Determine generalizability of head-motion model. A major issue with this model maybe that its utility is specific to a single subject’s brain and lacks generalizability to developmentalor clinical populations with a larger amount of movement. I will use another unique and publiclyavailable dataset, the Philadelphia Neurodevelopmental Cohort (PNC), to overcome thislimitation. Since the PNC consists of a pediatric, demographically diverse, developingpopulation, it is well suited to test the performance of the model defined in Aim 1 with a datasetmost prone to the previously identified motion confounds of FC-fMRI. I hypothesize that themodel identified will significantly outperform current state-of-the art processing methods,significantly reducing measurable motion related confounds5 and the reliance on censoring.Broader Impacts: This research has the potential to contribute crucial information to thegrowing discussion of motion in FC-fMRI. In depth investigation and rigorous control of motionin a single highly sampled subject has not previously been achieved and will demonstrate theupper limit of our ability to describe and correct motion artifact. With this information,generalizable gains in fMRI processing will follow, especially in mental illness anddevelopmental research where human fMRI is especially important. Following the global pushfor openness in research and collaborative science, I will use data that is publically available andopenly share all analytic programming code necessary to complete these analyses on GitHub sothat the entire neuroimaging community may use and expand upon this work. This type ofdetailed fMRI artifact investigation is crucial for its validity and without it, progress may bedampened and slowed by confounds that are not adequately managed by current processingmethods. Receiving support from NSF would allow me to develop these important motioncorrection methods during graduate school.Feasibility and Support: The proposed research is to be completed with Dr. Satterthwaite, aleader in the fMRI literature relating to motion artifacts and an investigator for the PNC4 .Thiswill streamline access to the PNC data and its growing longitudinal child dataset. My experiencewith motion correction in a high motion population (see personal statement) and the tools I havepreviously developed to do this will immediately lend itself to this project. Access to NSF’sXSEDE computing resources, made possible by this fellowship, will be indispensable forparallelizing the computationally-intensive analysis of the large datasets in this proposal.References: (1) PubMed Search “fMRI OR functional MRI OR functional magnetic resonance imaging”. (2) ColeMW, Bassett DS, Power JD, Braver TS, Petersen SE (2014) Intrinsic and task-evoked network architectures of thehuman brain. Neuron 83: 238 –251. (3) Power, J.D., Barnes, K.A., Snyder, A.Z., Schlaggar, B.L., Petersen, S.E.,2012. Spurious but systematic correlations in functional connectivity MRI networks arise from subject motion.NeuroImage 59, 2142–2154. (4) Satterthwaite, T.D., Elliott, M.A., Gerraty, R.T., Ruparel, K., Loughead, J., Calkins,M.E., Eickhoff, S.B., Hakonarson, H., Gur, R.C., Gur, R.E., Wolf, D.H., 2013. An improved framework forconfound regression and filtering for control of motion artifact in the preprocessing of resting-state functionalconnectivity data. NeuroImage 64, 240–256. (5) Power, J.D., Mitra, A., Laumann, T.O., Snyder, A.Z., Schlaggar,B.L., Petersen, S.E., 2014. Methods to detect, characterize, and remove motion artifact in resting state fMRI.NeuroImage 84, 320–341. (6) http://myconnectome.org/"
163.0,"Hypotheses: Molecular dynamics simulations can be used to quantify proton transport capabilitiesof amphiprotic materials for use in hydrogen fuel cells.Introduction: Vehicular internal combustion engines are responsible for 28% of greenhouse gasemissions in the United States and are the second biggest source of these emissions (1). Protonexchange membrane (PEM) hydrogen fuel cells are a cleaner alternative to the internal combustionengine, emitting only water (2). The high cost of hydrogen fuel cells, however, impedes theirsuccess. Current fuel cells operate at low temperatures (85OC) to maintain loading of themembrane with water. Water serves as the proton exchange fluid. Operating at these temperaturesrequires an expensive platinum catalyst (3). To overcome this problem I will implement cutting-edge modeling in the Scott Auerbach laboratory at UMass Amherst to develop anhydrous protonexchange materials and improve the viability of PEM fuel cells.Among the most promising proton conducting materials are azoles – five-membered carbon andnitrogen rings that both accept and donate protons (4). To increase molecule stability, we tetherthem to oligomer chains. Oligomers offer a compromise between material stability and liquid-likeflexibility, allowing for faster and more efficient proton motion (5). Molecular dynamics (MD)simulations enable the study of hydrogen bonding interactions of these systems. I proposeinvestigating the hydrogen bond lifetime and reorientation rate of amphiprotes tethered tooligomers using MD simulations. I will accomplish the following goals: 1) Run atomistic MDsimulations on tethered imidazole; 2) Run coarse-grain MD simulations on tethered imidazole; 3)Benchmark across length scales; 4) Use both models to investigate other azoles.The project focus is on hydrogen bonding networks that govern proton diffusivity. Throughmodeling we relate microscopic properties to macroscopic performance to design new PEMs.Background: To study hydrogen bonding networksformed by tethered amphiprotes, we run moleculardynamics (MD) simulations, which allow the observationof atomic-level changes. Efficient proton transport takesplace via the Grotthuss mechanism, which involves thetransport of a proton by the collective motion of manyhydrogen bonds (Figure 1). This is reminiscent of bucketbrigades to put out fires. The Grotthuss mechanism requireshydrogen bond networks followed by functional grouprotation before transport of the next proton (6). Herein liesthe challenge of designing efficient proton conductors:extended hydrogen bonding arises in solid-like systems, Figure 1: Grotthus mechanism ofwhile rapid functional group rotation occurs in liquid-like proton transfer in imidazole (6)systems. MD allows us to compare the atomic level trade-offs between extended hydrogen bond clusters and functional group dynamics. Balancing theseparameters is vital for designing next-generation PEMs.1) MD of tethered imidazole: Imidazole is promising because it offers long H-bond lifetime andfast reorientation compared to other azoles (5). I will use MD software DL-POLY to run atomisticsimulations on imidazole oligomers. With NPT constant temperature and pressure simulations weextract volume parameters that we input into NVE constant volume and energy models. Thesesimulations enable calculations of hydrogen bond cluster size, lifetime, and reorientation rate.These simulations cover extremely short times – on the order of 10-9 seconds. To study protontransfer over more realistic scales, the next step is coarse-grain modeling.2) Coarse-grain modeling of tethered imidazole: In MD, the formation and reorientation ofhydrogen bonds occur on the order of picoseconds (10–12 s) to nanoseconds (10–9 s), while the MDtime step is femtoseconds (10–15 s), thus requiring prohibitively long simulations. Coarse-grainedMD allow us to increase the time step by restricting atomistic degrees of freedom (such asvibrational modes between atoms.) Coarse-graining also allows us to consider systemsapproaching macroscopic dimensions of real membranes. I will build a coarse-grained model inGromacs software using the Martini force field (7). Martini maps four functional groups (such asCH ) to one coarse-grain bead. These beads imitate the behavior of the functional groups they2represent by replicating their dipole moments. Atomistic simulations consist of 300 oligomers, butthrough coarse-graining we can model up to 4500 oligomers, an order of magnitude increase. Thiswill enhance our understanding of the behavior of proton transfer fluids in an actual PEM.3) Model benchmarking: We will benchmark coarse-grain models against atomic-levelsimulations to ensure that hydrogen bond properties agree across length scales. To do so I willwork with Qinfang Sun, a graduate student in the Auerbach lab. She has built atomic-levelsimulations of azole liquids and oligomers, and her expertise will enable me to be successful. Iwill use her results to build a coarse-grained system to study long range interactions betweenmolecules. By combining the results from our studies, we will have a much more complete pictureof proton transfer and potential for use of tethered amphiprotic materials in fuel cells.4) Expansion of model to other amphiprotes: Once the coarse-grain model is benchmarked, itbecomes an effective tool for studying PEM materials. I will investigate how other azoles,including triazole, tetrazole, and pyrazole, change the nature of hydrogen bonding cluster size andlifetime. I will also study how oligomer backbone length affects these parameters, searching forbalance between percolating hydrogen bonds and rapid reorientation dynamics.Intellectual merit: My background as a chemical engineer is crucial for this project, combiningmy knowledge of chemistry with my engineering, problem-solving perspective. I will use myknowledge to build models that accurately represent material behavior. I will implement themodels to study hydrogen bond capabilities of proton exchange materials. However, this projectwill not be as simple as determining which material offers the highest performance. I must findthe optimal trade-off between hydrogen bond lifetime and reorientation rate. It is my responsibilityto decide which materials are most promising for next generation PEMs.Broader Impacts: Hydrogen fuel cells offer environmentally sustainable transportation. Myresearch will further PEM development by identifying the most promising materials to focus on inlab testing. These materials have the potential to revolutionize PEM fuel cells, reducing cost andincreasing cell lifetime. The goal of this research is to make fuel cells competitive with the internalcombustion engine, offering an environmentally friendly and cost effective alternative. Ifsuccessful, my research will give everyone access to affordable, green transportation.References1. EPA. Sources of Greenhouse Gas Emissions. 2014.http://www.epa.gov/climatechange/ghgemissions/sources.html2. EPA. Fuel Cells & Vehicles. 2012. http://www.epa.gov/fuelcell/basicinfo.htm#performance3. Baschuk, JJ, Li, X. Carbon monoxide poisoning of proton exchange membrane fuel cells. International Journal ofEnergy Research. 2001; 25(8): 695-713.4. Viswanathan, U, Basak, D, Venkataraman, D, Fermann, JT, Auerbach, SM. Modeling Energy Landscapes ofProton Motion in Nonaqueous Tethered Proton Wires. J. Phys. Chem. A. 2011; 115: 54325-5434.5. Harvey, JA., Auerbach, SM. Simulating Hydrogen-Bond Structure and Dynamics in Glassy Solids Composed ofImidazole Oligomers. J. Phys. Chem. B. 2014; 118: 7609-7617.6. Mangiatordi, GF, Laage, D, Adamo, C. Backbone effects on the charge transport in poly-imidazole membranes: atheoretical study. J. Mat. Chem. A. 2013; 1: 7751–7759.7. MARTINI Coarse Grain Force Field for Biomolecular Simulations. http://cgmartini.nl/"
164.0,"Sedge-Dominated Sites in Discontinuous Permafrost PeatlandsIntroduction: Rising temperatures in the subarctic are accelerating thaw of organic-richpermafrost peatlands, liberating organic carbon (C) from long term storage through microbialdecomposition, and increasing methane (CH ) emissions1,2. Methanotrophic bacteria can oxidize4(consume) CH in thawing peatlands, producing carbon dioxide (CO )3,4. Recent biogeochemical4 2research has elucidated the controls of CH production and flux in thawing peatlands; however,4CH oxidation and its controls remain significantly less understood than CH flux.4 4Both CH flux and CH oxidation vary along the gradient of permafrost thaw. As thaw4 4occurs, hydrology, plant communities, and geochemical characteristics will all vary spatially andexert controls on the carbon dynamics of thaw5. MethaneandCO are both greenhouse gases, but2CH has a >30x larger warming potential than CO . Thus, it is critical to gain further insight into4 2the factors determining the ratio of CH flux and CH oxidation in thawing peatlands to produce4 4accurate emissions projections for climate change models.Preliminary data from July 2015 fromStordalen Mire in Abisko, Sweden (68°21'N,18°49'E) provides evidence for permafrost thaw-induced methane oxidation at open-water sedgesites adjacent to collapsing permafrost palsas (Fig.1). Sedges contain aerenchymous tissues thatenable gas transport in and out of the watercolumn4. Sedges act as a conduit for CH out of4the water column and transport oxygen (O ) into2the rooting zone (rhizosphere), enabling CH4oxidation below the water table4.One major gap in validation ofbiogeochemical models of wetland CH emissions4 Fig. 1. Cores from above (surface) and belowis the lack of Eh or redox potential measurements. (depth) the water table were extracted from 10 sitesField measured Eh of pore water in sedge rooting over a permafrost thaw gradient. Bars representzones in thawing peatlands should show the extent mean oxidation rate across replicates ± standarderror; n=4. By thaw stage: F = 19.75, p < 0.001, byof O diffusion into the water column and indicate2 depth and thaw stage*depth: p > 0.05.whether aerobic (CH oxidation) or anaerobic (CH4 4production) processes are the dominant microbial metabolic pathways in thawing permafrost6,7.Little data is available on the redox state of peatland pore waters because reliable field Ehmeasurements have previously been difficult to attain and reproduce. Carefully calibrated fieldEh electrodes will enable more accurate in situ redox potential measurements8. In addition tofield Eh measurements, laboratory incubations of peat from these locations may link redoxpotential and areas of CH oxidation, particularly in the rhizosphere.4Measuring changes in redox potential through the water column of open-water sedge siteswill enable more accurate modeling of carbon dynamics in thawing subarctic peatlands, as it willindicate the zones in which CH production or CH oxidation dominate. Current research at4 4Stordalen Mire uses the DeNitrification-DeComposition Model (DNDC) to test CH production4pathways and flux9. Further monitoring of CH oxidation and its relationship to redox potential4will enable DNDC to better integrate CH oxidation and validate wetland CH emissions4 4predictions. Understanding the connection between pore water redox potential and oxidationrates in open-water sites is critical to understanding how permafrost thaw will influence carbondynamics and geochemical characteristics in transitional thaw stages in peatlands as thawprogression advances.Hypotheses: By pairing in situ Eh measurements in open-water sedge sites and laboratoryincubations of biomass from sedge sites at each Eh measurement depth, I will test the followinghypotheses. 1. A positive correlation exists between redox potential and potential oxidation rate.2. Redox potential and potential oxidation rate will be highest in the rhizosphere relative to therest of the water column in open-water sedge sites. 3. Incorporation of redox potential and CH4oxidation rates to DNDC will improve modeling of wetland CH emissions.4Methods: My research will focus on open-water sedge sites in Stordalen Mire, a thawingsubarctic permafrost peatland complex in northernmost Sweden containing palsas, semi-wetSphagnum sites, wet sedge-dominated sites, shallow lakes, and thaw ponds. As part of my REUexperience, I collected preliminary oxidation data using incubations of peat from across apermafrost thaw gradient in July 2015, which revealed high potential oxidation rates in open-water sedge sites proximal to thawing palsas.I will measure redox conditions (Eh) with a platinum electrode8 through the watercolumn in wet sedge areas in Stordalen Mire throughout the course of the snow-free season(June-September). I will also measure environmental correlates including CH flux, water table4depth, thaw depth, pH, and plant community composition to examine potential relationshipsbetween redox potential and other environmental variables. I will couple Eh measurements withaerobic incubations10 of sedge biomass to determine the relationship between redox potential andpotential oxidation rates in sedge areas. Incubations will occur at in situ temperatures and CH4concentrations, as determined by field measurements from the preceding field season. Incubationprotocol will be held constant across all replicates. After collection, redox potentials, oxidationrates, and environmental data can be incorporated into DNDC to test their effect on emissionsscenarios from Stordalen Mire and other similar permafrost peatland complexes. I will work withmy advisor’s (R. Varner) collaborators at UNH to integrate these data to DNDC.Intellectual Merit: This project will provide some of the first empirical data on in situ O2diffusion through the water column in thawing peatland complexes and its effects on carbondynamics. As previous models rely on hypothesized values for Eh and O diffusion, these data2are essential to developing more accurate biogeochemical models of thawing peatlands to yieldmore reliable estimates of CH emissions from wetlands as climate changes.4Broader Impacts: I am committed to better understanding climate change and biogeochemicalsystems to both further scientific understanding and to guide mitigation of future carbonemissions and climate change effects. Elucidating less-understood aspects of carbon dynamics,like CH oxidation, and their effect on future emissions is key to creating effective mitigation.4I will participate in programs facilitated by the Joan and James Leitzel Center forMathematics, Science, and Engineering Education (R. Varner, Director) to educate the widercommunity about global environmental change. Programming from the Leitzel Center aims toengage teachers, high school students, and undergraduates in STEM activities. I will implementeducational outreach in regional schools and mentor undergraduate students on research projects,with particular interest in encouraging female and low-income students to pursue their interestsin the STEM field.References: 1Turetsky, M.R., et al. (2014), Global Change Biol., 2183, 2Callaghan, T.V. et al. (2010), Geophys.Res. Letts., 3Kip, N., et al. (2010), Nature Geosci., 617, 4Ström, L. et al. (2005), Biogeochem., 65, 5Malhotra, A. andRoulet, N.T. (2015), Biogeosci., 3119, 6de Mars, H. and Wassen, M.J. (1999), Plant Ecol., 41, 7Popp, T.J., et al.,(2000), Biogeochem., 259, 8Hagris, T.J. and Twilley, R.R. (1994), Res. Methods Papers, 684., 9Deng, J., et al.,(2014), Biogeosci, 4753., 10Larmola, T., et al., (2013), Eco. Soc. of America, 2356."
165.0,"The evolution of similar traits in distantly related species is one of nature’s great surprises.Convergent evolution of traits has been widely observed throughout the animal kingdom;however, it remains unclear whether this phenotypic convergence results from convergentevolution of genes (Stern, Nat Rev Genet 2013). On a molecular level, convergent evolutionoccurs when the amino acids of a specific protein preferentially undergo mutations that producesimilar or even identical amino acid sequences within distinct evolutionary lineages. A high levelof adaptive convergent evolution – that is, convergence due to positive selection of beneficialmutations – would suggest that some genes have “optimal configurations,” which evolution usesand reuses across species. If such genes exist, then evolution is somewhat predictable,proceeding by one of a small number of possible paths (Stern & Orgogozo, Science 2009). Incontrast, the complete absence of adaptive convergence would indicate that proteinconfigurations beneficial to one species are seldom optimal within other species, and thatevolution may proceed by a much wider set of paths. Thus, two fundamental questions inevolutionary molecular biology are 1) how often convergent molecular evolution occursand 2) whether molecular convergence is a primary driver of phenotypic convergence. Toadequately answer these questions, genome-wide analyses are needed; however, most previousanalyses of convergent evolution have been limited to single genes (Li et al., Curr Biol 2010) orsmall taxa (Bazykin et al., Biol Direct 2007). Recently, the advent of whole-genome sequencinghas opened new opportunities for exploring molecular convergence. Published genomes nowexist for over 100 animal species, and 177 more are currently underway (Koepfli et al., Annu RevAnim Biosci 2015). Additionally, phenotypes for 4,541 mammalian traits have been documentedin a public database (O’Leary et al., Cladistics 2011). Together, these data enable a genome-wide search for convergent mutations throughout mammalian species followed by a test forassociation between convergent genes and specific convergent phenotypes, which mightachieve strong statistical power for detecting adaptive convergence.I plan to develop and apply a statistical model to test for convergent evolution among 61sequenced mammalian species. I hypothesize that convergent molecular evolution occurs at ahigher rate than has been previously observed, and that this genetic convergence drivesconvergence of observable traits. This model will extend the boundaries of biological knowledgeby measuring the frequency of adaptive convergence, and will augment existing statisticalmethods in a broadly applicable framework that can be extended to other genomes in the future.Aim 1: Develop a statistical framework for inferring convergent evolution between genomes. Iwill make my framework broadly generalizable to any data set with the following inputs: 1) aphylogeny containing the accepted evolutionary relationships within a set of species, and 2) thepairwise sequence alignments of all proteins in those species for which unique human orthologsexist. My analysis will integrate these data as follows: Step 1: Infer ancestral sequences. For every amino acid position in every sequence, I willemploy a linear-time approach to compute probability distributions of DNA and amino acidsequences at each ancestral node in the phylogeny (Yang, Mol Biol Evol 2007). Step 2: Infer patterns of adaptive convergent evolution between species pairs. At the proteinsequence level, I will apply a statistical analysis adapted from the CONVERGE algorithmdescribed by Zhang & Kumar (Mol Biol Evol 1997). For every pair of species within ouranalysis, I will examine each amino acid and compute the probability that this amino acidconverged between the two species, using the ancestral sequences from the previous step asreference. I will then determine the likelihood of convergence within each exon and withinthe gene. Because rapidly evolving genes often converge by random chance, called neutralconvergence, I will control for gene-specific mutation frequencies in order to distinguishadaptive convergence from neutral convergence (Thomas & Hahn, Mol Biol Evol 2015). Step 3: Evaluate performance on simulated data. I will simulate evolution of proteinsequences in which a small pre-selected subset of sequences evolve under a non-neutralconvergence pattern and the rest evolve neutrally. I will then test my model’s precision andrecall in inferring which of the sequences evolved under the convergent model, correcting forfalse discovery. If my model is able to detect evidence of convergent evolution in thesimulated data at a low false discovery rate, but I observe no signs of convergent evolution inmy analysis of the biological data, then these results will cast doubt on the hypothesis thatnon-neutral convergence is a significant driving force in molecular evolution.Aim 2: Quantify the levels of convergent evolution within mammalian genomes, and identifyfunctions enriched within convergent genes. Step 1: Identify specific genes that have evolved in convergence across species. Using publicalignment tools (Kent et al., PNAS 2003), the Bejerano Lab has obtained cross-speciessequence alignments and a phylogenetic tree for 61 mammalian species. I will apply mystatistical framework to all pairs of sufficiently diverged mammalian species and identifyparticular genes within each species-species pairing that exhibit non-neutral convergence. Ihypothesize that I will find widespread evidence of adaptive convergent evolution. Step 2: Identify potential phenotypic effects of convergent genotypes. If evolutionaryconvergence is truly adaptive, this would suggest that genes converge when they undergosimilar selective pressures within different species (Castoe et al., PNAS 2009). Therefore, Ihypothesize that genes facing similar pressures within independent species will be morelikely to evolve in convergence within those species. For example, in aquatic mammalssuch as dolphins, manatees, and walruses, we might expect high convergence of skin-expressed genes involved in thermoregulation. I have identified a set of 20 convergentphenotypes that arose independently in mammals. For each of these phenotypes, I willconduct Gene Ontology enrichment analysis on genes that show elevated levels ofconvergence among the animals possessing the phenotype in question. As a null model, I willapply the same enrichment tests within groups of species that do not exhibit phenotypicconvergence. If my hypothesis is correct, this analysis will suggest functions for whichsimilar selective pressures across species have necessitated similar courses of proteinevolution across these species. Importantly, in order to confirm these putative links betweenconvergent genotypes and convergent phenotypes, future experiments will be necessary. Thespecific amino acid substitutions that I identify will be prime targets for further examinationin functional assays, as described by Liu et al. (Mol Biol Evol 2014).My experience developing statistical models to quantify bias in genome-wide DNase-seqexperiments (Gloudemans, 2015 Honors Thesis) makes me well-qualified to develop a genome-wide statistical model of evolution. This project will help us to understand whether phenotypicconvergence is a direct result of genotypic convergence. To further facilitate broader impacts, Iwill create a user-friendly visualization that highlights hotspots of convergent evolution, and Iwill make this tool publicly available in the UCSC genome browser. This tool will allowbiologists to visually explore instances of molecular convergence and to ask even deeperquestions about the specific functional roles of these convergent mutations, ultimately increasingour understanding of how these proteins shape the lives of humans and all other species."
167.0,"first confirmed physics beyond the standard model, but has proven impossible to measure in thelab. However, neutrinos make up a significant fraction of the mass in the universe (up to 1%).Due to their very low, but non-zero, mass, they have a distinct effect on the growth of large scalestructure. At early times, neutrinos behaved as “hot” dark matter but became “cold” dark matteras the universe expanded. Hot dark matter is able to stream freely through potential wells createdby massive objects, pulling them apart while cold dark matter becomes trapped and enhancesthe structure. The formation of galaxy clusters, which are the most massive gravitationally boundobjectsintheuniverse,ishighlysensitivetotheneutrinomass. Moremassiveneutrinosbecomecoldearlier, leading to a larger number of high-mass clusters. Through the Sunyaev-Zel’dovich Effect,high-resolution microwave telescopes are able measure the abundance of clusters over cosmic time.The SZE is the result of photons in the Cosmic Microwave Background (CMB) interactingwith high-energy electrons in a galaxy cluster. When CMB photons scatter off the electrons,they are shifted in frequency. At low frequencies (below ∼220 GHz), this results in a reductionof the CMB intensity. These relatively small “shadows” are used to detect galaxy clusters inhigh resolution CMB surveys. The amplitude of the effect can be used to estimate the clustermass. Current cluster cosmology studies are limited by systematic biases of the cluster masses,some of which comes from emissive sources in the clusters themselves. Dust emission due to startformation in the member galaxies is a potentially important bias of cluster mass.In 2015, the Planck Collaboration released a paper exploring the correlation between the SZEand the Cosmic Infrared Background (CIB) [1]. The CIB is emitted by hot gas in star forminggalaxies. Unfortunately, the Planck cluster catalog only extends to redshift of ∼1.0, and the CIBprimarily comes from redshift >1.0. For cluster surveys with higher angular resolution (such asthose produced by data collected from the South Pole Telescope and the Atacama CosmologyTelescope), this effect has not been quantified for most of their clusters.I will probe the emission from dust in galaxy clusters out to redshift ∼1.5, usingclustersfoundindatafromtheSouthPoleTelescope(SPT)andCIBmapsfromPlanck. Following[1], there are two methods for performing this correlation. The first is a stacking analysis. I willmake small cutouts of the Planck CIB maps and SPT CMB maps at the locations of SPT-selectedclusters. Stacking the cutouts and using aperture photometry to extract the signal strength willreveal the average correlation between the SZE and CIB in each frequency band. The secondmethod uses Fourier techniques to account for both the clusters detected at high signal to noiseand lower significance clusters that are below the detection threshold. I will create an angularpower spectrum of the correlation of each band with the SZE signal. These two methods arecomplementary. The first is a very direct probe of known clusters. The second includes lowersignificance sources of SZE signal, which leads to higher signal to noise. Both of them requirecareful modeling of the SZE and CIB in order to distinguish the two terms.ExtendingthisworkbythePlanckteamwillprobearegionofredshiftthatismoreimportanttothe systematic bias of cluster mass. The star formation rate is increasing over the range that I willprobe,sotheemissionfromdustismoresignificant. Furthermore,mappingoutthecorrelationasafunctionofredshiftwillallowmetoprobehowitchangesoverthehistoryoftheuniverse. Ofcourse,this comes with additional analysis challenges, most of which have to do with the extreme distanceof the high redshift clusters in the SPT catalog. Since the CIB is emitted by hot compact objects,its amplitude decreases with distance (unlike the SZE, which is a spectral distortion of the CMB).Pushing to higher redshift will mean some loss in signal, simply from the distance. On the other1hand, the surface brightness (amplitude at the source) of the CIB is higher in the redshift range Iwillprobe. Thisisduetotheincreasedstarformationrate. TheexpansionofspaceeffectivelyshiftsthePlanckbandsintoahigherintensityregionoftheemissionspectra,furthercounteringthiseffect.My previous work with SPT has prepared me well for this project. I have been running asearch for clusters using data collected by the SPT in 2012 and 2013. Through this work, I havebecome accustomed to working with CMB maps through both my low level analysis tasks, andthe high level work to produce a cluster catalog from SPT data. Furthermore, I have been exposedto many more analysis techniques through collaborative work with my colleagues. Finally, as partof the SPT collaboration, I will have access to all of the resources I need to complete this project:SPT CMB maps filtered appropriately to isolate the SZE, Planck CIB maps (which are publiclyavailable) and minimal computing resources.This work will address a significant unknown in the systematic error budget of clustermasses. Even if I find significant contamination of the SZE by the CIB, that is simply the firststep in accounting for the error. Since cluster cosmology is currently limited by systematic errorson cluster mass, caused by effects like this, understanding and eliminating them will have lead tosignificant improvements in cosmological constraints from cluster surveys. Beyond the impact onfuture cluster cosmology surveys, the results of this correlation probe several other astrophysicalphenomena. The Butcher-Oemler Effect [2] predicts that star formation is suppressed in galaxyclusters, relative to a similar galaxy outside a cluster. Since the CIB traces star formation,this correlation would determine if there is statistical evidence for the Butcher-Oemler Effect.Furthermore, thecorrelationcanbebinnedinredshifttodetermineifthestarformationinclustersis time-dependent. The stacking method also includes spatial information, which allowed Planckto determine that the star formation in low redshift clusters is primarily in the outskirts of thecluster. This analysis would extend our knowledge to older clusters.The results of this work also have appeal outside of the scientific community. They help usto understand star formation in the largest objects in the universe. Using SPT-selected clustersallows us to look back in time, when the star formation rate was highest. I will present thisknowledge to the general public through several outlets. There are multiple local astronomicalsocieties (the Eastbay Astronomical Society and the Mount Diablo Astronomical Society, forexample) that are very interested in having graduate students speak about their work. I will begiving talks to some of them in the near future on my current work with the SPT, so when thiswork is done, it will be easy for me to return and present our new findings. My research groupis also starting a collaboration with the Chabot Space and Science Center. I will work with thento create a standalone exhibit detailing my work, and arrange talks for the public.References[1] PlanckCollaborationetal. Planck2015results.XXIII.ThethermalSunyaev-Zeldovicheffect–cosmicinfraredbackgroundcorrelation. ArXiv e-prints,September2015.[2] H. Butcher and A. Oemler, Jr. The evolution of galaxies in clusters. I - ISIT photometry of C1 0024+1654and3C295. Astrophysical Journal,219:18–30,January1978.2"
168.0,"in condensed matter physics. In particular, topological defects have underlied diverse phenomenafromfractionalelectriccharge1tothesuperfluidtransitioninliquidhelium-42. Evenmorerecently,theimportationofideasfromtopologyinelectronicsystemstophotonicsystemshasledtoafloodofnewdiscoveriesandpotentialdevices3. MyPh.D.researchwillfocusonthepredictionofnovelpropertiesoftopologicaldefectsinphotonicandelectronicsystems,withanemphasisonboththefundamentalphysicsanddeviceapplicationsofthesedefects.Intellectual Merit: I have past experience researching a particularly striking property oftopological defects. Since July I have been doing research full-time under Professor Claudio Cha-monatBostonUniversity,whereinarecentpublication(Science,inreview)wehaveproposedto use topological defects to realize non-Abelian exchange statistics in photonic systems4.The defect occurs as a vortex in the order parameter describing a certain lattice distortion in two-dimensional honeycomb lattices, and leads to the formation of localized states which gain non-Abelian geometric phases upon their exchange. Our proposal is the first to predict non-Abelianstatisticsinphotonicsystems,asopposedtothedelicateelectronicsystemstheirsearchwasprevi-ouslyconfinedto,andcouldthusleadtotheirfirstconclusiveexperimentaldetection.MypastresearchexemplifieswhatIfindfascinatingabouttopologicaldefectsinelectronicand photonic systems - exotic phenomena, with the potential for real-world realization and appli-cation. My future work willcontinue to espouse these traits. I propose two projects. In project (1)Iwillextendthedefectstatesstudiedinmypreviousworktoafamilyofstatesobeyingabroaderclass of non-Abelian exchange statistics, and use these states to propose a novel topologicalnonreciprocal optical device. In project (2) I will separately extend these defect states to Weylsemimetalsandtheirphotonicanalogues,andshowthattheycansustaindissipationlesstransportin both systems. Further, I will address how these topological defects could naturally arise inWeylsemimetalsusingafieldtheoreticapproach. Idescribeeachprojectinmoredetailbelow.Project (1) will seek to realize novel forms of non-Abelian statistics, which when imple-mented in photonics could lead to a strongly nonreciprocal optical device. While the statistics Ipreviouslystudiedrespectreciprocity(lightpassedthroughanexchangeinonedirectionwillgainthesamephaseshiftasintheoppositedirection),Ihavediscoveredasimple,exactlysolvable,fam-ilyoftopologicaldefectstateswith“nonreciprocal”statistics. Importantly,theHamiltoniangivingrise to these states breaks a particular symmetry present in the previous, “reciprocal”, Hamilto-nian. Unfortunately, these particular defects would be difficult to realize in photonics experiment.My research will thus take clues from this simple model and focus on using symmetry classifi-cation to discover new nonreciprocal extensions of these topological defect states, especiallythose which are experimentally feasible. Breaking symmetries of the system will bring us into adifferent symmetry class, in which case I will determine whether nonreciprocity and topologicalprotection of our state can coexist. I will be aided by international collaboration with ProfessorChamon’s colleague Doctor Christopher Mudry at the Paul Scherrer Institute in Switzerland, anexpert in symmetry classification of topological defects. In determining which photonic systemsare feasible, I will benefit from current collaboration with engineering and experimental pho-tonics groups at Boston University and MIT working to realize the experiment proposed in myprevious publication. Beyond device applications, providing a physical realization of this class ofnon-Abelianstatisticswouldconstituteamajoradvancementinfundamentalphysics.In Project (2) I will pursue a separate extension of the same topological defect states intoboth electronic and photonic systems, in which I propose to use a 3D generalization of thesestates to achieve topologically-protected dissipationless transport in Weyl semimetals. Weylsemimetals have a low-energy electronic theory similar to the systems I previously researched5,and are thus capable of sustaining 3D analogs of the same defect states. Crucially however, theseformerly-2D states will now extend in the third direction, and can carry current in that direction.I have already analytically shown that such states would have a chiral dispersion relation,leadingtoalackofbackscatteringandthusdissipationlesstransport. Tosubstantiatetheseclaims,in the first part of project (2) I will determine the position-space changes in hopping needed tocreate these topological defects, using common tight-binding models of Weyl semimetals. As inmypreviouswork,Iwillusethesehoppingstoperformexactdiagonalizationsimulationstoquan-titativelyprobetheresultingdefectstates,andverifytheirchiraldispersionrelation. Experimentalverification of these properties may be easiest in photonic realizations of Weyl semimetals3, forwhich I would adapt my model to the photonic setting and find estimates of experimental condi-tionsneededforthestates’realization,similartomypreviouswork.Thesecondpartofmyproject(2)willaddressthefactthat,inelectronics,theconductanceofasingledefectwouldbesmallevenwithdissipationlesstransport. Toremedythis,Iwillsearchfor a field theory of the order parameter describing the appropriate hopping distortions, inwhich the creation of a macroscopic number of topological defects would occur. The startingpoint must be a nonzero mean field value of this order parameter. To determine the conditions forthis to occur, I will introduce the appropriate order parameter couplings into the electronic fieldtheory, and integrate out the electron degrees of freedom to derive an effective action for the or-der parameter. Assuming a nonzero mean field value, one would anticipate a massless Goldstonemode associated with fluctuations in the order parameter phase. It would then be an open prob-lem to determine how topological defects in this Goldstone mode might form, although pursuingconnections to vortex formation elsewhere in condensed matter may be fruitful. My extensivegraduate-levelcourseworkinfieldtheorywellpreparesmeforthiscomponentoftheproject.BroaderImpacts: Bothofmyproposedprojectsfeaturetopologically-protectedstateswithlarge potential societal impacts through use in photonic and/or electronic devices. Project (1)proposes to use the geometric phase of a topological defect state to uniquely achieve stronglynonreciprocal photonic devices, usable in essential optical elements such as isolators and circula-tors. This could greatly reduce undesirable optical loss compared to traditional nonreciprocaldevices, which rely on weakly (relative to my proposal) nonreciprocal materials such as ferrite orstrong permanent magnets. Additionally, my proposal would not require breaking time-reversalsymmetry,openingthedoortononreciprocaldevicesusingonlyconventionalmaterials!Project (2) seeks to realize defect states with chiral dispersion in Weyl systems, with po-tential impact in both photonics and electronics. In photonics, these modes could function aslosslessopticallines,robustagainstimperfectionsduetotheirtopologicalorigin. Suchtopolog-ical “one-way waveguides” have been realized in photonic quantum hall edge states, and have aplethora of novel device applications3. In electronics, the accumulation of a macroscopic numberofthesemodeswouldleadtomassiveconductance,withclearlytremendousdeviceimplications.Assessing the applications and limitations of such devices would require a theory for how thisaccumulation of topological defects occurs, highlighting the need for the second component ofmy project (2). All together, this array of broader impacts makes the investigation of topologicaldefectsinphotonicsandelectronicswellworthpursuing. TheNSFGRFPwillallowmetodoso.[1]R.Jackiw,etal.,Phys. Rev. D(1976). [2]J.M.Kosterlitz,etal., JournalofPhysicsC (1973). [3]L.Lu,etal.,NaturePhotonics(2014). [4]T.Iadecola,etal.,(2015). [5]X.Wan,etal.,PhysicalReviewB(2011)."
169.0,"Dispositional Risk Factors to False Confessions: Personality Traits and PsychopathologiesIn 2012, Pedro Hernandez was brought in for questioning for the 1979 abduction of six-year-old Etan Patz. Mr. Hernandez, a man with no criminal history, confessed to the abductionand murder of Patz.1 However, his diagnosis of schizotypal personality disorder, extremely lowIQ, and prolonged and unrecorded interrogation—all known risk factors to making false confes-sions (FCs)—convinced a lone holdout juror of his innocence, prompting a mistrial in the murdercase against Mr. Hernandez. He is scheduled to be retried in February 2016. The potentially ex-culpatory circumstances of this ongoing case share many similarities with other post-convictionDNA exonerations. In fact, research suggests that FCs are present in a significant minority(~27%) of all DNA exoneration cases. The purpose of this study is to empirically examine dis-positional risk factors associated with FCs among a subgroup over-represented within thecriminal justice system and among confirmed FC cases: persons with psychopathologies.Background & Rationale. Psycho-legal scholars have proposed compelling theories to explainwhy innocent suspects admit to criminal acts they did not commit.2 Extensive research indicatesthat there are two types of risk factors: the use of certain interrogation tactics and dispositionalcharacteristics. Historically, the study of police interrogation tactics has relied on experimentalmethods, producing a large body of science, while the study of dispositional risk factors has pri-marily employed archival and correlational studies. Thus, less is known about dispositionaltraits, such as personality. Two such personality traits–suggestibility and compliance–are thoughtto confer vulnerability to FCs within the context of coercive police interrogations.3,4 Further-more, fewer studies have examined the link between psychopathology and individual differencesin these personality traits. Thus this project will investigate whether psychopathology increas-es the risk for suggestibility and/or compliance leading to increased prevalence of FCs.In addition to conferring risk to FCs, suggestibility and compliance may differentiallymediate the types of FCs made by innocent suspects. In coerced-internalized confessions, inno-cent, but suggestible, suspects come to believe they are guilty, sometimes even confabulatingfalse memories.2 To date, only one correlational study has assessed the link between individualdifferences in suggestibility and internalized FCs.5 The Gudjonsson Suggestibility Scale (GSS), afalse memory paradigm where participants are presented with misleading suggestive infor-mation, is widely used among forensic psychologists in criminal cases involving disputed con-fessions.6 Yet no experimental research has attempted to use this scale to establish a causal linkbetween suggestibility and internalized FCs—and certainly not among people with diagnosedpsychopathologies. Hence, I will evaluate whether psychopathology increases the risk forsuggestibility leading to coerced-internalized FCs.In coerced-compliant confessions, the innocent but compliant suspect is induced throughinterrogation to confess to a crime they did not commit for some immediate instrumental gain. Ina naturalistic setting, the Gudjonsson Compliance Scale (GCS), a 20-item, self-report measure ofcompliance using a true/false format, was shown to discriminate between alleged false confes-sors and defendants who resisted confessing whilst being interrogated.6 Other correlational stud-ies indicate that compliance may be associated with anxiety, low self-esteem, and ADHD symp-toms3,6—factors present in many major psychopathologies. Because compliance is distinct fromsuggestibility and relevant to the making of FCs 6, I will evaluate whether psychopathology in-creases the risk for compliance leading to coerced-compliant FCs.Proposed Study. I plan to use a well-established experimental paradigm known to elicit FCsamong innocent participants to explore these aims (see Kassin & Kiechel, 1996).7 First, partici-pants will be recruited for a ‘typing speed’ task and asked to fill out a demographicsStephanie A. Cardenas Graduate Research Proposalquestionnaire. Psychopathologies willbe assessed via the Mini-InternationalNeuropsychiatric Interview-PLUS: a 15-minute structured diagnostic interview.Suggestibility and compliance will bemeasured using the GSS and the GCS,respectively. Next, participants will beassigned to one of four groups: 2 (slowvs. fast task pace) x 2 (presence vs. absence of false incriminating evidence) between-subjectsfactorial design. During the task, participants’ computers will suddenly ‘crash’ and a distressedexperimenter will lay the blame on them. Two forensically relevant components will be manipu-lated: (1) participants’ subjective certainty of their own innocence by varying the pace of the task(i.e., slow-43 or fast-67 letters/min), and (2) the use of false incriminating evidence (i.e., falseeyewitness account of alleged participant behavior by a confederate), a common U.S. interroga-tion tactic. To determine whether the paradigm elicited a compliant FC, participants will beasked to sign a handwritten confession admitting their role in the computer crash. To determinewhether participants internalized the FC, a ‘curious’ confederate, will ask participants what hap-pened. Independent coders will determine whether participants unambiguously internalized faultbased on their description of the event to the confederate (e.g., “I caused the computer to crash.”)Anticipated Results [1] Psychopathologies will predispose individuals to higher levels of sug-gestibility and compliance (Fig. 1). [2] Higher levels of suggestibility will confer increased riskto making coerced-internalized FCs. [3] Higher levels of compliance will confer increased riskto making coerced-compliant FCs. Although different psychopathologies may confer vulnerabil-ity through different pathways (e.g., social anxiety may be associated with increased compliance,and therefore compliant FCs), highly symptomatic individuals are known to have increased ratesof alleged FCs regardless of primary diagnoses.8 Therefore, the role played by illness severity(e.g., bipolar disorder vs. hypomania) and time frame (e.g., current/past) will also be evaluated.Broader Impacts. The novel approach of this study integrates findings from criminology, clini-cal-forensic, and social psychology to test a hypothesis with notable implications for identifyingand protecting individuals who are vulnerable to persuasion in the interrogation room because ofpsychopathologies (e.g., providing mandated access to legal advice from individuals sensitive tothis population). By disseminating my findings at scientific conferences and in peer-reviewed ar-ticles, I will contribute to the understanding of how dispositional factors interact to influence thewrongful convictions of innocent suspects. This in turn will facilitate further collaboration be-tween attorneys, juries, judges, and social scientists to develop concrete ways to prevent thesemiscarriages of justice. Moreover, because juvenile status also confers increased risk to makingFCs, the proximity at my proposed graduate institution to programs like College Bound andSummer Enrichment Camps and to intercity youths from disadvantaged backgrounds will allowme to provide a positive outlet within the community for academic advancement.Finally, future studies will examine the role of dispositional risk factors in the context offalse guilty pleas (FGPs). Even though guilty pleas constitute nearly 95% of convictions in theU.S, FGPs remain grossly understudied. In fact, the same traits that place persons at risk for FCsmay also place persons at risk for FGPs.9 Therefore, findings from my proposed project promiseto put forward information that will inform this novel and unstudied related area of researchRefs: 1 Goldstein & Hager (2015 May). 2 Kassin et al (2010) Law Hum Behav. 3 Gudjonsson et al (2008) PsycholMed. 4 Gudjonsson (1991) Med Sci Law. 5 Sigurdsson & Gudjonsson (1996) Per Indiv Differ. 6 Gudjonsson (2003)Wiley. 7 Kassin & Kiechel (1996) Psychol Sci. 8 Redlich (2010) Law Human Behav. 9 Redlich (in press) APA."
170.0,"Imagine an empty room with four walls. Away from the walls and inside the space, aperson has the freedom to move 3-dimensionally in any direction and is constrained to move1-dimensionally with respect to time. However, this person is unable to view the entire roomwhile simultaneously residing in the interior. There are photons, particle interactions, andvarious physical phenomenon that are unable to transmit their information to the personwhen these events are out of sight − that is, unless this person is at the wall. At the bound-ary of this room, a person sacrifices a dimension of freedom in exchange for viewing theinternal dynamics of their space. This way, a person is able to survey their space and returnto the interior with knowledge of the native physical interactions − fully revealing the under-lying dynamics. This duality between an n-dimensional interior and an (n−1)-dimensionalboundary is known as the Anti-deSitter Space/Conformal Field Theory Correspondence.This correspondence is powerful. General Relativity asserts that space-time and gravityare fundamentally connected, while a pivotal aspect of Quantum Field Theory is the freedomfor symmetries to arise and reduces the number of degrees of freedom. Maldacena[1] was thefirst to assert that an interior space-time, such as Anti-deSitter Space described by GeneralRelativity, could be connected to a conformal boundary, where a Quantum Field Theorywould reside, thereby linking Gravity and QFT. This gauge/gravity duality has a variety ofapplications ranging from condensed matter experiments to particle physics.With respect to the Standard Model of Particle Physics, Quantum Field Theory assertsthat fundamental particles can be described as excitations of quantum fields. These parti-cles, such as quarks and gluons, constitute most of the visible matter in the universe, andare described by Quantum Chromodynamics through the strong force. As a strongly cou-pled gauge theory that lacks a fully theoretical description, the mapping provided by thegauge/gravity duality might reveal a gravitational dual to QCD, which is not only highlydesirable but also potentially feasible.Duringtheprevioussummer, IhadtheopportunitytoconductresearchthroughmysecondNSF REU at the University of Minnesota studying the AdS/CFT conjecture as applied tonon-perturbativegaugetheories, specificallyQuantumChromodynamics. UnderthetutelageofDr.JosephKapusta,Istudiedthepropertiesoftheglueball,aparticlecomposedofmultiplegluons predicted by the Standard Model, and a dilaton, a hypothetical particle that arisesfrom the scalar fields accompanying gravity. To incorporate the behavior and structureof these fundamental particles into this duality, one usually embarks on the bottom upapproach by assuming the existence of such a dual and, thereby, models QCD as an effectivefive-dimensional gravitational theory. This approach, known as AdS/QCD, provides thefreedom for the computation of physical quantities in QCD that can then be tested at thehigh energy collisions at particle accelerators.At the REU, I developed the equations of motion from considering an action[2],[3] thatconnects both gravitational field and the glueball and dilaton fields. This pen and paperwork derived an analytic expression for the potential and this result describes the behaviorof these particles at the IR and UV energy ranges. Early in the universe’s lifetime and inmodern-day particle collisions, a hot QCD quark-gluon plasma exists for short times whosebehaviorposesachallengeforQCDphysics. Theresultsofourstudymightshedlightonthisplasma, while furthering a theoretical description for QCD using the AdS/CFT conjecture,thereby connecting theory and experiment. As the lead author, I have attended the DNP2015 and APS 4C Conferences to present this work and aim to obtain my second publication.1Aditya Dhumuntarao Graduate Research ProposalI wish to continue applying the AdS/CFT Correspondence to QCD for myPh.D dissertation. With my Ph.D research, I aim the further bridge the gap between theplethora of experimental evidence and the developing theoretical considerations for QCD byincorporating additional phenomenological metrics into the AdS/QCD conjecture.A critical question that I wish to pursue is the construction of a model incorporatingthe dilaton field, glueball field, quark field, and other matter fields with finite temperaturefield theory. As finite temperature quantum field theory describes the expectation values ofphysical observables at finite temperatures in (n−1)-dimensions and links them to statisticalclassical field theories, such as gravity, in n-dimensions, the AdS/QCD conjecture seems tohave a natural supplement. Since Dr. Kapusta is a leader in the field of finite temperaturetheory[4], joining his research group is highly desirable for the formation of this model.Currently, IamworkingwithDr.Kapustatodeterminethepredictedglueballmassspectrafrom our REU analysis and ultimately compare this value against lattice QCD calculations.In fact, a recent publication[5] has argued that an experimentally detected particle, known asf (1710), is the glueball. Therefore, improving our model to include more realistic glueball0dynamics and performing a comparative analysis after determining the mass spectra of theglueball is of principle importance.In addition to tackling fundamental science harmoniously through theoretical and experi-mental considerations, this project contains broader impacts. A significant result from thisanalysis would lend further credence to the AdS/CFT conjecture. Although the conjecturewas founded on the premise of revealing a theory of quantum gravity, a more immediate ap-plication resides in condensed matter experiment where chiral magnetic fields are frequentlystudied with the conjecture. Also by revealing physics beyond the Standard Model, we maybe able to describe or construct new matter from gluons and quarks − one such highlight isthe strong evidence for the tetraquark found at CERN. This new matter might impact oursearches for dark matter often hypothesized[6] as complex quark matter, additional stableelements that may assist in creating new materials, and efforts in high energy plasma physicswhich has immediate applications for fusion.The purpose of the AdS/CFT conjecture is to explore and discover a unified descriptionof the universe and the interactions within our universal boundary. Matter is the fundamen-tal link that interacts with and connects gravity with the other forces. In the short term,developing a theoretical framework for QCD will inform and drive further experimental en-deavors, while the long term promises support for a candidate conjecture that currently seesa versatility of applications. With the support from the NSF GRFP, I will have the free-dom to immediately pursue this research and continue my current studies of the AdS/CFTconjecture to develop a unifying framework of quantum matter and gravity.[1] J. M. Maldacena. The Large N limit of superconformal field theories and supergravity. Int. J.Theor. Phys., 38:1113–1133, 1999.[2] S. P. Bartz, J. I. Kapusta. Dynamical three-field ads/qcd model. Phys.Rev.D, 90:074034, 2014.[3] J. I. Kapusta, T. Springer. Potentials for soft-wall ads/qcd. Phys. Rev. D, 81:086009, 2010.[4] Joseph I. Kapusta, Charles Gale. Finite-Temperature Field Theory. Cambridge UniversityPress, second edition, 2006. Cambridge Books Online.[5] F. Bru¨nner, A. Rebhan. Nonchiral enhancement of scalar glueball decay in the witten-sakai-sugimoto model. Phys. Rev. Lett., 115:131601, Sep 2015.[6] E. Witten. Cosmic separation of phases. Phys. Rev. D, 30:272–285, Jul 1984.2"
175.0,"In order to understand evolution, we need to understand the complex relationships betweenbiological systems and fitness. This is a difficult task, because there are an enormous number ofpossible genetic states, and the mutations underlying these states interact non-additively toproduce fitness. We can frame this problem by thinking of evolution as a process occurring on ahigh-dimensional map between this space of genetic possibilities and the fitness of eachpossibility, a function often referred to as the “fitness landscape.” As a population adapts to aparticular environment, it moves between neighboring genotypes, constrained by the force ofselection to follow paths of increasing fitness. By understanding the general properties of thefitness landscape, we can answer questions about the functional nature of a biological system - Ifa mutation knocks out this gene, what effect will that have on fitness? - and ask broad theoreticalquestions - Is evolution predictable, or does it depend on chance events?The growing field of experimental evolution provides an avenue for addressing thesequestions by empirically testing important features of the fitness landscapes of microbes. Wenow know that in the budding yeast Saccharomyces cerevisiae, the effect of a beneficialmutation depends on the fitness of the genetic background where it arises [1], but whether asimilar pattern holds for deleterious mutations is an open question. Deleterious mutations may becommon in populations due to environmental changes or population bottlenecks, and theyprovide a novel way to study adaptation and to test the role of contingency in evolution. In myPhD research, I will study the fitness landscape of S. cerevisiae by investigating theinterplay between deleterious mutations and adaptation. I will complete my PhD research inDr. Michael Desai’s lab at Harvard University, where I am uniquely situated to conduct workthat combines genetics, experimental evolution, and deep sequencing.Aim 1. Changes in the fitness effects of loss of function mutations over adaptive trajectoriesGiven that most loss of function (LOF) mutations are deleterious, competing models makedifferent predictions about how their effects should change with increasing population fitness.The Desai lab recently found that in S. cerevisiae, the fitness effect of a beneficial mutation in aparticular genetic background is primarily predicted by the fitness of the background, creating apattern of “diminishing returns” during adaptation [1]. If this “global epistasis” model holds forall mutations, deleterious mutations should also become less deleterious as the populationbecomes more fit. In contrast, Fisher’s geometric model predicts that the fitness effect of somemutations will change from negative to positive at different levels of adaptation [2]. I will usetransposon mutagenesis and sequencing fitness assays (Tn-seq) to measure the fitness effects of alarge set of loss of function mutations in populations with different initial fitness backgrounds.Hypothesis: I predict that, in accordance with the global epistasis model [1], LOF mutationswill be less deleterious in populations with higher fitness. Methods: First, I will evolve 24 S.cerevisiae populations in standard liquid media for 1000 generations (100days), following a similar protocol to [3]. I will freeze samples every 250generations to create a “frozen fossil record” of each population as itadapts and gains fitness. At each of the five timepoints in this record, Iwill unfreeze my populations and use Tn-seq to systematically probe thefitness effects of a large number of LOF mutations. As shown in thefigure at right, Tn-seq consists of two steps. In A, I transform a genedisruption library into the population, causing a diverse set of singleinsertion mutations. In B, I track the frequency of each mutation over 30generations using deep sequencing of a barcode region in the insertion[4]. Using this method, I can determine the fitness effect of every mutation in parallel byanalyzing the change in its frequency [3,4]. I will create my DNA-barcoded transposon (Tn)gene disruption library using genomic DNA from S. cerevisiae [3], and by sequencing thislibrary, I will associate a unique barcode with each gene disruption. These associations willallow me to connect my data to specific genes, yielding additional biologically relevantinformation about how S. cerevisiae adapts to laboratory conditions.Aim 2. Adaptation after disruption of the genetic systemEvolution often involves transient environmental changes that alter selection pressure orpopulation size, both of which can lead to the fixation of mutations that are not beneficial in theorganism’s primary environment. Do these events affect long-term outcomes of evolution? Thedynamics of adaptation after a population has been “bumped” off of its adaptive trajectory arenot well understood, but they have the potential to distinguish between models of adaptation. Forfitness landscape models in which mutations interact only additively, any deleterious mutationsimply slows adaptation. However, in “rugged” fitness landscape models where mutationsinteract non-additively, it is possible that deleterious steps can lead to exploration of a previouslyinaccessible part of genotype space, potentially allowing a population to ultimately reach higherfitness. I will capitalize on the Tn-seq method to distinguish between these models by evolving“disrupted” populations alongside “undisrupted” populations and comparing their fitnesstrajectories. Hypothesis: I hypothesize that deleterious mutations will be more likely toimprove evolutionary outcomes in poorly adapted populations, as predicted by [5].Therefore, I predict that disruption due to Tn insertions will lead to higher final populationfitness relative to the undisrupted populations only when the original disruption occurs atearly time points from the frozen fossil record. An alternate prediction is that disruption willslow adaptation in all cases, which would support additive landscape models. Methods: I willpropagate “Tn-disrupted” populations from Aim 1 for 500 generations. I will measure meanpopulation fitness every 100 generations in these populations and at the correspondingtimepoints in the “undisrupted” populations using standard fluorescence-based competitions [1].Intellectual MeritMy project aims to connect ideas about the dynamics of adaptation on fitness landscapes to afunctional understanding of how a model organism changes as it adapts. Using massivelyparallel, sequencing-based fitness assays, this project will provide unprecedented resolution ofthe functional changes a population experiences during adaptation, and through evolution of Tn-disrupted clones, this study will test basic questions about the fitness landscape of evolving S.cerevisiae.Broader ImpactsWe now know that large asexual populations, in the form of pathogens or cancer cells, areinvolved in over a quarter of deaths worldwide [4]. While my research is centered on basicscience questions, these basic principles of asexual adaptation are an important part of buildingmodels of how these diseases progress. I will publish my work in peer-reviewed journals aimedat a scientific audience, but I will also use the power of animations and interactivity to make myevolution research come alive on my web site, where it can be shared with the general public.As detailed in my personal statement, I will also use science communication and video toempower young people to pursue STEM careers by showing them the human side of research.[1] Kryazhimskiy S et al. 2014. Science 344: 1519-1522. [2] Fisher RA. 1930. Clarendon Press, Oxford, U.K.[3] Van Opijnen T et al. 2009. Nature Methods 6: 767-772. [4] Levy SF et al. 2015. Nature 519:181–186.[5] Nahum JR, et al. 2015. Proc Natl Acad Sci USA 112:7530–7535."
176.0,"Unlocking success: Neurobiological correlates of grit in adolescents.Intellectual Merit: During adolescence, the brain undergoes extensive structural andfunctional development. Specifically, adolescence is characterized by differentialdevelopment of reward circuitry and cognitive control systems such that cognitive controlregions are relatively underdeveloped compared to reward processing regions.1 Althoughadolescents are able to reason about risky decision making, they are also vulnerable to socialinfluences. In emotionally salient conditions (e.g., the presence of peers), the maturity ofadolescent reward circuitry compared to the less mature prefrontal control system appears toexacerbate risk taking that results in negative outcomes (negative risk taking).2 However,adolescent differential brain development and vulnerability to social influences may also leadto greater recruitment of cognitive control processes used to engage in risk taking that resultsin positive outcomes (positive risk taking), like “grit”. Grit is defined as the determinedpursuit of a superordinate goal in the face of failure.3 Higher levels of grit are associated,over and above IQ, with objectively measured successes (educational attainment, GPA)4 andgreater well-being.5 Neurobiological investigations of behavior can corroborate and challengeour assumptions regarding the neural mechanisms underlying motivational, cognitive, andaffective components of risk taking. Despite the large body of research investigating negativerisk taking, there is a gap in knowledge regarding the neural mechanisms of positive risktaking and whether these mechanisms differ from negative risk taking.Novelty: The brain-based mechanisms of positive risk taking remain unknown, and the onlyempirical investigations of grit are through self-report. This study will address gaps in ourunderstanding of the association between negative and positive risk taking in adolescence,provide the first ecologically valid experimental manipulation of grit, and will determine howgrit behavior relates to external measures of success (e.g., GPA).Experimental Design: Participants will consist of 60 adolescents (14-18 yrs).6 Participantswill undergo an MRI desensitization procedure in the Galván Lab mock scanner beforecompleting a novel computer task in an fMRI scanner.The fMRI task, the “Grit Task”, is a money-earning paradigm I created that builds onextensive delay of gratification and delay discounting literature. There are two types of trials,each worth a fixed amount, lower-value trials (LVTs) and higher-value trials (HVTs).Participants must choose to perform either LVTs or HVTs before beginning (path selection).Participants who select the HVT path will be considered “delayers” who have higher grit thanthose who select the LVT path. If LVTs are selected, money earned will be paid at the end ofthe session up to $10 max. If HVTs are selected, money earned will be paid in 1 week at amin. of $20, max. $30.7 In addition to the delay in payment, the HVT path will requirecompletion of a mental rotation task (MR task; participants must mentally rotate two 3-Dfigures and determine whether they are identical) between each money-earning trial.Requiring completion of the MR task will improve ecological validity compared to delay ofgratification measures that traditionally do not require completion of an effortful task toachieve higher-value rewards. For example, college success requires continued goal-orientedpursuit, not simply an initial decision to delay the receipt of reward for a greater reward.Prior to path selection, all participants will practice the MR task. Participants will betold they must successfully complete (unlimited attempts) the MR task before each money-earning trial if the HVT path is selected. Traditionally, MR tasks are used as a measure ofspatial processing, however here the MR task will facilitate manipulation of “failure”, anessential element of grit. Participants will be told, regardless of performance, that they havefailed at some MR task attempts (randomized). This will require that participants sustain theirchoice of the HVT path and continue to attempt the MR task to receive the higher reward.Between each money-earning trial delayers will decide whether they want to continue withthe HVT path or switch to the LVT path (reward decisions). Path selection and subsequentGraduate Research Planreward decisions are proxies for grit. Those choosing to continue on the HVT path andperform the MR task after they have failed will be considered more “gritty” delayers.Delayers who subsequently switch to the LVT path, and participants who select the LVT pathat the outset, will remain on the LVT path and will be capped at the LVT max award.Restricting low-to-high switching and setting min/max awards for each path will minimizestrategizing. On the LVT path participants will view the MR stimuli before money-earningtrials but will not be required to complete the MR task. MR tasks have been successfully usedin adolescent fMRI studies and adapted to eliminate gender differences.Validated survey measures will assess (1) supportiveness of adolescents’ home andpeer environments,8 (2) grit and impulsivity,9 (3) academic achievement, optimism, IQ, self-esteem, performance anxiety, and well-being.10 The Stoplight Task (ST), a computerizedfMRI task in which participants drive a virtual car, will be administered to determine whethergritty individuals are prone to more negative risk taking. In the ST, participants decidewhether to brake as the car approaches a yellow light at an intersection. Not braking results ina higher crash risk but also a potentially higher monetary reward for finishing quicker.Anticipated Findings: On the Grit Task, more gritty individuals will exhibit greater: (1)perseverance on the Grit Task, (2) activation in mesolimbic reward circuitry (ventralstriatum) at delayed reward presentation, and (3) activation in regulatory control regions(dorsolateral and ventromedial prefrontal cortices; dlPFC, vmPFC) during reward decisions,compared to less gritty individuals. Ventral striatum activation on the ST and Grit Task areexpected to be highly correlated. Gritty individuals are expected to exhibit more PFCactivation during both tasks resulting in more gritty behavior and less risky behavior(measured by ST yellow light decisions).Feasibility: I will work with Dr. Adriana Galván, a developmental neuroscientist withexpertise in adolescent brain development and my advisor, to implement this program ofresearch. Dr. Galván has a database of over 400 ethnically diverse adolescents from which torecruit participants, and her affiliation with the UCLA Center for Cognitive Neurosciencegives me access to state-of-the-art neuroimaging facilities. Scanning fees will be paid by Dr.Galvan’s unrestricted funds.Broader Impacts: Identifying the neural correlates of grit will advance our understanding ofpositive risk taking and inform efforts to improve positive goal-oriented pursuits (e.g.,academic achievement) for adolescents. For disadvantaged adolescents who lack externalencouragement to engage in positive risk taking, this research is critical. As part of UCLAPsychology in Action (PIA), I will share with educators and policy makers atinterdisciplinary symposia how positive risk taking is beneficial for adolescents. I will alsoengage with lay audiences about the implications of my research through PIA’s social mediaplatforms and through community outreach at area schools. I will use my findings toencourage educators and community organizations to provide positive outlets for adolescents.I will advance scientific knowledge by presenting my work in published manuscripts and atconferences, and through transdisciplinary collaboration investigating positive risk takingwith the UC Consortium on the Developmental Science of Adolescence. I will directlyprovide opportunities for adolescents to engage in positive risk taking by conductingleadership workshops at area high schools and will expose underrepresented groups tocareers in STEM fields by actively recruiting women and minority research assistants.References: 1Casey, B.J., Getz, S., & Galván, A. (2008). Dev Rev, 28, 62-77. 2Crone, E.A., & Dahl, R.E.(2012). Nat Rev Neurosci, 13, 636-650. 3Duckworth, A., & Gross, J.J. (2014). Curr Dir Psychol Sci, 23(5), 319-325. 4Duckworth, A.L., Peterson, C., ... (2007). J Pers Soc Psychol, 92, 1087-1101. 5Steger, M.F., Kashdan,T.B., ... (2008). J Res Pers, 42, 22-42. 6Sample size calculated using fmripower.org. 7Amounts based onintertemporal choice heuristic calculation; Ericson, K.M.M, White, J.M., ... (2015). Psychol Sci, 26(6), 826-833.8e.g., NRI-RQV, NRI-SPV. 9 e.g., Grit Scale, DOSPERT, BIS/BAS. 10e.g., LOT-R , WASI-II, Rosenberg Self-Esteem Scale, LSAS-SR, SWLS."
179.0,"More than 120,000 people in the United States are currently on the waiting list for life-saving organ donations; over 6,000 of these people die annually without receiving neededtreatment. Tissue engineering may help address issues of donor organ shortage and transplantrejection. However, applications have been limited by the ability to design complicated scaffoldsthat reproduce the architecture present in the cellular microenvironment. 3D bioprinting (3DBP)holds promise for addressing these shortcomings by producing biologically-inspired structuresbased upon computer-generated models. Unfortunately, low cell viability due to lack of nutrienttransport through thick scaffolds is a current barrier to clinical use. Without blood vessels tofacilitate nutrient and oxygen transport, cells at the center of the constructs die. There is anurgent need to improve methods such as 3DBP to develop implants to treat these patients.One method to address this problem involves artificial blood vessels created by physicalchannels through the scaffolds, seeding with endothelial cells, and adding growth factors. By thismethod, scaffold design must be further complicated by including vasculature. However,introducing oxygen-releasing polymers directly into the scaffolds may be a simpler way toaddress the need for oxygen transport.1 My research objective is to investigate the ability ofoxygen-releasing microspheres to decrease cell necrosis for adipose-derived stem cells in printedimplants.Using oxygen-releasing microspheres to reduce cell death rates for tissue engineeringapplications has only been referenced in one publication at the time of this application. Thissystem involves a two level approach. First, core-shell microspheres are created with the shellconsisting of poly(lactide-co-glycolide) (PLGA) and the core containing H O -modified2 2poly(vinyl pyrrolidone) (PVP). This shell system allows for slow release of H O -modified-PVP2 2for up to two weeks.3 Second, the microspheres are then encapsulated in a hydrogel with catalaseenzyme and cardiosphere-derived cells (CDCs). Catalase reacts with the H O bound to PVP to2 2generate oxygen, which is then free for use by the cells. This system has been shown to eliminatesignificant CDC death.4 This promising result may also be replicable in other cell types.Among the most propitious lineages of adult stem cells are the adipose-derived stem cells(ASCs) due to their ease of acquisition and ability to be chondrogenic, osteogenic, andadipogenic. Despite these advantages, ASC survival rates following in vivo implantation are low.Reduced viability may be due to lack of oxygen at the implant or inject site, which could beaddressed by oxygen-releasing polymers.2The steps involved in making a clinically relevant printed scaffold include materialchoice, cell type choice, printer type choice, scaffold material characterization, in vitro testing,preclinical animal testing, and clinical testing. Using this approach, I will complete the first sixsteps to adapt the PVA-H O system for use in 3DBP and test its ability to prevent necrosis in2 2adipose-derived stem cells using various hydrogel formulations. I hypothesize that usingoxygen-releasing polymers will increase ASC viability in engineered tissue systems. To dothis, I must address tissue engineering concerns such as refining 3D printing parameters,determining whether microsphere addition alters the mechanical properties of the gel, andselecting the gel type by printability and cell viability.2 RESEARCH PLAN2.1 Gel manufacture: For 3DBP applications, inks must solidify quickly, have appropriatemechanical properties, be non-immunogenic, and promote proliferation. Before manufacturingand encapsulating the microspheres, I will test several gel formulations including poly(ethyleneglycol) diacrylate to determine an appropriate method for 3DBP. Printability will be measured bythe degree to which the print matched the design specifications by calculating the percent errorof the printed scaffold compared to the 1 cm2 design. I will select the weight percent of eachhydrogel by testing printability.2.2 Manufacture of microspheres and gel encapsulation: To create the H O -modified2 2polymer, H O will be mixed with PVP in multiple molar ratios. The core-shell microspheres2 2will be electrosprayed using coaxial electrohydrodynamic atomization using a protocol describedby Nie et al.3 Both the flow rate and voltages will need to be optimized to create particles ofuniform size and morphology. I will use the previously determined weight percentage ofhydrogel to encapsulate the ASCs, catalase, and microspheres. The optimum concentration ofcatalase will be determined by studying oxygen release kinetics in a hypoxic, acellularenvironment and measuring which concentration of enzyme sustains oxygen release for thelongest time and at the highest levels. This will be determined over a 21-day period by usingRu(Ph Phen )Cl , a luminescent molecule sensitive to O concentration, while using rhodamine2 3 2 2b, a fluorescent molecule insensitive to O to correct for background absorbance.22.3 Testing printed materials: Ensuring that scaffolds are safe for cells in vitro prior to furthertesting is essential. Cell viability in the scaffolds printed with H O /PVP will be tested in vitro in2 2a hypoxic environment using Live/Dead, MTS, DNA content, and IHC assays; they will then becompared to control scaffolds without microspheres and containing microspheres with noincorporated H O . Should cell mortality persist, I will attempt to adjust the gel porosity, printing2 2methods, and O release system to increase viability. If viability improves with the microspheres2in vitro, I will test their efficacy during a subcutaneous study in mice.2.4 Timeline and Proposed Laboratory: To conduct this study, I would like to work in Dr.Warren Grayson’s lab at Johns Hopkins. Due to the close alignment of our research interests,when I met him at the BMES conference this year, he expressed considerable enthusiasm inworking with me and funding my project should I be awarded the NSF GRFP. I anticipate thisproject to take five years: two for gel and microsphere manufacture and testing and three for invitro and in vivo material studies.3 INTELLECTUAL MERIT AND BROADER IMPACTSCurrently, only Li et al. have used microspheres to deliver O to implant sites to prevent2cell morbidity. Instead, I will develop and test a rapid, accurate, and programmable method tofabricate these tissues using 3DBP. There have been no published papers that utilizemicrospheres, oxygen release, hydrogels, and 3DBP in conjunction to print biomaterials;integration of these techniques could greatly increase versatility of 3DBP in tissueengineering applications. As cell death is one of the primary concerns of tissue engineering ingeneral and 3DBP specifically, finding a solution to this problem could advance the field fromconstructing thin tissue sections, to larger tissues, and eventually organs.Developing a standard method for incorporation of oxygen-releasing microspheres into ahydrogel-based printed scaffold is a novel approach that has potential applications in areas suchas cardiac, bone, and cartilage tissue engineering. Osteoarthritis treatment is a particularchallenge because of the hypoxic environment, but the H O -polymer complex can be a source2 2of oxygen for implanted stem cells while they heal the native tissue. Should this method proveeffective, it could be used to encapsulate other materials such as growth factors or nutrients. Toeventually reach clinical application, I will collaborate with surgeons at Johns Hopkins todevelop materials that have clinical utility. Finally, I will present the results of my work atnational and international conferences.[1]Camci-Unal, G., et al. (2013) Polym Int. [2]Tsuji, W., et al. (2014) World J Stem Cells. [3]Nie, H., et al. (2010) JBiomed Mater Res A. [4]Li, Z., et al. (2012) Biomaterials."
180.0,"Nonlinear System Identification, Reduced Order Modeling, and Model Updating of theEffects of Mechanical Joints on Structural DynamicsKeywords: mechanical joints, nonlinear system identification, finite element model updatingSummary: Mechanical joints are present in nearly every structure, device, or vehicle inoperation today. As these become ever more complicated the need for the classification andunderstanding of the nonlinear effects on structural dynamics grows ever more critical. I proposeto apply recently developed nonlinear system identification methods, reduced order modelingand model updating techniques to characterize and model these nonlinear effects. The outcomeof this research will be the development of models for use in standard finite element (FE)methods that capture the nonlinear effects of mechanical joints.Literature Review: Several techniques exist for the identification of joint parameters, but thesemethods require extensive instrumentation and measurements that may not be practical and relyon frequency response functions that are assumed to be linear [1]. Yet the current FE modelupdating techniques necessitate accurate modal parameters and often produce results that differgreatly from experimental results [1]. A recently developed nonlinear analysis methodology withbroad applicability can be applied to alleviate these issues by characterizing the nonlinearitiesand developing reduced order models for use in standard FE codes.The proposed method relies on the assumption that the application of Empirical ModeDecomposition [2], a time-domain based signal decomposition method, results in nearlyorthogonal components, called Intrinsic Modal Functions (IMF), characterized by ‘fast’oscillations controlled by ‘slow’ changing amplitudes [3-5]. The IMFs result in local nonlinearinteraction models [6] that portray the local dynamics through sets of intrinsic modal oscillators(IMO). The IMOs are able to reproduce the measured times series while completely capturingthe effects of the nonlinearities.The global dynamics are determined by superimposing the wavelet transform (WT) of theoriginal time series in the energy-frequency domain with the frequency-energy plot (FEP) [7] ofthe representative Hamiltonian system. By assessing the global dynamics an understanding of theenergy dependence of the nonlinear normal modes [7] of the system can be developed. Thismethod was recently applied to a beam with a bolted lap joint to identify the dampingnonlinearities and the effects on the structural dynamics [8]. This research aims to continue thatstudy and extend the results into FE model updating.Hypothesis: Through the application of recently developed nonlinear system identification,reduced order modeling, and model updating techniques the nonlinear effects of mechanicaljoints on structural dynamics can be classified and incorporated into standard FE models.Research Method: In order to study the effects of mechanical joints, steel beams will beconstructed that incorporate bolted, riveted, and welded connections. “Monolithic” steel beamswithout any connections, but with holes, bolts, rivets, etc. will be used as experimental controlbeams for the analysis. The beams will be constrained in various positions to model the mostcommon structures: cantilever, fixed-fixed, fixed-pinned, and similar configurations.Accelerometers will be attached using adhesives at evenly spaced points across the beams. Twocases will be studied: 1) free vibration characteristics induced by impact forces and 2) forcedvibration characteristics induced by an electrodynamic shaker.Keegan James Moore Page 1 of 2Keegan James Moore Graduate Research ProposalLinear modal analysis in addition to the proposed nonlinear analysis will be applied toboth the “monolithic” systems and the systems comprised of mechanical joints. This will allowme to verify that the nonlinear analysis is able to reproduce both the linear and nonlinear effectsas well as e the deficiencies of the linear modal analysis. EMD will be applied to the measuredtime series to decompose them into nearly orthogonal IMFs. The extracted IMFs will be used todevelop IMOs that capture the local dynamics. The global dynamics will be characterized bysuperimposing the Hamiltonian FEP with the WT of the measured time series in the energy-frequency domain. A FE model consisting of two linear beams connected by a nonlinear elementwill be used to compute the Hamiltonian FEP and will serve as the basis for the model updating.By characterizing both the local and global dynamics, I will be able to develop a reducedorder model of the nonlinearity for each particular configuration. These reduced order modelswill be used to reproduce the dynamics of the measured systems and predict the dynamics ofunmeasured systems. Finally, the models will be incorporated into standard FE methods for usein a broad range of applications.Anticipated Results: 1) The application of the proposed nonlinear analysis methodology willfully capture the linear and nonlinear effects of mechanical joints on the structural dynamics.2) Reduced order modeling techniques will be developed that can be incorporated into standardFE methods that account for the nonlinear modal interactions produced by mechanical joints.Broader Impacts: This research aims to apply recently developed techniques to characterize thenonlinear effects of mechanical joints and to incorporate these effects into standard FE models.These models will made available for use in a broad range of applications in fields such asaerospace, automotive, heavy industrial equipment, turbo machinery and structural engineering.As this research progresses, I will present my findings at technical conferences such as theInternational Modal Analysis Conference and in technical journals such as the Journal of Soundand Vibration and Mechanical Systems and Signal Processing. Furthermore, this research willlay the foundations for developing further methods aimed at understanding nonlinear effects andincorporating them into standard FE analysis methods.Literature Cited1. R. Ibrahim, C. Pettit, Uncertainties and dynamic problems of bolted joints and other fasteners, Journal of Soundand Vibration 279 (2005) 857-936.2. N.E. Huang, Z. Shen, S.R. Long, M.C. Wu, H.H. Shih, Q. Zheng, N.C. Yen, C.C. Tung, H.H. Liu, Theempirical mode decomposition and the Hilbert spectrum for nonlinear and non-stationary time series analysis,Proceedings of the Royal Society A 454 (1998) 903-995.3. Y.S. Lee, A.F. Vakakis, D.M. McFarland, L.A. Bergman, A global-local approach to nonlinear systemidentification: a review, Structural Control and Health Monitoring 17 (2010) 742-760.4. A. Vakakis, L.A. Bergman, D.M. McFarland, Y.S. Lee, M. Kurt, Current efforts towards a non-linear systemidentification methodology of board applicability, Journal of Mechanical Engineering Science 225 (2011)2497-2515.5. Y.S. Lee, S. Tsakirtzis, A.F. Vakakis, L.A. Bergman, D.M. McFarland, Physics-based foundation for empiricalmode decomposition, AIAA Journal 47 (2009) 2938-2963.6. Y.S. Lee, S. Tsakirtzis, A.F. Vakakis, L.A. Bergman, D.M. McFarland, A time-domain nonlinear systemidentification method based on multiscale dynamic partitions, Meccanica 46 (2010) 625-649.7. A.F. Vakakis, O. Gendelman, L.A. Bergman, D.M. McFarland, G. Kerschen, Y.S. Lee, Passive NonlinearTargeted Energy Transfer in Mechanical and Structural Systems, Springer Verlag, Berlin and New York, 2008.8. M. Eriten, M. Kurt, G. Luo, D.M. McFarland, L.A. Bergman, A.F. Vakakis, Nonlinear system identification offrictional effects in a beam with a bolted joint connection, Mechanical Systems and Signal Processing 39 (2013)245-264.Keegan James Moore Page 2 of 2"
182.0,"Keywords climate change; exoskeleton; crustacean; calcification; gene expressionIntroduction Predicted ocean acidification levels (OA) have been shown to changecalcium carbonate structures of taxa ranging from corals to oysters, many of which experiencedecreases in calcification.1,2 Surprisingly, crustaceans appear to increase calcification, likelybecause of their osmoregulatory capacity.3 Increased temperature can also hinder internal pHregulation,4 so multivariate experiments are integral to understanding real-world responses ofcrustaceans to future ocean conditions.The California spiny lobster, Panulirus interruptus, is the fifth most important fishery inMexico and is fished recreationally by 30,000 people yearly in California alone.5,6 As urchinpredators, they play an important role in kelp forest ecology by reducing urchin disease andmacroalgae overgrazing.7 P. interruptus rely on their calcified exoskeletons as armor to preventpredation and as a tool for sound production to warn away predators.8 Predicted changes in oceanconditions could alter the integrity of the lobsters’ exoskeleton, ultimately affecting its predationand, given the species’ key role in the ecosystem, producing far-reaching trophic effects.Proposed Research To determine the potential impact of OA and increased temperature(hereafter referred to as multiple stressors) on P. interruptus exoskeletons, I will integrate toolsfrom biomechanics, genetics, and ecology. I aim to understand how multiple stressorspotentially affect (1) exoskeleton morphology, (2) gene expression, and (3) defensive soundproduction.Experimental Design Juvenile P. interruptus are readily collected along the SouthernCalifornia coast. Sixty-four animals will be maintained at Scripps Institution of Oceanography(SIO) in an existing flow-through, experimental aquarium system for six months. In four headertanks that feed to individual animals, I will maintain four combinations of pH and temperature:ambient conditions, and pH and temperatures that are adjusted to reflect changes predicted by theyear 2100 (pH reduced by 0.3; temperature increased by 3°C).1 All equipment is available in myadvisor Dr. Jennifer Taylor’s lab or open for use on campus.Aim I: Exoskeleton morphology I will test the hypothesis that lobsters will respond tomultiple stressors with increased calcification. I will examine exoskeleton ultrastructure usingscanning electron microscopy (SEM) and then quantify elemental composition using bothinductively coupled plasma mass spectroscopy and energy dispersive x-ray analysis. Results willestablish potential changes in mineralization and thickness of the lobster exoskeleton.Aim II: Regulation of calcification Spiny lobsters will likely respond to multiplestressors by regulating genes like those that concentrate and bind Ca2+ near the calcification site.9With assistance from Dr. Ron Burton’s lab (SIO), tissue from all treatments will be combinedand RNA-seq will be used to assemble a reference transcriptome. After its annotation, I willcompare transcriptomes of three animals per treatment against the reference to look for up- ordownregulation of epidermal genes. Results will establish the important link betweenenvironmental conditions and morphology in P. interruptus.Aim III: Anti-predation strategies Increases in calcification due to multiple stressorstend to confer hardness but also brittleness.10 Attacks may require greater bite forces, yetsuccessful bites may be more catastrophic. I will measure the hardness, stiffness, and brittlenessof the exoskeleton using materials testing machines. Results from this study will reveal howmultiple stressors affect the integrity of the calcified exoskeleton. These data will be compared topublished analyses of the bite mechanics of common predators like horn sharks.11In addition to armoring, the exoskeleton is critical for other anti-predation strategies.Spiny lobsters rub their antennae across a file near the eye to produce a sound that startles awaypotential predators.12 Individuals will be stimulated with a predator model while behavior andsounds are recorded using video and acoustic techniques. The file will then be excised andexamined using SEM for any ultrastructural changes that may influence ability to produce sound.Alternative hypothesis It is possible that the natural range of temperature and pHexperienced by P. interruptus makes them more adaptable to forecasted changes inenvironmental conditions. Thus, if my hypothesis in Aim I is not supported and there are nomorphological responses to multiple stressors, I will expand this research to include multiplespiny lobster species that inhabit different environments. Conducting this experiment acrossmultiple species within a phylogenetic framework will provide robust information about how thisimportant group of animals will respond to climate change.Intellectual merit Studying potential morphological changes and the underlyingmechanisms will help us understand how these animals may adjust to predicted ocean conditionsand determine if these responses are robust or if they leave them vulnerable to other threats likepredation. Examining morphological changes that may impact anti-predation mechanismselucidates how OA may not only affect individual species, but potentially have much largercommunity impacts if predation rates change. Spiny lobsters must contend with fishery pressuretoo, and it is important that managers anticipate any changes in population structure due to achanging environment. This study focuses on juvenile lobster that are not sexually mature untilage 4-6, so results will help us understand how potential changes in predation will impactrecruitment of mature and legal-size spiny lobster.13Broader impacts Expanding opportunities: I will involve undergraduate lab volunteersand recruit students in the Scripps Undergraduate Research Fellowship (SURF) program, whichprovides summer research experience to undergraduates that do not otherwise have access toocean science opportunities.Promoting education: Given their recognition in Southern California, spiny lobsterscreate an avenue to communicate climate change impacts with the general public. As such, I willwork with SIO’s Birch Aquarium to expand their OA and spiny lobster education programs anddevelop the results of this research into a SEA day at Birch Aquarium, a half-day event wherechildren learn science through hands-on activities. I will plan a similar event for Expanding YourHorizons San Diego, an annual conference designed to interest young girls in STEM fields.Fishery impacts: I will complete a report for the CA Dept. of Fish and Wildlife’s SpinyLobster Advisory Committee that clearly details how my results may show changes in juvenilesurvival, especially via potentially increased predation. I will plan a forum meeting through myinterdisciplinary program, which includes graduate students from UC San Diego and El COLEFin Tijuana, Mexico, and invite fishery managers to discuss this regional issue.References [1] Solomon, S. 2007. Cambridge University Press. [2] Ries, J. et al. 2009. Geology 37:1131-34. [3] Whiteley, N.M. 2011. Marine Ecology Progress Series 430: 257-71. [4] Dove, A.D.M. 2005. Journalof Shellfish Research, 24: 761-65. [5] Castañeda-Fernández-de-Lara, V. et al. 2005. New Zealand Journal of Marineand Freshwater Research 39: 425-35. [6] Neilson, D. 2011. California Department of Fish and Wildlife. [7]Lafferty, K. 2004. Ecological Applications 14: 1566-73. [8] Patek, S.N. et al. 2007. The Journal of ExperimentalBiology 210: 3538-46. [9] Luquet, Gilles. 2012. ZooKeys 176: 103-21. [10] Wainwright, S.A. 1982. PrincetonUniversity Press. [11] Huber, D. et al. 2005. Journal of Experimental Biology 208, 3553-71. [12] Staaterman, E. R.et al. 2010. Behaviour 147, 235-58. [13] Engle, J. M. 1979. PhD Thesis, University of Southern California, 298pp."
183.0,"Vehicle-Related HyperthermiaIntroduction:In the United States alone, nearly 40 young children die every year due to pediatricvehicle-related hyperthermia1,2,3,4,5,8. Young children are more at risk for vehicle hyperthermiabecause they cannot regulate their core temperature and sweat less than the average adult1. Thishealth issue was relatively prevalent in the news media during the summer of 2014, with manytragic cases occurring across the United States and abroad. Several researchers have examinedpediatric vehicle-related hyperthermia, but a gap in the literature exists with respect tocommunicating this risk to parents2,3,4. Guard & Gallagher (2005) note that addressing vehicle-related hyperthermia is a multifaceted problem that revolves around education and legislation.My primary focus is education and the need for campaigns that deliver more effective messagesto the targeted populations, for example, caregivers and parents2,4. While many public serviceannouncements (PSAs) and state campaigns have been undertaken in recent years, rigorousstudies have yet to be completed evaluating these campaigns on their ability to both raiseawareness and increase risk perception. To effectively target messages to the most relevantparent audience, a focus needs to be placed on parents of children five years of age and younger.A variety of health communication theoretical frameworks can aid in understanding andmodifying parents’ behavior when it comes to perceiving vehicle hyperthermia as a potentialrisk5. A common heath communication framework to predict health-risk behaviors, is the HealthBelief Model. The Health Belief Model is known for its use in the adoption and maintenance ofbehaviors involving both health prevention and promotion6. In order to encourage pediatricinjury prevention among parents with young children, it is essential that education andcommunication increase parents’ awareness of the risks, dangers, and change their perceptionsregarding the likelihood and severity of vehicle-related hyperthermia.Research Questions:1. What current knowledge do parents, who have children 5 years and younger, possess inregards to the danger vehicle hyperthermia poses to children and safety measures forinjury prevention?2. What is the most effective messaging strategy (e.g. scientific vs. emotional) tocommunicate the risk, alter the risk perception, and change the behaviors of parents (e.g.following recommendations to prevent pediatric vehicle-related hyperthermia)?Methods:To identify potentially effective messages and communication strategies, when it comesto parents of children five years old and younger, a mental model approach to riskcommunication will be implemented. The mental model approach consists of interviews withexperts and parents, a baseline questionnaire, message construction, and a final messageexperiment7. (1) Initially, I will interview parents from the Athens-Clarke county community todetermine their current knowledge, beliefs, and deficiencies in their understanding of vehiclehyperthermia. (2) After conducting several interviews with parents and experts, I will create aquestionnaire using the information received from those interviews to sample a wider audienceof parents across the southern United States. The questionnaire will be used as the control groupduring the message experiment and will generally consist of: parents’ risk perceptions, measuresof prevention, motivation and intention of adopting specific preventative measures, anddemographics of the sample (Question 1). (3) Two experimental groups will be created in order totest the effects and effectiveness of two different approaches to prevention messages on theknowledge, beliefs, and intentions of parents in relation to vehicle-related hyperthermia. Basedon preliminary parent and expert interviews, the nature of the messaging could include ascientific approach or an emotional approach, each of which will demonstrate a separate healthcommunication theoretical framework. Prior to the message experiment, a base-knowledgequestionnaire will be given to the participants in the experimental groups in order to understandtheir initial thoughts on the subject matter. Other questions regarding child vaccination will beprovided to mask the intent of the study. (4) During the message experiment, individuals will beassigned to one of the two experimental groups, in which the designated message will appear inbrochure format and be mixed in with other messages on child vaccination. (5) After reading thematerials, the experimental groups will be given a similar questionnaire in order to assess theirunderstanding of the risks and preventive measures of pediatric vehicle-related hyperthermia.The questionnaire results between the experimental and control groups can then be compared inorder to determine which message was the most successful in altering the perception of risk andintention of adopting preventive steps on the subject of vehicle-related hyperthermia (Question 2).Some limitations and weaknesses exist throughout this experimentation process.Although I plan to conduct a survey with a random sample of parents of children five years oldand younger in selected southern states, a completely generalizable sample will not be met. Asample of the southern states was chosen due to the high volume of pediatric vehicle-relateddeaths that have occurred in this region8. A better understanding of the current knowledgeinvolving pediatric hyperthermia would be better achieved using a nationwide sample of parents.Broader Impacts/Intellectual Merit:With my interdisciplinary background, involving the fields of risk communication,psychology, and climatology, I can successfully implement this project and impact society bypotentially increasing our understanding of how parents’ perceive vehicle hyperthermia. Usingthe expertise of my well-rounded committee members at the University of Georgia, wedeveloped a multi-method approach that has the potential to create a new subfield examining riskcommunication efforts in the atmospheric sciences. Developing a sound communication strategyfor vehicle hyperthermia is a positive step toward preventing future pediatric injury2,4. It is myhope that this project can develop and implement an evidence-based method for communicatingthe risk of vehicle hyperthermia to parents. Using the results of the study, I aspire to use thisempirically-based method of communication to further develop messaging strategies for otherheat-related and natural hazards.1 Duzinski, S. V., Barczyk, A. N., Wheeler, T. C., Iyer, S. S., & Lawson, K. A. (2013). Threat of paediatrichyperthermia in an enclosed vehicle: a year-round study. Injury prevention, injuryprev-20132 Grundstein, A., Null, J., & Meentemeyer, V. (2011). Weather, geography, and vehicle-related hyperthermia inchildren. Geographical review, 101(3), 353-370.3 Grundstein, A., Dowd, J., & Meentemeyer, V. (2010). Quantifying the heat-related hazard for children in motorvehicles. Bulletin of the American Meteorological Society, 91(9), 1183-1191.4 Guard, A., & Gallagher, S. S. (2005). Heat related deaths to young children in parked cars: an analysis of 171fatalities in the United States, 1995–2002. Injury Prevention, 11(1), 33-37.5 Toolo, G., FitzGerald, G., Aitken, P., Verrall, K., & Tong, S. (2013). Are heat warning systems effective?.Environmental Health, 12(27)6 Richard, L., Kosatsky, T., & Renouf, A. (2011). Correlates of hot day air-conditioning use among middle-aged andolder adults with chronic heart and lung diseases: the role of health beliefs and cues to action. Health educationresearch, 26(1).7 Morgan, M. G. (Ed.). (2002). Risk communication: A mental models approach. Cambridge University Press.8 Null, J. (Updated: 2014, October 16). Heatstroke Deaths of Children in Vehicles. Retrieved September 8, 2014,from http://www.ggweather.com/heat/"
184.0,"control gene expression levels. In eukaryotes, a key contributor to transcriptional regulation isthe chromatin architecture; that is, the arrangement of nucleosomes, transcription factors (TFs),and other proteins that bind along the genome at any point in time. One way to predict bindingsites is by scanning the sequence for motifs commonly associated with TF binding; this methodis fairly sensitive but also prone to a large number of false positives. Thus, to ascertain the invivo chromatin architecture, scientists have developed experimental methods, such as ChIP-seqand DNase-seq, to pinpoint the genomic locations of protein-DNA interactions.ChIP-seq is considered the “gold standard” for locating transcription factor binding sites(TFBSs). This assay identifies the locations at which a particular TF binds to DNA in vivo.However, ChIP-seq requires a separate experiment and antibody for every TF, making theprocedure time-consuming and costly. An alternative method, DNase-seq, gauges theaccessibility of DNA at specific regions in the genome. In this protocol, the nuclease DNase Imakes cuts throughout the genome, and the locations of the cuts are then mapped to a referencegenome for analysis. Since regions bound by proteins are less accessible to the DNase enzymethan unbound regions, composite plots of DNase digestion patterns at TFBSs reveal reducedlevels of digestion at many TFBSs, creating “footprints” in the data (1). Thus, DNase-seq allowsdetection of binding sites for multiple TFs using just one experiment.Recent studies showed that unique and dramatic fluctuations exist within the DNasefootprints of specific TFs, often at the resolution of a single base pair, distinguishing any oneTF’s footprints from those of other TFs (1). Some recent studies have suggested that thesepatterns mirror the small-scale biochemical interactions between the bound protein and the DNAmolecule (1). If true, this might allow identification of a specific TF’s binding sites based on theDNase digestion pattern alone. However, follow-up studies challenged this claim, demonstratingthat most high-resolution fluctuations in DNase digestion are an artifact of DNase’s inherentsequence binding preferences (2). Most TFs only bind certain DNA sequence motifs, and somespecific positions within these binding site motifs are cut more often than others due to DNase’sown sequence preferences. In fact, some have suggested that most TF footprints are not evenfootprints at all, but rather false positives where DNase cut counts are depleted due to aninherently DNase-resistant sequence context (2).I have analyzed DNase’s sequence biases using experimental data from DNase digestionof naked (protein-free) DNA. I determined the relative “cuttability” of every possible 6-mernucleotide sequence and used this information to produce corrected TF footprint plots in thebudding yeast S. cerevisiae. My results confirmed that some TFs had almost no visible footprintafter bias correction, but almost half of the 102 TFs I tested still showed visible footprints. Forthose TFs that still had footprints, correcting the sequence bias produced smoother footprintswith a lower variance in cuts at individual positions, but for some TFs, such as MCM1, a clearfactor-specific footprint shape was still present even after bias correction. Furthermore, differenttranscription factors have different footprint widths. Thus, although the factor-specific footprintpatterns are not as striking as was originally suggested, it is still quite likely that a statisticalmodel could incorporate this information to infer which specific TF binds at a given location.I plan to investigate how the chromatin landscape influences transcriptional regulation ineukaryotes, using yeast as a model organism in order to understand basic regulatory principlesthat might later be extended to human data. My project will explore how differences in thislandscape across time and across cell types are correlated with differences in gene regulation.There are two stages to the project. I will first improve upon existing methods for predicting thelocations of transcription factor binding sites and identifying the specific transcription factorsthat bind at each one. I will then apply my model to existing datasets to investigate to whatextent changes in the chromatin landscape correlate with changes in gene expression levels.I have spent over 2 years analyzing data from DNase-seq experiments, with the broadgoal of determining transcription factor binding sites. To date, no model exists that explicitlymodels sequence bias in DNase experiments to fully harness the high resolution of the data. Mygoal is to develop a novel statistical method that uses DNase data to compute the likelihood thateach position is bound by a particular protein. Specifically, I will use a hidden Markov model(HMM) in which the DNase cut counts at each position in the genome are the observed data, andeach of the model’s “hidden” states represents a specific bound protein, which may be a TF, anucleosome, or no protein at all. The HMM will include separate parameters for the individualpositions within each TF, in order to take full advantage of the high resolution of DNase data. Toavoid confounding the “actual” footprints with the sequence biases of DNase, I will include thesequence at each position as an additional predictor of DNase cut counts, using expectationmaximization (EM) to simultaneously infer the parameters that govern the bias and theparameters of the underlying footprint patterns. To validate my results, I will compare mypredicted binding patterns with published results of ChIP-seq experiments and nucleosomepositioning experiments previously performed on the yeast genome.Once I have developed a reasonable model for inferring the chromatin landscape, I willextend my results to directly investigate how this configuration of proteins affects geneexpression. Specifically, I will predict gene transcription rates using features derived from theadjacent protein landscape. Previous attempts to solve this problem have achieved moderatesuccess, but only within a certain subset of test cases (3). Most of these models have usedsequence data such as kmer counts as the sole predictors of gene expression (3). One downsideof this approach is that these features lack clear biological significance: it is still difficult tounderstand the indirect process by which a given kmer’s appearance in the promoter influencesthe level of gene expression. In my proposed machine learning model, the features, or predictivevariables, will be easily interpretable features that represent attributes of the gene’s surroundingprotein landscape. These features will include the number and location of TFs and nucleosomesin a gene’s promoter region, and I will obtain them using the model that I developed in the firstphase of my project. Thus, the two phases form a pipeline: first I will infer the chromatinarchitecture, and then I will use the model output as predictors for modeling transcription rates.Developing tools to elucidate chromatin architecture is crucial for understanding geneexpression. Differential gene expression drives many critical processes within an organism,allowing cells to adapt to changes in the environment and even become specialized through theprocess of cell differentiation. Despite our awareness of gene expression’s importance to anorganism, the processes regulating gene expression are far from fully understood. My proposedresearch project will bring us closer to understanding these fundamental cellular dynamics.The DNase-seq data for this project were generated by the Crawford Lab at Duke and theStam Lab at the University of Washington, and are freely available online.1) Hesselberth, J. R., et al. (2009). Global mapping of protein-DNA interactions in vivo by digital genomicfootprinting. Nature Methods, 6(4), 283-289.2) Sung, M. H., et al. (2014). DNase Footprint Signatures Are Dictated by Factor Dynamics and DNASequence. Molecular Cell.3) Meyer, P., et al. (2013). Inferring gene expression from ribosomal promoter sequences, a crowdsourcingapproach. Genome Research, 23(11), 1928-1937."
185.0,"EvaluatingCausalModelswithBiometricallyInformedDataThe relationship between poverty and health has been widely covered in the popular media;within the last year, the Atlantic, Time Magazine, and the New York Times have all featured theSES-health gradient at length, drawing strongly upon conventional explanations that material dis-advantage directly (e.g, access to medical care)1 or indirectly (e.g, chronic environmental stress)2causes health inequalities. Such explanations account for differences between those who haveresources and who do not. However, Gottfredson3 argued that situational explanations do not ac-count for the finely stratified health differences that exist across the entire range of SES, whereasindividual differences in intelligence and personality do. Indeed, Chapman and colleagues4 foundthatpersonalitycharacteristicsaccountfor20%oftheSES-healthgradient.Regardless of whether the person or situation is the “elusive fundamental cause”3 of the SES-healthgradient,thedebatecannotbesettledusingexperiments. Althoughrandomizedstudiessup-port inferring causality for most situational explanations, poverty cannot be randomly as-signed.Norcanwerandomlyassignmostpersoncharacteristics5. Instead,longitudinalquasi-experimentalstudiesareused,andpotentialconfoundsareincludedascovariates.The typical use of covariates does not provide control for systematically confounded geneticand environmental influences. This approach risks misattributions of causality. Indeed, povertyand individual differences covary with genes and environment, to such a degree that the covariateapproach is fundamentally biased (Rowe & Rodgers, 1997)6. Yet, the covariate approach has beentheprimarymethodusedtoevaluatethecauseoftheSES-healthgradient.Instead, quasi-experimental designs can be used; such designs support causal inference with-out random assignment7. Sibling-based quasi-experimental models are particularly effective at in-corporating genetic and environmental design elements8. However, such models are underused inpsychology (Rodgers et al, 2001)9, tend to focus on environmental confounds1,0 and do not nat-urally incorporate varying levels of relatedness8. My research proposal aims to address both themethodological problem of evaluating person-driven hypotheses and the substantive problem ofexplainingtheSES-healthgradient,usingandextendingthesiblingcomparisonapproach.KinshipDyadsTraditionalsiblingcomparisonmodelsoftenrelyonrareevents(i.e,twins)oradvancedmethod-ology (e.g, propensity score matching, multilevel modeling). As an alternative, my advisor andI have adapted Kenny’s reciprocal standard dyad model1.1 Our adaptation controls for gene andshared environmental influences within a simple regression framework, by taking the differencebetweenthetwosiblings(Rodgers,Garrisonetal,2014):12Y =β +β Y +β X +β Xdiff 0 1 mean 2 mean 3 diffY +Y X +X1i 2i 1i 2iwhere Y =Y −Y ;Y = ;X =X −X ;X =diff 1i 2i mean diff 1i 2i mean2 2In this model, the relative difference in outcomes (Y ) is predicted from the mean level ofdiffthe outcome (Y ), the mean level of the predictor (X ), and the between-sibling predictormean meandifference (X ). The mean levels support causal inference through at least partial control fordiffgenes and shared environment. Therefore, we simultaneously evaluate the individual difference(X diff) and the joint contribution of genes and shared environment (Y mean&X mean). Preliminaryapplicationshavegivenestimatesconsistentwiththeliterature(Garrisonetal,2015)1.3S.MasonGarrison,VanderbiltUniversityS.MasonGarrison,VanderbiltUniversityProposedStudiesApplication I will apply the kinship dyad model to two nationally representative householdsamples: the National Longitudinal Survey of Youth 1979 (NLSY79) and the NLSY97. The twohousehold sampling techniques have resulted in 15,589 families with 19,374 sibling pairs, whichourresearchteamhasidentifiedandvalidated. Bothsurveysincludemeasuresofconscientiousnessandintelligence,themostconsistentpredictorsofhealthandSES.TheNLSY97alsoincludesself-reportedBigFivepersonalityindicators.I will directly test the impacts of SES, personality, and intelligence on health, estimating howmuch of the SES-health gradient is caused by each (including covariance among the predictors).Then, I will evaluate specific causal mechanisms, such as access to health care, neighborhoodquality, and education level. Identifying specific mechanisms will facilitate translating findingsinto interventions. To ensure that these findings are externally valid, I will compare results acrosssamplestotestwhetherthegradienthaschangedacrosscohorts.Extension After validating the model using real-world data, I will extend the model in threeways: 1extendthemodeltoincludeadditionalhighlycorrelatedpredictors,2evaluatethemodel’srobustnessundermeasurementerror;3incorporatemultiplegenerations.First, although the Big Five are orthogonal by design, intelligence is correlated with multi-ple facets. For my 1st year project, I evaluated the separate impact of intelligence and conscien-tiousness by partialing out the common variance, resulting in uncorrelated and uncontaminatedmeasures of each1.3 Generalizing this approach will enable the model to test more complicated re-lationships between predictors. 2 To evaluate the model’s robustness, I will conduct a series ofMonte Carlo simulations, using NSF’s high-performance computing service, XSEDE under var-ious levels of measurement error for both the outcome and predictor variables. Moreover, I willevaluatethemodel’sexternalvalidityinrelationtopreviousresearchthathasprovidedparametersestimates for the relationship between individual differences, health, and SES. If the kinship dyadmodel correctly estimates the parameters, this further supports that the model has performed cor-rectlyunderreal-worldconditions. 3Themodelcanbefurtherextendedbyexaminingthechildrenofthesiblings,inthesamewaythatthechildrenoftwinsdesignworks–byexploitingthecommongenetictraitsanddissimilarenvironmentaleffectswithinstandardbiometricalmodels. Thiswouldallow the model to distinguish between genes and shared environmental causes. Moreover, theeffectivenessofthisextensioncanbetestedusingthemultigenerationalstructureoftheNLSY79.Merit&ImpactThisresearchhasthepotentialtohelpuntilttheSES-healthgradient. Directly,byapplyingthismodeltotestthecausesoftheSES-healthgradient,Iwilldeterminewhetherthepersonorsituationis driving the gradient. Identifying specific mechanisms will facilitate translating these findingsinto actionable interventions. Indirectly, my research will support accessible and parsimonioussolutiontomakecausalinferencesaboutperson-drivenhypotheses. OtherresearcherswillbeabletoemploythismodelintheirownworkontheSES-healthgradient.To enhance the model’s accessibility to other researchers, I will develop R, SAS, and SPSSsyntax, and make it available on my website with detailed tutorials. Moreover, as this approachcan be used on many datasets, I will identify and link to compatible files from various academicdatabases,suchasHarvard’sDataverseandUniversityofMichigan’sICPSR.Refs1Adleretal(1994)AmeriPsych. 2Baumetal(1999)NYAcadSci. 3Gottfredson(2004)JPSP.4Chapmanetal(2009)AmeriJofEpi. 5West(2009)CurDirPsychSci. 6Rowe&Rodgers(1997)DevRev. 7Shadishetal(2002)Wadsworth. 8 Rutter (2007) Persp Psych Sci. 9 Rodgers et al (2000) Ameri Psych. 10 Lahey et al (2010) Cur DirPsychSci. 11Kennyetal(2001)PsychBul. 12Rodgersetal(2014Jun)BGA.13Garrisonetal(2015Feb)SPSP."
187.0,"Computational Design and Structural Analysis of Novel Peptidine OligomersKey words: Peptidomimetics, rotamer library, foldamers, rational drug desing.Background and SignificancePeptides are essential endogenous molecules with intriguingFigure 1.structures that enable them to have innumerable biorelevant functions.Oligomer-basedAlthough peptides have been designed as potential pharmaceutical agents,biopolymers andtheir poor bioavailabity and poor in vivo stability makes them bad drugmimetics. Depictedcandidates. This fact led to the study of peptidomimetics. One result fromare structures ofthese efforts is peptoids, which contain a non-canonical peptidic backbone.peptide, peptoid andPeptoids appear to be resilient to degradation, but their structures possessthe proposedmore degrees of freedom and thus pay a higher entropic penalty for targetpeptidine oligomers.binding when compared to peptides (1). Monomer BackbonePeptidines are a novel class of oligomers, structurally derived from differences arepeptides and peptoids (see figure 1). These molecules consist of repeating shown in red.units of N- substituted amidines, a functional group found in drugs such asthe histamine receptor antagonist cimetidine and ranitidine (Zantac) (2). Theunique structure of peptidines enables the duplication of the amount of sidechain; this structural feature could confer a unique secondary structure.Peptidine synthesis is a straightforward process that consists of theiterative addition of imidoyl chloride and primary amines in sequence. Tothe present fifteen trimers, three tetramers and one pentamer have beensynthesized in the Spiegel lab at Yale University (an example of one of thissuccessful synthesis is shown in figure 2). However, studies regardingpeptidine’s structure are lacking. Gaining insight into peptidine structurewill allow further investigation to evaluate these novel oligomers as key[ ] = monomermolecules for the development of peptidine based, more efficient nsequencetherapeutics.I propose to study peptidines structure using an array of powerful techniques such ascomputational modeling software, X-ray Crystallography and Nuclear Magnetic Resonance(NMR). I hypothesize that a) peptidines will have characteristic secondary structures similar tothose found in peptides, although their secondary structures will be more rigid than peptoids andpeptides due to their higher functional density; furthermore b) peptidine structure will vary withchanges in pH, temperature and solvent, but c) by varying computationally the degree of sterichindrance on each side chain I will be able to control peptidine folding patterns in differentchemical environments and thus control their function and selectivity once synthesized.Figure 2. Former synthesized peptidine trimer. Peptidines show higher functional density compared to peptides;this characteristic will enable the formation of rigid secondary structures.J. Torres-Robles, 2Aim 1: To determine experimentally former synthesized peptidine’s structures using X-raycrystallography and multidimensional NMR spectroscopy.I will use X-ray crystallography to determine the electron density of former crystallinepeptidines at Yale X-ray crystallography facility. Electron density data will allow me tocharacterize chemical bonds, electronic properties, dihedral angles and finally the mean positionof atoms in each oligomer. To supplement crystallographic studies, I will use H1 NMR NOESYfor the characterization of peptide secondary structure (3), these studies will be held at Yale westcampus NMR facility. Unlike other 2D NMR techniques (ex. COSY and TOCSY) NOESYdetects spin polarization caused by through space dipolar interactions of atoms within 5 Å ofdistance. Thereby, using this data I can assign and analyze the sequence of interactions through asingle oligomer which will lead me to its secondary structure. Using the same technique I willdetermine how these interactions change with variations in pH, temperature and solvent.Aim 2: To determine computationally peptidine’s energetically favored conformationsRecent expansions to the ROSETTA algorithm software allow the study of non-canonicalbackbones (4). In order to do molecular simulations using this program it is necessary to create arotamer (energetically favored rotational conformers) library (5). To construct the library,dihedral and torsional angles from side chains and backbone must be determined. Usingcomputational software like Chimera, I can predict torsional angles for a set of side chains. Thisdata will be incorporated to ROSETTA along with dihedral angles to do molecular modeling(Density functional theory (DFT) and molecular mechanics (MM) calculations will be used incase ROSETTA software do not recognizes peptidine primary structure). I will then be able topredict peptidine structural preferences with various side chains. Intramolecular interactions canbe studied for different sets of side chains this will be useful to determine folding patterns. Also,intermolecular binding activity will be studied to determine the degree of peptidomimetics in thisnew type of oligomers by modeling with biological receptors. This data will shed light onpeptidine’s function and its relation to their structure.Intellectual meritStudying the structures of peptidines will be a worldwide innovation in the field ofpeptidomimetic. It will contribute to the fundamental understanding on the relation betweenstructure and function in oligomers that contain intriguing secondary structures that allow themto perform by efficient chemical mechanism in vivo. This infromation will allow the design ofmolecules with the desired secondary structures in order to improve and control their bindingselectivity and function. Fundamentally the prediction of peptidine’s biological interactions willbe useful to establish their potential use as better drug leads.Broader impactBecause peptidines are expected to have a more rigid structure, in comparison withpeptoids and peptides, they will pay a lower entropic penalty for target binding. These noveloligomers are thus potential candidates to develop more efficient drugs by rational drug design totreat a wide variety of diseases. Robust peptidine based libraries can aid in the development ofnovel therapeutics that will be expected to have better binding efficiency, higher selectivity andvastly improved bioavailability, compared to those of peptoids and peptides.References1. Josephson,K.; Ricardo, A.; Szostak, J.W. (2014) Drug Discov. Today. 2014, 4, 388-399.2. Silverman, R.B. and Hollday M.W. the organic chemistry of drug design and drug action. 3rd ed., 2014, pp.151-155.3. Stanger, H.E.; Gellman, S., et al. PNAS. 2011, 98, 12015-12020.4. Drew, K., et al. Plos one. 2013, 8, e67051, 1-175. Butterfoss, G.L.,et al. JACS. 2009, 131, 16798-16807."
194.0,"Recollection and neurophysiological correlates of fictional memoriesKeywords: autobiographical memory, fiction, episodic memory, cortical potentialThis project aims to understand the differences between experienced and fictionalmemories, from brain processes to behavioral effects. Episodic memories are characterized by asense of re-living and visual imagery, and form the basis for developing an autobiographical self.Rubin et al. assessed the qualities of autobiographical memories by measuring variablesincluding degree of reliving, visual and auditory imagery, emotions, setting, and belief1. Recentinvestigations have begun to probe the shared processes of remembering (“I went to the sciencemuseum 2 years ago”) versus imagining (“I imagine myself graduating from college in thefuture”). Absent from the literature is thorough behavioral data on fictional memories: thememory of an imagined experience without an explicit reference to self, derived from fiction (“Ican visualize Atticus Finch standing in a Southern courtroom”). Fictional memories are encodedand retrieved with subjective characteristics similar to veridical memories, and can be source ofintegrated knowledge about the world2; as such, they occupy an interesting and largelyunexplored niche in memory research.Conway et al. used electroencephalography (EEG) to record the dynamic process ofretrieving true memories from the past3. Using the excellent temporal resolution of EEG, heestablished a distinct neural signature for what retrieving and maintaining autobiographicalmemory broadly looks like in the brain. First, there is activation in the prefrontal cortex,followed by additional temporo-occipital activation once the memory is formed. In a differenttask, subjects constructed future, imagined scenarios that were plausible and involved the self.Conway found that the real and imagined conditions relied heavily on the same brain regions.However, one difference that left prefrontal activation was highest during active maintenance ofplausible imagined memories, presumably because this construction task is more effortful.Secondly, he found that temporal and occipital lobe activation is greater in the recall of realautobiographical memories, suggesting that imagined memories elicit stored sensory data, theydo so less than real autobiographical memories.In order to gain a theoretical and practical understanding of fictional memories, bothbehavioral and neurophysiological data are important; my proposed study will investigate theseperspectives. I expect that many fictional memories can be vividly re-lived, they may not beassociated with a particular time or place. I also expect fictional memories to evidence thedynamic localization of autobiographical memory. And if memories that are explicitlyunderstood to be not real are incorporated into autobiographical memory, then they can influenceidentity and behavior. Developing a clearer picture of the neurophysiology of fiction andmemory could illuminate how fiction-reading contributes to cognitive and affectivedevelopment, or how fictional sources could be used intentionally by educators. If fictionalmemories do not show activity aligned to real and imagined autobiographical memories, then wemust begin to explain how any episodic-like memory can exist without these networks.I propose a research project to be carried out in two phases. Since there is not existingresearch on how to cue a fictional memory and it is critical to have reliable and controlledprotocols for in the next, EEG-centered phase, I will first establish this protocol, as well as gatherbehavioral data through surveys. This first phase will also allow me to find and address anyunanticipated sources of error in this novel process, and yield data to modify the design of thenext phase. I will limit the study to fictional memories generated through the written word (e.g.novels and short stories). Subjects will be given a cue to recall a scene from a written work offiction that can be strongly recalled; I will seek to gather 30 observations per subject. To gatherBrenda Yang Graduate Research Statement NSF GRFP 2015pilot data, EEG will be used to record cortical scalp potentials (more detailed methods arebelow). I anticipate that these memories—like veridical episodic memories— will differ in manyways within and between participants, including time since the last experience, personal interest,and amount of rehearsal. These qualities will be assessed via a questionnaire modified fromRubin et al.1, which asks participants to rate their experience on a scale of 1 to 7 for questionsthat address recollection (like reliving), component processes (like visual imagery, spatial layoutand emotions), and reported properties (like importance, rehearsal, and age of memory). Thequestions will be delivered after each cue through a provided keyboard.In the second phase, I will use an EEG paradigm to examine the temporal dynamics offictional memory construction. In two conditions, I will record scalp potentials with EEG whilesubjects recall and maintain (1) true memories of the past and (2) plausible imagined scenarios ofthe self; these are the scenarios studied by Conway, and will be used as controls. In the third (3)experimental condition, I will elicit the retrieval and maintenance of fictional memories using theprotocol established in phase 1. I will seek to gather 5 observations for each condition perparticipant to balance the need for statistical rigor with maintaining a reasonable length for thestudy. Each trial will begin with the memory instruction “Real Memory,” “Imagined Memory”or “Fictional Memory” on screen for 3s. A fixation stimulus will be presented for 3s, followed bythe cue for one of the three scenarios. The cue will remain on screen until subjects indicate witha bimanual joystick pull that a memory has been successfully retrieved or generated. Participantswill communicate that they were unable to retrieve a memory via a keyboard instruction, whichwill lead to a new trial. After the memory is retrieved, subjects will fixate on the screen and beinstructed to hold in mind the memory for 7.5s. Then, the participant will then type a briefdescription of their memory using the keyboard provided.In designing the cues and trials, it will be critical to balance cues and trials acrossparticipants. Subjects with high shifts in voltage throughout the trials will not be analyzed.Statistical significance will be assessed using a 3-way ANOVA involving the electrode levelsand the 3 conditions of memory instruction. If fictional memories are experienced as episodicmemories, I would expect to find patterns of cortical potential for fictional memories that aresimilar to that of the imagined future events. That is, the activation of posterior brain regionsshould be reduced compared to remembrances of real events. Of interest is the degree to whichthe prefrontal cortex is activated in the absent of a scenario that does not explicitly involve theself. Behaviorally, I expect to find that re-living of fictional memories to be comparable toveridical ones and primarily visual in nature. Of interest are differences in how the event comesto the subject “a coherent story,” the perspective of the experience, and whether the memorycomes back “in words” for a fictional memory that was, after all, delivered through language.To support this work, I am seeking graduate programs which would allow me to combinebehavioral and brain measures. I have established contact with several institutions where thiswould be possible and where training and facilities for EEG is available. For example, ElizabethMarsh at Duke University studies fiction, false memories, and applications to educationalpractice. Conditional on my acceptance to the program, she has offered guidance forcollaboration between her lab and others in the psychology and cognitive neurosciencedepartments. I am confident that with these supports, my experience designing novelexperiments, and solid conceptual background, I can carry out this research within three years.1Rubin, D.C., Schrauf, R.W., Greenberg, D.L. (2003). Belief and recollection of autobiographical memories.Memory & Cognition, 887-901. 2Marsh, E.J., Meade, M.L., Roediger, H.L. (2009) Learning facts from fiction.Journal of Memory and Language, 519 –536. 3Conway, M. A., Pleydell-Peace, C. W., Whitecross, S. E., & Sharpe,H. (2002). Neurophysiological correlates of memory for experienced and imagined events. Neuropsychologia, 1-8."
195.0,"2fired power plants1. Due to the role of CO in global climate change, reducing emissions is2imperative, and its capture and sequestration at the source is highly attractive. While scrubbingtechnologies are currently employed as the industrial standard, they are inefficient andregeneration of the amine reagent used for CO capture is expensive.12Several classes of adsorbent materials have been proposed as alternatives for CO capture,2but metal-organic frameworks (MOFs) are one of the most promising. As porous, crystallinesolids, their robustness, chemical tunability, and void space for guest occlusion, i.e. a gas or solventmolecule within the pore, make MOFs highly attractive for such applications. Designing a porousmaterial such as a MOF to replace reagent-based methods is a challenge, as it must exhibit superiorselectivity for CO at elevated temperatures and low partial pressures, from a mostly nitrogen-rich2atmosphere. In addition to excellent CO adsorption under challenging conditions, the MOF must2possess a high tolerance to water, straightforward regeneration, and robustness over thousands ofcycles.2Selective gas or solvent adsorption in a static MOFs is attributed to size exclusion and/orfavorable host-guest interactions.2 MOFs that exhibit framework distortion upon guest addition orremoval offer an additional route for tuning selectivity. Termed “breathing MOFs”, they werepioneered by Ferey and Kitagawa in the early 2000s.3 Though their body of literature has grownsignificantly, the ability to rationally design new breathing MOFs has yet to be demonstrated,contrary to their static counterparts.4 Selectivity in breathing MOFs is attributed to a “gate-opening” pressure in which the pore expands, allowing the guest to enter. This unique propertycould offer a superior method for designing new, more efficient materials for CO capture.2Thoroughly understanding how chemical environment, pore aperture, and breathing ability affectselectivity for CO could yield a great leap toward designing an industrially viable material.2Objective: Utilizing isoreticular synthesis5, I will develop a series of porous, breathing MOFstailored for CO capture. Exceptional guest selectivity will be achieved through optimizing a2synergistic relationship between functionality, pore availability (i.e. aperture), and breathing motif.By tuning the pore environment in such a way, it will be possible to enhance the initial framework-CO attraction and reduce the available “gate-opening” pressure to that of CO .2 2Methodology: Using a set of semi-rigid, organic linkerswhere size, shape, and functional groups have been altered, Iwill synthesize 2-pillared, 2D sheet MOFs or 1D tube MOFs,which are also referred to as metal-organic nanotubes(MONTs). Continuing work started in the blank group6, thesebreathing MOFs will exhibit guest-dependent rotation of theligand (Figure 1). Characterization using X-ray diffractionmethods will be employed. For MOFs in which breathing is aresult of rotation of phenyl rings in the ligand, breathing canbe verified by 13C CP MAS NMR, as demonstrated in apublication currently under revision by the blank group.Tuning pore size and functionality within a frameworkFigure 1: Illustration depictinghas been well documented5. Triazole ligands of increasingligand rotation in breathing MOFs.size that adopt a syn-geometry will be incorporated into theframeworks, and isoreticular synthesis will be exploited by adorning the non-triazole moiety withamino, nitrile, hydroxyl, methyl, halide, and ester groups, similar to previous reports (Figure 2).5,7Experimental evidence show that these alterations can affect a framework’s selectivity for CO2over CH , N , and O ; moreover, nitrogen-containing functional groups tend to enhance the4 2 2framework-gas attraction via a Lewis acid-base interaction.8 My first aim is to identify thefunctional groups that enhance framework interaction with CO in breathing MOFs. From there, I2will determine the role of pore aperture by systematically increasing the ligand size. The finalvariable to evaluate if breathing mechanism influences selective CO adsorption. The effects of2these alterations can be understood by single and multi-component gas adsorption studies.Selectivity will be evaluated according to previously-published methods that evaluate the role ofkinetic favorability in mixed-gassystems.7Anticipated Results: My work willresult in the development of a porous,breathing MOF that will outperform themost highly-selective materials to datefor selective CO adsorption in mixed-2gas systems.7 Preparation of such a MOFcould form a platform for newer, moreefficient materials to be developed. My Figure 2: Representative ligands for MOF synthesis.findings will be presented at regional andnational conferences, and published in relevant peer-reviewed journal articles.Broader Impacts: Because of the correlation between increased atmospheric CO levels and2rising global temperatures, curbing anthropogenic CO emissions is a goal of utmost importance2for our society; capturing these emissions at the source is highly attractive. In addition, syntheticchemists are seeking routes to convert CO to valuable commercial commodities like plastics9 and2synthetic fuels.10 Efficient capture of CO will help advance these processes, as CO is an abundant2 2C -feedstock. Development of a highly selective and efficient porous, adsorbent material for CO1 2capture from coal-fired power plants would be invaluable for its environmental and economicbenefits.Intellectual Merit: My relevant experience working with gas storage materials at both blank andblank has prepared me well for graduate work at the University of blank, where I will work underDr. blank blank. I possess strong synthetic skills and a familiarity with an array of characterizationtechniques (see personal statement). I have presented posters and oral presentations at severalregional and national conferences, and was recently published11 as a co-author for my work atblank.As a Latino in science, I hope to mentor young scientists from underrepresentedbackgrounds in STEM fields through tutoring and educational outreach initiatives. My leadershiprole at a non-profit organization (see personal statement) has left me with the experience to engagethe general public in educational discourse, and I hope to foster an understanding of basic sciencein our society. Whether I pursue academia, industry, or government-employment, I look forwardto joining the generations of scientists who will solve the greatest issues of our age.References[1] Science 2007, 317 (5835), 184-186. [2] Coord. Chem. Rev. 2011, 255 (15–16), 1791-1823. [3] Chem. Soc. Rev.2009, 38 (5), 1380-1399. [4] Coord. Chem. Rev. 2014, 258–259 (0), 119-136. [5] Science 2002, 295 (5554), 469-472.[6] blank citation blank citation. [7] ProC. Natl. Acad. Sci. USA 2009, 106 (49), 20637-20640. [8] J. Am. Chem. Soc.2009, 131 (11), 3875-3877. [9]http://www.research.bayer.com/en/CO2.aspx, 2012. [10] Chem. Ing. Tech. 2013, 85(4), 489-499. [11] blank citation blank citation."
196.0,"2Keywords: carbon capture, amine degradation, aminosilica adsorbents, adsorbent regenerationHypotheses: Aminosilica adsorbents used for post-combustion carbon capture can be partiallyregenerated through treatment with acid, transesterification, and a Hoffman rearrangement.Introduction: The most readily available technology to reduce carbon emissions is carboncapture through amine scrubbing followed by geological sequestration. However, aminescrubbing has environmental risks: volatile amines escape into the atmosphere and carcinogenicnitrosamines form from NO .1xOther technologies exist to capture carbon, but most do not have the fundamental knowledgenecessary for pilot testing. Amines covalently tethered to silica supports for adsorption (ASA)use similar chemistry as amine scrubbing to selectively bind CO but avoid the environmental2side effects because of a lack of volatility and by binding nitrosamines. The method for attachingamines to silica is common among industry,2 so scaling up ASA production would be morefeasible than other novel adsorbents. Similar to amine solvents, flue gas components, NO andxO also reduce effectiveness of ASA. NO preferentially bind to the amine group3 while pure O2, x 2oxidizes ASA to form imines, amides, and carboxylic acids, thus degrading the adsorbent.4Since production of ASA has both environmental and economic costs, reusability is vital forany industrial application. A study by Hallenback and Kitchin explored using NaOH toregenerate adsorbent poisoned with SO ,5 but there have been no studies to evaluate the2regeneration capacity of amine adsorbents for carbon capture after exposure from NO or O . Ix 2propose investigating the degradation of ASA from NO and O and developing regenerationx 2methods to reduce the frequency of adsorbent replacement. More specifically I will1) Synthesize and characterize the ASA from primary, secondary, and tertiary amines2) Degrade the ASA using NO and O in a packed bed reactorx 23) Regenerate NO treated ASA using aqueous acetic acid and bromidex4) Regenerate O treated ASA using the Hoffman rearrangement or transesterification21) Synthesis and Characterization: ASA will be created through condensation of MCM-41mesoporous silica with a chloroalkoxysilane followed by reactionwith ammonia, ethylamine, and diethylamine to form primary,secondary, and tertiary ASA. Since the experimental proceduresinvolve toxic chemicals, a risk assessment will be conducted todetermine necessary safety precautions.Between sections 1, 2, 3, and 4, ASA will be tested for surfacearea (using Brunauer-Emmett-Teller method3), pore size (Barrett-Joyner-Halenda method3), elemental analysis (sent for externalPrimary ASA degradationtesting), bonding structure (using C NMR and Fourier Transform13 from NO and O to formInfrared Spectroscopy4,5), and CO 2 capacity and kinetics (in a nitrosamix ne (uns2 table) andpacked bed reactor with live analysis of exiting gas composition5). amide2) Degradation: The characterized ASA will be placed in packed bed reactors with a mixture ofgas containing N , CO , H O, and either NO or O . The NO experiments will be conducted at2 2 2 x 2 x50°C, the standard adsorbing temperature, while the O experiments will run at 150°C, the2desorption temperature. The ASA will be considered degraded when the exiting concentration ofpollutant approaches the inlet concentration. The degraded ASAs will then be characterized.I expect that ASA will initially react with NO and O in a similar manner with aminex 2solvents: NO will form nitrosamines and nitramines, and O will oxidize the α-carbon.x 2Furthermore, primary ASA should show a decrease in nitrogen content after exposure to NOxsince primary nitrosamines degrade into N . A mixture of alcohols, amides, imides, and acids2should result from the O exposure at elevate temperatures.4 These all decrease the capacity of2the amine solvent.3–53) Regeneration-NO : To remove nitrosamine and nitramine functional groups, thexdenitrosation procedure for aliphatic nitrosamines described by Dix et al.6 will be followed. Ifmore stringent conditions are necessary, testing an ASA embedded with 2-amino acetic acidwould indicate whether oxidative degradation improves amine denitrosation.6 Regeneration fromNO may not work well for primary amines since they degrade into N . Secondary and tertiaryx 2amines treated with NO should increase in capacity as the original amines reform.x4) Regeneration-O : For primary amines, a Hoffman rearrangement can produce an amine from2the degraded amide using mild reagents.7 Secondary and tertiary amines would require too strongreducing agents and cause significant damage to the silica. For these, transesterification withethanol amine will be employed to recover lost activity. Due to the variety of products formed,regeneration from O exposure may be more difficult than denitrosation.2Further Analysis: The effluent from the regeneration steps will be tested for silica to determinethe extent of support degradation. Assays requiring acidic treatments will use adsorbent with t-butyl groups near the organosilane bond to protect from hydrolysis. For the methods that showmarginal improvement, conditions for regeneration will be altered to improve effectiveness. Forthese optimized methods, repeated degradation and regeneration cycles will assess durability.Expected Results: These results will indicate the most suitable ASA given different captureconditions. For example, when NO are removed before carbon capture, primary amines may bexmost beneficial since the Hoffman rearrangement can easily reform amines from O oxidation.2Furthermore, the findings may also correlate well with other solid amine adsorbents, so a generaltrend in regeneration can be seen regardless of the type of amine adsorbent.Broader Impacts: Reducing CO emissions will help stabilize our planet’s temperature to2prevent negative effects of climate change like desertification and a rising sea level which woulddecrease food supply and increase land scarcity. ASA can isolate CO to reduce emissions and2slow climate change. The degradation studies in this project will further characterize ASA, andthe regeneration methods developed will help make using ASA more economical. Since aminebased adsorbents can capture CO with reduced emissions of toxic amines and carcinogens, this2work will also help reduce the negative environmental impact of carbon capture.I will disseminate my results through conferences and publications so other researcherscan improve upon and apply the findings towards further development and application. I willmentor undergraduate students and encourage them to develop their own projects so that theygain valuable research skills before graduate school. Since solving climate change requiresinternational cooperation, I plan to collaborate with foreign institutions specializing in carboncapture like the Norwegian Technical University to accelerate the application of CO capture.2(1) Jackson, P.; Attalla, M. I. Rapid Commun. mass Spectrom. 2010, 24, 3567–3577.(2) Materne, T.; de Buyl, F.; Witucki, G. L. Organosilane Techonology in Coating Applicaions; 2012.(3) Co, P.; Adsorption, C. S.; Rezaei, F.; Jones, C. W. Ind. Eng. Chem. Res. 2013, 52, 12192–12201.(4) Bollini, P.; Choi, S.; Drese, J. H.; Jones, C. W. Energy & Fuels 2011, 25, 2416–2425.(5) Hallenbeck, A. P.; Kitchin, J. R. Ind. Eng. Chem. Res. 2013, 52, 10788–10794.(6) Dix, L. R.; Oh, S. M. N. Y. F.; Williams, D. L. H. J. Chem. Soc. Perkin Trans. 2 1991, 1099–1104.(7) Patel, I.; Opietnik, M.; Bohmdorfer, S.; Becker, M.; Rosenau, T. Holzforschung 2010, 64, 549–554."
198.0,"Key words: Polymer-clay nanocomposite, brominated flame retardants, sustainabilityIntroduction: As a consumer, you hope that the products you use are safe, sustainable, and non-toxic - but that is not guaranteed. Many chemicals in everyday products have unknown orconcerning impacts on human health and the environment. At the same time, a growing numberof people use electronic products on a daily basis and are exposed to the chemicals contained inthem, like brominated flame retardants (BFRs). BFRs are used in electronics because they areextremely effective at reducing the inherent flammability of polymeric materials. However, thereis a desire in the flame retardant community to move away from brominated chemicals becauseof increasing concerns about the impact they may have on human health and the environment,especially during e-waste disposal[1]. BFRs are heavily used in high performance applicationslike epoxy based printed circuit boards. Over 90% of boards contain tetrabromobisphenol A(TBBPA) reacted with the epoxy matrix [2].A promising new sustainable flame retardant ismontmorillonite or “nanoclay” (flame retardantmechanism is shown in Fig. 1)[3] . Montmorillonite isattractive because just a few weight percent of it in apolymer composite improves the flame retardantcharacteristics, it is abundant in many different countries,Fig. 1. A layer of clay and char buildsand it is a low cost additive. But to date, nanoclay has notduring burning, protecting the polymerbeen demonstrated to be an effective flame retardant onunderneath from further degradation.its own, instead being included in a mix of flameretardants used to achieve the desired properties. These mixes include BFRs in lowerconcentrations than when used without nanoclay and so still pose sustainability problems.Hypothesis: Even dispersion of clay layers and an epoxy-tailored clay surface will improvethermal, mechanical, and fire retardant properties of the epoxy-clay nanocomposite. Thismaterial will therefore be suitable for use as a flame retardant, bromine-free plastic.Research Plan: There are four main challenges in literature regarding the use of nanoclay as asustainable flame retardant in epoxies, stated below with proposed solutions[4].1) Weak bonding between the clay and epoxy leads to poor composite propertiesIn order to achieve strong bonding between the two nanocomposite constituents, organicallymodified montmorillonite (organoclays) will be made. Organoclays have been used to increasethe dispersion in polymeric matrices, but the proposed surfactants will also be used to strengthenthe interaction between the two phases. Novel surfactants will be grafted onto montmorillonitethrough well-established methods[4]. Aminosilane and epoxysilane surfactants were chosenbecause they will bond strongly to the epoxy network and to silica in montmorillonite (Fig. 2).Grafting and bonding strength in the nanocomposite will be determined by Fourier transforminfrared spectroscopy (FTIR), thermal gravimetric analysis (TGA) differential scanningcalorimetry (DSC), and dynamic mechanical analysis (DMA).2) Even dispersion of individual clay layers in the epoxy matrix is hard to achieveMontmorillonite consists of ~1nm thick by 50-100μm diameter sheets stacked together withweak charges and Van der Waals forces bonding them together. Processing conditions such asgrafting reaction temperature/time, intercalation procedure, and the kinetics of the epoxy curinginside and outside the clay layers will be factors thataffect the dispersion of clay layers and will beoptimized for this system. Conditions will be assessedby their potential for implementation in large scalemanufacturing. Dispersion will be determined by x-ray diffraction (XRD) and transmission electronmicroscopy (TEM).3) Nanoclay has not been shown to meet the UL94standard when used as a flame retardant by itselfFlame retardancy of the final nanocomposites will be Fig. 2. Selected structures of proposed noveltested at the Forest Products Lab in Madison, WI, due surfactants. Silane groups will bonds toto the lack of equipment at Purdue University. All montmorillonite and the amine/epoxy groupswill bond into the epoxy network.nanocomposites are not expected to be promising, butonce a final epoxy-organoclay composition is settled on it will be sent to the UnderwritersLaboratory (UL) to receive a rating for the UL94 standard “the Standard for Safety ofFlammability of Plastic Materials for Parts in Devices and Appliances testing.” Flammabilitywill be determined by cone calorimetry and limiting oxygen index (LOI).4) There is no standard assessment of sustainability for flame retardantsIn order to determine whether our nanocomposite is more sustainable than what is currentlyused, a comparative Life Cycle Analysis (LCA) will be conducted focusing on energy & waterusage and pollutants produced from cradle to grave. Sustainability will be determined throughOpenLCA software used with the EPA’s TRACI impact assessments (Tool for the Reductionand Assessment of Chemical and other environmental Impacts).Expected Results: One or more of the surfactants tested will create an epoxy-organoclaynanocomposite with desired thermal, mechanical, and flame retardant properties when madeunder specific processing conditions. Higher mechanical and thermal properties are alsoexpected from a fully dispersed nanocomposite. A fundamental understanding of silane modifierstructure/properties relationships on epoxy-organoclay nanocomposites will be contributed toscientific knowledge. Four papers will be published on: organoclay and nanocompositemanufacturing and properties, nanocomposite fire retardancy, sustainability assessment ofnanocomposites, and reaction scheme of silanes bonding to montmorillonite. Conferences will beattended to present these findings including the American Chemical Society National Meetingand the International Symposium of Sustainable Systems and Technologies.Broader Impacts: This nanocomposite can be used in current epoxy applications, replacing theneed for BFRs. Due to improved properties of the nanocomposite less material will be needed toachieve the same strength, reducing the environmental impact of a potential epoxy product.These findings will also be shared through outreach programs such as Project Interchange andInnovation to Reality to inform and inspire the next generation of scientists and engineers.[1.] Sjödin, A., Carlsson, H., Thuresson, K., Sjölin, S., Bergman, A., and Ostman, C. “Flame Retardants in IndoorAir at an Electronics Recycling Plant and at Other Work Environments.” Environmental Science & Technology(2001) [2.] EPA. “Flame Retardants in Printed Circuit Boards” Design for the Environment (2008) [3.] Morgan,A. B. and Gilman, J. W. “An Overview of Flame Retardancy of Polymeric Materials : Application, Technology,and Future Directions” Fire Materials (2012) [4.] He, H., Tao, Q., Zhu, J., Yuan, P., Shen, W., and Yang, S.“Silylation of Clay Mineral Surfaces” Applied Clay Science (2013)Statement of originality: I certify that this proposal is my independent and original work."
199.0,"Introduction: High latitude permafrost soils contain vast reserves of organic carbon (C) that, withwarming, may become a significant source of greenhouse gases (GHGs) due to increased microbialactivity. Current climate model predictions for C storage and fluxes in these ecosystems dependheavily on the rate at which soil organic matter (SOM) is broken down.1 At present, there aresignificant uncertainties regarding how the varying chemical and physical differences among theseSOM pools and their interactions with the surrounding environment will affect the rates at whichthey are being degraded by the local biological community.It has been shown that organic C molecules sorbed to sediment mineral surfaces tend todecompose more slowly, and to a lesser extent than dissolved organic matter (OM).2 This may bedue to the physical occlusion of the OM by minerals, reducing its susceptibility to microbial attack,thereby changing its long-term accumulation and translocation in the soil profile.3 Recentradiocarbon (Δ14C) values taken from Alaskan permafrost soils indicate that the carbon dioxide(CO ) and methane (CH ) being released to the atmosphere are derived from older C buried deeper2 4in the soil profile.4 Mineral phases and complexation mechanisms responsible for the stabilizationof permafrost SOM are largely unknown and the role of these C-mineral interactions in the Arcticecosystem and global C budgets is not well understood.Research Objectives: The following research questions will be investigated to better quantify andpredict GHG emissions from thawing permafrost in response to climate change:R1) What are the major mineral species present in Arctic permafrost soils, and how do theyaffect SOM distribution in the soil profile?R2) What are the key chemical bonding mechanisms between soil organic C and mineralphases in these systems?R3) How does topographical variation impact C-mineral associations and, in turn, SOMstabilization and GHG emissions?Hypotheses:H1) The major mineral elements I expect to find in these systems are Fe, Ca, and Al. Fe oxideswill prove to be an important sorbent in the spatial distribution of SOM-mineral complexformation because of their strong selectivity for aromatic compounds and high molecularweight fractions,2 qualities commonly associated with permafrost soils.H2) OM preservation will largely be controlled by electrostatic interactions and sorption ofminerals into micropores along the soil profile.H3) Concentrations of Fe oxides and the relative proportion of OM bound to mineral surfaceswill increase at lower topographic regions. Greater portions of OM will be physicallyprotected from the microbial community leading to increased recalcitrance and decreasedfluxes of CO and CH to the atmosphere.2 4Preliminary Results: Addressing these questions will require close monitoring of permafrost soildynamics throughout seasonal thaw and at different depths along the soil profile. Working withthe NGEE-Arctic biogeochemistry team at Oak Ridge National Lab (ORNL), I have helped designand test a large, temperature-controlled soil column apparatus for intact soil cores. Using a two-stage cooling mechanism, this system successfully mimics or accelerates seasonal thaw patternsin the lab.5 Access ports for the collection of gas and liquid samples allow for continuous,nondestructive monitoring of biogeochemical properties and their changes over time and space,on the order of days to weeks and cm to m, respectively.Study Site: Field observations will take place at the Barrow Environmental Observatory (BEO),located at the northernmost point of the Arctic coastal plain, near the remote, native Iñupiaq villageof Barrow, Alaska. This high-latitude ecosystem is characterized by a dynamic landscapeMallory Ladd Graduate Research Statement 11/8/13dominated by distinct morphological subunits: ice-rich polygonal tundra and drained thaw lakebasins (DTLB). The site consists of continuous permafrost with the active layer reaching ~20-55cm deep. Frozen soil cores (~7.7 cm diameter by 1m depth) will be obtained from low- and high-centered polygons from DTLBs of varying age using a SIPRE auger6 and a hydraulic drill.Experimental Approach: Using cores obtained in the field, (R1) I will first physically andchemically fractionate samples from the organic, mineral, and permafrost horizons and thencharacterize the mineralogical components with energy-dispersive x-ray (EDX) spectroscopy.Intact soil grains will be examined with micro-Raman and Fourier-transform IR spectroscopies toobtain compositional information, including the relative proportions of polysaccharides, aminosugars, phenols, lignin, and lipids to estimate the mineral interactions with different OM functionalgroups. (R2) The stability of these interactions will be tested using batch equilibrium techniques,while the aggregate surface area and soil micropore volumes will be determined by scanningelectron microscopy (SEM). (R3) Using the soil column mesocosms, I will monitor changes intemperature, moisture, pH, redox potential, and concentrations of gases and solutes throughout acontrolled thaw, helping to identify where CO , CH , and dissolved organic C are being generated.2 4During my summer field campaigns, I will continuously measure land-surface fluxes of CO and2CH using chamber measurements and laser-based infrared gas analyses. The isotopic composition4and age of mineralized C and SOM C from each core will be determined at the Center forAccelerator Mass Spectrometry at Lawrence Livermore National Lab.Intellectual Merit: Collectively, this research will provide a deeper mechanistic understanding ofthe physical and chemical controls on SOM stabilization in permafrost soils, while advancing ourfundamental knowledge of the role of C-mineral chemistry in the Arctic ecosystem. These datawill help provide a firmer empirical foundation for predicting the most important drivers of Cdegradation and GHG emissions in these high-latitude regions. As a graduate student at UTKworking with researchers at ORNL, I will have full access to the extensive resources provided byboth, including all instrumentation mentioned, and the support of expert faculty and scientists whospecialize in terrestrial biogeochemistry and can help optimize any necessary techniques.Broader Impacts: Given the importance of climate change to all sectors of society, these resultswill provide critical data for improving global climate models. Various researchers from a varietyof disciplines may use this data to better interpret Arctic systems chemistry and make moreinformed decisions on current and future governmental policies. My continued involvement withthe ACS local section and my tutoring efforts will allow me to actively recruit high school andundergraduate students from underrepresented groups to gain valuable research experience on thisproject. The interdisciplinary nature of this research will significantly broaden their scientificexperience and enhance their understanding of the importance of chemistry in the Arctic to globalclimate change. I will encourage them to apply for REU support to join me in the field where theywill participate in weekly public scientific discussions with native Iñupiaq community members.I am applying to host a PolarTREC teacher, who has recently contacted me from the EastTennessee area, during a summer field campaign where we will connect with her students to shareour experiences from the field. Given the close proximity, we will be able to connect more directlywith her students through class presentations and scientific demonstrations. On a more regularbasis, I am able to share the importance of environmental research, Arctic biogeochemistry, andtheir impacts on public policy and education, to the broader public, via my website and blog “ThinkLike a Postdoc” (www.malloryladd.com).References: [1] Jenkinson et al. (2008) Euro. J. of Soil Sci., 59, 400 [2] Gu et al. (1994) Env. Sci. & Tech. 28, 38 [3]Mikutta et al. (2006) Biogeochemistry, 77, 25 [4] Vogel et al. (2009) J of Geophys. Res., 114 [5] Ladd et al. (2013)ORNL Ann WIS Poster Session: http://malloryladd.com/ [6] Bockheim et al. (2007) Soil Soc. of Am. J., 71, 1889"
200.0,"Impacts of Radioactive Cs on Marine Bacterioplankton: Effects of the FukushimaDisaster on Hawaii’s Kaneohe Bay Bacterial CommunitiesIntroduction Marine bacteria are unmatched in their diversity and abundance. They exhibitmutualism with economically significant organisms, synthesize life-saving natural products, andplay a vital role in oceanic nutrient cycling. Despite our dependence on marine bacteria, verylittle research has been conducted on how they respond to large-scale disasters.One such catastrophe, a tsunami off the coast of Japan, occurred on March 11, 2011. Thetsunami caused the Fukushima-Daiichi Nuclear Power Plant to emit 10 PBq of radiation2, thelargest ever release of anthropogenic radionuclides into the ocean4. The main pollutant, 137Cs,has a half-life of 30 years and will first hit the US territories at the Hawaiian Pacific Islands inearly 2014, diluted by only three orders of magnitude2 (figure 1).While 63 marine species have already exceeded the Japanese limit for radioactive Cs (100Bq/kg), the impacts of radioactive waste on marine microorganisms are largely unknown6. Dueto their short reproductive lifecycle and unicellularity, bacteria evolve faster than mosteukaryotes when exposed to radiation, so much so that radiation is used in laboratories to inducemutagenesis.This project aims to assess the impacts of radiation on the bacterioplankton community ofKaneohe Bay in Oahu, Hawaii. The bay is in the direct path of Fukushima’s radioactive wasteand has a bacterioplankton community that was well-characterized pre-disturbance1, making itthe ideal case study for the microscopic impacts of radioactive pollution. I will compare trendsafter radiation exposure to previously documented annual/seasonal fluctuations. This is possiblebecause Fukushima bacterial populations were catalogued bimonthly over an 18-month period.Hawaii HawaiiFigure 1: Predicted spread of 137 Cs after 2.5 and 5 years2; color scale shows dilution factorResearch Questions1. How has the bacterioplankton species composition in Kaneohe Bay (as determined by 16Ssmall-subunit ribosomal RNA (SSUrRNA) barcodes) changed since the Fukushima leak?2. Has there been a significant increase in single nucleotide polymorphisms (SNPs) since theradiation event, as compared to mutation rates that would occur due to random chance?Methods I will work within the Rappé laboratory for aquatic microbial ecology at HawaiiInstitute of Marine Biology (University of Hawaii at Manoa), which is equipped with allnecessary instruments and sampling materials. Rappé is at the forefront of bacterioplanktonecology, and having established the 2006-2007 baseline1, his lab will provide an excellentknowledge base for collecting comparable data.Seawater will be sampled at a depth of 1m at 2 sites (reef flat and lagoon) separated by 600mnear Coconut Island in southern Kaneohe Bay. Samples will be taken twice monthly fromJanuary 2015 to July 2018 between 07:00 and 08:30h. In situ measurements of temperature,salinity and pH will be taken at 1m depths using a multi-parameter sonde, and radiation levels+will be monitored with a scintillation probe. Dissolved inorganic nutrient concentrations (NH ,4– 3–NO2 , PO4 , silicate) will be measured using a continuous segmented flow system. Bacteria willbe isolated by filtering 1L of water through a 1.6 µm microfiber membrane pre-filter followed bya 0.2 µm polyethersulfone membrane and stored at –80°C in DNA lysis buffer. Genomic DNAwill be extracted using the DNeasy Tissue kit1.Bacterioplankton will be characterized by PCR of SSUrRNA and sequenced in a barcodedIllumina HiSeq run. The bacterial primers 27F-B-FAM and 519R will be used1. OCTUPUS andUC-LUST will be used to process raw reads, which will then be clustered into operationaltaxonomic units using MegaBLAST3. Mutation and species compositional shifts due to randomchance will be determined from the 2006-2007 data1 using a Poisson distribution andextrapolated to determine the number of mutations that should occur from 2015 to 2018. Theexperimental 2015-2018 community structure and SNP prevalence will be compared againstthese values to identify changes that are due to radiation.Anticipated Results1. The bacterial community structure will change significantly more than due to random chance.2. Post-Fukushima species will have significantly more nonsense and missense mutations innon-essential genes and neutral mutations in housekeeping genes than would have accumulateddue to random chance.Broader Impacts This research will help characterize the full repercussions of radioactivepollution at its first outset, providing insight that will allow us to prepare for future radiationleaks and the arrival of the contaminants to the California coast6. It will reduce the knowledgegap of what potential harm radioactivity causes marine microbial communities, and give policymakers the information they need to manage affected ecosystems. In light of the recent shifttowards increased nuclear power reliance, this research will inform the tradeoffs of pursuingvarious energy sources in future development, as well as allow policy makers to establish andenforce adequate safety standards for nuclear power plants. In doing so, this research will protectthe ecosystem services that marine bacterioplankton provide for humanity, including the nutrientcycling that supports economically important fisheries and large-scale oceanic biodiversity.Resultant policies will protect the biodiversity of marine microbes, which has already provenitself a priceless source of natural products that combat neurological disorders, infections, andcancer5. This study will also characterize the impact of radiation on pathogenic bacteria incoastal communities, which is crucial to fully assessing the impact of radioactive waste onhuman and environmental health.Literature Cited1. Apprill, A. and M. S. Rappé (2011). ""Response of the microbial community to coral spawning in lagoon and reefflat environments of Hawaii, USA."" Aquatic Microbial Ecology 62: 251-266.2. Behrens, E., et al. (2012). ""Model simulations on the long-term dispersal of 137Cs released into the Pacific Oceanoff Fukushima."" Environmental Research Letters 7(3): 034004.3. Bik, H. M., et al. (2012). ""Sequencing our way towards understanding global eukaryotic biodiversity."" Trends inecology & evolution 27(4): 233-243.4. Rossi, V., et al. (2013). ""Multi-decadal projections of surface and interior pathways of the Fukushima Cesium-137radioactive plume."" Deep Sea Research Part I: Oceanographic Research Papers.5. Villa, F. A. and L. Gerwick (2010). ""Marine natural product drug discovery: Leads for treatment of inflammation,cancer, infections, and neurological disorders."" Immunopharmacology and immunotoxicology 32(2): 228-237.6. Wada, T., et al. (2013). ""Effects of the nuclear disaster on marine products in Fukushima."" Journal ofenvironmental radioactivity 124: 246-254."
201.0,"Eukaryotic post-translational modification of bacterial effectorsKeywords: asparagine hydroxylation, Legionella pneumophila, Yersinia pestis, bacterialeffectorsLegionella pneumophila, the causative agent of Legionnaire’s disease, has only recentlybecome a human pathogen. Its intracellular lifecycle in amoeba, the natural host, has primed thebacteria for invasion into human alveolar macrophages. Co-evolution within amoeba andhorizontal gene transfer has helped shape the near 300 effectors produced by Legionella that areinjected into the host cell by the Dot/Icm type IVB translocation system1. A majority of theseeffectors have eukaryotic-like domains such as: F-box, U-box, Sel-1, ankyrin repeats, leucine-rich repeats, and CaaX motifs, which were likely acquired by horizontal gene transfer2. Thesedomains aid in the hijacking of host processes by L. pneumophila in order to promote growth andreplication. Many injected bacterial effectors are modified by the host through various post-translational modifications, however asparagine hydroxylation modification has never beenobserved.Post-translational asparagine hydroxylation of proteins in mammalian cells is mediatedby Factor Inhibiting HIF (FIH). FIH is most commonly studied for its role in asparaginehydroxylation which regulates the Hypoxia inducing Factor (HIF), responsible for thetranscription of around 100 hypoxia-related genes. FIH recognizes the amino acid sequenceLxxxx(D/E)ϕNϕ3. This motif can be found in 11 of the injected effectors of L. pneumophila,designated as Hydroxylated Effectors of Legionella (HEL). This motif can also be found in otherinjected bacterial effectors such as, the Outer Protein M (YopM) of Yersinia pestis, IpaH4.5ubiquitin ligase of Shigella flexeneri, and an uncharacterized ankyrin protein of Rickettsia felis.It is likely that this motif is present in many other bacterial effectors that have yet to bedescribed.Exploitation of host post-translational modification plays an important role in bacterialpathogenesis by further tuning it with the host, allowing it to manipulate and modulate hostfunctions. Our hypothesis is that pathogens hijack host FIH in order to hydroxylate effectorproteins, making them biologically functional. To test this hypothesis, three aims are proposed.Aim 1-Hydroxylation of effector proteinsIn order to determine if the HEL proteins of L. pneumophila, YopM of Y. pestis, andIpaH4.5 of S. flexeneri are hydroxylated in human cells, HEK293 cells will be transfected withplasmid containing FLAG-tag fusion proteins. Purified proteins will be analyzed by matrix-assisted laser desorption/ionization (MALDI) Mass Spectrometry (MS), to identify a 16 daltonmass shift in the fragment containing the hydroxylation motif. This will be done in collaborationwith Dr. Michael Merchant. To confirm the role of FIH in asparagine hydroxylation, FIHinhibitors and FIH silencing by RNAi will be utilized. We have tested and confirmedhydroxylation in this manner for one of the HEL proteins, AnkH. This gives us reason to believethat others may be hydroxylated as well and supports our reasoning for these studies.1Ashley Richards Dissertation Proposal 2013Aim 2- Protein-protein interactions of FIH and effectorsOur preliminary studies have shown colocalization of the host FIH and some of the HELproteins to the Legionella containing vacuole (LCV). Therefore, interaction between FIH andeffectors is likely to occur. Due to the transient enzymatic nature of interactions with FIH,Bimolecular Fluorescence Complementation (BiFC) will be used to show the interactionbetween the proteins of interest and FIH. This system utilizes two plasmids each harboring halfof a fluorescent molecule that emits light when brought together by interacting proteins fused toeither half. If fluorescence can be detected by confocal microscopy in cells transfected with twoplasmids, containing the N-terminal portion of the fluorescent molecule fused to either FIH oreffector protein and the C-terminal portion of the fluorescent molecule fused to an effectorprotein or FIH, then interaction between of the two proteins can be suggested.Aim 3- Role of asparagine hydroxylation motif in the biological function of effectorsGenerating point-mutations in the asparagine of the hydroxylation motif for each proteinwill elucidate how hydroxylation of this residue is important to the function of the protein. Thiswill be in comparison to the knock-out mutant, lacking the gene, which will also be generated.These mutants will be used in functional studies in a variety of species and cells such as humanderived macrophages, mice, and amoebae. Because L. pneumophila has a plethora of hosts, it ispossible that a mutant has an effect in one species or type of cell but not another. This will alsobe done with Y. pestis YopM mutant in human macrophage cell line, in collaboration withYersinia researcher Dr. Matthew Lawrenz.Hydroxylation of bacterial proteins has never been shown before. This post-translationalmodification could be the key to more refined modulation and regulation of the host. This motifseems to be abundant in human pathogens and has implication in convergent evolution ofbacterial effectors to better survive in its mammalian host. Not only will this educate us onbacterial host interactions but also provide more insight on FIH, as little is known about thenature of FIH hydroxylation outside of its role in hypoxia.Broader Impacts: These studies would lead into knowledge about effector proteins in the studywith unknown function. Ultimately better understanding bacterial effectors and their role in thehost could result in potential targets for novel treatments. My research will provide new insightsinto bacterial protein post-translational modification, and be added to publically accessibledatabases designed to predict protein structure and function. This will allow others to use thisinformation to elucidate novel functions or regulatory mechanism for proteins in other species.References[1] de Felipe, K.S., Glover, R.T., Charpetier, X., Anderson, O.R., Reyes, M., Pericone, C.D., and Shuman, H.A.(2008) Legionella eukaryotic-like type IV substrates interfere with organelle trafficking. PLoS Pathog 4, e1000117[2] Al-Quadan, T.P., Price, C.T., and Abu Kwaik, Y. (2012). Exploitation of evolutionarily conserved amoeba andmammalian processes by Legionella. Trends Microbiol 20, 299-306[3] Wilkins, S. E., Karttunen, S., Hampton-Smith, R. J., Murchland, I., Chapman-Smith, A., & Peet, D. J. (2012).Factor Inhibiting HIF (FIH) Recognizes Distinct Molecular Features within Hypoxia-inducible Factor-α (HIF-α)versus Ankyrin Repeat Substrates. Journal of Biological Chemistry, 287(12), 8769-8781.2"
202.0,"Intellectual Merit: Alternative reproductive tactics (ARTs) are phenotypically distinctreproductive strategies that achieve approximately equal fitness (different fitness peaks). As amodel system for studying the evolution of variation1, ARTs of males have been extensivelystudied, characterized by color and/or size, morphology, behavior (i.e. territorial vs. sneakermales), etc.1. By contrast, female ARTs are poorly studied. Female ARTs occur in ovipositionsite selection, mating behavior, and ontogenetic shifts in female size and fecundity, but manyopen questions remain1, 2: What selective factors cause divergent female behavior and/ormorphology? Are they driven by predator avoidance, developmental limitations, physiology, ordid they evolve in other functional contexts, for example, trophic niches1? Have morphologicaland reproductive behavioral differences evolved as correlated responses to sexual selection,which then impact other life history aspects, such as feeding? Or does natural selection causefeeding dimorphisms that in turn shape morphological and reproductive behavioral differences1?My research will explore phenotypic variation and ecological niches as underlying mechanismsof female alternative reproductive tactics in a novel, model system.Model System: Olive ridley sea turtles (Lepidochelys olivacea) exhibit strikingly divergentfemale reproductive tactics (Table 1). In the same population, some nest synchronously (SYN)en masse (>10,000 individuals) on a few, distinct, beaches whereas others nest solitarily (SOL)on multiple beaches over thousands of kilometers of coastline3. L. olivacea are the only sea turtlespecies to exhibit these ARTs, which were not formally recognized until 2002. Virtually nothingis known about why or how the ARTs occur3.I hypothesize that these alternative reproductive tactics are a result of an ecologicaldimorphism. SYN nesters migrate throughout the E. Pacific and aggregate to mate offshore ofSYN nesting beaches to ensure copulation3. I predict SOL nesting females are neritic foragers,allowing them to nest more frequently and find mates more often making SYN aggregationsunnecessary. I will sample females at 2 SYN and 3 SOL study site (6 if logistics permit).Table 1: Known characteristics of L. olivacea divergent reproductive tacticsCharacteristic Synchronous nesters (SYN) Solitary nesters (SOL)Inter-nesting period4 28 days 14 daysNesting phenology3 Rainy season All yearSite fidelity 4 High LowFemale body & clutch size3 Larger SmallerEco-morphology AIM 1 AIM 1Spatially explicit foraging ecology3 Nomadic, pelagic; AIM 2 AIM 2AIM 1: DEFINE THE MORPHOMETRICS OF SOL AND SYN NESTING L. OLIVACEA. Morphologicaldifferences are common attributes of ARTs1. There is some evidence that SYN are larger thanSOL nesters3 but basic morphology of these divergent ARTs is unknown. Using morphometrictools I will test my hypothesis that there are significant differences in size, shell depth, shellshape and flipper morphology between the two tactics. Morphological differences relating toforaging behavior are known in other sea turtle species5-7. Ecological dimorphisms have beenshown in three populations of Caretta caretta6, 7 where small females forage in pelagic habitatsand larger in neritic habitats. In Chelonia mydas, a pelagic population has larger flippers than aneritic one5. Methods: I have defined 10 flipper landmarks related to underlying skeletal andmuscle structure. These landmarks and standard sea turtle body measurements8 (i.e. shell width& length, body depth & mass) will be quantified. I will use principal components analysis to testfor morphological differences, and if found, to evaluate which attributes drive the variation. Iestimated from a power analysis9 (F-test, p =.05, 10% effect size) that a sample of 100 femalesper study site (N=500) will provide a power of 89% to detect a difference.AIM 2: DEFINE THE FORAGING ECOLOGY OF SYN AND SOL NESTING L. OLIVACEA. Stable nitrogen(δ15N) and carbon (δ13C) isotope ratios, coupled with satellite telemetry, have proven to beeffective tools for defining sea turtle ecological dimorphisms in 3 of the 6 other species7, 10, 11. Iwill utilize these tools to test my hypothesis that SYN nesters are nomadic, pelagic (openocean) foragers with no localized foraging ground, whereas SOL nesters are neritic foragerswith distinct neritic foraging grounds. Methods: Skin and dorsal shell samples will be taken toprovide recent (skin) and multi-year (shell) foraging histories12. Samples will be taken duringearly, mid and late nesting season to account for migrations from various foraging grounds andwill be collected, prepared and analyzed using established methods12. The power analysisdemonstrated that a sample size of 35 turtles per sample period, per site, for skin and shell tissue(105 per site, total N=524) is sufficient. To examine spatially explicit foraging ecology I willattach satellite tags to randomly assigned females sampled for stable isotopes (10 at each studysite, total N=50). Implementing robust state space modeling, I will analyze the data usingestablished protocols13. Sampling from multiple sites and using spatial statistical analyses willaccount for the possibility of pseudoreplication (spatial autocorrelation in this system).This is the first detailed morphological analysis of L. olivacea ARTs and the firstexamination of ecological niches as an underlying mechanism driving them. Both aims arefeasible; the methods have been successful in other sea turtle studies, I have tested them in thefield and I have support of international collaborators. My results will contribute to a meta-analysis creating a stable isotope landscape for the E. Pacific Ocean, headed by a NSF GRF. Iam organizing the first L. olivacea working group to address the unknown life history traits,which will have important management applications for this vulnerable species. My field seasonincludes fall semester and at least two are needed. This fellowship is crucial in allowing me to bedecoupled from campus and will greatly increase my capacity to do fieldwork.Broader Impacts: Communicating my research is an important part of my career path andprofessional development. Using social media I share my research and discuss science issueswith scientists and lay people. Working with Texas Sea Grant I am developing STEMeducational materials, using charismatic sea turtles as flagship species to promote watershededucation in K-12 classrooms. I will develop a network of graduate students across Texas tospeak with classes about their adventures in pursuit of higher STEM education.I will assemble and train undergraduates (including those in the Texas A&M, NSF-funded, Louis Stokes Alliance for Minority Participation program), Costa Rican communitymembers and personnel from NGOs and national parks to assist in my research. Participants willreceive a hands-on opportunity to learn about experimental design, fieldwork, data analyses andethics of working with animals all while engaging in cultural exchange. I will continue todisseminate my work to the scientific community via presentations and peer-reviewed papers.This fellowship is key in allowing my work to impact the evolutionary understanding of ARTs,life history of an understudied species and a wide nonscientific audience through education andcollaboration. References: 1Oliveria et al. 2008 Alt Repro Tactics.2Henson & Warner 1997. Annu Rev Ecol Syst28:571-92.3Plotkin 2007. Biol and Conserv of Ridley Sea Turtles.4Kalb 1999. Ph.D. Diss. 5Balazs et al. 1997. ProcAnn Sea Turtle Symp.6Hawkes et al. 2006. Curr Biol 16, 990-5.7Hatase et al. 2002. Mar Ecol-Prog Ser 233:273-281.8Wyneken. 2001 The Anatomy of Sea Turtles.9Cohn1988. Stat Power Analysis for the Behav Sci.10Hatase et al.2006. Oecologia 149:52-64. 11Caut et al. 2008. PLoS One e1845. 12Reich & Seminoff 2010. Proc Ann Sea TurtleSymp. 13Block et al. 2011. Nature doi:10.103/nature10092."
204.0,"Key Words: Peptide Release, Ribosomal Stalling, Gene Regulation, Student MentoringAbstract:The aim of the proposed research is to gain a mechanistic understanding of peptide releaseand nascent peptide mediated ribosome stalling by employing both a synthetic and structuralapproach. This project will broaden our understanding of protein synthesis and gene regulationby the ribosome and promote teaching and learning in all educational levels through mentoringand collaboration. This research will be completed with the guidance of Dr. Scott Strobel at YaleUniversity, with all the requested resources and collaborations available to successfullyaccomplish the following aims.Background and Significance:Protein synthesis by the ribosome is a fundamental process found in all life. A set of highlyconserved nucleotides located in the active site of the large subunit of the ribosome are responsiblefor two biologically important reactions: peptide bond formation and release. Termination ofprotein synthesis occurs when one of three stop codons are recognized in the small ribosomalsubunit and decoded by release factor proteins (RFs) 1. Upon recognition, a highly ordered watermolecule nucleophilically attacks the aminoacyl ester linkage of peptidyl-tRNA hydrolyzing theester bond which links the nascent polypeptide to the peptidyl-tRNA. As seen in Figure 1a, it ishypothesized that asthe ordered watermolecule attacks theester linkage, thecarbonyl carbonproceeds through atetrahedral transitionstate containing adeveloping negativecharge, an oxyanion.While terminationof translation hasFigure 1. a) General mechanism of peptide release. b) Generic structure of peptide release been known fortransition state analogs. c) Generic structure of peptide formation transition state analogs.some time now2, it isless studied than elongation and the underlining mechanistic processes are only starting to emerge.Thus transition state characterization and structural studies can help define how the ribosomecatalyzes this challenging reaction.In addition to catalyzing the formation and release of polypeptides, the ribosome has alsobeen found to have the ability to monitor the structure of the growing polypeptide duringelongation, a process which is poorly understood. Accumulating evidence shows that some nascentpeptides result in ribosomal stalling due to specific RNA interactions within the exit tunnel of theribosome. Many of these have been found to play a role in regulating the expression of genes suchas erythromycin resistance in bacteria3. Recent cryo-EM reconstructions of the stalled ribosomehave suggested that certain interactions within the tunnel are relayed to the peptidyltransferasecenter (PTC) to arrest translation4. However, how this information is communicated to the PTC isessentially unknown. By further understanding the mechanism of ribosome stalling it may yieldinsights into the events that regulate gene expression from bacteria to humans, which can lead tothe rational design of more efficacious drugs.Specific Aims:Aim 1: To synthesize and measure the binding affinity of a series of transition state analogs.In the Strobel lab, I will create a series of peptide release transition state analogs containingfunctional groups of varying shapes, charge distributions, and hydrogen-bonding potentials andmeasure their relative affinity for the ribosome using RNA chemical footprinting (Figure 1b).With this technique, nucleotides in the 23S rRNA will be probed using dimethyl sulfate as afunction of inhibitor concentration using established protocols5. All of these inhibitors have thesame basic geometry and each is synthesized as a pair of diastereomers that allow both non-bridging oxygens to be characterized independently. Transition state theories predict that enzymesbind the tightest to the transition state of the reactions they catalyze. Therefore, the inhibitors thatbest complement the electrostatic environment of the active site will bind the tightest, and fromchanges in the extent of modification of ribosomal residues, the relative affinities will allow us todraw conclusions about the geometry and charge distribution of the active site during release.Aim 2: To gain a structural understanding of peptide release and induced ribosomal stalling.Given the implications of the ribosome in peptide release, its role in translational arrest,and its essential yet understudied role in gene regulation, it will be vital to develop a mechanisticunderstanding of how the ribosome performs all these actions. Using high-resolution crystalstructures I will investigate how important structural features of the ribosome, peptidyl tRNA andrelease factor proteins position a water molecule for optimal attack of the aminoacyl ester linkageof peptidyl-tRNA. I will also elucidate how specific conformations of the nascent polypeptidechain and subtle conformational changes in the ribosome can feedback inhibit the PTC. I will thuscollaborate with the Steitz lab at Yale, which is preeminent in ribosomal X-ray crystallography, toget a crystal structure of release factor 2 bound to the ribosome with the best peptide releasetransition state analog from Aim 1 (Figure 1b). Using solid phase synthesis, I will also synthesizetransition state analogs of peptide bond formation with an attached polypeptide of known stallingability that can be tethered into the exit tunnel (Figure 1c). By visualizing the peptide-exit tunnelinteractions through crystallography together with biochemical and computational data, it ispossible to propose a more accurate mechanistic model of nascent polypeptide chain-mediatedtranslational stalling.Aim 3: To promote teaching, mentoring and collaboration in multiple educational levels.In collaboration with Dr. Nicolas Carrasco at Quinnipiac University, I am in the uniqueposition to teach and mentor possible undergraduate students from both Yale and Quinnipiac whowish to participate in this project by helping them experience graduate-level research, andteaching them how to communicate their findings at conferences. These students will work towardthe synthesis of various oligonucleotide-peptide conjugates in order to further research stallingpeptides and investigate the role of various cofactors in the formation of the stable stalled ribosomecomplex. I will also use this work as a teaching tool during TA sessions at Yale for science andnon-science oriented undergraduate classes by teaching students how to think critically andanalytically. Additionally, I will become involved in the New Haven Science Fair Mentor Program(NHSFMP) to help elementary school students and teachers become more excited about science.I will facilitate weekly brainstorming sessions meant to teach students to form a hypothesis,develop an experimental approach, and analyze their results. My long term goal is to help create abetter science curriculum to show their students how to become future scientists.References:1. Weixlbaumer, W. et al. (2008) Science. 322: 953-956. 2. Capecchi, MR. et al. (1967) Proc. Natl. Acad. Sci. 58:1114-51. 3. Ramu, H. et al. (2011) Mol. Cell. 42: 321-330. 4. Seidelt, B. et al. (2009) Science. 326: 1412-155. Parnell, K. et al. (2002) Pro. Natl. Acad. Sci. U. S A. 99: 11658-1166"
205.0,"gene expression. Transcription factor (TF) activity itself is difficult to measure experimentally inhigh-throughput; however, many insights can be gained from applying statistical methods toinfer activity from the expression of TF target genes. This indirect quantification of TF activityhas been made possible by gene expression microarrays, which simultaneously profile thousandsof genes. There has been extensive research on how to test for differential expression of a prioridefined gene sets such as TF target genes.1 One method recently developed in the Kleinstein lab,Quantitative Set Analysis of Gene Expression (QuSAGE), is unique in that it produces aprobability density function for each set by convolution of the expression profiles of individualgenes.2 Still, the efficacy of all these methods relies on the chosen TF target gene set. Theadjacent figure shows how the NFkB activity inferred after stimulation with TNF (an inducer ofNFkB) is highly dependent on the choice of gene set. Thus, there is a need to improve methodsfor generating and refining such sets.There are numerous ways to generate putative TF targetgene sets both computationally and experimentally.Inferred NFkB ActivityComputational predictions provide candidate targets byscanning for a specific binding motif in promotersequences genome-wide. However, this method isknown to generate many false-positives. Protein-DNAbinding experiments (e.g. ChIP-Seq, ChIP-ChIP)provide experimental evidence for TF-DNA interactions.However, there are a large number of bindinginteractions observed, many not in the promoter ofknown genes, and these interactions may be specific tothe cell line used. In addition, the accuracy of both ofthese prediction methods suffers because the occurrenceof a TF binding site or the actual binding of a TF to a gene promoter does not necessarily implytranscriptional regulation. Networks from pathway databases (e.g. KEGG) provide someadditional information about which genes interact at a transcriptional level. However, thenumber of interactions in pathways is limited. Currently each TF is associated with a singletarget gene set. This is problematic because, in reality, TF target genes depend on the cellularand environmental context of the cell. To infer TF activity more accurately, candidate targetgene sets from many sources can be refined to include only the genes under a TF's control in thespecific context being studied. I will develop a method for generating context-specifictranscription factor target gene sets (Aim 1), and apply these gene sets to infer transcriptionfactor activity during infection and vaccination responses (Aim 2).Aim 1: Develop a method for generating context-specific TF target gene sets.I will begin with a large set of proposed candidate TF target genes and then to utilize co-expression patterns from gene expression data to select candidate genes having a similar geneytivitcAFT1.5x1.0 x0.5x0.0 x xSet 1 Set 2 Set 3 Set 5 Set 4(149genes)(206genes)(301genes)(2757genes)(96genes)100.0− 500.0− 10.0− 50.0− 1.0− 1 1.0 50.0 10.0 500.0 100.0TF Target Gene Setsexpression pattern. One limitation of current approaches is that each gene is either a candidate ofa TF, or it is not. I plan to integrate multiple information sources including computationallypredicted binding sites from motif scanning algorithms, protein-DNA binding data, and pathwayinformation to compute a prior probability for each gene being a candidate target of each TF.This prior probability represents the strength of the evidence for a certain gene being a target of acertain TF. Because the relative importance of each of the data sources is not known, I willestimate them as parameters in a Bayesian network. I hypothesize that this extra informationwill improve correct identification of TF targets. The method will allow for overlap of genesbetween target sets but I will explore whether this is necessary, since dependence between targetsets is often problematic for quantification of TF activity. The proposed method will build on theframework proposed by Fertig et al.3 Some TFs are transcriptionally regulated themselves,allowing for estimation of activity directly from gene expression measurements. I will evaluatemy method by comparing the activities inferred from the proposed and published methods forthese transcriptionally regulated TFs.Aim 2: Apply these gene sets to infer transcription factor activity during infection andvaccination responses.One natural application of these TF target gene sets is to infer TF activity. Thus, I plan to applythe developed method to specific time-series gene expression data sets of influenza infection andvaccination responses. I have access to these data through the NIAID funded Program forResearch on Immune Modeling and Experimentation (PRiME) and the Human ImmunologyProject Consortium (HIPC). In the case of the influenza infection data, the different contextscorrespond to four different strains of in vitro influenza infection; while in the case ofvaccination response data, the contexts correspond to vaccine responders or non-responders.Generating context-specific gene sets will allow us to answer two fundamental questions: Arethere changes in which genes are regulated by certain TFs across contexts? And how do theactivities of TFs differ between contexts? I will answer the first question by applying differentialnetwork analysis, a method to identify how the regulatory network is rewired in differentcontexts. To answer the second question, I will infer activity of each gene set using QuSAGE tofind quantitative differences in TF activity between contexts.Significance and Broader Impacts TFs are key regulators in development and disease. Theability to better characterize TF activity thus has implications for understanding disease statesand the mechanisms underlying development. The proposed integrative approach to generatecontext-specific TF target gene sets will improve understanding of transcriptional regulation andallow for a more accurate inference of TF activity.1. Hung, J.-H., Yang, T.-H., Hu, Z., Weng, Z. & DeLisi, C. Gene set enrichment analysis: performance evaluationand usage guidelines. Brief. Bioinform. 13, 281–91 (2012).2. Yaari, G., Bolen, C. R., Thakar, J. & Kleinstein, S. H. Quantitative set analysis for gene expression: a method toquantify gene set differential expression including gene-gene correlations. Nucleic Acids Res. 41, e170 (2013).3. Fertig, E. J., Favorov, A. V & Ochs, M. F. Identifying context-specific transcription factor targets from priorknowledge and gene expression data. IEEE Trans. Nanobioscience 12, 142–9 (2013)."
206.0,"MULTI-MODAL DATA!Keywords: Alzheimer’s Disease, Structural MRI (sMRI), Functional MRI (fMRI), MildCognitive Impairment (MCI), GPU computing!Summary: I propose to use multiple imaging systems, such as structural and functional MRIimaging to provide a temporal evolution of Alzheimer’s disease (AD) with multi-modal data. Itwill include patients that show no symptoms and patients that have MCI. This temporalevolution will show how different regions of the brain changes and how AD evolves. Thehippocampus region will be a main region of interest, but other regions like the temporal lobewill be examined [2,3]. In addition with the imaging system, looking at the cerebrospinal fluidwill provide great insight to how AD affects the body [1]. I will also incorporate GPUcomputing to make it efficient.!Motivation: AD is ranked as one of the leading diseases in increasing deaths. AD plans toincrease among the world, which will have an effect on the economy. It is proposed that theexpected cost of AD will rise to $1.2 trillion by 2050 [2]. Some methods have shown how somepatients who have MCI evolve into AD [4]. If AD is not detected early, it will lead the patientsto be in the latter stages of AD. The latter stages, such as stage 5 create severe cognitive declineand require the AD patient to need assistance in performing routine tasks [2]. Thus, detectingAD early is very crucial.!Hypothesis: Detecting AD in the early stages could be very beneficial to future patients, but hasbeen a challenge. One group has said that validating imaging biomarkers for AD has broughtcontroversial findings [5]. Now, using multi-modal data, such as fMRI, sMRI, and otherimaging systems, could capture how AD progresses through time. With seeing different areas ofthe brain and CSF, it could provide insight to how AD evolves with patients that show nosymptoms and patients that have MCI.!Research Strategy: To develop an extensive model of what makes AD develop between patientsthat show no symptoms at all and patients that have MCI.Objective 1: Identify the critical parts/aspects that could lead to Alzheimer’s developing.Objective 2: Examine the different imaging systems that have been used to look forAD, such as fMRI, sMRI, PET, and etc.Objective 3: Extract the regions from the different imaging systems that show whereAD could develop and run pattern recognition methods to classify which arelikely to develop.Objective 4: Identify which interconnections between regions to show how the diseaseprogresses.!Research Methodology: This research methodology is based on several pattern recognitionapproach. Other people have used different image processing techniques to extract regions ofinterest that show where Alzheimer’s could develop and use pattern recognition to classify theregions. Overall, biomedical image processing and pattern recognition will be the foundation indeveloping more information about detecting AD in the early stages.!Anticipated Results: The anticipated result will show how different areas of the brain can showhow Alzheimer’s progresses throughout the patient’s age. It will also show evolution betweenpatients with no previous symptoms and patients with MCI. Plus, I plan to incorporate GPUcomputing so the data could be computed faster because some of the imaging systems, such asfMRI is computationally expensive and extensive [1]. The research that is conducted will besubmitted to a journal paper. A journal publication could be sent to IEEE Transactions orComputer Vision and Pattern Recognition.!Institution: Dr. Alan C. Bovik from University of Texas at Austin is a great professor to conductresearch for this project. One of his research areas is biomedical engineering. His work hasdone detection and diagnosis of breast cancer. The Laboratory for Image and Video Engineeringwould be a great place to conduct research for this project.!Intellectual Merit and Broader Impacts: This research could be valuable to the medical field.It would help multiple people in trying to understand more about AD. The major problem withAD is trying to diagnose it earlier in the beginning stages because there people could prepare.When AD is detected at the latter stages, the damage is done and the patients diagnosed with ADwill need to be cared for the rest of their life. If a new patient is experiencing common trendscompared to a previous patient where it showed the patient’s temporal evolution, then thetemporal evolution can provide a model to show if a new patient with similar patterns willdevelop AD.!!1 2 3 4 5!!!1 Mason, Emily J., Manus J. Donahue, and Brandon A. Ally. ""Using Magnetic Resonance Imaging inthe Early Detection of Alzheimer's Disease."" (2013).!2 Bukhari, Ijaz. ""Early Detection of Alzheimer's-A Crucial Requirement."" arXiv preprint arXiv:1305.2713(2013).!3 Ahmed, Olfa Ben, et al. ""Alzheimer Disease detection on structural MRI."" Proceedings of ESMRMB2013 Congress. 30th annual meeting. 2013.!4 Douaud, Gwenaëlle, et al. ""Brain Microstructure Reveals Early Abnormalities more than Two Yearsprior to Clinical Progression from Mild Cognitive Impairment to Alzheimer's Disease."" The Journal ofNeuroscience 33.5 (2013): 2147-2155.!5 Dukart, Juergen, et al. ""Generative FDG-PET and MRI Model of Aging and Disease Progression inAlzheimer's Disease."" PLoS computational biology 9.4 (2013): e1002987."
207.0,"Background. Frontal association cortex is a brain region critical for flexible action selection inmammals. In humans and other primates, this area includes the supplementary motor complex(SMC), which has been shown necessary for suppression of inappropriate motor plans--an extremecase being 'alien hand syndrome,' in which SMC damage leads to complex and seeminglypurposeful hand movements in the absence of voluntary control.1 Premotor cortex (M2) is thoughtto be the rodent homolog of SMC. Lesions to M2 selectively disrupt goal-directed behavior2, andin particular the ability to adapt choice of action to changes in reward values.3 Despite the evidencefor its causal role in behavioral flexibility, the mechanisms by which neural networks in frontalassociation cortex realize this vital function remain a mystery.Preliminary Findings. To investigate the neural substrates for flexible action selection in M2, Iwill use a combination of rodent behavior, in vivo imaging of neural ensemble activity, and localsilencing methods. During my first year of PhD research, I developed a two-choice decision taskfor mice that requires flexible switching between different action selection strategies in order toobtain optimal reward. The first phase of the task requires a cue-guided strategy in which theanimal must discriminate between two distinct auditory stimuli that each indicate the availabilityof water reward at a corresponding lick port on either side of the animal's mouth. In the secondphase, an action-guided strategy is necessary: reward is contingent upon licking a specific portregardless of the cue presented. The two phases are alternated many times within a single sessionwithout any sensory cue to indicate the phase-switch. Thus, the task requires flexible adaptationof action selection strategy to changing contingencies between cue, action, and reward.In a first step toward understanding the neuralbasis of behavioral flexibility, I have begun imagingensembles of M2 neurons at cellular resolution as miceperform this task (Fig. A&B). To measure changes inneural activity, the genetically encoded calciumindicator GCaMP6 was first transduced into layers 2/3of M2 using an adeno-associated virus (AAV). Acranial window was implanted above M2, andfluorescence traces were recorded using 2-photonmicroscopy. By aligning the traces recorded fromindividual neurons to specific events in a trial (e.g., cueor response onset), I have correlated animal behaviorwith activity changes in single neurons, as well as withthe aggregate activity of all neurons in the recordedensemble. Preliminary analyses have produced two keyfindings that motivate detailed investigation: (1) A large proportion (>25%) of individual neuronsrecorded in M2 were choice-selective, i.e., these neurons showed significant differences in activitydepending on which port was chosen (Fig. C). Interestingly, the fraction of choice-selective neuronsincreased following reward delivery, and peaked ~2-sec post-reward (Fig. D). (2) A greaterproportion of neurons were choice-selective when the task required an action-guided versus a cue-guided response. Furthermore, a large fraction of neurons showed pre-response choice selectivitywhen an action-guided strategy was utilized.Aim 1: Test causal role of M2 ensemble dynamics in behavioral flexibility. Our preliminaryfindings indicate delayed choice-selective activity in M2 that may serve as a feedback signalimportant for reinforcement of the current action-selection strategy. In order to test this hypothesis,AC E x a m p le C e ll DBG r o u p D a t an = 5 6(5m2 ce llsice)I will silence M2 in a temporally specific manner using an optogenetic approach. First, the light-sensitive neuronal silencer ArchT will be transduced bilaterally into M2 using an AAV. Lightpulses will then be delivered through an optical cannula to inactivate M2 specifically during the3-sec post reward in order to block delayed choice-selective activity. If such activity is importantfor reinforcement of action-selection strategy, then this manipulation should increase the numberof trials taken to reach a criterion rate of correct response after phase switches, as well the numberof perseverative errors. Preliminary observations also reveal early choice-selective activity duringaction-guided correct trials that may bias action selection toward the appropriate response. If thisis the case, silencing M2 during the 3-sec prior to response should increase trials-to-criterionduring the action-guided phase while having no effect on performance during the cue-driven phaseof the task.Aim 2: Investigate contribution of GABAergic inhibition to M2 ensemble dynamics anddetermine causal role in flexible action selection. GABAergic inhibition is known to serveessential computational roles in the neocortex. For example, fast-spiking PV+ interneurons (PV-INs) are known to generate the gamma rhythm and sharpen feature selectivity in sensory areas.4,5However, the function of PV-INs in cognitive areas of cortex remains unexplored. The idea thatPV-INs modulate choice selectivity within M2 ensembles is an intriguing hypothesis. To test thispossibility, I will modify the in vivo imaging experiment described above to include PV-specificsilencing, using a transgenic mouse line (PV-cre) that expresses cre-recombinase only in PV-INs.Because an optogenetic approach would preclude simultaneous imaging, a cre-dependentinhibitory receptor activated by the drug CNO (Gi-DREADD) will be transduced into M2 usingan AAV, to allow PV-specific silencing as mice perform the decision task. I hypothesize thatsilencing PV-INs with CNO will reduce choice selectivity within the imaged ensemble byremoving task-related inhibitory control of choice-selective neurons. Additionally, if PV-INs inM2 are critical for strategy reinforcement, then PV-specific silencing should disrupt adaptation ofaction selection strategy, and thus increase trials-to-criterion and perseverative errors after shiftsin cue-action-reward contingencies.Broader Impacts. Research on flexible decision-making will benefit a wide variety of fields thatconcern human and animal behavior. Economic decisions are essentially a form of goal-directedbehavior in which appropriate error signals derived from expectation, reward, and punishmentmust play a key role. By improving understanding of how decision strategy is adapted, we mightdevelop a more informed view of how markets operate, and possibly reduce the human toll ofmarket dysfunction. Similarly, the justice system requires a nuanced understanding of conceptssuch as incentive structure, deterrence, and risk, all of which must be rooted in goal-directedbehavior. As a complement to the study of normal decision-making, it will also be important tostudy how flexibility of the system is hampered by stress, distraction, mood, etc. A moremechanistic understanding may lay the foundation for discovery of measures we can all take tooptimize our level of cognitive flexibility, in order to make better decisions as individuals and asa society. Finally, flexibility is notoriously difficult to implement in current hardware and software.Since behavioral adaptation is evidently a great talent of animals, biomimetic engineering basedupon our own neural wetware may one day deliver some very smart machines.References: 1) Nachev et al. (2008) Functional role of the supplementary and pre-supplementary motor areas. NatRev Neurosci, 9(11), 856-869. 2) Gremel et al. (2013) Premotor cortex is critical for goal-directed actions. FrontiersComp Neurosci, 7. 3) Sul et al. (2011) Role of rodent secondary motor cortex in value-based action selection. NatNeurosci, 14(9), 1202-1208. 4) Cardin et al. (2009) Driving fast-spiking cells induces gamma rhythm and controlssensory responses. Nature, 459(7247), 663-667. 5) Lee et al. (2012) Activation of specific interneurons improves V1feature selectivity and visual perception. Nature, 488(7411), 379-383."
211.0,"suffered severe facial trauma. I underwent several procedures torepair the damage, including maxillofacial reconstruction (Figure1) and extensive dental surgery. During my recovery, I becamefascinated with the sophistication of the materials used in myrepairs and became deeply interested in orthopedic and dentalbiomaterials. This interest, combined with my strengths in physics Figure 1.and mathematics, led me to pursue my undergraduate education in bioengineering with anemphasis in materials science at The Pennsylvania State University.Through my educational, teaching, leadership and outreach activities, I have sinceformulated my career aspiration to become a professor at a research institution. My desires toaddress biomedical challenges creatively, to advance my education, and to share my knowledgeare perfectly suited to this profession.Educational Experiences. In addition to maintaining a high GPA, I have participated inacademic activities to prepare myself for graduate study. For example, I joined the SchreyerHonors College my sophomore year to gain experience in writing an honors thesis. Being in thehonors college also has afforded me the opportunity to take higher-level courses that incorporatemy research interests. For instance, I enrolled in a graduate-level musculoskeletal mechanicscourse for the spring. I am also a scholar in the Ronald E. McNair Post-BaccalaureateAchievement Program, a federal TRIO program designed to prepare low-income, firstgeneration, and underrepresented students for doctoral study. The program initially appealed tome because it organizes professional development activities for its scholars and financiallysupports a nine-week summer research internship with a faculty advisor. This program was aunique opportunity to develop my career objectives and gain valuable research experience. In thespring of 2007, I was accepted into the program and joined the laboratory of two faculty advisorswhose research aligned with my interest in orthopedic biomaterials: Dr. Erwin Vogler fromMaterials Science and Engineering and Bioengineering and Dr. Andrea Mastro fromBiochemistry and Molecular Biology. These two professors collaborate on studying breastcancer metastasis to bone.Teaching Experiences. As a low-income, first-generation college student, I work tosupport my education and have sought opportunities where I both can be compensated and canreinforce concepts from my coursework. For instance, I have served as a grader for the MathDepartment in six differential equations courses overTeaching Experiences two semesters and have volunteered to run• Physiology Teaching Assistant chemistry, physics and calculus study groups for theWomen in Engineering Program. During this time, I• Engineering Design Lab Assistantalso accepted an internship with the Chemistry• WEP Facilitator – Chemistry,Department, which combined research, volunteer andCalculus, Physics groupsteaching components. Under the advisement of Dr.• Chemistry Dept. internshipJoseph Keiser, I researched the life and scientific• Grader, Differential equations achievements of George Washington Carver,• 400-level Bioengineering course focusing on his experiments with peanuts. Extractinginformation from farming bulletins, Carver’s patents and my own laboratory experiments, Ideveloped a laboratory curriculum for students in general chemistry, and implemented thecurriculum in the form of a make-up laboratory. The curriculum was later adapted into acalorimetry laboratory for an honors introductory chemistry course. Because I also wanted to be1involved in teaching activities more closely related to my academic pursuits in bioengineering, Iaccepted a position as a laboratory assistant for an engineering design course, helping students inthe development and presentation of design projects.As my teaching skills strengthened, I wanted to challenge myself to lead a classroom. Forthat reason, I became a teaching assistant for an introductory physiology laboratory, a role inwhich I could teach independent from a faculty instructor. I have taught six sections of thiscourse over the past two years. Each semester, I manage approximately 60 students. As the onlyTA studying bioengineering, I also mentor bioengineering students from other sections. Myresponsibilities for the course include preparing and instructing pre-laboratory lectures,developing weekly quiz questions, demonstrating laboratory techniques, leading post-laboratorydiscussions, and formulating instructions for written reports. I have received Institutional AnimalCare and Use Committee (IACUC) training for the use of animals in the laboratory. With thehelp of another TA, I developed an academic writing tutorial as a supplement for the course. Iwill further challenge myself in the spring as an assistant for a 400-level bioengineering courseby teaching more difficult material.Leadership Activities. In addition to assuming leadership roles in the previouslymentioned activities, I currently serve as treasurer for the Penn State chapter of the BiomedicalEngineering Society. I help coordinate volunteer activities and professionaldevelopment workshops for our members, including an American RedCross blood drive, an H1N1 vaccination clinic, and a graduate schoolportfolio workshop. Our chapter has also established “Lunch and Learn”activities, which give bioengineering students an opportunity to learn about the research andcareer paths of department and adjunct faculty members. Additionally, I am presently workingwith other bioengineering students and faculty to establish a chapter of AEMB, the NationalBiomedical Engineering Honor Society.Outreach. I have also participated in numerous educational outreach activities.Currently, I work with a program called Engineering Ambassadors to encourage high schoolstudents, particularly women, to pursue an education in science or engineering. In this program, Itravel to biology, chemistry, and physics courses at high schools across Pennsylvania and givepresentations about research emerging at the intersection of science and engineering. I was oneof two students to pilot this program over the past summer and present the results of the pilot toadministrators in the College of Engineering. Positive feedback from our presentation hasallowed the program to expand to include 15 female presenters, with plans for visits to schoolsacross the state throughout the year.While I was taking a physiological systems bioengineering course, I observed that aconsiderable amount of time was spent reviewing basic physiology because it was beingpresented from the engineering perspective. This academic year, I am re-designing pre-laboratory PowerPoint presentations used in the physiology course that I teach in order toapproach the basic physiology from this engineering perspective. These modified materials maybe incorporated into a bioengineering-section of the course in the future. I have also contributedto an engineering communications course by recording a class presentation as an educationalweb resource for students in a wide variety of engineering disciplines. Additionally, the slides Ideveloped for the class are now used by course instructors as strong examples.As I near the end of my undergraduate career, I look forward to working toward a Ph.D.and a career as an academic. The NSF fellowship would provide me with the resources toachieve this goal.2In the spring of 2008, I began undergraduate research in the laboratories of Dr. ErwinVogler and Dr. Andrea Mastro, who collaboratively study breast cancer metastasis to bone usingan engineered three-dimensional bone tissue developed in a compartmentalized bioreactor. Thisresearch offered me the opportunity to learn fundamentals of osteobiology and osteopathologythat would translate to studies of orthopedic biomaterials later in my career. I was fascinated bythe simplicity of the bioreactor design, the sophistication of the tissue it supported and thepotential for this in vitro model to enhance the investigation of metastatic bone disease. I havesince dedicated myself to this research by working full-time throughout the summers of 2008 and2009 as well as throughout the past two academic years to complete my honors thesis.Background. The American Cancer Society estimates that one in eight women will bediagnosed with breast cancer in the course of their lifetime. Breast cancer is the second mostcommonly diagnosed cancer in women in the United States, accounting for nearly 27% of allfemale cancers in 2009.1 Breast cancer frequently metastasizes to bone(Figure 1), with bone metastases occurring in approximately 70% ofpatients with advanced breast cancer.2 Breast cancer disrupts normalbone remodeling by suppressing the function of osteoblasts (bone-forming cells) and increasing the activity of osteoclasts (bone-resorbingcells), resulting in increased bone degradation coupled with the release offactors from the bone matrix that support tumor growth. CurrentFigure 1. therapies target this “vicious cycle” between tumor cells and theskeleton.3 Bisphosphonates are a family of drugs that bind avidly to mineralized bone where theyare internalized by osteoclasts and signal osteoclast destruction, resulting in reduced bonedegradation. They are often administered alongside chemotherapy drugs (taxanes).4 Theinteraction of bisphosphonates with osteoclasts is well understood, but little is known abouteffects of bisphosphonates on osteoblasts.Undergraduate Thesis Research. My research involves the study of these drugs withconsiderations for their effects on osteoblasts. The purpose of this study is to characterize theeffect of a bisphosphonate (zoledronic acid) and a taxane (docetaxel), alone and in combination,on osteoblasts in conventional tissue culture and osteoblasts challenged with metastatic breastcancer cells in the compartmentalized bioreactor. I hypothesize a combination therapy will showsynergistic antitumor effects but have little effect on the integrity of osteoblast tissue.In the summer of 2008, I gained valuable skills in cell culture and maintenance byassessing the effects of these drugs on osteoblast proliferation and differentiation in conventionaltissue culture. During this time, I was supported bythe Ronald E. McNair Summer UndergraduateResearch Program and fulfilled all programrequirements, which included documenting aminimum 40 hours of research each week, writing aresearch paper for the Penn State McNair journal,and presenting the research at the annual McNairsummer conference. Throughout the 2008-2009 Figure 2.academic year, I became skilled in developing osteoblastic tissue in the bioreactor, challengingthat tissue with breast cancer cells, and monitoring cancer progression with confocal microscopy(Figure 2A). I participated in the McNair program again the following summer and wasadditionally supported by the Undergraduate Summer Discovery Grant awarded through theuniversity. I enhanced my previous data by optimizing cell viability assays and expanded my1experiments to the bioreactor, evaluating the effects of zoledronic acid on this model of breastcancer in bone. I discovered a single dose of zoledronic acid at 0.50 µM administered three daysafter co-culture reduced the formation of breast cancer colonies and disrupted cancer cellalignment with osteoblast tissue (Figure 2B). This finding suggests that, in addition to effects onosteoclasts, zoledronic acid may have a direct antitumor affect on breast cancer cells. Thesefindings will be published in the next McNair journal and were presented at the McNair summerconference in 2009. My abstract was also accepted for poster presentations at two professionalconferences, one in the field of engineering and the other in bone metastasis research. Theopportunity to engage in conversations with engineers, biologists, and oncologists and receivetheir feedback was a rewarding experience that taught me the value of being an active member ofthe scientific community.This academic year, I will complete my thesis research by evaluating the combinationbisphosphonate and taxane therapy in the bioreactor model. I am currently supported by thePennsylvania Space Grant Consortium Sylvia Stein Memorial Scholarship and Federal WorkStudy. In addition to detailing my research project, a portion of my thesis will be devoted toevaluating the potential for the bioreactor to serve as a system for testing therapeutics. I havealso begun a small research project in collaboration with Dr. George Engelmayr, abioengineering professor, to investigate the effects of surface topography on osteoblastdevelopment in the bioreactor. We predict that microfabricated surface topographies willaccelerate or enhance maturation of osteoblastic tissue in the bioreactor.While I work alongside my advisors, a graduate student, and a laboratory technician todevelop my research skills, my application of these skills is original and my research isindependent. Perhaps the most important thing I learned throughout this experience is thatapproaching a research problem from only one perspective is inefficient. I truly value mycapacity to work within a highly interdisciplinary team and my ability to leverage skill sets fromdifferent fields to achieve a more holistic understanding of my research problem. Additionally,the experience of working with the bioreactor has taught me that successful strategies in researchdo not necessarily have to be complex – success can sometimes be achieved through simplicity.Publications and Presentations1. Miller, Genevieve (forthcoming). “Bisphosphonate effects on breast cancer colonization ofthree-dimensional osteoblastic tissue.” The Penn State University McNair Scholars Journal.2. Miller, Genevieve. 2008. “Bisphosphonate and taxane effects on osteoblast proliferation anddifferentiation.” The Penn State University McNair Scholars Journal.3. “Bisphosphonate Effects on Breast Cancer Colonization of Three-Dimensional OsteoblasticTissue.” Poster presented at The IX International Meeting on Cancer-Induced Bone Disease,October 29-30, 2009 and the Biomedical Engineering Society Annual Fall ScientificMeeting, October 8, 2009.4. “The effect of a bisphosphonate, zoledronic acid, on osteoblasts in vitro.” Presentationoffered at Penn State McNair Summer Research Conference, July 18, 2009.5. “Bisphosphonate and taxane effects on osteoblast proliferation and differentiation.”Presentation offered at Penn State McNair Summer Research Conference, July 19, 2008.---------------------------------------------------------------------------------------------------------------------1American Cancer Society, American Cancer 3Steeg P; Theodorescu D, Nature ClinicalSociety, Inc. 2009, 1-72. Practice Oncology 2008, 5(4): 206-19.2Coleman RE, Cancer 1997, 80(S8): 1588-94. 4Green J, The Oncologist 2004,9(suppl 4):3-13.2Engineered Bone Tissue for the Study of Mechanotransduction in OsteocytesNumerous studies have shown that micro-gravity conditions induce bone loss during long-terminhabitation of space; decreased mechanical stimulation of bone results in uncoupled boneremodeling favoring bone resorption.1 Efforts to prevent or treat micro-gravity induced bone losstypically involve resistive exercise to impart mechanical loads on the skeleton. While somestudies indicate that exercise may reduce the uncoupling of bone remodeling, exercise has yet toeffectively reduce bone loss.1 Thus, an understanding of the mechanisms by which external loadsare sensed by bone cells and translated to cellular signals may elucidate targets forpharmaceutical interventions.Proposed Research. The objective this study is to investigate osteocyte mechanobiologyusing principles of tissue engineering and to ascertain mechanisms by which osteocytes respondto mechanical loading. I propose to study the effects of small-magnitude, high-frequency fluidshear stresses on the maturation of osteocytes cultured in a compartmentalized bioreactor.Background. Osteocytes are stellate cells abundant in cortical bone that develop fromosteoblasts that become entrapped in secreted extracellular matrix (Figure 1).Osteocytes occupy lacunar spaces within bone matrix and are thought toinfluence their surroundings via cytoplasmic intercellular processes thatextend through microscopic canals in the bone called canaliculi.2 It is widelyaccepted that osteocytes are responsible for sensing mechanical signals(mechanosensation), but the mechanisms by which those mechanical signalsFigure 1.are translated to the cells (mechanotransduction) are still unclear.2Osteocytes are difficult to study in situ because they are embedded in mineralized matrixand relatively inaccessible. Similarly, demineralization of bone matrix for in vitro studies fails toreproduce tissue with an appropriate three-dimensional architecture and a complexlacunocanalicular network.2 Principles of tissue engineering may lend improvements todeveloping biologically relevant bone models for mechanobiologystudies.3 My undergraduate thesis research involved engineeringosteoblastic tissue in a compartmentalized bioreactor (Figure 2) andchallenging that tissue with breast cancer cells.4 Through this experience,I gained an appreciation for the ability of engineered tissues to serve as invitro models of osteopathologies and developed an interest in applyingFigure 2. these models for studying osteobiology. Krishnan et al. recently reportedthat pre-osteoblasts proliferate in the bioreactor to form a three-dimensional mineralizingosteoblastic tissue that progressively develops an osteocytic phenotype.5 Cobblestone-shapedosteoblasts mature into stellate cells embedded in a dense matrix with numerous intercellularprocesses.5 Therefore, the bioreactor provides access to the continuum of osteocyte developmentin vitro, including the aforementioned lacunocanalicular network.Previous studies have indicated that external forces are transduced to osteocytes bymeans of “fluid shifts” within the lacunocanalicular network.2 This theory (the poroelasticmodel) accounts for the effects of low-amplitude, high-frequency forces associated with themajority of daily human activities, such as sitting, standing and changing posture, as well aseffects of high-strain activities such as exercise.2,6 While the effects of shear stresses have beenevaluated in vivo and on osteocyte-like cell lines such as MLO-Y4, effects of fluid shear on theprogressive maturation of osteocytes have yet to be investigated.2Materials and Methods. Compartmentalized bioreactors based on the principle ofsimultaneous growth and dialysis7 will be assembled to develop engineered bone tissue that can1be mechanically manipulated. Murine calvarial osteoblasts (MC3T3-E1) can be cultured in thebioreactor for up to 10 months to progressively develop an osteocyte-like phenotype.5 Cells canbe microscopically monitored throughout the culture interval using confocal microscopy.The bioreactor can be inserted into a mechanical device (Figure 3) that produces small-magnitude deformations in the membrane encasing the device. This external force will generate apressure gradient within the cell-culture medium, and incorporation ofa flow-loop for each compartment will allow the fluid to shift withinthe lacunocanalicular network. This system, once fully developed, canbe used to investigate proposed mechanotransduction pathways andbiochemical markers, such as ATP, prostaglandin E and nitric oxide.8 I2am particularly interested in quantifying the expression of the proteinsclerostin, an osteocyte-specific product of the SOST gene that inhibits Figure 3.bone formation.8 Murine models have shown decreased sclerostin expression following loading,suggesting another potential mechanism for mechanotransduction in osteocytes.9Agenda. In the first year of my fellowship tenure, I will design and construct thebioreactor and characterize the development of osteocytes in the culture system. Throughout thesecond year, I will determine a protocol for mechanically loading the bone tissue and investigateproposed mechanotransduction pathways. I will focus on developing quantitative methods ofmeasuring signaling pathways in the bioreactor system. The final year will be devoted toanalyzing effects of mechanical stimulation on osteocyte biomarkers and inducing mechanismsof osteocyte mechanotransduction in bone.Broader Impact. The aim of this project is to gain an understanding of the complexmechanisms underlying mechanotransduction in bone. Discovering these mechanisms couldcontribute to the development of therapies to treat micro-gravity induced bone loss experiencedby astronauts during space travel. This research also has implications for the treatment of otherbone diseases, such as osteoporosis and Paget’s disease. The collaborative nature of the Harvard-MIT Division of Health Sciences and Technology will allow for numerous perspectives tocontribute to this work and my doctoral studies. Furthermore, participation in the BioastronauticsTraining Program would guide my research and enhance my understanding of space medicine.I have actively participated in educational outreach activities during my undergraduatestudies and will continue to do so throughout my graduate career by mentoring underrepresentedstudents as a McNair alumna and encouraging high school students to pursue careers in scienceand engineering. As I continue to pursue my aspiration of becoming a professor, I look forwardto probing new research questions and sharing my knowledge and experiences with studentsfrom a variety of disciplines and backgrounds.---------------------------------------------------------------------------------------------------------------------1LeBlanc A.D. et al., J Musculoskelet 6Hwang S.J. et al., Clin Orthop Relat ResNeuronal Interact 2007, 7(1): 33-37. 2009, 467: 1083-1091.2Allori A.C. et al., Tissue Engineering: Part B 7Rose G.G., Int. Rev. Exp. Pathol. 1966, 5:2008, 14(3): 285-293. 111-178.3Freed L.E. et al., Tissue Engineering 2006, 8Riddle R.C.; Donahue H.J., Journal of12(12): 3285-3305. Orthopaedic Research February 2009, 143-4Dhurjati R. et al., Tissue Engineering 2006, 149.12(11): 3045-3054. 9Robling A.G. et al., The Journal of5Krishnan V. et al., In Vitro Cell.Dev.Biol – Biological Chemistry 2008, 283(9): 5866-Animal 2009, Accepted 3 Sept. 2009. 5875.2Rating Sheet 1:Overall Assessment of Intellectual Merit: Very GoodExplanation to the applicant:Student's proposed plan of research was well organized and well presented. She documentedseveral awards and scholarships as well as a few publications and presentations Noteworthy thatshe researched accomplishments of Geo. Washington carver and then developed lab curriculumfor students in general chemistry. Also noted that she mentored students in bioeng. and becameTA for physiology lab excellent letters of recommendationOverall Assessment of Broader Impacts: Very GoodExplanation to the applicant:active in Biomed Engin. Society as treasurer and helped coordinate volunteer outreach activitiesSought to motivate more young women to go into engineering and other STEM fields bycreating 20-minute presentation served as Engineering Ambassador and presented data frompilot program to administrators which brought about funding for the group. Applicantdemonstrated leadership through this initiative and spearheaded visits to her former high schoolRating Sheet 2:Overall Assessment of Intellectual Merit: ExcellentExplanation to the applicant:excellent academic performance excellent leadership and outreach activities Honors collegestudent Chemsitry intern-includes research, volunteer and teaching components a number ofpublications and presentations - both oral and poster excellent research experiences innovativecourse/curriculum slides, example approach basic physiology from engineering perspective andother similar ones good communication skills, very good write-up with suitable figures forprevious and proposed research studies Excellent choice of institution excellent referencesOverall Assessment of Broader Impacts: Very GoodExplanation to the applicant:excellent prior accomplishments excellent community outreach-volunteer for Red cross blooddrive, H1N1 vaccination clinic, engineering ambassador-to encourge high school studentsespecially girls, to pursue carrers in science/engineering very good future plan excellentindividual experience very good inegration research and education very good leadershipexperiences and skills and got the potential to be a future leader, considering first generation,low-income college student involved in Women In Eng society activiites Designed an innovativelab course which was used for honors degreeRating Sheet 3:Overall Assessment of Intellectual Merit: ExcellentExplanation to the applicant:The student is strong academically, with an extremely strong supportive package. She hasmaintained an excellent standard of work while simultaneous working at many jobs. She doesnot merely fulfill the obligations of her jobs, but goes above all expectations to develop newprocesses, teaching materials, etc. The applicant has substantial research experience leading to aposter presentation. The work is with tissue engineering, but not in order to produce replacementtissues. Instead, the engineered tissue is used to study the role of osteoblasts, osteocytes, andpharmaceuticals in diminishing the potential of breast cancer cells to metastasize. Her previousexperience will translate directly to her proposed research project. Again, she will use tissueculture as a means of studying bone formation and loss. In this case, she will look at themechanisms of bone loss and the interaction of exercise with bone loss. The proposal mentionsthat the mechanisms of cell signaling will be investigated. I would have liked to see thoseoutlined more clearly, and I highly recommend that the student have a clear protocol beforebeginning the task of building the bioreactor.Overall Assessment of Broader Impacts: ExcellentExplanation to the applicant:As previously mentioned, the student has held several jobs where she has not only completed herduties, but has worked to improves processes, teaching materials, etc. I have the opinion that shehas done this not to further her own ambitions, but out of extreme conscienciousness. In additionto many hours of work, a rigorous academic schedule, and participation in research, the studenthas also contributed as a leader in the BMES club and is helping to charter an AEMB HonorSociety. She has shown her capability to disseminate scientific results through preparation of amanuscript, presentation of a poster, and being a ""poster child"" of oral presentation skills. Ibelieve that she has the ability to make a meaningful impact in the field of biomedicalengineering."
213.0,"Introduction: To better understand the impact of global climate change and the effects ofincreased biogenic and anthropogenic emissions, more research is needed into the uniquephotochemical processes that take place in the Arctic atmosphere. Although geographicallyremote, the Arctic has a significant impact on globally important feedbacks to climate change.Since ozone (O ) is the precursor for most of the oxidizing, or self-cleaning, capacity in the3troposphere, it generally controls the oxidation potential of the atmosphere. Similar to thediscovery of stratospheric ozone depletion, observations of ozone depletion events (ODEs) in thepolar boundary layer (BL) were surprising.Springtime episodic depletions of tropospheric O , and the characteristic photochemistry3involved, are current areas of considerable research. These sudden and recurrent ODEs duringlate winter and spring are associated with elevated concentrations of halogenated radicals. Theconversion of inert halide salt ions into reactive halogenated species has been shown to depleteO following the onset of Polar Sunrise [e.g. 1,2]. While it is widely accepted that bromine is the3primary driver of ODEs via photochemical reactions, the role of iodine chemistry in ozonedestruction and oxidizing strength of the atmosphere is not well understood [e.g. 3,4]. Thedominance of bromine in Arctic ODEs appears to be a function of its abundance only, as evensmall perturbations in the iodine concentration significantly impact the rate of ozone depletion inrecent models [5]. These models have also shown that interactions with iodine may double theefficiency of bromine in ozone depletion [6].Problem Statement: To date, few successful in-situ measurements of iodine compounds havebeen achieved in the Arctic due to the lack of analytical methods. As a result, iodine chemistry isoften omitted from current climate models that simulate Arctic ODEs, which may significantlyunderestimate the rate of ozone depletion. Research Objectives: This study proposes theexploration of new technologies and methods for the selective, quantitative chemical detection ofiodine compounds that may play an important role in Arctic ODEs. In this study, I propose toinvestigate new analytical procedures and instrumentation to observe and quantify I and IO2during springtime Arctic ODEs. This work will then allow iodine chemistry to be incorporatedwith reduced uncertainty into kinetic analyses and computer model simulations.Method Development: To complete these objectives, I will work with Prof. Paul Shepson ofPurdue University, a leading scientist in the field of atmospheric halogen chemistry in the Arctic.I will design new laboratory techniques to study the reaction mechanics of Arctic iodine speciesusing chemical ionization mass spectrometry (CIMS), and inductively coupled Argon plasmamass spectrometry (ICP-MS). CIMS has not yet been used to detect I /IO in the High Arctic,2however, the Shepson lab has adapted a CIMS for the field and I plan to expand the capabilitiesof that instrument to detect I and IO in-situ, using SF gas as the ion source.2 6Study Site and Field Observations: Field observations of I and IO using CIMS and filter2sampling will take place in Barrow, Alaska where Beaufort meets the Chukchi Sea in the ArcticOcean. This site is ideal for studying an Arctic maritime environment as it is coastal, surroundedby first-year sea ice, and the predominantly northeasterly winds come from clean, undisturbedsnow over the sea ice. This ensures that our measurements include only halogenated compoundsfrom the natural environment. Filtered samples from the field site will be transported andanalyzed using ICP-MS at the Mass Spectrometry Center at Purdue University.Mallory Ladd Proposed Research 11/14/12Modeling: Initial models established in the Shepson lab will be expanded to include observationsof reactive iodine species (I, IO, HI, HOI, I O , INO ) significant to ODEs in the Arctic.2 2 xImprovements will be made to a multiphase, zero-dimensional model used previously to study Brand Cl radicals [6], in order to predict the chemistry of iodine species and their involvementduring ODEs. Developments to the model needed to expand on the heterogeneous iodineproduction mechanism and provide a better representation of snowpack and aerosol chemistryare as follows: nitrate and sulfate chemistry will be included; pH, temperature and theavailability of oxidants will be varied; and finally, vertical mixing rates will be updated toinclude a better parameterization of the transfer of halogenated compounds between snow,interstitial air and the boundary layer. This model will aim to quantify the fraction of O depleted3by iodine during ODEs, the impact of iodine on the rate and timescale of O depletion, and the3effect of iodine on other important atmospheric oxidants such as HO and NO .x xIntellectual Merit: Significant opportunities exist in this proposal to discover fundamentalknowledge related to the kinetics of Arctic iodine species and their relationship to ODEs. Inaddition to the development of a sensitive and selective method for quantifying reactive iodinespecies from the High Arctic during an ozone depletion event, this research will produce a modelof Arctic ozone photochemistry that incorporates the effects of I /IO chemistry in addition to2those of Br and Cl. This will lead to a better understanding of the role of iodine chemistry inODEs and other tropospheric chemical cycles important to the future of global climate change.My previous experience with analytical instrumentation has provided me with a strongfoundation for success in developing this method. Undergraduate research and my currentposition as a lab and field technician have prepared me well for conducting research in anacademic setting as well as in the field (see previous research essay). Working in the Shepson labwill be central to the growth of my knowledge about environmental modeling. Having presentedmultiple research projects, in addition to preparing a manuscript and following it throughsubmission and revision, I am trained in effectively communicating the results of my research.Broader Impacts: I will share this research via publications in peer-reviewed journals for generaland specialized audiences, and presentations at both national and international conferences. I willcontinue my involvement with the ACS and AXΣ (see personal statement) via the ACS StudentAffiliates and the AXΣ-Beta Nu chapter at Purdue. In each phase of this project, I will activelyrecruit high school and undergraduate students from underrepresented groups to gain valuableresearch experience in our lab. I will encourage students from the ACS Project SEED and theNSF REU program to apply for these positions. The interdisciplinary nature of this research willsignificantly broaden their scientific experience and enhance their understanding of theimportance of chemistry in the Arctic to global climate change. I also plan to be in close contactwith the PolarTREC program so that I may host a high school teacher during my field campaignin the Arctic. I plan to partner with them to connect directly to their students back home via acyber-based platform so that we may share our experiences in the field. Through digitalstorytelling, I will also be able to communicate the importance of this research to the broaderpublic via a website that Dr. Shepson has previously developed (www.arcticstories.net).Literature Citations: [1] Bottenheim, J.W., et al. (2002) Atmos. Environ., 36, 2535-2544 [2] Helmig, D., et al.(2012) J. Geophys. Res., 117, D20303 [3] Barrie, L.A.; Platt, U. (1997) Tellus 49B,450-454 [4] Mahajan, A., et al.(2010) J. Geophys. Res., 115, D20303 [5] Calvert, J.G.; Lindberg, S.E. (2004) Atmos. Environ., 38, (30), 5087-5104[6] Stephens, C.R. (2012) PhD Dissertation, Purdue University"
214.0,"Key Words: Proteins, Electrostatics, Folding, Stability, Interactions, 3D Modeling, pK , SmallaAngle Neutron Scattering, NMR, ab-initio calculations, molecular dynamicsHypothesis: The combination of experimental methods and computational modeling of theproperties of proteins will enable a more fundamental understanding of biophysical principlesand allow for innovative and practical solutions to problems in medicine, computationalmodeling, and bio-engineering.Introduction:The role played by electrostatics on protein folding, stability, and interactions is a crucialelement in our understanding of the cell and its functions. Particularly, charged amino acidsinfluence the stability and interactions of proteins, but their charge state depends on their pK .aTherefore, accurate predictions of pK values are critically important for successfully modelingathe pH-dependence of protein folding, stability, and interactions. Accurately modeling thesecharacteristics of proteins can improve the development of practical solutions to problems thatarise such as when certain bacteria render an entire set of antibiotics useless (Norris 2007).However, calculating pK values of amino acids in proteins and modeling protein characteristicsais a difficult task and a constant challenge in biophysics.Research Plan:To calculate the pK s of proteins, one must calculate the energy difference betweenaprotein ensembles with ionized and neutral (non-ionized) amino acids to determine the pK shift,ai.e. the change of pK induced by interactions within the protein. Common methods used in theseacalculations include the finite difference Poisson-Boltzmann (FDPB) method, the GeneralizedBorn (GB) method, molecular dynamics (MD), empirical methods, and combinations of thesetechniques. However, with each of these methods there are strengths and weaknesses inpredicting experimental data. Problems arise because protein structures are given by X-raycrystallography, and there are various structural artifacts due to the crystallization process. Thecalculations mentioned above must average over an ensemble of the multiple proteinconformations. Since proteins do not have a static structure, the flexibility of proteins introducesmore complexities as the charges will fluctuate due to this flexibility. Therefore, successfulmodeling of energies and pK values requires either (a) explicit modeling of theseaconformational ensembles or (b) the development of approaches that can mimic the effect ofensembles. My previous research focused on the second task, as described in my previous essay.My future research will focus on the explicit modeling of conformation ensembles.The problem of modeling these complicated systems can utilize experimental methods aswell. By complementing the computational modeling with experimental methods such as NMRspectroscopy and small angle neutron scattering, a stronger understanding of the properties offolding and conformation changes in protein interactions will be possible. At the University ofTennessee, there is continuous collaboration with Oak Ridge National Laboratory, and OakRidge has the premier Spallation Neutron Source (SNS). Neutron scattering allows for betterspatial resolution of protein structures since neutrons interact with nuclei and the scattering candistinguish hydrogen from deuterium. Also, my work on the Palmetto cluster at Clemson enablesme to work with larger supercomputers such as Jaguar and Kraken which are hosted at OakRidge. With the resources of NMR spectroscopy at the University of Tennessee and the SNS atOak Ridge, there is a great potential for more accurate models of proteins and a betterunderstanding of protein interactions.Anticipated Results:The use of ab-initio principles and molecular dynamics will accurately model changesmade to ionization sites within proteins as I have demonstrated through the pKa cooperativeinitiative. With small angle neutron scattering, I will be able to use protein crystals to createmore accurate 3D images of the protein. I will use this data to measure the accuracy of theproposed theoretical models and improve these models. Because of prior success, I am hopefulthat the availability of new information from the scattering will further improve the accuracy ofthe models and aid in our understanding of protein folding, stability, and interactions.During my research with Dr. Serpersu, I learned how important it is to utilize variousexperimental methods such as ITC and NMR to understand properties of proteins. These are notthe only experimental tools available, and I will learn and use all of the necessary methods. Theuse of experimental methods will be used to further verify and understand protein characteristics.It is important to investigate whether or not the addition of ab-initio calculations correctlymodels pK s. If the initial ab-initio calculations incorrectly model the pK , I propose that ab-a ainitio calculations are completed for all sites that are the proximal to the charged amino acid.This will allow for more flexibility in the MD calculations. Using the method proposed above, itis expected that the results obtained will align closely with the experimental results. I havesuccessfully modeled charged amino acids within alpha helices of proteins. In this case, ab-initiocalculations rearrange the structure so that the side chain of the titratable group is modeled asfacing the surrounding water or other medium. If the modeling of proteins using theaforementioned methods is indeed accurate, then the results of this research will allow scientiststo predict the pK of proteins and to model the 3D structure of proteins more accurately.aBroader Impacts:A more fundamental understanding of the properties of proteins will also allow us to takesteps towards the development of methods to combat antibiotic resistant bacteria. The results ofmy research will be published in peer-reviewed scientific journals, and I will present my researchto the public to cultivate an interest in science among the general public. My local presentationsof research have struck many chords with young students. I mentor high school studentsthroughout the year, and they consistently ask me how they can get involved with research.Many of these students have gone on to research in their undergraduate careers. Throughencouraging and communicating with younger students, there is a great potential that they willalso become interested in how they can help change the world through the progress of science.Works Cited:Norris, A. and Serpersu, E. “Interactions of coenzyme A with the aminoglycosideacetyltransferase (3)-IIIb and thermodynamics of a ternary system.” Biochemistry. (2010).49(19): 4036-42Talley, K. and Alexov, E. “On the pH-optimum of activity and stability of proteins” Proteins:Structure, Function, and Bioinformatics. (2010)Talley, K., Ng, C., Shoppell M., Kundrotas P.J. and Alexov, E.""On the Electrostatic Componentof Protein-Protein Binding Free Energy"" PMC Biophys. (2008)"
225.0,"Improve Surface Age DeterminationAli BramsonKeywords: primary and secondary craters, hierarchical clustering, networks, dendrogramBackground:Crater statistics are a fundamental tool for learning about the geology and surfaces ofplanets, as well as the population of bodies in the solar system doing the impacting. Withoutphysical samples, crater densities remain the only way we can estimate absolute ages ofplanetary surfaces [1]. Impacts generally are considered to happen randomly in time and space,so the more craters a surface has, the older it is. The size-frequency distribution (SFD) of cratersfollows an inverse power law [2], so the number of craters increases with decreasing craterdiameter. This means smaller craters are more statistically significant when used for calculatingsurface unit ages [3]; however doubts have recently emerged about how these smaller cratersshould be interpreted.Secondary craters form when the ejecta from a large crater re-impacts the surface. Thesesecondary craters lead to higher than expected crater counts within a geologic instant [2], whichpresents a problem for age determination because it makes a surface appear artificially older.Most of these secondaries appear close to their primary in clustered patterns such as rays and socan be excluded from crater counts. However, they often can be hard to distinguish frombackground small primary craters. This is especially true if they re-impact far from their source(at high velocities), in which case they match the circular morphology and depth to diameterratios of primary craters.A detailed study of the Europan surface by Bierhaus et al. 2005 shows that secondarycraters comprise up to 95% of craters with diameters < 1 km. The ability to extract thesesecondary craters from the background primary crater density is essential if we wish toaccurately constrain the ages of surfaces. The amount and quality of imaging data from recentplanetary missions (such as the Mars Reconnaissance Orbiter, Mercury Messenger, and LunarReconnaissance Orbiter) drive the need for a technique that can not only identify secondarycraters, but also work on the very large data sets we are currently receiving.Fortunately, there is a growing body of work in computer science, devoted tounderstanding networks and clustering, which can assist in the analysis of these data. Inparticular, social networking algorithms have been developed to better understand how people indifferent groups are connected [4], and I have experience from my undergraduate senior thesis inapplying such techniques to astronomy (galaxy groups). I propose to combine my interest incomputer science and passion for planetary science by applying hierarchical clusteringtechniques common to network science to find patterns in spatial locations of craters. Applyingthese techniques to analyze the patterns of crater locations is a logical project that could prove tobe very insightful, helping us to distinguish primary craters from secondary.The Algorithm:The hierarchical clustering technique [5] iteratively builds a hierarchy of clusters bystarting with all nodes (the craters in question, in my case, or people in the social science setting)as separate groups and connecting them until they are all in the same group (agglomerative). Toconnect these features, it creates a distance matrix, a matrix of “similarity”, where each elementwill be the distance between two craters. In a social setting, the distance matrix could use numberof friends in common as a measure of similarity. The agglomerative technique then merges thetwo nodes that are the closest into one cluster. These nodes are removed from the distance matrixwhile our new cluster is added in, and the process is iterated until all objects have been mergedinto one cluster.Bierhaus et al. 2005 utilized aspects of this algorithm, combining them with otherclustering and statistical techniques in his study of Europa’s surface. However, Europa is asimpler case because it is sparsely cratered compared to other surfaces, making it easier todisentangle primary from secondary craters [3]. I propose to apply this algorithm to the morecomplicated Martian surface, using the latest database of impact craters on Mars from Robbins &Hynek 2012 [6,7].Data:I will use a new global Martian (covering >99% of the surface area of the planet) craterdatabase from which is freely available via the U.S. Geological Survey’s (USGS) Mars CraterConsortium, for my study [6,7]. This database contains 384,343 craters and is statisticallycomplete down to diameters ≥ 1km. The database does have secondary crater classification for aselect section of the database [1,8]. This will allow me to compare my technique to the manualclassification of Robbins and Hynek. This comparison can be used to assess the accuracy of myautomatic methods.Expected Results:I will use the output of the hierarchical clustering to yield a tree-like “dendrogram” toshow the order in which the craters have been connected. Rosolowsky et al. (2008) have useddendrograms to determine the structure of molecular clouds. Where the branches of theirdendrograms correspond to self-gravitating molecular cloud structures, the branches of mydendrograms would correspond to larger networks of craters. The shape of these branches cantell us about the spatial patterns of the craters; if the dendrograms are flat, with manyconnections at equal distances, the features are distributed homogenously. Long connectionshigh in the dendrogram connecting groups of low-level links indicate the features spot thesurface of the planet in a much less uniform manner (i.e. we can automatically identify clusters).I will also create dendrograms for a random distribution of objects of equal density as acomparison. I predict that the comparison to random will extract the primary craters that dot thesurface randomly, leaving behind the probable secondaries that will appear in groups of low-level links that deviate from random.The advantage of this technique is that it could be used in any field that involvesclustering and connections e.g. creating dendrograms of asteroid proper orbital elements couldlead to new asteroid groupings. We might also expect the clustering of surface features on Io tobe connected with volcanic events or other asymmetries between the leading and trailinghemispheres of tidally locked moons. The broad applicability across many disciplines is a keypart of the broader impact and intellectual merit of this research. While I am passionate aboutplanetary science and this research’s applicability within the field, the algorithms and techniquesI use will be valuable to many fields.References: [1] Robbins, S.J. & Hynek, B.M. 2011, GRL, 38, L05201. [2] McEwen, A.S. & Bierhaus, E.B. 2006,Annu. Rev. Earth Planet. Sci., 34, 535. [3] Bierhaus, E.B., Chapman, C.R. & Merline, W.J. 2005, Nature, 437,1125. [4] Mucha, P.J., et al. 2010, Science, 328, 876. [5] Newman, M.E.J. & Girvan, M. 2004, Phys. Rev. E, 69,026113. [6] Robbins, S.J. & Hynek, B.M. 2012, JGR, 117, E05004. [7] Robbins, S.J. & Hynek, B.M. 2012, JGR,117, E06001. [8] Robbins, S.J. & Hynek, B.M. 2011, JGR, 116, E10003. [9] Rosolowsky, E.W. et al. 2008, ApJ,679, 1338."
226.0,"StressKEYWORDS: personality; cognitive appraisal; emotion; stress reactivity; ecologicalmomentary assessmentINTRODUCTION: Everyone experiences stressful life events, but the magnitude of stressexperienced in response to the same stressor can vary considerably between two people. Forexample, certain people tend to express more heightened negative emotion in response to lifeevents and therefore perceive their lives as more stressful.1 Personality factors such as increasedneuroticism, behavioral inhibition, and negative attributional style are also implicated in thisgreater stress reactivity1,2. I propose that these individual differences in response to stressors arestrongly influenced by personality, and lead to variation in cognitive-emotional appraisal andprocessing of the stressful lifeSTRESSORevent. In turn, this cognitive-emotional appraisal contributes to Cognitive Appraisalvarying physiological reactivity, Personality -Worry/Ruminationas measured by immune, -Neurotic/Anxious -Perceived Control Physiologicalcardiovascular, and endocrine -Behaviorally- -Perceived Severity ReactivityInhibited-Immuneresponse (See Figure 1).-Cardiovascular-NegativeCognitive appraisal involves -EndocrineAttribution Style Emotionalthe perceived severity andReactivityperceived controllability of the-Negative Affectstressor, as well as the magnitudeFigure 1. Proposed model of personality, cognitive appraisal,and frequency of persistent,emotional reactivity, and physiological reactivity in response to stressmaladaptive, negative thoughtsleading up to and following the stressor (worry/rumination). Emotional reactivity involves thepresence of positive or negative affect in response to the stressor (See Figure 1). A betterunderstanding of how subjective cognitive-emotional reactions to stress relate to individualvariation in physiological reactivity is needed to better understand key individual differencesbetween people.It is well established that stress relates to immunological dysregulation (e.g. slowed woundhealing and increased viral susceptibility).3 Yet the interplay between individual differences instress reactivity and immune system reactivity has seldom been investigated, particularly withregard to how such changes play out in real time, real-life human contexts.2 One reason for thislack of understanding is that studies of immune reactivity have largely been limited to short-termlaboratory studies that use blood draws for serum/plasma-based biomarkers. With less invasivesalivary biomarker techniques that are currently in development, more ecologically-validstudies of individual differences in stress reactivity could be conducted.RESEACH AIM 1: To investigate how individual differences in personality relate todifferences in physiological reactivity, specifically markers of immune system function.RESEARCH AIM 2: To examine how cognitive appraisal of a stressor and emotional reactivityto a stressor mediate the relationship between personality and physiological reactivity.RESEARCH AIM 3: To determine how relationships between personality, cognitive appraisal,emotional reactivity, and physiological reactivity play out over time in an ecological context.METHODS: I have already independently conducted an extensive literature review to elucidatethe connection between salivary and blood measures of inflammation and plan to publish areview article on this work. Along with Penn State investigators who are spear-heading furtherinvestigation of salivary immune diagnostics, I hope to incorporate salivary measures of immunereactivity into novel methodological approaches to studying individual variation in the stressresponse. My research program during my graduate training will culminate in myimplementation of three original studies described below.STUDY 1 (S1): I will begin by using an existing data set to examine connections betweenindividual differences and immune responses to stress. My advisor is PI on a longitudinalinvestigation of the degree to which inflammation mediates connections between stress andcognitive aging among diverse adults. I will be able to use those data to explore new dimensionsof how personality (e.g. behavioral inhibition, negative attribution style) is related to cognitive-emotional responses to stress and, consequently, to physiological reactivity over a 4-year period.STUDY 2 (S2): To experimentally model the relationship between personality and immunefunction, I will expose participants to an acute social lab stressor in order to measure individualdifferences in stress reactivity through endocrine, immune, and cardiovascular measures andthrough self-reported assessments of cognitive-emotional state. Specifically, immune functionwill be measured through circulating inflammatory markers obtained via saliva and blood.STUDY 3 (S3): The data from S1 and S2 will be used to inform a larger naturalistic study whichwill utilize ecological momentary assessment (EMA), a method whereby participants report whatthey are feeling and/or how they are behaving in real-time in natural settings. In collaborationwith Penn State’s Dynamic Real-Time Ecological Ambulatory Methodologies (DREAM)initiative – a unique program designed to popularize and educate researchers on EMA methods –participants will be given smart phones which will prompt them to fill out assessments ofcognitive-emotional states and to give saliva samples at specific time points. State-of-the-arthierarchical linear modeling and structural equation modeling will be utilized for mediationanalyses in S1 and S2, as well as to examine between-subject and within-subject variation,including how multiple daily assessments change over time in S3.INTELLECTUAL MERIT and BROADER IMPACTS: With the levels of stress that manyin our society are facing, it is imperative to better understand the mechanisms by which somepeople become more susceptible to the physiological consequences of stress. My program ofresearch has potential implications for improving quality of life, coping strategies,interpersonal relationships, and productivity in the workforce, as well as fostering self-actualization through stress reduction. These three studies will advance the field ofpsychoneuroimmunology by examining the underutilized combination of less-invasivesalivary inflammatory biomarkers with respect to individual differences. The additionalassessment of this concept through EMA will allow for greater external validity of results andhelp popularize more ecologically-valid studies. Pre-existing partnerships with a number facultywho already investigate individual differences in the stress response makes me well-poised toimplement the tri-part research initiative I am proposing. In conjunction with the DREAMinitiative and Penn State’s Centers for Healthy Aging and “De-Stress Zone” (a biofeedbackfacility), I also plan to design and hold workshops for education on ecological measurementof stress and stress self-management to implement with diverse populations. With all of theopportunities for research and outreach available at Penn State, my current position places me inan ideal situation to begin explaining the individual variation that is often overlooked inphysiological psychology studies.REFERENCES: [1] Suls, J., Green, P., & Hillis, S. (1998). Emotional reactivity to everyday problems, affectiveinertia, and neuroticism. Pers & Soc Psych Bltn. 24: 127-136. [2] Segerstrom, S.C. (2000). Personality and theimmune system: Models, methods, and mechanisms. Annals of Behav Med. 3:180-190. [3] Contrada, R., & Baum,A. (Eds.). (2010). The handbook of stress science: Bio., psych., & health. New York, NY: Springer Publishing Co."
231.0,"Davidow, Juliet Y.I am fond of the saying that research is “me-search”, meaning that some researchers tend tofocus their work on issues that are personal or that they are curious about understanding in someway about themselves. I am one of these researchers. My broad interest in how adolescents learnand apply learned information stems from my own learning experiences as well as myprofessional and research experiences working with different developmental populations. Here Iwill highlight aspects of my educational experience that have contributed to my interestspecifically in learning mechanisms, and in the period of adolescence.Interest in Adolescence: As an undergraduate student, I wanted to gain direct experience toexplore my interest in clinical psychology. To this end, I volunteered at St. Luke’s-RooseveltHospital in New York City, working with an ethnically and socioeconomically diverse group ofpatients in the Alternative Adolescent Day Program (AADP) and the Comprehensive AddictionsProgram for Adolescents (CAPA). This particular set of outpatient programs appealed to mebecause in addition to therapy and treatment, the patients took classes towards their GeneralEquivalency Diploma or High School Diploma in a curriculum taught by New York Board ofEducation teachers. I tutored the patients in their class work, helped them complete theirhomework, as well as facilitated social milieu therapy projects, such as a school newspaper. Thepatients reminded me of the Montessori philosophy; Adolescence is a period characterized bychanges and challenges, and these patients additionally struggled with psychopathology andaddiction, and despite all these obstacles were committed to their schooling.Interest in Learning: My own passion for learning developed in the Montessori school Iattended from 3 to 13 years of age. Two major principles of the Montessori philosophy are thatwhen children are motivated to learn they will engage in self-directed study and that every childhas different optimal strategies for learning. Peer-to-peer-learning is also pivotal, and theMontessori classroom is built around encouraging it, with 3 grade-level groups in a singleclassroom (e.g. 4th, 5th and 6th graders). This structure allows students to tap multiple resources,from books and other materials to more senior students in the classroom, before turning to theteachers (of which there are usually 2-3 per classroom). This unique early experience of seekingacademic help from my classmates, and in turn sharing my knowledge with my peers, instilled inme the desire to learn so that I could in turn teach another.Because of my strong research skills and academic record, I have had the rare opportunityto work under an extraordinary group of mentors. Specifically, Drs. Dima Amso, BJ Casey, andDaphna Shohamy have deeply impressed me as rigorous, female scientists, whose researchdirectly impacts the lives of children and adults, in healthy and other populations. I aspire to be astrong female role model in science, a researcher whose work can improve educational practicesacross the country, and an educator directly bringing my love of learning to students, and towardsthese ends I have begun my PhD work at Columbia University. I believe my proposed researchholds the potential to expand into a career dedicated to understanding the brain-and-behaviorinteractions necessary for successful navigation through adolescence.Broader impact in the community: I am beginning to share the knowledge I have gainedfrom my mentors with a rising generation of hopeful scientists. In early December, I will bepresenting and discussing my research at a ‘Careers in Science’ fair for middle and high schoolstudents, organized by the Women in Science at Columbia (WISC) and the Center forEnvironmental Research and Conservation (CERC). This event will be attended by asocioeconomically diverse group of students from all over New York City, with a focus onencouraging young women in particular to consider careers in the sciences. This emphasis is ofparticular importance to me, because I am woman working in the sciences, and my greatest rolemodels and influences to follow this course have been women.Page 1 of 2(cid:1)(cid:1)2010 NSF Graduate Research Fellowship: Personal StatementDavidow, Juliet Y.A key goal of mine, expressed in my personal statement from my previous submission,was to begin sharing my work directly with adolescents in the community. To this end, I will bemaking presentations at local high schools, starting with The Calhoun School in Manhattan,speaking in classrooms about what cognitive neuroscience has taught us about changes in behaviorand the developing brain during adolescence.I have been mentoring a high school student, Michael, and supervising him through aresearch project in the lab that will culminate in his applications to the Intel National ScienceTalent Search, the New York Science and Engineering Fair, and other award programs. To thisend I have been teaching Michael the foundations of research methods, including how to surveythe existing literature, statistical tools, and the ethical principles researchers must abide by.Michael is interested in how socioeconomic differences in adolescent populations might relate tothe learning and generalization mechanisms outlined in my research proposal and the possible rolegeneralization plays in racial stereotyping. Mentoring Michael has been rewarding, and I wasexcited at the opportunity to interact one-on-one with a student at his level on such a long-termproject, given how uncommon it is to have students before the undergraduate level work hands-onon research projects.Graduate Training: My first year of graduate study has been punctuated withacknowledgements of my accomplishments. I was the recipient of the Leo Rubinstein EndowedFellowship. I applied and was awarded a travel grant from the Kavli Institute for Brain Sciences topresent results at the recently past Annual Meeting of the Society for Neuroscience [1]. This study,conducted in my first year of graduate work, tested 74 healthy adults behaviorally, and tested asubset of 53 of these adults in a functional Magnetic Resonance Imaging scan. This sample ofadults will be used as a comparison group in the cross-sectional, developmental study that Ipropose in this application. And perhaps most notably, I was recognized with an HonorableMention on my first submission of my NSF GRFP application. I was pleased and excited to seethe enthusiastic responses from the raters of my essays, and found their feedback to be extremelyhelpful. The points raised by my raters indentified clear areas where my proposal could beimproved, and by directly addressing these issues, I believe my current, revised proposal isstronger.This past semester, I have been taking a course in Methods of Teaching towards improvingmy skills as a Teaching Assistant (TA) for Undergraduate courses at Columbia University. I willhave the opportunity to directly apply my new skills this spring, when I TA for the introductoryDevelopmental Psychology course, a class I am eager to work on, given my strong background indevelopmental research and methods.With the support of Dr. Shohamy and her expertise in neural networks for learning, I havean ideal mentor for exploring the development of learning processes over the course ofadolescence. With cutting edge behavioral and brain imaging facilities at Columbia, I have accessto the testing resources my research requires. Situated in Upper Manhattan, I am surrounded bypeople with diverse ethnic and socioeconomic backgrounds, providing me access to arepresentative population of potential research participants that will allow me to generalize myresults for the benefit of many children. These elements combined with my research backgroundgive me confidence that I will be an outstanding student and researcher whose contributions willimpact a number of fields within psychology and beyond.Reference: 1. Davidow, J., Kahn, I., & Shohamy, D. (November, 2010). The ability to learn and generalizeknowledge is related to intrinsic interactions between multiple memory systems during rest. SfN Annual Meeting,California, USA.Page 2 of 2(cid:1)(cid:1)2010 NSF Graduate Research Fellowship: Research ProposalJuliet Y. DavidowLearning in adolescence: Neural mechanisms and implications for education.Keywords: Learning, education, development, adolescence, striatum, hippocampus, fMRI.Introduction. There have been significant advances in understanding cognitive and neuralmechanisms for learning in adults, with important implications for everyday learning situations[e.g. 1, 2, 3]. However, far less is known about the cognitive and brain mechanisms underlyinglearning during the critical developmental stage of adolescence. This research program aims tobridge this gap. The proposed research will use behavioral studies combined with functionalMagnetic Resonance Imaging (fMRI) in healthy adolescents to delineate the cognitive and neuraldevelopment of specialized learning systems over the course of adolescence (10-18 years of age).The results will provide a novel understanding of learning mechanisms during adolescenceand will inform educational approaches towards learning in the classroom.Background & Rationale. Converging evidence from research in animals, patients andhealthy adults demonstrates that there are different kinds of learning that depend on distinct neuralsystems [2, 3]. Gradual, feedback-based learning of stimulus-response associations – oftenreferred to as “habit” or “incremental” learning - depends on the striatum [4, 5]. This system issensitive to feedback and results in knowledge that is relatively inflexible and specific to thecontext in which the learning took place [6]. A distinct and independent “declarative” or“episodic” system supports rapid learning of events and depends on the hippocampus [1, 6]. Incontrast to the striatum, the hippocampus is thought to form knowledge that is flexible and easilygeneralized to novel situations and contexts [1, 6]. It has been shown that individuals who showmore hippocampal activation during learning are more likely to integrate and generalize what theylearned [5]. Together, these findings indicate that in the healthy adult brain, there is a balancebetween activity in the striatum and the hippocampus during learning, with consequences for howlearned knowledge is used. A key open question is how developmental changes in learningmechanisms relate to changes in the striatum and the hippocampus during adolescence.Some insight into this question comes from longitudinal research of structural brainchanges, which revealed differential developmental trajectories in the striatum and thehippocampus [7]. The volume of the striatum peaks around pubertal onset and then diminishes,with reductions continuing into early adulthood [7, 8]. Far less is known about the developmentaltrajectory of the hippocampus [7, 9]. However, existing results support relatively early maturationof the hippocampus, consistent with adult-level episodic learning performance in children [10].Together, these findings suggest that the striatum and the hippocampus may develop atdifferent rates during adolescence, with important implications for learning. Given thestructural differences in the brain’s learning systems over the course of adolescence, what is thetrajectory of different forms of learning (‘incremental’ vs. ‘episodic’)? To address questions aboutinteractions between behavior and brain mechanisms, I will characterize the relationship betweenlearning processes and brain development in human adolescents using a paradigm demonstrated inadults to be a sensitive index of both striatal-dependent incremental learning and hippocampal-dependent episodic learning. These studies will investigate the neural mechanisms in adolescentlearning so that educational programs can be informed directly by cognitive neuroscience datafrom adolescents, instead of making inferences from studies of adults.Experimental methods. I propose three studies that make use of an incremental learningand generalization paradigm (‘acquired equivalence’)[e.g. 5], shown to selectively probe differentforms of learning and their neural substrates in adults. Although ideally these studies would beconducted longitudinally, the constraints of my time as a graduate student make cross-sectionaland between-subject studies most feasible. The acquired equivalence (AE) task consists of twophases. First, subjects engage in feedback-based learning where they learn to associate a series of(cid:1) Page 1 of 22010 NSF Graduate Research Fellowship: Research ProposalJuliet Y. Davidowfaces with different objects. This feedback-based learning phase has been shown to depend on thestriatum. In the second phase, subjects are tested on their memory for the previously learnedassociations. Critically, they are also asked to generalize what they learned to novel stimuluscombinations. This ability to generalize depends on the hippocampus [e.g. 5].Figure. ‘Acquired Equivalence’ task structure.a. In Phase 1, subjects learn a set of independent but overlappingassociations. Learning is incremental and based on feedback.b. In Phase 2, subjects are tested for their (1) memory on learnedpairings (Learned) and for (2) inferential transfer to novelcombinations they have not previously seen (Generalized).This paradigm is particularly well suited for studying special populations, including youngersubjects. Specifically, it allows as many learning trials as is necessary before the second testphase. This unique feature will permit us to independently explore adolescent learning trajectoriesfor both incremental learning and for episodic generalization.(cid:1)Using fMRI, I will record brainactivity at learning and test phases of the task while measuring subjects’ behavioral responses. Byusing converging methods, I can simultaneously characterize incremental learning from feedbackand flexible generalization of learned information in adolescents while exploring individualdifferences in reliance on neural networks implicated in adult performance. Study 1 will use theAE task with feedback during the learning phase to ask how adolescents learn to associate itemsand generalize to novel pairings, and delineate the underlying neural networks. Study 2 will usean AE task that compares active learning-with-feedback to passive learning-by-observation, withno feedback. This manipulation has been shown to modulate both hippocampal and striatalcontributions [4] and will allow me to compare memory and generalization from active versuspassive learning, qualify what kinds of learning are most effective for different kinds of outcomes,and probe the role of active engagement for successful learning. Study 3 will use the AE task andwill manipulate whether the feedback involves monetary rewards or not, to explore the impact ofheightened reward sensitivity during adolescence [8] on learning behaviors. Together, thesestudies will build a foundation for understanding (I) learning and generalization behaviors, (II)differential maturation of brain function, and (III) behavior-and-brain interactions over the courseof adolescent development. This foundation will be critical in bridging the research fields ofneuroscience, development, and education, and also holds potential to impact society withimplications for special education, early learning intervention, and psychopathology.Future studies will probe the role of individual differences on learning behaviors, includinginfluences from social environment and genetic phenotypes. Due to the dearth of learning researchin healthy adolescents, my proposal promises to put forward novel information about behavior andbehavior-and-brain interactions to bear on several fields. Understanding typical adolescentdevelopment of learning mechanisms and how knowledge is applied in novel circumstances isimperative to adolescents’ success in the classroom and when faced with challenging decisions.References 1. Eichenbaum, H.E. & Cohen, N.J. From “Conditioning to Conscious Recollection”, 2001.2. Gabrieli, J.D. Annual Review of Psychology, 1998. 49: 87-115.3. Knowlton, B.J., Mangels, J.A., & Squire, L.R. Science,1996. 273: p. 1399-1402.4. Shohamy, D., et al. Brain, 2004. 127: p. 851-859.5. Shohamy, D., & Wagner, A.D. Neuron, 2008. 60: p. 378-389.6. Shohamy, D., et al. Journal of Cognitive Neuroscience, 2008. 21(9): p. 1820-1832.7. Giedd, J.N. Journal of Adolescent Health, 2008. 42: p. 335-343.8. Somerville, L.H., Jones, R.M., & Casey, B.J. Brain and Cognition, 2010. 72(1): p. 124-133.9. Gogtay, N., et al. Hippocampus, 2006. 16: p. 664-672.10. Ofen, N., et al. Nature Neuroscience, 2007. 10(9): p. 1198-1205.(cid:1) Page 2 of 2Ratings Sheet 1 of 3Score for Davidow, JulietIntellectual Merit CriterionOverall Assessment of Intellectual MeritExcellentExplanation to ApplicantThecandidatehasanexcellentrecordofresearchexperience. Thisisevidencedbyhertwoco-authoredpapersand multiple presentations. Also, her references speak to her independent contributions to the researchprograms. She has presented a very well crafted research proposal. The justification for her hypotheses iscompelling and the methods are sound. It will be an interesting and potentially important study.Broader Impacts CriterionOverall Assessment of Broader ImpactsExcellentExplanation to ApplicantI appreciate the candidate’s recognition of the important role that scientists have in improving scienceeducation in their communities. She shows ample evidence of giving back to her community through hermentorship of young people and participation in community projects. She will be an engaged scientist whowill continue to help others in her broad community.2011 NSF GRFP Applicant: Juliet Davidow Applicant ID: 1000100934Ratings Sheet 2 of 3Score for Davidow, JulietIntellectual Merit CriterionOverall Assessment of Intellectual MeritExcellentExplanation to ApplicantThe applicant demonstrates are strong record of research training through their undergraduate and post-baccalaureate employment including an excellent record of publication/presentation. She has demonstratedboth independence and insight. Her broad training is noted.Broader Impacts CriterionOverall Assessment of Broader ImpactsExcellentExplanation to ApplicantThe applicant demonstrates a sustained commitment to the ideals of this criterion through her volunteer,mentoring,andserviceactivities. TheseincludeparticipationinWISCevents,speakingatlocalhighschoolsabout cognitive neuroscience, and mentoring high school students. Her application would be even strongerwith concrete plans that address this criterion in the near and far terms.2011 NSF GRFP Applicant: Juliet Davidow Applicant ID: 1000100934Ratings Sheet 3 of 3Score for Davidow, JulietIntellectual Merit CriterionOverall Assessment of Intellectual MeritVery GoodExplanation to ApplicantThe applicant has considerable experience working in various laboratories and has mastered a large set ofresearch skills that have prepared her to function as a research scientist. She has two journal articles, onearticle submitted for publication, and several national conference presentations. Thus she understands theprocess of scientific research from beginning to end.Her proposed line of research is based on a broad appreciation of the literature and is thoughtfully andcarefullyplanned. Therewereafewdetailslackingintheresearchplanthatwereimportantinunderstandingthe practicality of the proposed effort.Broader Impacts CriterionOverall Assessment of Broader ImpactsExcellentExplanation to ApplicantEvidencefortheapplicant’senthusiasmforeducationanddiversityissuescanbefoundinherpastvolunteerwork, her efforts to mentor students in research, and in her choice of research topics.Theproposedresearch,ifsuccessful,hassomebroadapplicationsthatwereclearlyindicatedbytheapplicant.2011 NSF GRFP Applicant: Juliet Davidow Applicant ID: 1000100934file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating1.txtLogo-asee-printNSF GRFP RESULTS*Juliet Davidow* | logout </ratingsheets/logout>Rating Sheets* *2010 Rating Sheet 1** 2010 Rating Sheet 2 </ratingsheets/ratingsheets/84303>* 2010 Rating Sheet 3 </ratingsheets/ratingsheets/84304>Overall Assessment of Intellectual Merit: Very GoodExplanation to the applicant:Excellent academic preparation with impressive GRE scores. Sought outundergraduate and postgraduate research experiences and has continued toproduce at the graduate level, with one published paper and nineconference papers (one first-authored). her letters of recommendationwere very strong and attested to her fine research ability. Her proposedresearch plan was well-articulated and based on past published research.Overall Assessment of Broader Impacts: Very GoodExplanation to the applicant:The broader impacts of her research and her role as a scientist were notarticulated directly. She has an excellent record of community serviceand has demonstrated an understanding of the scientist's roe incommunicating findings to the larger community. Articulated an interestin montoring and teaching,OTHER YEARS* *2010*OUTSIDE LINKS* Fastlane <https://www.fastlane.nsf.gov/grfp/>file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating1.txt (1 of 2) [9/21/11 12:19:11 AM]file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating1.txt* NSF GRFP Program Announcement <http://www.nsf.gov/grfp>National Science Foundation Graduate Research Fellowship ProgramOperations Center Administered by: American Society for EngineeringEducation (ASEE)1818 N Street NW, Suite 600 Washington, DC 20036 | 866-NSF-GRFP,866-673-4737(toll-free from the US and Canada) or 202-331-3542 (international) |info@nsfgrfp.org <mailto:info@nsfgrfp.org>file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating1.txt (2 of 2) [9/21/11 12:19:11 AM]file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating2.txtLogo-asee-printNSF GRFP RESULTS*Juliet Davidow* | logout </ratingsheets/logout>Rating Sheets* 2010 Rating Sheet 1 </ratingsheets/ratingsheets/84302>* *2010 Rating Sheet 2** 2010 Rating Sheet 3 </ratingsheets/ratingsheets/84304>Overall Assessment of Intellectual Merit: ExcellentExplanation to the applicant:The applicant has extensive research experience and a strong academicbackground. Her proposed research plan is well laid out. She has goodcommunication skills, works well with others and independently.Overall Assessment of Broader Impacts: Very GoodExplanation to the applicant:The applicant expresses a desire to be a role model and participate inoutreach programs to deliver science to those who might not otherwise beexposed to it. Her research will enhance scientific and technicalunderstanding. Improved understanding of how adolescents learn will dodoubt benefit society. The applicant could more explicitly address thebroader impact criteria, especially regarding encouraging diversity.OTHER YEARS* *2010*OUTSIDE LINKS* Fastlane <https://www.fastlane.nsf.gov/grfp/>* NSF GRFP Program Announcement <http://www.nsf.gov/grfp>file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating2.txt (1 of 2) [9/21/11 12:19:55 AM]file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating2.txtNational Science Foundation Graduate Research Fellowship ProgramOperations Center Administered by: American Society for EngineeringEducation (ASEE)1818 N Street NW, Suite 600 Washington, DC 20036 | 866-NSF-GRFP,866-673-4737(toll-free from the US and Canada) or 202-331-3542 (international) |info@nsfgrfp.org <mailto:info@nsfgrfp.org>file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating2.txt (2 of 2) [9/21/11 12:19:55 AM]file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating3.txtLogo-asee-printNSF GRFP RESULTS*Juliet Davidow* | logout </ratingsheets/logout>Rating Sheets* 2010 Rating Sheet 1 </ratingsheets/ratingsheets/84302>* 2010 Rating Sheet 2 </ratingsheets/ratingsheets/84303>* *2010 Rating Sheet 3*Overall Assessment of Intellectual Merit: Very GoodExplanation to the applicant:Strengths: The applicant has participated in undergraduate research andas a lab manager, followed by work as an RA, and is now enrolled ingraduate study. From these experiences, the applicant learned basicpsychological research tools, including behavioral study design andanalysis, measuring eye movements, ERPs and fMRI. All of these skillswill be highly valued in the applicant's ongoing training. Theapplicant's research efforts have resulted in an honors thesis, onelocal invited talk, one first authored international conferencepresentation, authorship on numerous additional conference abstracts,and authorship on two manuscripts in various stages of publication.Weaknesses: The research plan lacks some important information. Forexample, is there any behavioral evidence that the incremental andepisodic learning systems have different developmental trajectories?This is important to establish prior to moving the experiment into thescanner, which isn't going to tell us much about mechanisms, just moreabout ""where"". I'm assuming that this is a between-subjects design, andnot a longitudinal study, because a graduate student career is likelytoo short to measure longitudinally. However, this is not specified. Theapplicant does not have any first-authored peer-reviewed manuscipts atthis time.Overall Assessment of Broader Impacts: Very GoodExplanation to the applicant:The applicant has served both as a peer counselor and as a volunteerfile:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating3.txt (1 of 2) [9/21/11 12:20:15 AM]file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating3.txttutor working with teenagers with drug addiction difficulties. Theseexperiences motivated the applicant to pursue studies on the typicaladolescent development. The applicant intends to promote neuroscience inK-12 classrooms with the help of SFN's online materials.OTHER YEARS* *2010*OUTSIDE LINKS* Fastlane <https://www.fastlane.nsf.gov/grfp/>* NSF GRFP Program Announcement <http://www.nsf.gov/grfp>National Science Foundation Graduate Research Fellowship ProgramOperations Center Administered by: American Society for EngineeringEducation (ASEE)1818 N Street NW, Suite 600 Washington, DC 20036 | 866-NSF-GRFP,866-673-4737(toll-free from the US and Canada) or 202-331-3542 (international) |info@nsfgrfp.org <mailto:info@nsfgrfp.org>file:///Users/ironoap/Desktop/Davidow_NSF/Feedback_2010/rating3.txt (2 of 2) [9/21/11 12:20:15 AM]"
236.0,"KEYWORDS: digitallogic,evolutionarycircuitdesign,geneticmodels,inversion,recombination,systemsbiology,transcriptionalnetworks. Thisprojectisoriginalandofmyowndesign.BACKGROUND: Biologicalsystemsself-regulatevianetworksofinteractingtranscriptionfactors.Such networks produce complex behavior; some theorists have argued that they can produce anybehaviordesired.1 However,existenceproofsdonotguaranteethatpractical solutionsexist.One method to test if a desired behavior can be achieved is to run a computer simulation. Thecomputer can test thousands of designs quickly, converging on the best matches. This process hasbeenusedtoevolvedesignsforoscillators,latches,andotherinterestingbehaviors.2,3To demonstrate and extend the power of simulated evolution for biological network design, Iwillevolveageneticallyencodedbinarycounter. Syntheticbiologyhaslongusedbinarycountingas a model system. It is perhaps the simplest behavior which requires a full implementation ofdigitallogic;thisissignificantbecauseoftherobustnessandsimplicityofdigitalcircuits. Countershave inspired many entries in the iGEM design contests4 as well as high profile experimentalattempts,suchastheunary(linear)counterinlastyear’sScience.5 However,tomyknowledge,allthesedesignshaveusednonstandardelementssuchasrecombination-basedgeneticswitches.RESEARCH PLAN: I will perform simulated evolution and compare counter designs with andwithout switches. Viable designs will be refined by hand and ultimately become physical DNAconstructs for testing in vivo. I predict that only designs evolved with switches will be viable.These results will be significant in themselves; they will also inform the synthetic biology designprocessandimprovethemodelinginfrastructureforfutureresearch.ON COUNTERS: Briefly, a counter element changes state every nth time it is triggered. For abinary counter, n = 2. One could imagine using a binary counter to produce yeast that turn greenfor every 2nd cell division. More seriously, one could imagine a researcher in aging or cancerconnectingfivesuchcounterstomakecellsturngreenwhentheyhavedivided25 =32times.AIM 1: Performselectionforbinarycountinginsimulatedgeneticnetworks.Existing software can simulate evolution in genetic networks. This work will use Genetdes,6freeopen-sourcesoftwarewhichnativelyusesSBMLformat7todescribethenetworksitactsupon.Asaformermetabolicengineer,IamproficientinSBMLandwithnetworkmodeling.HYPOTHESIS 1: Electronic circuits will evolve into binary counters. The field of evolutionarycircuit design began inelectronics, and a mature literature exists on the topic.8,9 Counter design isa common test case, and has been demonstrated a number of times. This will serve as a positivecontrol;Iwilltestandrefinetheselectionmethodsonatargetknowntoexist.HYPOTHESIS 2: Under validated selection conditions, networks of interacting transcriptionfactors will NOT evolve into binary counters. Selection will be performed with Genetdes using aproven fitness function. However, success appears unlikely. No human designer has produced acounternetworkfrompurelytranscriptionallogic,nordoknownexamplesexistinnature.AIM 2: Improvesimulatednetworksbyincludingrecombination-basedgeneticswitches.To test these switches in the context of a modeled network, I will make several changes to theGenetdes simulator and its underlying SBML representations. Current SBML standards permitembeddedtriggersforfunctionsanddiscontinuousevents;thesearekeyfeaturesforimplementingrecombination. InthisAim,IwillthereforeextendGenetdestofullSBML-2compliance.Toupdatethemodel,Iwillfirstcreatenewparts: matchedpairsofrecombinaseandtargetsite(Rec and INT), using available kinetic data for the fim system.10 Rec binds INT, then complexeswith another bound Rec. This complex triggers a discontinuous event, in which the paired INTsexchange locations. INTs will be context aware, storing the connections made at their geneticlocation (cis interactions). I will also create a new cell compartment where active INTs and theirneighborswillbehiddenduringthisexchange,mimickingDNAblockedbyReccomplex.HYPOTHESIS 3: Networks containing switches will outperform transcription factors alone.Recombination is the favored mechanism for natural behaviors with periodic state changes, suchas E. coli virulence10 and S. cerevisiae mating.11 The switches are discrete, leak-free, and fairlyefficient-goodtraitsforacounter.5 Iexpectthatswitchingwillimprovethecounterdesigns.AIM 3: Convertevolvedcountermodelstophysicalformandconfirmactivityinvivo.GOAL: Producefunctionalnetworksinalivingcellwithsimulatedevolution. Forhigh-scoringdesigns, I will perform stochastic simulations on their network to assess noise tolerance. Designswhichsurvivethistestwillbesubjecttosensitivityanalyses,determiningtheirrobustnesstokineticparameters. TheseanalyseswillbeperformedwiththeSimBiologytoolkitinMATLAB.For the most promising designs, I will manually ensure that each model element has a corre-sponding physical part with the right kinetics. I will also choose the most informative elements totagwithfluorescentreporterproteins. Designswillbebuiltwithcharacterizedpartslibraries.12,13Testing and debugging the designs will require dynamic analysis of multiple reporter proteins,ideally in single cells. I plan to work with Prof. Hasty of UCSD, a pioneer of this technique. Hisgrouphasperformedsimilarworkforoscillatorsandcircadianclocks,showingfeasibility.14AIM 4: Produceeducationalsoftwareusingideasfromnetworkevolutionmodels.ThealgorithmsthatevolveSBMLmodelsinGenetdescanbegeneralizedtouseanystructuredinput.6 I will refactor existing software to develop a general-purpose evolution simulator; thissimulatorwillbeusedtocreateprogramsinTurtle,asimplegraphicslanguageforchildren.ThefitnessofaTurtleprogramwillberatedbyhumanscomparingitsoutputtoatargetimage.Thiswillbeawebgame,whichwillincorporategamedynamicssuchasallowinguserstocompeteon how well their scores match the consensus. I will create time-lapse videos of the evolutionaryprocess;thesewillbepostedonYouTubetoprovidevisuallyappealingtoolsforeducation.RESOURCES: Pilot studies for Aims 1 and 4 will be conducted on a small Beowulf cluster15planned for DIYbio-Boston. Next fall, I plan to enroll in graduate school; I will use universityresources(orideally,TeraGrid)forAim2. LabsforAim3canbefoundatUCSDandelsewhere.BROADER IMPACTS: I have dedicated a full Aim to public outreach. For the Turtle project, thetools will be developed in partnership with amateur scientists in DIYbio. Data will be collectedthroughpublicparticipation,andresultswillbepackagedtoreachthewidestpossibleaudience.I take scientific impacts just as seriously. I will continue to publish and give talks, makingsuretoreachthebroadergroupwhichcouldexpandonmywork. Forinstance,thepartsdesignerswouldwanttoknowifIwaslimitedbyaspecificgapinthepartslibraries,andthemodelerswantaformalismforrecombination. Withinmysubfield,Ialsohopetouseinterestingresultstomakethecasefordesignpracticeslikesimulatedevolution. Syntheticbiologywantstobetransformative;itcouldbe,ifwewerebetteratit. Bylearningtodesignbiologicalsystemsbetter,smarter,andfaster,andbysharingthatknowledge,webuildtheinfrastructurethatwillallowittoreachitspotential.REFERENCES: (1)Buchleretal.2003.ProcNatlAcadSciUSA.(2)RodrigoG&JaramilloA.2007.SystSynthBiol.(3)CaoHetal.2010.SystSynthBiol.(4)igem.org(5)FriedlandAEetal.2009.Science.(6)RodrigoGetal.2007.Bioinformatics.(7)sbml.org(8)BeielsteinTetal.2002.IEEE-CEC.(9)ShanthiAPetal.2005.IEEE-EH.(10)HamTSetal.2008.PLoSONE.(11)HaberJE.1998.AnnuRevGenet.(12)partsregistry.org(13)biofab.org(14)BennettMR&HastyJ.2009.NatRevGenet(15)beowulf.org"
237.0,"An Adaptive Chemistry Reduction Method for Detailed Modeling ofAdvanced Combustion SystemsKey words: combustion, mechanism reduction, stiffness removal, CFDCombustion of hydrocarbon fuels provides 85% of energy in the modern United States [1];the current energy crisis is in reality a fuel crisis. While renewable forms of energy are beingpursued to supplement combustion-based sources, hydrocarbon fuels will remain the majorcomponent for the next few decades. Currently, there is high demand to improve the efficiencyof combustion technology to decrease the amount of fuel consumed and to reduce the emissionsin an effort to lessen the environmental impacts; in addition, fuel-flexible designs that can run onboth conventional and alternative fuels are desired.Computational modeling drives the design of new combustors and engines for aerospace,transportation, and energy applications, but accurate prediction of fuel consumption andpollutant emissions requires detailed chemical reaction mechanisms. Detailed mechanisms forliquid hydrocarbons of interest contain large numbers of species and reactions; for example, thereaction mechanisms for n-heptane (C H ) and iso-octane (C H ), important molecules for7 16 8 18gasoline modeling, contain almost 1000 species and 8000 reactions [1]. Despite rapidadvancements in computing power, it is generally formidable to integrate such detailed reactionmechanisms into large-scale computational simulations, in terms of CPU time and memoryrequirements. In addition, the wide range of time scales (from nanosecond to second) and thenonlinear coupling between species and reactions induces stiffness when governing equations aresolved. Due to these computational demands, practical simulations using detailed chemistry areimpossible with modern computational tools.Mechanism reduction schemes are used to allow quantitative modeling while keepingrealistic chemistry effects. Non-adaptive methods perform reduction based on a predicted rangeof conditions typically by removing unimportant species and reactions and identifying thespecies with fast time scales for further reduction, providing a single global mechanism. Mostadaptive reduction methods, on the other hand, operate by storing chemical kinetics informationand retrieving necessary data during the simulation to avoid direct integration of the governingdifferential equations; newer techniques use multiple mechanisms reduced prior to the simulationat various points in the flow. I propose the development of a novel adaptive and computationallyfriendly reduction method that will remove unimportant species and reactions and eliminatestiffness on the fly. I aim to explore and develop new algorithms while using existing reductionmethods as a basis.Non-adaptive reduction methods attempt to provide a valid reduced mechanism bypredicting the range of conditions (pressure, temperature, mixture composition) of interest in asimulation. However, the size of the reduced mechanism is limited by locations in thecomputational domain that require more detailed chemistry due to high reaction activity. Manymethods have been developed to reduce mechanisms in this manner, but the application ofdirected relation graph (DRG) theory [2] is particularly useful. In this method, nodes of theDRG represent species and directed edges represent coupling of species. Important targetspecies are defined (e.g. fuel, oxidizer, pollutants) and a graph-searching algorithm finds thedependent sets of species needed to accurately predict the targets’ production rates. Species withcontributions below an error threshold are considered unimportant and removed from themechanism, and the algorithm eliminates reactions containing unimportant species. For furtherelimination of stiffness in reaction systems, the quasi steady state (QSS) and partial equilibrium(PE) assumptions are applied [3]. QSS species and PE reactions have very short time scales,1NSF GRFP 2009 – Proposed Plan of Research – Kyle Evan Niemeyercausing stiffness, and the approximations seek to replace differential equations with algebraicrelations to solve for species’ concentrations. Computational singular perturbation (CSP) andintrinsic low dimensional manifold (ILDM) [3] are traditional methods for finding QSS speciesand PE reactions by separating fast and slow processes.Adaptive reduction methods rely on different approaches to increase computationalefficiency during simulations. Approaches such as in situ adaptive tabulation and artificialneural networks [4] perform storage and retrieval of chemical kinetics information to saveprocessing time. Newer adaptive methods such as genetic algorithms [5] and optimization-basedapproaches [6] use various techniques to provide multiple reduced mechanisms for use duringthe simulation at different points in the flow. Highly detailed chemistry needs to be consideredat locations where reactions are actively occurring, while regions with low reactive activity canuse extremely reduced mechanisms. However, all of the methods currently rely on predictivereduction, which will not provide the highest level of accuracy or reduction.I propose the investigation of a new adaptive reduction methodology that will perform onthe fly removal of species and reactions and elimination of stiffness. Identification and removalof unimportant species and reactions based on local conditions allows for the highest level ofreduction and therefore the least computational demand, while keeping high accuracy. First, Iwill explore a novel algorithm for species and reaction removal using the DRG concept as astarting point; previous studies [2] based on DRG have shown it to be fast and reliable, suitablecharacteristics for on the fly application. This work will build directly on the preliminary non-adaptive reduction method I developed [7]. Second, I will investigate efficient methods foridentifying fast processes such as QSS species and PE reactions; traditional methods such as CSPand ILDM are time-intensive [3] and therefore not well suited for on the fly stiffness removal.The adaptive reduction method I have proposed can be directly applied to the simulation ofcombustion processes for aeropropulsion, transportation, and energy applications. Theincorporation of detailed chemistry while providing speedy simulation will allow accuratemodeling of fuel consumption and emissions and help drive the design of next-generationengines and combustors. A method based on graph theory could also be applied to the modelingof other complex systems; broader applications consist of food web/ecosystem modeling, diseasespreading modeling, climate modeling, and biological systems modeling. Also, a newmethodology developed to perform mechanism reduction could also be used to collect importantinformation about complex systems. For example, a CSP-based method was used to gatherinformation about explosive processes in a simulation of a hydrogen/air turbulent lifted jet flame[8] - the new method I propose could be used similarly for data mining.References[1] “Basic Research Needs for Clean and Efficient Combustion of 21st Century Fuels,”DOE/BES Workshop Report (2006).[2] T.F. Lu, C.K. Law, Combust. Flame 144 (2006) 24-36.[3] T.F. Lu, C.K. Law, C.S. Yoo, J.H. Chen, Combust. Flame 156 (2009) 1542-1551.[4] J.-Y. Chen, J.A. Blasco, N. Fueyo, C. Dopazo, Proc. Combust. Inst. 28 (2000) 115-21.[5] I. Banerjee, M.G. Ierapetritou, Combust. Flame 144 (2006) 619-33.[6] O.O. Oluwole, P.I. Barton, W.H. Green, Combust. Theory Model. 11 (2007) 127-46.[7] K.E. Niemeyer, C.-J. Sung, M.P. Raju, “Skeletal mechanism generation of surrogate fuelsusing directed relation graph with error propagation and sensitivity analysis,” Combust. Flame(submitted).[8] T.F. Lu, C.S. Yoo, J.H. Chen, C.K. Law,AIAA 2008-1013 (2008).2"
238.0,"The relationship between craft production and the political and economic development ofcomplex societies continues to generate debate in the field of Anthropology. The study remainsrelevant because craft production is a firmly embedded element of culture (Costin 1991:2). Thisfield of research has broad impacts as it can be expanded to the understanding of socio-economicorganization as well as the identification of gender roles (Brumfiel 2006: 862). Ultimately,knowledge of production methods and their roles in a society can lead to a strongerunderstanding of political organization (Brumfiel and Earle 1987:3-5). Earle‟s (1987:69) workon Hawaiian and pre-Inkan societies indicates that the centralization of production reflectedstrengthening political control. Further evidence for an increasing complexity in these societiescame from emphasis on specialized craft production. Earle‟s work is an excellent example ofhow archaeological research can tie craft production to the development of complex society.This proposal discusses conducting further research on this topic in the Early Bronze Age(EBA) settlement at Zincirli, Turkey. This site, known primarily for its Iron Age occupation, hasan eight hectare walled town dating to 2500 BCE. Excavation conducted in the late 19th centuryuncovered ceramic and architectural remains which have been used to date the EBA areas(Lehman 1994:106-107). No further excavation on these areas has been attempted since thattime, although magnetometry readings have produced evidence for additional architecture.Excavation of the EBA sections at Zincirli will begin in 2010, led by Dr. ChristophBacchuber as sub-director to Dr. David Schloen, of the University of Chicago. This excavationwill provide an opportunity to examine the relationship between craft production and politicalcentralization. A model well suited for the interpretation of this work is the political developmentmodel of specialization, exchange, and complex society, as defined by Brumfiel and Earle(1987:1-4). This model suggests that elites control the organization of local craft production andconsequently are the primary beneficiaries. The political development model is reflected byevidence of craft specialization, the organization of local production, and the mobilization ofgoods from producers to elites. To properly address this model and determine its efficacy inunderstanding the EBA settlement at Zincirli, the following research questions will be addressed:1. To what degree were craft production activities specialized at this site?2. How was craft production organized at this site? (What are the units of production?)3. What manner of mobilization of craft products to elites is present?Costin (1991:4) defines specialization as a “differentiated, regularized, permanent, andperhaps institutionalized production system” in which an individual does not produce all of thegoods he/she consumes, but rather is dependent on others to produce certain items. A supportiveexample of this would be the discovery of a collection of a particular artifact type bearing a highdegree of standardization. Conversely, a highly diverse artifact typology suggests a greaternumber of individuals and thus less specialization (Costin and Hagstrum 1995: 632).Organization can be determined through the distribution of particular artifacts (tools, rawmaterial, waste). Appearing in a centralized location suggests a „work-shop‟ organization,whereas a more diffuse distribution in individual structures suggests household production(Costin 1991:6, 8, 21-29). Control of craft product by elites can be identified through theproximity of production centers to elite residencies (Earle 1987:68-69) and the appearance ofspecialized craft goods in elite settings (Brumfiel and Earle 1987:3-5). A wide dispersal ofspecialized craft goods could indicate a lack of elite mobilization.In order to address my research questions, data will be derived through excavation and theentry of piece plotting measurements into a GIS database. After three field seasons with theChicago team, I anticipate having a database large enough to derive spatial patterns indicatingeither the presence or absence of centralized craft production. This analysis, similar to that usedat Titriş Hoyuk (Hartenberger 2000), will provide the basis for determining the relationshipbetween craft production and political centralization. Titriş Hoyuk, a comparative case study forcraft production, is approximately 115km east of Zincirli, and has a contemporaneous EBAhabitation. Excavation has yielded a lithic workshop indicating organized, centralized, andspecialized craft production (Hartenberger 2000:51).Intellectual MeritThe results of this analysis will increase our knowledge of the conditions of this timeperiod and region of Anatolia. The Anatolian Early Bronze Age marks a significant change ineconomic, political and technological developments (Yenner & Vandiver 1993: 208). Thisproposed research will provide information on each of these characteristics. One advantage ofincreasing this knowledge is the ability to link it with the wealth of research that has beenconducted in Mesopotamia. This will aid in producing a larger and more regional picture ofcomplex society in the Eastern Mediterranean.My class work, which has trained me in GIS, and my previous excavation experience,especially at Zincirli, Turkey, have given me the tools to conduct this research. My currentresearch for a Bachelor‟s of Philosophy thesis has enabled me to use these tools on a similararchaeological problem. Through my focus on textile production at the EBA site Karataş, in SWAnatolia, I am familiar with much of the relevant literature for this proposed research. Also, Inow have experience in using GIS to derive information from artifact distribution and densities.Broader ImpactThis work builds on previous research conducted on craft production, and will contribute toour understanding of this phenomenon both regionally and theoretically. To disseminate theoutcomes of this research, I will actively engage with the academic community by presenting myfindings at academic conferences and by producing publications. This work will also contributeto my abilities to teach anthropology and archaeology, by giving me the knowledge andexperience to express these concepts to others.References CitedBrumfiel, Elizabeth (2006). Cloth, Gender, Continuity, and Change: Fabricating Unity inAnthropology. American Anthropologist, Vol. 108, No. 4: 862-877.Brumfiel, Elizabeth and Timothy K. Earle (1987). Specialization, Exchange, and ComplexSocieties. Cambridge University Press: Cambridge.Costin, Cathy Lynne (1991). Craft Specialization: Issues in Defining, Documenting, andExplaining the Organization of Production. Archaeological Method and Theory, Vol. 3: 1-56.Costin, Cathy Lynne and Melissa B. Hagstrum (1995). Standardization, Labor Investment, Skill,and the Organization of Ceramic Production in Late Prehispanic Highland Peru. AmericanAntiquity, Vol. 60, No. 4: 619-639.Earle, Timothy K (1987). Specialization and the Production of Wealth, in Elizabeth Blumfiel andTimothy K. Earle, eds., Specialization, Exchange, and Complex Societies. pp. 64-75.Cambridge University Press: Cambridge.Hartenberger, Britt et al.(2000). The Early Bronze Age Blade Workshop at Titris Hoyuk.Near Eastern Archaeology, Vol.63, No.1:51-58.Lehmann, Gunnar (1994). “Zu den Zerstörungen in Zincirli Während des Frühen 7. Jahrhundertsv. Chr.” Mitteilungen der Deutschen Orient-Gesellschaft zu Berlin, 126:105–122.Yenner, K. Aslihan, and Pamela B. Vandiver (1993) Tin Processing at Göltepe, an Early BronzeAge Site in Anatolia. American Journal of Archaeology, Vol. 97, No. 2:207-238."
239.0,(cid:80)(cid:83)(cid:1)(cid:86)(cid:84)(cid:70)(cid:1)(cid:88)(cid:74)(cid:85)(cid:73)(cid:80)(cid:86)(cid:85)(cid:1)(cid:81)(cid:70)(cid:83)(cid:78)(cid:74)(cid:84)(cid:84)(cid:74)(cid:80)(cid:79)(cid:15)(cid:36)(cid:80)(cid:81)(cid:90)(cid:83)(cid:74)(cid:72)(cid:73)(cid:85)(cid:1)(cid:19)(cid:17)(cid:18)(cid:17)(cid:1)(cid:88)(cid:88)(cid:88)(cid:15)(cid:83)(cid:66)(cid:68)(cid:73)(cid:70)(cid:77)(cid:68)(cid:84)(cid:78)(cid:74)(cid:85)(cid:73)(cid:15)(cid:68)(cid:80)(cid:78)(cid:1)(cid:34)(cid:77)(cid:77)(cid:1)(cid:51)(cid:74)(cid:72)(cid:73)(cid:85)(cid:84)(cid:1)(cid:51)(cid:70)(cid:84)(cid:70)(cid:83)(cid:87)(cid:70)(cid:69)(cid:1)(cid:85)(cid:80)(cid:1)(cid:48)(cid:83)(cid:74)(cid:72)(cid:74)(cid:79)(cid:66)(cid:77)(cid:1)(cid:34)(cid:86)(cid:85)(cid:73)(cid:80)(cid:83)(cid:15)(cid:1)(cid:37)(cid:80)(cid:1)(cid:47)(cid:80)(cid:85)(cid:1)(cid:37)(cid:86)(cid:81)(cid:77)(cid:74)(cid:68)(cid:66)(cid:85)(cid:70)(cid:80)(cid:83)(cid:1)(cid:86)(cid:84)(cid:70)(cid:1)(cid:88)(cid:74)(cid:85)(cid:73)(cid:80)(cid:86)(cid:85)(cid:1)(cid:81)(cid:70)(cid:83)(cid:78)(cid:74)(cid:84)(cid:84)(cid:74)(cid:80)(cid:79)(cid:15)
240.0,"Do not duplicate or use without permission www.rachelcsmith.comMaking Optimal Decisions for an Uncertain Future: Quantifying the Effects ofAnthropogenic Disturbance on Biodiversity and Ecosystem ServicesKey Words: Disturbance Effects, Biodiversity, Ecosystem Services, Ecosystem ManagementIntroduction: Anthropogenic disturbances negatively impact species, genetic and functionaldiversities of ecosystems, reducing the essential services they provide. While we know that thepresence of diverse functional traits in an ecosystem is directly linked to the successfulprovisioning of essential services1, it is often easier to quantify an ecosystem’s genetic diversitythan to determine its functional diversity. Unfortunately, we lack a fundamental understanding ofthe interrelationships between these forms of diversity and whether or not one can be used as aproxy for another. This gap in our knowledge impedes our ability to make management decisionsthat maximize future ecosystem services. My proposed research will:Research Objectives:1. Determine if and how genetic diversity and functional diversity are related.2. Determine if and how natural and anthropogenic disturbances alter the relationshipbetween genetic diversity and functional diversity.3. Create a predictive management tool that allows us to maximize genetic and functionaldiversity, and thus the provisioning of ecosystem services, in the uncertain future.To accomplish these objectives, I will develop a database of the species present before and afteranthropogenic disturbances. The database will contain data from a global range of ecosystems, aswell as a subset of data that will be provided by Sierra Pacific Industries (SPI), the largest privatelandowner in California. I will analyze these data to determine how genetic and functionaldiversities change after disturbance and then create an easy-to-use online management tool thatpredicts how future anthropogenic disturbances will alter biodiversity and ecosystem services.Background: Phylogenetic Diversity (PD) is the length of evolutionary pathways connectingtaxa, and it is a well-known index used to measure genetic diversity2. When managing an area toconserve overall biodiversity, maximizing PD is likely the best way to hedge our bets andincrease the probability of having the right extant species at our disposal in a future of unknownenvironmental, economic, and medical needs3. Functional diversity (FD), the total branch lengthof a tree of functional traits, measures the diversity of functional traits in an area4. Maximizingthe FD of an area is important because essential ecosystem services are directly tied to the value,range, and abundance of an ecosystem’s functional traits1.It is quickly becoming more practical and economical to determine the PD rather than theFD of an ecosystem because DNA barcoding can reliably complete large taxonomic surveys,while quantifying the functional traits present in an area is still a large undertaking. It is possiblethat PD can serve as a proxy for FD, which would allow us to assess an ecosystem’s functionwithout quantifying functional traits. However, no large-scale study has ever demonstrated therelationship between genetic and functional diversities. Additionally, we currently have no wayto accurately predict the effects of anthropogenic disturbances on PD and FD.SPI owns approximately 1.7 million acres of land and must routinely make managementdecisions without knowing the exact consequences of their management practices. SPI isinterested in learning if their management causes changes to the biodiversity and ecosystemservices of their land. Therefore, in addition to studying disturbances in a range of globalecosystems, I will collaborate with SPI to determine the effects of harvesting-relateddisturbances.NSF-GRFP Proposed Graduate Study Copyright 2010 to Original Author All Rights Reserved.Do not duplicate or use without permission www.rachelcsmith.comMethods: I am currently collecting data from published articles that document changes to thespecies diversities of a range of organisms after anthropogenic disturbances (e.g. fire, timberextraction) in ecosystems subject to diverse natural disturbance regimes (e.g. fire, flooding). SPIhas already compiled a dataset that details the plant species observed before and afterclearcutting, replanting, and applying herbicides in 200 forest patches. With this data, I will:1. Build separate phylogenetic and functional trees of species found before and after humandisturbance, using known phylogenies, programs such as Phylomatic and TreeBASE, andlists of functional traits, such as USDA PLANTS and Jepson Herbarium’s Flora Project.2. Analyze relationships between disturbance, PD, and FD. Using a likelihood and Bayesianapproach, I will compare changes to PD and FD after disturbance and changes in the K scoreof trees, which is the difference in the relative branch lengths and topologies of phylogenetictrees5. If PD and FD change in correlated ways after disturbances, then PD can serve as aproxy for FD. I will also determine if the changes in PD, FD, and K score can be explainedby specific disturbance regimes.3. Organize data and results in an SQL database. Create an accessible online tool that will beavailable to researchers, landowners, government, and NGOs. It will formulate ecosystemmanagement plans and allow users to predict how their actions will change their land’sbiodiversity and ecosystem services. I will also develop a California version for use by SPI.Expected Results:1. Ecosystems with a high PD will have a correlated high FD.2. If an ecosystem faces an anthropogenic disturbance that mimics its natural disturbanceregime, PD and FD will change in correlated ways, and PD can serve as a proxy for FD.Broader Impacts: Large-scale biodiversity loss directly threatens ecosystem stability andreliability by impairing ecosystem services, such as primary production, carbon storage, andpollination1. Gaining a better understanding of the effects of our ecosystem managementdecisions will allow us to avoid the irreversible loss of biodiversity and ecosystem functions orto at least limit the scale, frequency, and intensity of anthropogenic disturbances in the future.My research findings will elucidate the relationships between genetic and functional diversities. Iwill provide the information and tools we need to make economically efficient and sociallyoptimal resource management decisions, ensuring that we conserve the organisms that willprovide essential ecosystem services in an uncertain future.I have already started data collection for this project, and I am currently mentoring threeundergraduates, including two women who also belong to ethnic minorities, who are aiding inthe development of my dissertation project. After developing the management tool, I will holdworkshops for landowners throughout California. I will teach them to use the tool, and I willspeak on the benefits of managing land to maximize biodiversity and ecosystem function. Myresearch will inform the long-term management decisions of landowners in California.References: [1] Diaz, S et al. 2007. Incorporating plant functional diversity effects in ecosystemservice assessments. PNAS 104:20684. [2] Faith, D. 1992. Conservation evaluation andphylogenetic diversity. Biol Cons 61:1–10. [3] Forest, F et al. 2007. Preserving the evolutionarypotential of floras in biodiversity hotspots. Nature 445:757-760. [4] Petchey, OL & Gaston, KJ.2002. Functional diversity (FD), species richness and community composition. Ecol Letters5:402-411. [5] Soria-Carrasco, V et al. 2007. The K tree score: quantification of differences inthe relative branch length and topology of phylogenetic trees. Bioinformatics 23:2954."
241.0,"duplicate or reproduce without permission. www.rachelcsmith.comSeasonal Migration Within Aseasonal Tropical Rainforests:A Phenomenon With Immense ImplicationsINTRODUCTION: Tropical rainforests (TRF) are often considered aseasonal, however every TRFstudied shows seasonal phenological variations corresponding to precipitation and solarirradiance1. Flushing, flowering, fruiting, and invertebrate biomass have general community-wide peaks during a region’s wet season, with large-fruited trees exhibiting the strongestphenological clumping1,2. Due to local precipitation regimes, phenology peaks vary in differentgeographical locations, creating spatio-temporal resource shifts1,3,4. Migration, the large-scaleseasonal range shifts that occur in response to disparities in regional resources, has not beenstudied as a faunal survival adaptation within tropical rainforests1.Uncovering how animals move in response to seasonal resource shifts is critical to theconservation of migrating species and the ecological processes they perform5,6,7,8. Furthermore,species dependent on variable resources are the first to face local extinction after forestfragmentation. Moreover, migrating species are particularly threatened by current global climaticchanges5,6. I will create a spatio-temporal model of fruiting shifts in SE Asia, then track hornbillmovements to test my hypothesis that migration exists in TRF to follow resource shifts.BACKGROUND: Current research on migration as a response to seasonal resource shifts isfocused on temperate and highly seasonal tropical regions5. While altitudinal migration thatfollows seasonal phenological changes does exist in TRF, large-scale seasonal migration thatfollows regional climatic differences is completely unreported2,6,7. Newton’s comprehensivetextbook on migration argues that the increased movements required to cross climatic gradientsand the limited resource inequalities between TRF negate the returns for intra-TRF migration7.However, highly mobile TRF frugivores like hornbills can traverse hundreds of kilometers perweek, and in SE Asia, seasonality is sufficient to create resource disparities4,8,9.SE Asia is the optimal location to test for migration because monsoons create localizedweather patterns in lowland TRF. Variations in wet seasons form a matrix of adjacent landscapeswith offset phenologies1,4. Consumers depend on these spatio-temporal rhythms in the foodsupply1,2,3,8. Local seasonal resource disparities are extreme, exceeding six fold increases infruiting species during months of peak rainfall. This provides incentive for migration6.Hornbills are large frugivorous birds that are highly mobile and capable of migration. Theyfavor large, ripe, oily fruits in rare canopy/emergent tree species that fruit seasonally2,3,8,10.Hornbills are keystone seed dispersers and the SE Asian equivalent of toucans8,9. Hornbills trackresources throughout their home ranges and juveniles are known to roam until they obtainterritories, however hornbills are not known to migrate8.A seasonal flock of 3000+ plain pouched hornbills, Aceros subruficollis, has recently beendiscovered around Lake Tasek Temengor in Peninsular Malaysia11. The hornbills fly north afterstaying in the region during the two month period of peak rainfall and fruiting3,11. Thedestination of A. subruficollis is unknown, however, it has never been recorded as a breeding inMalaysia8,11. The seasonal presence of this flock in Malaysia for purposes other than breedingsuggests that A. subruficollis is migrating outside of Malaysia, most likely into Thailand.If A. subruficollis is migrating, it would constitute the first documented migration by aTRF species7. Altitudinal migration can be refuted because A. subruficollis vacates from theLake Tasek Temengor region where elevation changes exceed 1000m within a 30km zone11. A.subruficollisis is currently listed as a vulnerable species due to the rapid decline in small totalpopulation. In addition, the details of its range, life history and ecology are unknown8,12.NSF Proposed Research 2010 All Rights Reserved to original author. Do notduplicate or reproduce without permission. www.rachelcsmith.comHYPOTHESIS: i) Rainfall-driven local phenology differences have resulted in significant seasonalresource disparities across space within TRF. ii) A. subruficollis will migrate in order to exploitseasonal resources. Null: i) Resources are homogeneously distributed in time and ii) A.subruficollis movements do not correlate with resource abundance.OBJECTIVE 1: Create a spatio-temporal resource model using GIS mapping techniques to test therelationship between rainfall and phenology of fruiting trees. Then, model optimal migrationpaths for A. subruficollis based on distance and temporal resource abundances.METHODs: 1) Create regional monthly rainfall/fruiting species database. Precipitation data isavailable from the Malaysian and Thai Hydrological departments, phenological data is availablefrom the literature1. 2) Model month-by-month rainfall and fruit abundance by region in ArcGIS.3) Use large-scale layered models to quantify resource disparities across time and space. 4)Model A. subruficollis optimal movements to exploit spatio-temporal resource peaks.OBJECTIVE 2: Test if A. subruficollis migrates to exploit spatio-temporal resource abundances.METHODS: 1) Radio-track 15 A. subruficollis individuals for two years9. Capture birds withpulley-mounted canopy mist-nets at roost in Malaysia and attach satellite-transmitters at the baseof the tail feathers9. Monitor their movements with a receiver9. 2) Input A. subruficollismovement data into a GIS spatio-temporal resource model. 3) Determine if there is causalrelationship (using spatial auto-correlation) between movements and spatio-temporal resources.CONSEQUENCES: Migrants and species dependent on seasonal resources are particularlyvulnerable to climatic changes and forest fragmentation5,7,8. Moreover, concerns about climatechange stress the importance of keystone seed dispersers, like hornbills, to help move the trees tomore suitable climates8,9. A positive feedback response could develop where keystone migrantsdisappear from disturbed forests, decreasing ecosystem functioning and future forest resilience.TRF migration also directly challenges Rapaport’s Rule of decreasing animal range size withlatitude, a theory based on decreased resource variability in the tropics. The seasonal resourcemodels I will create will bring the degree of variability into question. Migrating frugivores alsoprovide rapid long-range seed dispersal along distinctive corridors and back to roosts, shapingthe spatial regeneration patterns and diversity of forest trees3,10.BROADER IMPACTS: I will partner with the Forestry Research Institute of Malaysia (FRIM).Malaysian researchers will aid in all aspects of this project including anticipated co-authorshipson publications, and becoming fully trained in the methods and analyses. FRIM helps to manageMalaysia’s natural resources, making it optimal to immediately bridge my research with policyand action. Additionally, this research will locate movement corridors that are critical toconservation efforts for this vulnerable species, which benefits future human generations of allnations12. A. subruficollis is also a charismatic species and important tourism draw in the region8.Finally, Dr. Poonswad at the Mahidol University in Bangkok has enlisted master’s studentsworking on Thailand Hornbill Project (THP) to help track A. subruficollis in Thailand. Workingwith FRIM and THP will bring together an international team and facilitate the local and broaddissemination of results in English, Malay and Thai.BIBLIOGRAPHY: [1]van Schaik, C.P.,Terborgh, J.W. and Wright, J.S. 1993. Annun. Rev. Ecol. Syst. 24;[2]Walker, J.S. 2006.Biol. Conserv.130; [3]Medway, F.L.S. 1972.Biol. J. Linn. Soc. 4 [4]Kumagai, T. etal. 2009.Water Resources 45; [5]Both, C., et al. 2006. Nature 441; [6]Levey, D.J. 1994. The Auk 111;[7]Newton, I. 2008. Academic Press,London; [8]Kinnaird, M. F. & T. G. O'Brien. 2007. [9]Holbrook, K.M.& T.B. Smith. 2000. Oecologia125; [10] Hardesty, B.D., Hubbell, S.P., et al 2006. Ecology Letters 9.[11]Chew, H.H., & S. Supari. 2000. Forktail 16; Univ. Chicago Press; [12]IUCN 2009. Version 2009.1;"
242.0,"www.rachelcsmith.com *All Rights Reserved to Original Author 2010 GRFP Research ProposalNative Bee Reproductive Success in Restored HabitatsIntroduction: Ecological restoration can rehabilitate ecosystem services, but its success dependsupon the ability of the restored site to sustain functional populations.1 Restoration has beenproposed as a way to promote conservation of native bee populations that have declined due tohabitat loss and fragmentation.2 Native bees are effective pollinators of many economicallyimportant crops,3 and drastic crashes in managed, non-native honey bee populations due tocolony collapse disorder have highlighted systemic vulnerability, as well as the need to diversifyon-farm pollinator communities. Within agricultural systems, hedgerows (linear strips of nativeflowering shrubs planted in fallow field margins) are the preferred restoration method: In 2007,Congress passed the Pollinator Habitat Protection Act (S.1496), incentivizing the creation ofpollinator-friendly hedgerows. However, agricultural landscapes have become increasinglysimplified due to intensive farming practices, and potential source habitat may be too distant toprovide reliable immigration to hedgerows.4 In addition, recent research5 suggests thathedgerows may be sink habitat, where the death rate is greater than the birth rate.6 This researchused species richness as a proxy for reproductive success, which is problematic because it givesno indication of long-term population viability within sites. If hedgerows are sinks, pollinationservices could be threatened.3 Therefore, I propose to directly measure native bee reproductivesuccess in order to assess the sink hypothesis and the conservation potential of hedgerows.Background: Native solitary bees typically have one generation per year, therefore there are twomain components that influence reproductive success: per female fecundity and offspringsurvival. Fecundity may be influenced by proportion of forage (pollen) available for provisioningof brood cells7 at both the local and landscape level.8 Hedgerows often contain low plantdiversity (usually between 8 - 15 species); if these resources are inadequate, bees may need toforage in the surrounding landscape to obtain sufficient pollen to meet larval needs.4,8 Limited orpatchy landscape resources could reduce success as fewer nests could be created.Larval mortality can be heightened by increased parasitism, and cleptoparasite and parasitoidabundance is often greater in restored sites than in natural areas.10 Additionally, parasitism rateshave been correlated with resource availability: in resource-poor environments, bees compensatefor floral scarcity by increasing search time, broadening the window for successful parasitism.11While exposure to herbicides12 and abiotic factors, such as high in-nest moisture and temperaturelevels,13 can also be fatal to larvae, their effects are difficult to measure; therefore, I will dividecauses of mortality into two categories: parasitism and unknown.10In order to demonstrate the occurrence of source-sink dynamics it is necessary to comparepopulation demographics in multiple habitats.14 Thus, treatments will be in two habitat types,restored (hedgerow), and un-restored (fallow field margins), situated in either complex(heterogeneous) or simple (homogenous) landscapes (n = 18). Additionally, in order to havebaseline data against which gauge the success of the restored sites, fecundity and offspringsurvival will be recorded in natural habitats (n = 4).I will use trap-nesting bees (cavity-nesters) as my study taxon because ninety percent of thenative bee species managed for agriculture are trap-nesters, and they readily occupy artificial“trap-nests,” bundles of hollow reeds, that can be lined with removable straw inserts to facilitatemonitoring of nest progress.8Hypotheses: In order to examine the capacity of hedgerows to sustain viable populations of trap-nesting bees, I will measure fecundity and parasitism in two landscape contexts:1. Fecundity of trap-nesting bees will decline with decreased resources. I hypothesize thatlandscape complexity will be more important to fecundity than local-level resources. In simpleNative Bee Reproductive Success *Do not Reproduce without Permissionwww.rachelcsmith.com *All Rights Reserved to Original Author 2010landscapes, I do not expect to find significant differences in fecundity between hedgerows andfallow field margins. In contrast, I predict that in complex landscapes fecundity will in higher inboth treatment types, approaching observed levels in natural habitat. However, if fecundity inhedgerows in simple landscapes is higher than in fallow field margins, it would indicate that thelocal resources they provide are sufficient, bolstering claims that they are an appropriaterestoration method in homogenous landscapes.2. Parasite pressure on larvae will increase with decreasing resources, negatively impactingreproductive success. In simple landscapes, I expect to observe spikes in parasitism levels inboth habitat types. I predict that the additional resources provided in heterogeneous landscapeswill buffer larvae against heightened parasitism in hedgerows but not in fallow-field margins.Further, I predict that offspring survival in hedgerows and field margins in both landscapes typeswill be significantly lower than in natural habitat, signifying that disturbed landscapes subjectlarvae to increased threats from parasitism and other factors shown to increase mortality.Methods: Study Location: This study will take place in Yolo County, an agricultural region inCalifornia’s Central Valley. In the study region, complex landscape is a mosaic of naturalhabitat, riparian corridors, organic farms, and conventional agriculture; simple landscapes aredominated by intensive agriculture (> 80%). Landscape features will be categorized using GISlandsat data. Each site will contain a 300 m transect with a trap-nest in the center, and will be atleast 2 km apart to ensure isolation.15Floral Resources: Vegetation sampling will commence with nest initiation and terminate whennesting ceases. I will record flowering species and number of inflorescence in 1 m2 quadratsalong transects. To determine the proportion of local and landscape resources used, I will collectvoucher pollen from all flowering plants within a 1500 m radius of trap-nests, and compare itwith sub-samples of pollen from nests.8Parasitism: Once nests are completed, I will x-ray larvae in the lab to ascertain which areparasitized;8 parasitoids will be identified after emergence by Dr. Robbin Thorp, of the UC DavisBee Biology Lab. Unparasitized pupae will be stored in optimal conditions at the UC Berkeleyinsectary and monitored for emergence of cleptoparasites.Broader Impacts: Due to the persistent, damaging effects of colony collapse disorder,restoration of native bees is essential for the maintenance of pollination services in agriculturalareas.3 These findings could validate hedgerows as an effective restoration method, or illuminateits short-comings. Worldwide, native bees are the most important pollinators in natural systems,and are therefore necessary for preservation of biodiversity.3,16 The result of this study will helpidentify factors that could contribute to the success of pollinator restoration at larger scales. I willsubmit papers to scientific journals, present at conferences, and share my results with farmers atannual workshops put on by the Xerces Society, a non-profit dedicated to insect conservation.References: 1. Ormerod, SJ. J. of Applied Ecology 40 (Dec 2003) 2. Dixon, KW. Science 325 (Jul 2009)3. Kearns, CW. et al. Ann. Review of Ecology and Systematics 29 (1998) 4. Ricketts, TH, et al. EcologyLetters 11 (May 2008) 5. Ockinger, E, HG Smith. J. of Applied Ecology 44 (Feb 2007) 6. Pulliam, HR.American Naturalist 132 (Nov 1988) 7. Muller, A, et al. Biological Conservation 130 (Jul 2006)8. Williams, NM, C Kremen. Ecological Applications 13 (Apr 2007) 9. Steffan-Dewenter, I. EcologicalEntomology 27 (Oct 2002) 10. Exeler, N, et al. J. of Applied Ecology 46 (Oct 2009) 11. Goodell, K.Oecologia 134 (Mar 2003) 12. Freemark, K, C Boutin, Agriculture Ecosystems & Environment 52 (Feb1995) 13. Hranitz, JM, et al. Environmental Entomology 38 (Apr 2009) 14. Watkinson, AR, WJSutherland, J. of Animal ecology 64 (Jan 1995) 15. Gathmann, A, T Tscharntke. J. of Animal Ecology 71(Sept 2002) 16. Allen-Wardell, G, et al. Conservation Biology 12 (Feb 1998)"
243.0,"Dynamics of Alliance Formation in Pueblo SocietiesKeywords: Climate Change, Agent-based modeling, Alliance, Puebloans, Cooperation, ConflictIntroduction: Previous work within the Village Ecodynamics Project (VEP) has successfullyestablished a detailed, semi-realistic, household-level model for Puebloan ecodynamics1. Ipropose to extend this household model to create agent-based models for conflict andcooperation in the context of the 700-year archaeological record of the central Mesa Verderegion. Here, the formation of larger groups is linked in a complicated way with conflict, but it isalso probable that mutualistic activities not motivated by between-group conflict contributed tothese larger group sizes. This model will help us understand the years of peace within the MesaVerde region, and the circumstances under which Puebloan people resorted to violence, as thesecycles have been locally described by Cole2. The models I create will be applicable to othersmall-scale societies—and elsewhere, with appropriate caution.Background: As resources dwindle, climate change is reshaping the earth, leaving us faced withproblems with potentially dire consequences3. Repeated calls have recently been made to applyagent-based modeling to contemporary affairs4, both to understand crises as they unfold, and toanticipate them. In these efforts, archaeology assists by providing a long-term view of therelationship between demography, distribution of human group sizes, environmental factors andviolent conflict. My place at Washington State University in the context of the VEP will allowme to address these questions with support from archaeologists, geologists, geographers,computer scientists and economists engaged in VEP empirical and modeling efforts.Hypotheses: My research will investigate how human cooperation affects the demographicsuccess and spread of human groups. Specifically, my research will examine the followinghypotheses: 1) both kinship- and non-kinship-based coalitions formed in response toenvironmental pressures, such as dwindling per-capita resources due to climate change orpopulation growth; 2) coalitions do not form only as a response to external conflict; rather, theyare leveraged by humanity’s evolved sociality5 and can serve to provide positive returns toincreasing group size; 3) coalitions may fracture when within-group competitive pressuresbecome too great, or when between-group competitive pressures relax.Research Plan: Working with Dr. Timothy Kohler and the VEP, I will participate in ongoingfield research in the Mesa Verde region. As an NSF Graduate Research Fellow, I will generatespatial goodness-of-fit measures between VEP simulations and the archaeological record toassess the general fidelity of the simulation to archaeological data from Mesa Verde, as well asto analyze and interpret the residuals. I aim to understand how accurately the existing agent-based models (ABM) predict the spatial distribution of households, subsistence and technology,and to evaluate the extent to which the simulations generate the archaeological record. Moreover,I will explore various methods of assessing spatial goodness-of-fit using over 4,000archaeological sites in the VEP study area from AD 600 to 1280.Next, I will create a model describing the emergence of alliances based on kinship andeconomic ties. Currently, the Village simulations do not allow for cooperation beyond thatprovided by exchange, or conflict beyond that generated through household-level competition forresources. Building upon Dr. Sergey Gavrilets’ (University of Tennessee Knoxville, Biology)framework for alliance formation6, I propose to create a stochastic model describing theemergence of cooperation resulting from between-group competition for key resources. I willgradually add levels of complexity to the unidimensional model as described by Gavrilets, whichaccounts for alliance formation only through competition for rank or mates. I will introduce ameans of incorporating scalar stress in order to generate nested groups, in contrast to theStefani Crabtree Proposed Research Essayexponential growth of alliances in Gavrilets’ model. An additional shortcoming of the previousmodel is that it only accounts for alliance-formation as a response to conflict, which ignoresaltruism and mutually beneficial relationships in coalition formation. Using the experimental testbed provided by the ABM, I will see whether approaches to generating cooperative networksmodeled on the sodalities seen in Southwestern societies provide a better fit to the known facts ofthe archaeological record than do alliances generated out of between-group conflict. In modernHopi societies, for example, sodalities form around a specific clan, “which own[s] theceremonies, kivas, and ritual items used by each sodality. However, while sodalities are managedby specific clans, sodality members can come from any clan”7. My benchmark for comparisonwill be the well-known and precisely-dated archaeological record of the central Mesa Verderegion, which provides a dataset that is unparalleled in the Neolithic world.Broader Impacts: This novel approach will provide critical information on the nature of humanalliance formation. As my research will analyze how issues such as control of resourcesinfluence the formation of alliances, I will be able to determine how these alliances break downwhen resources become scarce. My results may have widespread applicability as the humanpopulation continues to grow worldwide, stretching the resources of our fragile planet.Understanding what lead to the dissolution of civilizations in the Neolithic world may helppolicymakers anticipate future challenges. My research will inform efforts to understandsociopolitical impacts of climate change. Through agent-based models of the archaeologicaldata, I will analyze how people reacted to fluctuating temperature, reduction of key resourcessuch as woody fuels and water, crop failure, and inter and extra-tribal hostilities, which may havebeen induced from the changing environment.Additionally, this research will examine the extent to which alliances form out ofconflict, or as a means of providing positive per capita return in procurement of resources, andhelp us to understand not only the years of peace dominating the Mesa Verde region, but also thewave of violence that swept the area in its final years2. Future researchers will be able to build onthese models to understand the complex dynamics of human relations in other societies. We arepoised at a cross-roads as a civilization, plagued by many of the same issues that our ancestorsfaced. An understanding of our past will help us make informed decisions about our future.1 Kohler, T., et. al. 2007. Settlement Ecodynamics in the Prehispanic Central Mesa VerdeRegion. In The Model-Based Archaeology of Socionatural Systems, edited by T. A. Kohler andS. van der Leeuw, pp. 61-104. SAR Press, Santa Fe.2 Cole, S. 2007. Population Dynamics and Sociopolitical Instability in the Central Mesa VerdeRegion, A.D. 600-1280. Unpublished Master’s Thesis, Department of Anthropology,Washington State University, Pullman.3 Cabrera, D. et al. 2008. What is the crisis? Defining and prioritizing the world’s most pressingproblems. Frontiers in Ecology and the Environment 6(9):469–475.4 for example, see: Buchanan, Mark. 2009. Meltdown modeling: Could agent-based computermodels prevent another financial crisis? (News Feature) Nature 460(6):680-682.5 Henrich, J., et.al. (2005) ‘Economic Man’ in Cross-Cultural Perspective: Ethnography andExperiments from 15 small-scale societies. Behavioral and Brain Sciences, 28, 795-855..6 Gavrilets S., et. al. 2008. Dynamics of Alliance Formation and the Egalitarian Revolution.PLoS ONE 3(10): e3293. doi:10.1371/journal.pone.00032937 Kantner, J., 2004. Ancient Puebloan Southwest. Cambridge University Press. Cambridge, UK.p. 262"
244.0,"The First LAI-Linked Predictive Model for Below- and Above-Ground CarbonSequestration in Quaking AspenKeywords: vegetative regeneration, carbon modeling, climate change, aspen, conifersBackground: Forest ecosystem carbon is a key component to global climate initiatives and forestecosystems are the primary ecotype used for carbon registration protocols. Althoughmethodologies for estimating above-ground carbon sequestered are well established, using leafarea index (LAI) linked to basal area, below-ground carbon estimates are hampered by thepaucity and inconsistency of data for both coarse- and fine-root biomass (1). As soil rootcarbon is a more stable carbon sink than above-ground carbon, accurate below-ground carbonestimates are indispensable for modeling efforts (2).Objectives: I will measure the total biomass of quaking aspen in representative North Americanstands. LAI has strong positive correlations to coarse- and fine-root aspen biomass (3),(4).Above- and below-ground biomass and LAI will be determined in order to develop the firstpredictive model that relates LAI to above- and below-ground biomass for aspen. Quakingaspen (Populus tremuloides) is an excellent candidate for necessary root biomass samplingand carbon modeling. Populus is one of the most widely cultivated northern temperate treegenera in the world, and has both ecological and economic significance; in many ways, it isbecoming a ‘model tree’ for biomass and carbon sequestration (5). The most widelydistributed species in North America, aspen is extremely important ecologically for waterquality and habitat. However, it is in decline in the western United States for reasons notyet fully understood. Aspen root systems are unique; this species regenerates vegetatively fromshallow lateral roots, forming large clonal stands which can persist indefinitely, given the correctdisturbance regime. These coarse roots, then, persist after removal or decomposition of above-ground biomass, and possibly for several such stand-replacing events. This is very different fromroots of seed-regenerated trees, in which the root system dies with stem death and is subject tosoil microorganism heterotrophy.Expected Results: This study will generate a predictive model that relates quaking aspenLAI to above- and below-ground carbon allocation. It will also advance understanding ofthe ecology of a vegetatively reproducing forest species, an important but often overlookedniche (6). This research methodology may be applied to other species and used to explore below-ground relationships of other vegetatively regenerated forest ecosystems.Moreover, an accurate model that related above-ground aspen LAI to below-ground biomassand persistence will be useful economically for forest managers and carbon accreditation. Withthe basal area: LAI relationship we will develop, this model will be economical and practicalacross scales and for many interested parties, from small landholders to climate modelers.For small landholders with small forests, income from carbon accreditation can be important indeciding whether to invest in afforestation. A persistent soil carbon stock in aspen stands, ifpresent, would create significant financial incentive for afforestation with and preservation ofaspen. Benefits would also accrue for global climate and for areas historically forested withaspen.Broader Impacts: Through my ongoing volunteer work at high schools in Oakland UnifiedSchool District with minorities and disadvantaged students, I will integrate the project and itsactivities with educational activities for a variety of students. Interested students will be givenProposed Plan of Research Benjamin Caldwellthe opportunity to involve themselves in the research, with special effort made to employunderrepresented groups as field assistants and involve them in the laboratory. Oncedeveloped, our LAI-carbon model will be made available for download free of charge. Inaddition to the peer-reviewed literature, we will make presentations at conferences for forestmanagers and environmental organizations.Methodology: I will sample aspen in representative stands in western North America. Stands willbe selected on the basis of prior disturbance regime, stand health, and ecotype. I will use severalcomplementary methods to obtain a complete picture of leaf area, course root and above-groundbiomass, and fine-root flux.Leaf area: We will determine leaf area relationships by destructive sampling of approximately30 trees. A random subset of leaves from each tree will be collected and weighed in the field, andsubsequently scanned in the laboratory to determine leaf surface area. This will allow theprediction of leaf area at the stand level from basal area.Above-ground biomass: We will use fixed-area inventories from plots we installed to estimateabove-ground biomass. Canopy leaf weights and wood density will be used to predict carboncontent with allometric equations.Course root biomass: Since aspen roots are typically superficial, they are relatively easy to map.We will map root systems using ground-penetrating radar. This methodology is much lessinvasive and labor-intensive than excavation, and can be used to map changes in coarse-rootbiomass over time. Soil cores will be taken to standardize data sets and extrapolate root maps tobiomass and carbon (7).Fine root biomass: Fine-root biomass annual flux is best estimated over the course of one yearusing minirhizotrons (8). We will install minirhizotrons, capped plastic pipes measuringapproximately 180 by 5 cm, at a 45 degree angle from the soil surface. We will then takephotographs of roots which infiltrate the pipe throughout the course of the year, and determineroot length and biomass by analysis with dedicated software. Root biomass, determined from soilcores at the beginning of the sampling period, will be extrapolated to the stand level. Using theinitial root biomass and the initial minirhizotron values, we will find fine-root flux for the stand.Analysis: I will use regression analysis to develop leaf area prediction models from tree basalarea and height of the crown base in aspen. Tree growth will be predicted from tree leaf area.Using data on root biomass and stand LAI, we will develop predictive equations that relate LAIto above- and below-ground tree carbon. Results will be integrated with MASAM, an existingforest stand health model, to provide tree restoration guidelines, LAI, and carbon estimates (9).Cited Literature1. Brown, S. Environmental Pollution. 116, 363-72 (2002)2. Rasse, D. P., Rumpel, C., Dignac, M. Plant and Soil. 269, 341-356 (2005)3. DesRochers, A., Lieffers, V. Canadian Journal of Forest Research. 31, 1012–1018 (2001)4. Davis, J., Haines, B., Coleman, Hendrick, R. Forest Ecology and Management. 187, 19-335. Taylor, G. Annals of Botany. 90, 681-689 (2002)6. Bond, W., Midgley, J. Trends in Ecology & Evolution. 16, 45-51 (2001)7. Butnor, J. et al. Soil Science Society of America Journal. 67, 1607 (2003)8. Hendricks, J. J. et al. Journal of Ecology. 94, 40-57 (2006)9. O'Hara, K. Forest Ecology and Management. 118, 57-71 (1999)"
245.0,"An Empirical Analysis of the Role of Ecological Filters in Grassland RestorationKeywords: restoration, ecological filters, community assembly, invasive plant managementIntroduction: (cid:39)(cid:72)(cid:74)(cid:85)(cid:68)(cid:71)(cid:68)(cid:87)(cid:76)(cid:82)(cid:81)(cid:3)(cid:75)(cid:68)(cid:86)(cid:3)(cid:85)(cid:72)(cid:71)(cid:88)(cid:70)(cid:72)(cid:71)(cid:3)(cid:72)(cid:70)(cid:82)(cid:86)(cid:92)(cid:86)(cid:87)(cid:72)(cid:80)(cid:3)(cid:86)(cid:72)(cid:85)(cid:89)(cid:76)(cid:70)(cid:72)(cid:86)(cid:3)(cid:82)(cid:89)(cid:72)(cid:85)(cid:3)(cid:81)(cid:72)(cid:68)(cid:85)(cid:79)(cid:92)(cid:3)(cid:75)(cid:68)(cid:79)(cid:73)(cid:3)(cid:82)(cid:73)(cid:3)(cid:87)(cid:75)(cid:72)(cid:3)(cid:40)(cid:68)(cid:85)(cid:87)(cid:75)(cid:182)(cid:86)(cid:3)(cid:79)(cid:68)(cid:81)(cid:71)(cid:3)area, making an understanding of ecological restoration a critical issue for ecology [1].However, restoration has historically been practiced on an ad hoc basis, without adequateplanning or proper application of the scientific method. As a result, most restoration projects failto achieve lasting change and seldom provide insights that may be broadly applicable andadvance restoration theory.Experts in the field of restoration ecology are now calling for studies that applyecological principles to empirically test basic ecological theories that are pertinent to restoration,such as community assembly and succession and, specifically, the role of trophic interactions [2].My research attempts to respond to this call by answering questions regarding the interactions ofherbivory, seed-predation and biotic soil disturbance in the restoration of a grassland ecosystemin California. Through my efforts, I hope to advance the science and practice of large-scalegrassland restoration.Background: The ultimate goal of restoration ecologists is to manipulate assembly andsuccession in ways that produce the most desirable stable state, either by speeding up naturalprocesses or by overcoming thresholds that might be insurmountable without humanintervention. Ecological filters are biotic or abiotic variables that favor the assembly of certainspecies over others. If well-understood, these filters can be used to favor desirable species whileinhibiting the establishment of undesirable ones, thereby directing community assembly towardsthe most desired state. In grasslands that have been invaded by exotic annual grasses, managerscould use ecological filters to promote the re-assembly of native bunchgrasses to improve habitatquality for native plants and animals and improve forage quality for livestock [3].The role of plant-herbivore interactions such as herbivory, seed-predation, and biotic soildisturbance as potential ecological filters is poorly understood. Evidence suggests that physicalsoil disturbance caused by burrowing rodents, such as the endangered Giant Kangaroo Rat(Dipodomys ingens) in my study system, promotes the invasion of exotic annual grasses [4].However, recent work has shown that kangaroo rats also preferentially eat the large seeds ofexotics and thus the net effect of their presence on plant recruitment is currently unknown [5].Another study found that the exotics responded to defoliation with more vigorous regrowth thannatives did, and the authors therefore concluded that grazing by large herbivores promotesdominance by exotics [6]. However, the effects of grazing are not limited to defoliation; animalsalso exhibit preferential selection and alter soil characteristics through compaction and nutrientaddition [7]. Thus, the net or synergistic effects of these interactions on native plant restorationremain unclear.Hypotheses: (1) Soil disturbance by kangaroo rats will favor the assembly of exotic grasseswhile compaction caused by cattle will favor native bunchgrasses. (2) Nutrient addition by bothanimal species will favor the assembly of exotics and have a greater impact on the re-assemblyprocess than physical soil disturbance. (3) Cattle with help export excess nutrients by selectivelygrazing nutrient rich vegetation and kangaroo rats will control the abundance of exotics bypreferentially consuming their seeds. (4) A combination of cattle and kangaroo rats will be mostsuccessful in directing re-assembly towards a state dominated by native bunchgrasses.Research Plan: To test the effects of herbivory, seed-predation, and soil disturbance on re-seeding efforts I will establish 1-m2 restoration plots within an existing framework of nestedcattle and kangaroo rat exclosures(cid:178)allowing for the quantification of both the individual andPage 1 of 2Proposed Plan of Research Christopher M. Gurneycombined effects of cattle and rodents. Two plots will be established in each of the three testareas, one on rodent disturbed soil and one on undisturbed soil (n = 10 exclosures). Additionally,soil samples will be taken on and off disturbed soil in each test area and will be analyzed for bulkdensity and chemical composition. These data will allow for the artificial decoupling of physicalsoil disturbance from nutrient addition. Additional plots will be established in the kangaroo ratexclosures(cid:178)one to simulate physical soil disturbance, one to simulate nutrient addition, and oneto simulate both types of disturbance (for comparison with genuinely disturbed plots) for bothanimal species. Differences in bulk density will be simulated using a soil corer (to reducedensity) or a rammer (to increase density). To simulate nutrient addition, fertilizer will be addedto plots in an amount necessary to achieve the observed soil chemical composition wherekangaroo rats or cattle have been active.All plots will first be surveyed in the spring using a pinframe method, then sprayed withherbicide and sown with four rows of seeds in the following winter. Each row will be randomlyassigned to one of four native species of varying forage quality(cid:178)two were preferred and twowere avoided in kangaroo rat feeding trials [5]. Plots will be monitored weekly through thegrowing season. Soil disturbance, seed germination, and herbivory on seedlings will be recorded.Plant cover will be monitored annually each spring. Data will be analyzed using mixed-modelANOVAs.Logistics and Support: The nested cattle and kangaroo rat exclosures were constructed twoyears ago as part of a concurrent project. The effectiveness of this experimental framework hasalready been demonstrated [5], and the kangaroo rat exclosures are checked on a regular basis forevidence of rodent activity. Our partners at the Bureau of Land Management (BLM) are in fullsupport of this project and have generously agreed to provide the required seed and equipment.As a graduate student at UC Berkeley, I will also have access to the resources provided by theGraduate Group in Range Management(cid:178)including the support of expert faculty who specializein grassland ecology and restoration.Broader Impacts: The results of my research will advance ecological theory by helping toelucidate the roles of herbivory, seed predation, and biotic soil disturbance on plant communityassembly. Since many of the issues addressed in my research are ubiquitous throughoutgrassland ecosystems, my findings could be broadly applied in restoration all over the world.These results will also be useful to land managers and ranchers who hope to reduce the damagecaused by invasive plants(cid:178)currently estimated at $2 billion annually in US grasslands [8].Besides preparing the results for peer-reviewed publication, I will also collaborate with variousstakeholders to determine how my findings can best be applied to large-scale management andrestoration. At a local level, the joint managing partners of Carrizo Plains National Monument(the BLM and the Nature Conservancy) have already demonstrated a keen interest in applyingthe results of my research in future restoration projects at the Carrizo Plains(cid:178)(cid:38)(cid:68)(cid:79)(cid:76)(cid:73)(cid:82)(cid:85)(cid:81)(cid:76)(cid:68)(cid:182)(cid:86)(cid:3)(cid:79)(cid:68)(cid:85)(cid:74)(cid:72)(cid:86)(cid:87)(cid:3)remnant grassland and home to 13 endangered species.References: [1] G.C. Daily, Science, 269, 350 (1995). [2] V.K. Temperton et al. Assembly Rulesand Restoration Ecology (Island Press, 2004). [3] L.F. Salo, Journal of Arid Environments, 57,291 (2004). [4] Schiffman, P.M. Biodiversity and Conservation 3, 524 (1994). [5] L.R. Prugh,Carrizo Exclosure Experiment Report (Prepared for The Nature Conservancy, 2008). [6] S.Kimball, and P.M. Schiffman. Conservation Biology 17, 1681 (2003). [7] M.R. Stromberg, J.D.(cid:38)(cid:82)(cid:85)(cid:69)(cid:76)(cid:81)(cid:15)(cid:3)(cid:68)(cid:81)(cid:71)(cid:3)(cid:38)(cid:17)(cid:48)(cid:17)(cid:3)(cid:39)(cid:182)(cid:36)(cid:81)(cid:87)(cid:82)(cid:81)(cid:76)(cid:82)(cid:17)(cid:3)(cid:3)California Grasslands Ecology and Management (University ofCalifornia Press, 2007). [8] J.M. DiTomaso, Weed Science, 48, 255 (2000).Page 2 of 2"
248.0,"Feature Discovery in Link MiningKeywords: link mining, feature discovery, machine learning, graph theory, relational dataBackground: Traditional data mining approaches attempt to find patterns in a data setcharacterized by a collection of independent instances of a single relation. This is consistent withthe classical statistical inference problem of trying to identify a model given a random samplingof an underlying distribution. A key challenge for machine learning is the problem of miningmore richly structured data sets in a way that leverages the linkages between records [1]. In thisparadigm, which more accurately resembles real-world data, instances in the data set arerelational where different samples are related to each other, either explicitly as typified byfriendship relationships in a social network, or on the web by hyperlinks [2]. However, in mostlarge data sets, relationships also exist that are not explicitly annotated. According to Jensen,naively applying traditional machine learning methods to this type of data can lead toinappropriate conclusions [3]. Therefore new approaches are needed to appropriately correlateinherent relationships (i.e. links) in real-world data sets.In recent years, there has been a growing interest in learning from structured, real-world data.This type of data can be described by a graph where the nodes in the graph represent objects, andedges in the graph represent relationships between objects. Perhaps the most famous example ofexploiting link structure is the PageRank algorithm [4] employed by the Google search engine.Link mining is situated at the intersection of graph theory, machine learning, and web mining.This research is potentially useful in a wide range of application areas including bio-informatics,bibliographic analysis, financial analysis, national security, social network analysis, and internetsearch to name a few. While my research is focused more on the theoretical aspects of this topicthan in the applicative possibilities, I was happy to see that my work has already been adapted tothe bioinformatics domain to study the interactions of proteins [5].Research: Despite the recent advances in link mining, this topic is still relatively new and thereare many fundamental challenges that remain. Unlike more mature fields of research there doesnot exist any public package or toolkit that provides a standard baseline from which to explore.Therefore, I propose to create a link mining framework that adapts several of the core principlesof link and graph mining into a scalable, shared package. This toolkit would be an essentialresearch and teaching tool similar to the University of Waikato’s WEKA toolkit [6] or GeorgeMason’s ECJ system [7]. Initially, this project would only incorporate fundamental and highly-extendable principles of link mining, but most importantly it will serve as a launch-pad for moreinteresting, collaborative theoretical work.With a core link mining package in place I propose to study the dynamic temporal and graphicalnature of relationships within various domains in order to advance the theory of andmethodology for determining probabilities of link existence where none are explicitly annotated.This process involves several steps. First a domain must be selected that exhibits the relationalattributes applicable to the link mining paradigm. Data from social networks, protein inter-actions, citations, microarrays, etc. all contain necessary attributes; therefore this step is arguablythe most straightforward because many real-world data sets are inherently relational [1].After the domains are defined, features that describe the relationships need to be extracted. Forexample, friendship in a social network is annotated by the inclusion of the friend’s name on aTim Weninger 2008 NSF Graduate Fellowship Research Proposaluser’s homepage. Pair-dependent features, such as the size of the intersection of interests, etc.,offer supplementary evidence for the existence of a friendship. These pair-dependent featureswill be used to determine the probability for link existence where it is not annotated. Finding thenon-obvious pair-dependent features is arguably the most difficult part. Therefore, I propose theuse of recent developments in association rule mining and frequent pattern mining by Dr. JiaweiHan et al. [8] to find correlations between data points that best suggest link existence.Furthermore, the general problem of feature selection, extraction and discovery is widelyregarded as the most important factor in machine learning [9].Besides pair-dependent features, I propose to explore the role that graph features have inidentifying relationships that lack explicit annotation. In my experience, graph features, such asthe shortest path distance between candidate vertices, offer the best support (in terms of entropy)for the existence or absence of links. The major problem with this approach is that extractinggraph features is computationally expensive for sufficiently large graphs. Although I have begunwork on developing fast, approximate search algorithms I will need to formalize and empiricallystudy these methods. Finally, these features will be used by traditional machine learners to deriveinformation about relationships in data sets.In each step, theories would be tested using the aforementioned link mining toolkit in order toefficiently derive empirical results. I plan to advertise and freely share my toolkit, and continueto present and publish results at refereed conferences and in refereed journals on a regular basis.While my research generally aims to expand the theoretical and computational potential ofmachine learning, the implications of link mining research can already been seen in thebiological, physical and social sciences, and many researchers believe that the application of linkmining techniques will continue to grow as more research is conducted.With help from the NSF GRF I intend to study at the University of Illinois Urbana-Champaign(UIUC) where the Data Mining Research Group led by Dr. Jiawei Han (reference letter writer)and I already have a working relationship. I believe that Dr. Han and his colleagues at UIUC areamong the best researchers in the world, and they would provide the wisdom and expertisenecessary for me to continue my work in this fascinating field.References:[1] Lu, Q., Getoor, L., “Link-based Classification”. ICML'03, Washington DC, 2003.[2] Sen, P., Getoor, L., “Link-based Classification”. University of Maryland CS-TR-4858. 2007.[3] Jensen, D., “Statistical challenges to inductive inference in linked data”. In Proceedings of theSeventh International Workshop on Artificial Intelligence and Statistics. 1999.[4] Page, L., Brin, S., Motwani, R. & Winograd, T. “The pagerank citation ranking: Bring order tothe web”. Technical Report. Stanford University. 1998.[5] Paradesi, M.S.R., Caragea, D. and Hsu, W.H., “Structural Prediction of Protein-ProteinInteractions in Saccharomyces cerevisiae”, IEEE-BIBE'07, vol. 2, Boston, MA, Oct. 2007.[6] Witten, I. H. and Frank, E., “Data Mining: Practical machine learning tools and techniques”, 2ndEdition, Morgan Kaufmann, San Francisco, 2005.[7] ECJ: A Java-based evolutionary computation research system, 2006. http://cs.gmu.edu/eclab/projects/ecj/[8] Han, J., Pei, J., & Yin, Y., “Mining frequent patterns without candidate generation”, InternationalConference on Management of Data ACM-SIGMOD'00, pp. 1-12. 2000.[9] Caruana, R, Niculescu-Mizil, A., “An empirical comparison of supervised learning algorithms”.ICML'06, pp. 161-168, Pittsburgh, PA, 2006."
249.0,"An Adaptive Chemistry Reduction Method for Detailed Modeling ofAdvanced Combustion SystemsKey words: combustion, mechanism reduction, stiffness removal, CFDCombustion of hydrocarbon fuels provides 85% of energy in the modern United States[1]; the current energy crisis is in reality a fuel crisis. While renewable forms of energy arebeing pursued to supplement combustion-based sources, hydrocarbon fuels will remain the majorcomponent for the next few decades. Currently, there is high demand to improve the efficiencyof combustion technology to decrease the amount of fuel consumed and to reduce the emissionsin an effort to lessen the environmental impacts; in addition, fuel-flexible designs that can run onboth conventional and alternative fuels are desired.Computational modeling drives the design of new combustors and engines for aerospace,transportation, and energy applications, but accurate prediction of fuel consumption andpollutant emissions requires detailed chemical reaction mechanisms. Detailed mechanisms forliquid hydrocarbons of interest contain large numbers of species and reactions; for example, thereaction mechanisms for n-heptane (C H ) and iso-octane (C H ), important molecules for7 16 8 18gasoline modeling, contain almost 1000 species and 8000 reactions [1]. Despite rapidadvancements in computing power, it is generally formidable to integrate such detailed reactionmechanisms into large-scale computational simulations, in terms of CPU time and memoryrequirements. In addition, the wide range of time scales (from nanosecond to second) and thenonlinear coupling between species and reactions induces stiffness when governing equations aresolved. Due to these computational demands, practical simulations using detailed chemistry areimpossible with modern computational tools.Mechanism reduction schemes are used to allow quantitative modeling while keepingrealistic chemistry effects. Non-adaptive reduction methods perform reduction based on apredicted range of conditions typically by removing unimportant species and reactions andidentifying the species with fast time scales for further reduction, providing a single globalmechanism. Most adaptive reduction methods, on the other hand, operate by storing chemicalkinetics information and retrieving necessary data during the simulation to avoid directintegration of the differential equations; newer techniques use multiple mechanisms reducedprior to the simulation at various points in the flow. I propose the development of a noveladaptive and computationally friendly reduction method that will remove unimportant speciesand reactions and eliminate stiffness on the fly. I aim to explore and develop new algorithmswhile using existing reduction methods as a basis.Non-adaptive reduction methods attempt to provide a valid reduced mechanism bypredicting the range of conditions (pressure, temperature, mixture composition) of interest in asimulation. However, the size of the reduced mechanism is limited by the locations in thecomputational domain that require more detailed chemistry due to high reaction activity. Manymethods have been developed to reduce mechanisms in this manner, but the application ofdirected relation graph (DRG) theory [2] to describe reacting systems is particularly useful. Inthis method, nodes of the DRG represent species and directed edges represent dependencesbetween species defined by normalized contributions to production rates. Important targetspecies are defined (e.g. fuel, oxidizer, pollutants) and a graph-searching algorithm finds thedependent set of species needed to accurately predict the production rate of targets. Species withcontributions below a certain error threshold are removed from the dependent set, and the finalreduced mechanism contains the union of all dependent sets. The algorithm then eliminatesreactions containing the unimportant species. For further elimination of stiffness in reaction1NSF GRFP 2008 – Proposed Plan of Research – Kyle Niemeyersystems, the quasi steady state (QSS) and partial equilibrium (PE) assumptions are applied [3].QSS species and PE reactions have very short time scales, causing stiffness, and theapproximations seek to replace differential equations with algebraic relations to solve forspecies’ concentrations. Computational singular perturbation (CSP) and intrinsic lowdimensional manifold (ILDM) [3] are traditional methods for finding QSS species and PEreactions by separating fast and slow processes.Adaptive reduction methods rely on different approaches to increase computationalefficiency during simulations. Approaches such as in situ adaptive tabulation (ISAT) andartificial neural networks (ANN) [4] perform storage and retrieval of chemical kineticsinformation to save processing time. Newer adaptive methods such as genetic algorithms (GA)[5] and optimization-based approaches [6] use various techniques to provide multiple reducedmechanisms for use during the simulation at different points in the flow. Highly detailedchemistry needs to be considered at locations where reactions are actively occurring, whileregions with little reactive activity can use extremely reduced mechanisms. However, all of themethods currently rely on predictive reduction, which will not provide the highest level ofaccuracy or reduction.I propose the investigation of a new adaptive reduction methodology that will perform onthe fly removal of species and reactions and elimination of stiffness. Identification and removalof unimportant species and reactions based on local conditions allows for the highest level ofreduction and therefore the least computational demand, while keeping high accuracy. I willexplore a novel algorithm for species and reaction removal using the DRG concept as a startingpoint; previous studies [2] based on DRG have shown it to be fast and reliable, suitablecharacteristics for on the fly application. Traditional methods for identifying QSS species andPE reactions such as CSP and ILDM are time-intensive [3] and therefore not well suited for onthe fly stiffness removal; as such, I will also investigate efficient methods for identifying thesefast processes.The adaptive reduction method I have proposed can be directly applied to the simulationof combustion processes for aeropropulsion, transportation, and energy applications. Theincorporation of detailed chemistry while providing speedy simulation will allow accuratemodeling of fuel consumption and emissions and help drive the design of next-generationengines and combustors. A method based on graph theory could be also be applied to themodeling of other complex systems; broader applications consist of food web/ecosystemmodeling, disease spreading modeling, climate modeling, and biological systems modeling.Also, a new methodology developed to perform mechanism reduction could also be used to mineimportant information about complex systems. For example, a CSP-based method was used togather information about explosive processes in a simulation of a hydrogen/air turbulent lifted jetflame [7]- the new method I propose could be used similarly for data mining.References[1] “Basic Research Needs for Clean and Efficient Combustion of 21st Century Fuels,”DOE/BES Workshop Report (2006).[2] T.F. Lu, C.K. Law, Combust. Flame 144 (2006) 24-36.[3] T.F. Lu, C.K. Law, J.H. Chen, AIAA 2008-1010 (2008).[4] J.Y. Chen, J.A. Blasco, N. Fueyo, C. Dopazo, Proc. Combust. Inst. 28 (2000) 115-21.[5] I. Banerjee, M.G. Ierapetritou, Combust. Flame 144 (2006) 619-33.[6] O.O. Oluwole, P.I. Barton, W.H. Green, Combust. Theory Model. 11 (2007) 127-46.[7] T.F. Lu, C.S. Yoo, J.H. Chen, C.K. Law, AIAA 2008-1013 (2008).2"
250.0,"permission.CAUSES AND CONSEQUENCES OF BIOCOMPLEXITYKeywords: Adaptation, biocomplexity, biodiversity, natural selection, resilienceConspecific populations often differ in important fitness-related traits. Why might this be?One mechanism driving population differentiation is divergent natural selection, wherein spatialvariation in selection drives divergence of populations. Such phenotypic diversity amongproximate populations [hereafter “biocomplexity” (1)] is important for the long-termsustainability of the larger population complex because the relative contribution to totalproduction may shift among different life histories depending on the prevailing environmentalconditions (1). Despite the intuitive appeal of these ideas, the causes and consequences ofbiocomplexity are rarely studied.Variation in natural selection is the presumed mechanism generating biocomplexity. Forinstance, spatial variation in selection has been shown to drive divergence in age-at-maturity ofTrinidadian guppies (2). Similarly, temporal variation can drive evolution of phenotypic traits, asevidenced by microevolution of beak size in Darwin’s finches in response to short-term climateperturbations (3). Yet, studies quantifying spatio-temporal variation in selection are exceedinglyrare and the ecological circumstances driving selection are rarely understood.The overarching goal of my study is to examine the causes and consequences ofbiocomplexity among proximate salmon populations. Pacific salmon are an excellent system inwhich to test these ideas because they form discrete breeding populations, which are then subjectto local selection pressures. Reproductive isolation combined with spatially varying selectionpressures result in adaptation to local conditions and, ultimately, a diversity of phenotypesamong populations. Furthermore, fine-scale variation in environmental conditions also leads toecologically-driven variation among proximate populations (i.e., phenotypic plasticity). Herein, Ipropose to study coho salmon (Oncorhynchus kisutch) during their freshwater-rearing (juvenile)stage across multiple sites within the Lagunitas Creek watershed (California).Goal 1: Determine the causes of biocomplexityHypothesis 1: Physical habitat attributes drive variation in fitness-related traits. Variation inlocal conditions can lead to phenotypic variation among salmon populations (4). Indeed, recentwork has demonstrated that when habitat diversity is lost, specific salmon life historycomponents are also lost (5). I will quantify seasonal variation in stream temperature and flowamong ten tributaries of Lagunitas Creek across 3 years using standard methods (6). At each site,I will mark individual fish to monitor their size and growth through time. I will use a formalmodel comparison approach (7) to determine the physical habitat attributes contributing tophenotypic diversity among these proximate salmon populations.Hypothesis 2: Food web structure drives variation in fitness-related traits. Variation in streamflows has been shown to have a strong impact on food web structure among years (8). Moreover,variation in food-web structure can influence fitness-related traits in fish consumers (9). Toinvestigate the role of food web structure as a driver of biocomplexity among salmonpopulations, I will characterize variation in food web structure among three tributaries spanninga gradient of stream size. Specifically, I will sample tissues from multiple trophic levels andquantify stable isotopes of carbon and nitrogen to illuminate food web structure (10). I will againuse a formal model comparison approach to test the drivers of variation in food web structureamong sites using data collected as part of Hypothesis 1, as well as the consequences of variationin food web structure to size and growth of salmon across sites.Hypothesis 3: Spatio-temporal variation in natural selection drives variation in body size. Afterdetermining the drivers of variation in size and growth, I plan to quantify natural selection actingCopyright 2008 All Rights Reserved to Original Author. Do not duplicate or use withoutpermission.on these traits. I will use data collected on individual fish across multiple seasons to relatephenotypic traits to survival across focal intervals (e.g., winter). I will use standard approaches(11) for quantifying natural selection across sites and years.Goal 2: Determine the consequences of biocomplexityHypothesis 4: Variation in smolt size and production differs among sites and years. Manystudies have demonstrated the importance of size-at-smolt migration to ocean survival, withlarger smolts presumed to survive at higher rates than relatively smaller smolts (12). I propose todetermine the consequences of biocomplexity in juvenile growth rates and survival byquantifying variation in smolt size and production among sites by trapping out-migrating smoltsfrom each site, measuring body size, and estimating site-specific smolt production. Analysis ofthese data will allow me to determine the consequences of variation in the ecologicalcircumstances experienced during the juvenile-rearing stage to smolt size and production, whichthen influence adult production. This will then allow me to identify production “hotspots” withinthe system and to distinguish factors that lead to high smolt production in those areas.Anticipated Results: I anticipate that variation among sites of abiotic conditions and food webstructure drives biocomplexity among proximate salmon populations. I also expect to findevidence of spatio-temporal variation in the strength and form of selection acting on body size.With the above factors potentially driving biocomplexity, I expect smolt size and production tovary among sites. This underscores the importance of maintaining a diversity of freshwaterhabitats to maintain biocomplexity among salmon populations as a buffer for future changes.Intellectual Merit and Broader Impacts: With the recent collapse of California salmon stocks,investigations regarding the link between biocomplexity and sustainability are becomingincreasingly important. My research seeks to provide insight into the causes and consequences ofbiocomplexity and may help create more robust management practices that maintain the fulldiversity of phenotypes in proximate populations, thus ensuring some resilience to futureperturbations. To communicate the significance of my original research, I plan to disseminate thefindings of this study through various modes including via 1) peer-reviewed, published literature;2) the Ecological Society of America conference (where I am a student member); and 3) tointerested citizens via, for instance, the Point Reyes National Parks Service Podcast.Additionally, I plan to work closely with a local community-based group, the Salmon Protectionand Watershed Network (SPAWN), in order to convey my findings to the local community.Finally, as a Burmese-American student in the environmental sciences, I am aware of the lack ofethnic diversity in my field. U.C. Berkeley has an incredibly diverse undergraduate body and Iwill strive to incorporate students from diverse backgrounds into all aspects of my research.References: 1. R. Hilborn, T. P. Quinn, D. E. Schindler, D. E. Rogers, Proc. Natl. Acad. Sci. U.S. A. 100, 6564 (May, 2003). 2. D. A. Reznick, H. Bryga, J. A. Endler, Nature 346, 357 (Jul,1990). 3. P. R. Grant, B. R. Grant, Science 296, 707 (Apr, 2002). 4. P. J. Wigington et al.,Frontiers in Ecology and the Environment 10, 513 (Dec, 2006). 5. M. M. McClure et al.,Evolutionary Applications 1, 300 (2008). 6. F. R. Hauer, G. A. Lamberti, Methods in StreamEcology. (Academic Press, San Diego, CA, ed. 2nd, 2007). 7. K. P. Burnham, D. R. Anderson,Model Selection and Multimodel Inference: A Practical Information-Theoretical Approach.(Springer, New York, ed. 2nd ed., 2002). 8. M. E. Power, M. S. Parker, W. E. Dietrich,Ecological Monographs 78, 263 (May, 2008). 9. K. B. Suttle, M. E. Power, J. M. Levine, C.McNeely, Ecological Applications 14, 969 (Aug, 2004). 10. J. C. Finlay, S. Khandwala, M. E.Power, Ecology 83, 1845 (Jul, 2002). 11. R. Lande, S. J. Arnold, Evolution 37, 1210 (1983).12. T. P. Quinn, The Behavior and Ecology of Pacific Salmon and Trout. (University ofWashington, Press, Seattle, 2005)."
251.0,"Crossover Regulation During Caenorhabditis elegans MeiosisKeywords: chromosome structure, condensin, crossover interference, meiosis, recombinationMeiosis is essential for the generation of genetic diversity. All sexually-reproducing eukaryotesundergo this specialized cell division, consisting of one round of DNA replication followed by tworounds of chromosome segregation. Successful segregation requires crossover recombination, which isinitiated by a programmed double strand break (DSB) that causes the reciprocal exchange of geneticinformation between homologous chromosomes. Crossovers (COs) provide physical links betweenhomologs, but they also facilitate evolution by culling deleterious mutations and creating novel alleliccombinations.Due to their importance, COs are subject to strict regulation that guarantees at least one CO perhomolog pair and ensures wide spacing of multiple COs. Additionally, COs preferentially occur ongenomic intervals called “hotspots.” These flank haplotype blocks, allelic combinations that tend to beinherited together and are evolutionarily more stable.1 Hotspots determine the evolutionary genomiclandscape, but efforts to predict their location have only been partially successful.2 CO hotspots are alsohotspots for DSBs, though not all DSBs become COs.3 Therefore, CO regulation affects DSBdistribution and DSB resolution into COs or noncrossovers (NCOs). 4,5 The nematode C. elegansprovides an elegant system to study this control, for it exhibits complete CO interference: each homologpair only has one CO per meiosis.6Chromosomes are structured by a number of protein complexes, one being the highly-conservedcondensin complex. C. elegans has three condensins involved in dosage compensation, chromosomecompaction, and CO control.7 Disruption of the meiotically-active condensin I complex causeschromosomal axis extension, which alters DSB distribution and thus CO distribution.5 Previously, thecondensin II complex was thought to act only in mitosis – but work in the Meyer lab has shown that it isalso involved in meiosis, downstream of CO regulation.8 Preliminary data from the lab implicates atleast one condensin II subunit earlier in meiosis that affects CO distribution in a way that differs fromcondensin I.Though CO control is widespread, its precise mechanism remains a mystery. I propose to use C.elegans as a model in which to deepen our understanding of CO regulation by examining how COdistribution is affected by both meiotic condensin complexes.Hypothesis: Condensin II regulates crossover frequency at the level of DSB initiation by lengtheningchromosome axes, which changes the binding of DNA to each axis. Mutations in condensin I or II willcause a change in CO frequency manifested by altered hotspot distribution.Aim 1. Do changes in chromosome structure affect CO number by altering DSBs?To determine when CO regulation occurs, I will identify the relationship between DSBformation, DSB resolution, and changes in chromosomal structure as revealed by a lengthened axis. Foreach experiment proposed below, I will test five condensin II subunit mutants, which we have in lab.Previously-characterized condensin I mutants will serve as a positive control and wild type animals as anegative control. I will also generate animals with mutations in both condensin I and II to uncoverinteractions between the two complexes. a. Measuring CO frequency. I will score six X chromosomeSNPs (single nucleotide polymorphisms) in recombinant individuals generated from crosses betweentwo divergent laboratory strains. In males, CO frequency and distribution can be ascertained alongsingle X chromatids. Preliminary data leads me to expect increased CO frequencies in condensin IImutants, implying that condensin II limits CO formation, but a decreased CO frequency would indicatethat condensin II acts to trigger CO formation. b. Measuring DSB frequency. To demonstrate thatincreased CO frequency is due to increased DSB frequency, I will label DSB position throughoutmeiosis by immunostaining with RAD-51 antibody, which marks recombination intermediates.Correlation of elevated DSB numbers with higher CO frequencies in condensin II mutants wouldindicate that additional DSBs provide further substrate for COs, while a lower DSB frequency wouldCopyright 2008 Original Authorimplicate involvement at the level of DSB resolution. c. Measuring chromosomal axis length. Tomeasure axis length of X chromosomes, I will use fluorescent in situ hybridization to sequencescontaining the SNPs from Aim 1a. After immunostaining for DSBs and an antibody to thechromosomal axis protein HTP-3, I can trace labeled X chromosome axes through deconvolved 3Dimage stacks. Computationally straightening these traces with software present in the lab will allow meto measure axis length within microns and analyze DSB foci on individual X chromatids. Unlikeprevious lower-resolution studies, this will identify whether sub-chromosomal axis expansions correlatewith increased DSB frequency in condensin mutants, demonstrating that changes in chromosomestructure affect CO number by creating more DSBs. However, any change in DSB frequencies onaltered axis intervals would further bolster a relationship between chromosome structure, DSB initiation,and CO resolution.Aim 2. How do condensins I and II exert effects on chromosome structure?If the condensin complexes affect higher-order chromosome structure by modifying axis length(which I will have determined in Aim 1c), they must also change where DNA attaches to thechromosome axis. To examine whether condensin mutants have these structural changes, I will useChIP-seq (chromatin immunoprecipation sequencing) to detect the binding of REC-8, a meiosis-specificcohesin that marks DNA-axis attachment, and the axis protein HTP-3. ChIP will isolate specific DNAsequences of protein binding to be identified by high-throughput Solexa sequencing. UC Berkeley hastwo Solexa sequencers readily available to graduate students in my department. I will analyze REC-8and HTP-3 binding in condensin I mutants, condensin II mutants, and the double mutant, choosing thesubunit mutant conditions that show the strongest CO effect from Aim 1a; wild type animals will serveas a control. Antibodies to both proteins suitable to ChIP have been generated in the lab. If condensinmutants exhibit no change in REC-8 or HTP-3 binding, CO regulation may change axis length withoutaffecting DNA-axis attachment. However, differential DNA-axis binding and altered axis lengths incondensin mutants will reveal a direct association between chromosome structure and CO regulation.Aim 3. What are genome-wide trends of CO in C. elegans?To determine the relationship between DSBs and their resolution into COs or NCOs, I will usemicroarrays to generate recombination maps for wild type and animals mutant for condensin I, II, andboth, again choosing mutant conditions with the strongest CO effect. Previous recombination studieshave lacked the resolution to detect NCO formation. To address this, I will use hundreds of SNPs oneach chromosome that cause differential hybridization between two divergent laboratory strains,choosing markers that are reproducibly observed on high-throughput tiling arrays.9 Several studies in S.cerevisiae have utilized similar technology,10,11 but few other metazoans will prove as tractable to agenome-wide analysis as C. elegans, due to its small genome, numerous SNPs, and clonal individuals. Iwill define CO hotspots, and therefore haplotype blocks, using the wild type recombination map. I willalso uncover, for the first time, whether NCOs have an effect on overall CO regulation in C. elegans.Additionally, if hotspot architecture changes in condensin mutants, I will have identified a chromosome-wide mode of CO regulation consistent with global control of hotspot activity.This project is fundamentally interesting because it will elucidate a conserved and universalphenomenon for generating diversity, but it will also have a significant impact on our understanding of abasic evolutionary mechanism. Condensins have the ability to exert global effects on chromosomearchitecture – permitting chromosome-wide communication that could explain the appearance anddisappearance of CO hotspots within short spans of time. Determining the mechanism responsible forCO regulation and identifying CO hotspots will be crucial to our understanding of genome organizationand evolution.All proposed research is original and of my own design.References: (1) Kauppi L et al. 2007. Prot Natl Acad Sci USA. (2) Petes TD. 2001. Nat Rev Genet. (3) Szostak JW et al.1983. Cell. (4) Bishop DK & Zickler D. 2004. Cell. (5) Mets DM & Meyer BJ. 2008. MS in preparation. (6) Hillers KJ &Villeneuve AM. 2003. Curr Biol. (7) Tsai CJ et al. 2008. Genes Dev. (8) Chan RC et al. 2004. J Cell Bio. (9) Jones MR etal. 2008. BMC Genomics. (10) Chen SY et al. 2008. Dev Cell. (11) Mancera E et al. 2008. Nature."
252.0,"permission.Investigating Informal E-Waste Recycling Methods and Associated Soil PollutionKey words: environmental pollution, heavy metals, e-waste, recycling, informal, DelhiWhere does your computer go to die? Electric and electronic waste (e-waste) containshazardous materials and much of it is processed with few environmental controls. Annually, anestimated 20 to 50 million tons of e-waste is produced worldwide1 and due to the substantialamount of labor involved in the recycling of electronic devices, many e-waste dealers turn todeveloping economies for processing2. Policies designed to address the movement of e-wasterecycling increasingly require robust scientific evidence of toxic leaching and the nascent bodyof evidence describing the environmental effects of unregulated or informal e-waste recycling islargely anecdotal3, 4. The few empirical studies have operated at an inappropriate scale to makeassociations between processing categories and associated levels of pollution5; have analyzedpolicy at a more global scale2, 6; or have focused on pollutant leaching in a laboratory setting as aproxy for environmental leaching7. The recent US Government Accountability Office report(GAO-08-1044, August 2008) criticizing the US EPA’s handling of e-waste highlights therelevance of this research. My study will make a significant contribution to both research andpolicy by addressing this gap in scale and context and by testing for robust associations betweenquantified pollutant levels and specific e-waste industrial processes in the field environment.This investigation will classify and map e-waste recycling operations and quantifyassociated pollutant levels in the soil. Hypothesis: the concentrations of key pollutants in the soilwill increase in association with more destructive recycling processes (e.g. repair and resale willbe associated with lower toxin concentrations as compared with smashing cathode ray tubes forthe copper yokes).Methods: My proposed field site is Delhi, India, due to the city’s established e-wasterecycling industry and well-documented specialized processing areas4, 8. I will collaborate withthe following non-governmental organizations in the United States and on-site in India: SiliconValley Toxics Coalition; Toxics Link, Delhi, India; and Chintan Environmental Research andAction Group, Delhi, India. Base maps of Delhi will be collected from map archives, universitydepartments, and government offices. These will include streets and historical land use to assistin navigation and pollutant baseline controls; elevation for surface/hydrological modeling; andgeology, soils, and streams for environmental controls. Additional information will be gatheredfrom public records if historical maps are not available. All data will be translated intogeographic space, and digitized in a Geographic Information System, with coordinate systemsdefined, projected and transformed as necessary. Following this, key individuals from localNGOs, government offices, and universities will be interviewed to provide qualitative data forthree critical components: types of e-waste recycling operations in Delhi, site locations, andhistorical land use not captured in the base map construction.Combining the results of these interviews with published literature on recyclingprocesses8, 9, a series of recycling operation categories will be categorized (e.g. one code for goldextraction from printed circuit boards using acid-baths versus another code for cell-phonerefurbishment), resulting in approximately 3-5 analytical codes. Information gained in theinterviews will be verified and geo-located in the field by surveys assisted by a differentiallycorrected geographic positioning system (GPS). Using the population of coded recyclingoperations, a stratified simple random sample of individual recycling sites within each code willbe selected. Soil analysis will primarily be performed with a field-portable x-ray fluorescenceanalyzer (fp-XRF), supplied by Ron Amundson’s lab, based in the Department of EnvironmentalScience, Policy and Management at UC Berkeley. The fp-XRF will be calibrated for lead,Copyright 2008. All rights reserved to original author.Copyright 2008 All rights reserved to original author. Do not duplicate or use in any way withoutpermission.arsenic, cadmium, bromine, mercury, and chromium, toxic elements most commonly associatedwith e-waste2. All samples collected and fp-XRF readings will be catalogued with geographiccoordinates using GPS.The first sampling phase will define pollutant plumes and concentration strata usingtransect sampling with the fp-XRF. Systematic random sampling will assign sampling locationswithin each plume strata. In situ soil readings and ex situ samples will be collected during thesecond phase. To aid in precision and bias control, two methods will be employed: 1) onerandomly selected site will provide field calibration values by double sampling: ex situ soilsamples and in situ readings 2) 20% of all in situ readings will be accompanied by ex situsamples at remaining sites as a further control for environmental variations10.Potential sources of error include sampling design insensitivity to local variations,sampling obstructions at individual sites, non-soil ground-cover (mitigated by alternatecollection protocol for dust using thin-sample), dynamic environmental conditions (mitigated byhydrologic modeling or averaging multiple series), and changing land use at observation sites(mitigated by a study design with more sampling sites than necessary).After ex situ soil samples have been laboratory tested, all soil data will be digitized andgeo-referenced. In situ readings will be calibrated against quantitative laboratory resultsproducing a measure of estimated bias. Multivariate Analysis of Variance (MANOVA) will beused to assess the combination of toxin concentrations against the categories of recyclingprocesses. Additional variables will be tested for inclusion in the model such as historical landuse and environmental features such as slope and soil type. Weights will be applied in the modelfor the concentration strata and to control for spatial autocorrelation. Covariance will beaddressed in the MANOVA model.Anticipated Results: As the recycling process becomes more destructive, theconcentrations of key soil pollutants are expected to increase. The results of this study can aidmore precise targeting of particular waste-handling practices for environmental controls, thusfacilitating a more nuanced approach to improving e-waste recycling operations. Methods usedin this project could also be replicated in other locations to examine environmentalcontamination associated with formal and informal e-waste recycling.Support: My advisor, Rachel Morello-Frosch (study design and environmentalpollution); Ron Amundson (soil sampling methodology); John Radke (spatial analysis andsampling techniques); Alan Hubbard (statistical analysis); and Alastair Iles and Kate O’Neill(hazardous and e-waste trading). Oladele Ogunseitan at UC Irvine, and Jaco Huisman with theUN’s StEP Initiative (e-waste toxicity and recycling processes).1. Schwarzer, S., et al. in Env Alert Bulletin 4 (UNEP, 2005). 2. Widmer, R., et al. Globalperspectives on e-waste. Env Impact Assess Rev 25, 436-458 (2005). 3. Puckett, J., et al. (BasalAction Network, 2005). 4. Puckett, J. B. et al. (Basal Action Network & Silicon Valley ToxicsCoalition, 2002). 5. Wong, C. S. C., et al. Evidence of excessive releases of metals fromprimitive e-waste processing in Guiyu, China. Env Pollution 148, 62-72 (2007). 6. Iles, A.Mapping Environmental Justice in Technology Flows: Computer Waste Impacts in Asia. GlobalEnv Politics 4, 76-107 (2004). 7. Lincoln, J. D., et al. Leaching Assessments of HazardousMaterials in Cellular Telephones. Env Sci & Tech 41, 2572-2578 (2007). 8. Agarwal, R., et al.1-57 (Toxics Link, 2003). 9. Streicher-Porte, M. et al. Key drivers of the e-waste recyclingsystem: Assessing and modelling e-waste processing in the informal sector in Delhi. Env ImpactAssess Rev 25, 472-491 (2005). 10. Kalnicky, D. J. & Singhvi, R. Field portable XRF analysisof environmental samples. J of Haz Materials 83, 93-122 (2001).Copyright 2008. All rights reserved to original author."
255.0,"permission.Analysis of Bacterial, archaeal, and viral dispersal between distantly separated acid minedrainage systems through metagenomic analysisKeywords: Acid mine drainage, metagenomics, biogeographyBackgroundAcid mine drainage (AMD) is a serious mining-related environmental problem thatcauses acidification and metal contamination of waters and rivers. The exposure of sulfideminerals such as pyrite to oxygen and water produces sulfuric acid and releases heavy metalsinto the draining waters (1). It has been shown that microorganisms significantly contribute tothis process by catalyzing the limiting step of the involved reaction (1, 2). I propose to studythe rates of dispersal of AMD microorganisms, which will provide insight intounderstanding the processes that initiate and accelerate AMD formation.Microbial communities found in AMD systems are ideal samples to study due to theirlow diversity and complexity. The most abundant organisms include Leptospirillum group II,Leptospirillum group III, Acidithiobacillus ferrooxidans and Ferroplasma acidamarnus (3).AMD has been widely reported in several countries. The Richmond Mine at IronMountain, California, USA is an unusually well studied AMD system (e.g., 2, 3, 4).Metagenomic analysis of microbial biofilms from the Richmond Mine allowed reconstruction ofnear complete genomes of Leptospirillum group II (4) and Leptospirillum group III (5), amongother organisms. On the other side of the equator, Chile is one of the biggest producers ofcopper in the world, and, due to extensive mining activity, AMD has been found in severalabandoned mines along the country. I propose to compare AMD microbial communities atNorth and South American sites as a function of their geographical separation, usinggenomics of total community DNA, i.e., metagenomics.It has been reviewed that diversity of microorganisms correlates with distance separation(biogeography) (6). Because AMD organisms are adapted to extreme environments that areseparated by long distances, their rates of migration are limited (7). I propose to determine thebiogeographic and evolutionary dynamics that can account for strain diversity in thementioned AMD systems. More specifically, I will determine whether diversification occurreddue to contemporary environmental conditions or due to geographical separation, or whetherboth factors are responsible. This information will provide insights into the rates at whichbacteria and archaea responsible for AMD colonize new exposed sites.Prior studies have indicated that similar AMD environments with similar geochemicalconditions tend to have similar microbial communities (8, 9). The objective of this proposal,therefore, is to study strain diversification of the most abundant members of these communities.Thus I hypothesize that:1) Any two strains of a single archaeal species from two different sites will be moreevolutionary distant than a pair of bacterial strains from the same two sites.This hypothesis is based on the concept that opportunities for dispersal of acid-adaptedmicroorganisms will be limited (7). Therefore, bacterial and archaeal populations from distantlyseparated sites should be distinct at the strain level. Archaeal dispersal is more difficult due tothe lack of cell wall, leading to more phylogenetic diversity than that of coexisting bacteria,which would disperse more easily.Copyright 2008Copyright 2008 All rights reserved to original author. Do not copy or use in any way withoutpermission.2) AMD virus populations will be generally similar at all sites, despite likely rapid evolutionaryrates, due to their efficient rates of dispersal.This hypothesis is based on findings that viral populations in other systems are similar atsites separated far apart (10).To test these hypotheses, I propose to sample and analyze microbial communities foundin AMD in Chile. Results will be correlated with metagenomic data from the Richmond mine inCalifornia available at Dr. Banfield’s lab. Access to sites in Chile will be arranged incollaboration with Drs. David Homes and Raquel Quatrini, from the Millenium Institute inSantiago, and Dr. Cecilia Demergasso from the Northern Catholic University in Antofagasta,Chile. In collaboration with these labs and UC Berkeley, I will apply at the Joint GenomeInstitute (JGI) for a community-sequencing project. I will collect samples from at least 5 AMDsites in Chile for screening. Initial identification and abundance of organisms will be done usingfluorescent in situ hybridization (FISH), a technique I have worked with extensively in the past. Iwill also do 16S rDNA clone libraries in order to determine initial phylogenetic relationships. Iwill select two samples that share the majority of species for metagenomic analysis.I will request a total of 70 Mb of metagenomic sequence from JGI. Since complete ornear-complete genomes of AMD organisms are available, I will use these genomes to assignDNA fragments to specific organisms. I will assemble genomes using software that our lab hasextensive experience with. Then, I will analyze sequence variation within sites and between sitesin order to: i) determine whether there is more or less variation within the populations thanbetween them; ii) quantify the extent of diversity within populations of each organism, and iii)for the virus datasets, to determine whether there is evidence for closely related virus populationsat the different sites. In summary, I will do a comprehensive genomic and phylogenetic studybetween microorganisms found in AMD from the US and Chile.My research experience working at Dr. Banfield’s lab, and completing an undergraduatethesis, has well prepared me to do this kind of analysis. Being a coauthor in two publications alsodemonstrates my ability to work as part of a team. No existing community research project issimilar to my proposed work, therefore, this will be a big step in understanding the rates ofevolution of microorganisms found in AMD and their relationships within the community. It willserve as a model for studying other microbial communities separated by long distances. Mywork will be shown at national and international conferences, for both specialized and generalaudiences. In addition, as a mentor for the SMASH program I will teach my work tominority high school students, hoping to recruit them as future researchers in this field.References(1) Schrenk MO, et al. Science. 1998 Mar 6; 279(5356): 1519-22, (2) Edwards KJ, et al. ChemGeol. 2000 169: 383–397, (3) Bond PL, et al. Appl Environ Microbiol. 2000 Nov; 66: 4962-71,(4) Lo I, Denef VJ, Verberkmoes NC, Shah MB, Goltsman D, et al. Nature. 2007 Mar 29;446(7135):537-41, (5) Goltsman D, Banfield JF. (In preparation), (6) Hughes Martiny J, et al.Nat Rev Microbiol. 2006 Feb; 4(2): 102-112; (7) Whitaker RJ. Phil Trans R Soc B. 2006361:1975-1984; (8) Coram N, et al. App Environ Microbiol. 2002 68: 838-845. (9) Dold B, et al.Environ Sci Technol. 2005 39: 2515-2521. (10) Breitbart M, Rohwer F. Trends Microbiol. 2005Jun;13(6):278-84.Copyright 2008"
257.0,"Impacts of Climatic Change on the Arid Savanna Fire Regimes of West AfricaKeywords: Fire Regime, Climate Change, West Africa, Land Degradation, Arid SavannaIntroduction: Changing global conditions may be driving increasingly severe fires thatare further deteriorating already highly altered arid savanna ecosystems in West Africa.With the continued rise in anthropogenic fires, vulnerable ecosystems have undergonechanges in species dominance, ecosystem structure, and even ecosystem collapse. I hy-pothesize that altered climatic variables are at least partially responsible for increases infire severity that degrade the West African arid savanna.Background: Arid savannas, dry grasslands with scattered shrubs and drought-resistanttrees, are regarded as one of the ecosystems most likely to be affected by climate change(Louppe et al 1995). Though arid savannas require periodic surface fires to maintain theircharacteristic vegetation, increasingly severe fires have resulted in the annual degradationof more than 200,000 hectares of sub-Saharan arid savanna (Nsiah-Gyabaah 1994).In the past, these losses were attributed either to unsustainable agricultural prac-tices, or the belief that the Sahara was in a period of growth as part of the Earth’s axialobliquity cycle. Today we accept the sophistication of West African land managementtechniques, and there is evidence that the Sahara is actually in a greening period (Nsiah-Gyabaah 1994). Many suspect that the increase in land degradation is the result of cli-mate change driving fire intensity and frequency increases. The consequences of alteredfire regimes are clear, but West African fire regimes are themselves poorly understood.I became interested in studying fire-influenced land degradation when, during aWatson Fellowship studying fire, I returned to my childhood home in Ba’Nso, Camer-oon. Throughout the region, I encountered Fulani herdsmen who had relocated to findbetter pastureland. The Francophone farmers I met described barren fields, complainingthat no amount of burning restored the land’s fertility.Objectives: The study I propose is designed to investigate the impact of altered climaticconditions on fire-induced land degradation, producing some of the first quantitative re-search on fire regimes in West Africa. Fire regimes have been defined using characteris-tics such as frequency, intensity, burning season, and fire size (Goldammer 1988). I willstudy these physical parameters in West African arid savannas in order to determine ifthere is a relationship between altered climatic variables and fire severity, and what theimpact is on land degradation. After conducting field research in the Ghanaian Accraplains, I will analyze remote sensing data to determine the change at longer timescales.Methodology: Working with Dr. Kwesi Orgle and Forest Resources Management, I willconduct field research on the arid savanna in the Accra Plains on fire plots maintained bythe University of Ghana (Swaine 1992). We will analyze three study plots: a control inwhich fire has been excluded since 1957, another which has been burned annually since1957, and a plot of extant vegetation which we will burn annually beginning in 2007 andfor a subsequent two years. Our research team, including traditional landowners, will col-lect annual data on fires in study plots, measuring consumption of plant biomass, fire ex-tent, and intensity with thermocouples. We will document plant species turnover, theProposed Plan of Research Smith, Rachelrelative proportions of vegetation repopulation, and evaluate changes in rates of land deg-radation through a comparison with data collected since 1957.To identify change over a longer timescale, I will conduct an analysis of NOAA-AVHRR satellite image data captured for West Africa between 1985 and 2005. Thesepreviously processed data will be compared to monthly temperature and precipitationdatasets by the University of East Anglia’s Climate Research Unit to determine what, ifany, relationship exists between changes in numbers of fires, timing, and area burned,and altered precipitation and temperature. Dr. Johann Goldammer, head of the UN-FAOTeam of Specialists on Forest Fire has agreed to collaborate with me on this analysis.We’ll use these data to inform a broader scale analysis, using severity indexes and NDVItrends to discern any relationship between changing fire severity and land degradation.Anticipated Results: Climate change may be the dominant influence on the surge in fire-influenced land degradation in West Africa, but the current paucity of quantitative dataon fire in this region makes it difficult to understand the relationship between fire andclimate. My research will provide the first quantitative measurements of fire regime char-acteristics, identifying fire frequency, size, and intensity thresholds above which ignitionsmay result in land degradation. Furthermore, it will explore the possibility of interactionsbetween individual fire regime characteristics. I anticipate my research being able to con-clude whether fire-influenced land degradation is caused by climate change.Broader Impacts: This original project will provide critical information on fire regimesand offer insight into the extent to which climatic change is altering fire regimes in WestAfrica, constituting some of the first quantitative research on basic fire regime parametersin the West African arid savanna. Future researchers will utilize my data in their studies.Traditional landowners, such as the subsistence farmers in Ba’Nso and the Fulaninomadic herders whose livelihoods are tied up in the complex relationships linking fireand land arability, have a vital interest in this research. We will engage key stakeholdersas research collaborators and make all literature available in English, French, and Fulbe.Regionally, this project will provide resource managers with ground-truthed datalinking fire and climatic change. These data will assist them in formulating managementplans and help them anticipate future changes in fire behavior from climate change.Implications of this research stretch beyond Africa to other arid rangelands wherefires might be increasing in incidence or severity. My study may help scientists and landmanagers identify vulnerable areas in other parts of the world. My partnership with TheNature Conservancy and other organizations will make my results widely available.References: Goldammer, J.G. 1988. Rural land-use and fires in the tropics. AgroforestrySystems 6: 235-252.Louppe, D., Ouatara, N. & Coulibaly, A. 1995. Effet des feux de brousse sur la vegeta-tion. Bois et Forêts des Tropiques 245: 59-74.Nsiah-Gyabaah, K. Environmental degradation and desertification in Ghana. Brookfield:Aldershot, 1994.Swaine, M. D., Lieberman, D. and Hall, J. B. 1992. The effect of fire exclusion on savan-nah vegetation at Kpong, Ghana. Biotropica 24,2a: 166-172."
258.0,"Game Ranching in Botswana: Effects on Wildlife and Rural CommunitiesKeywords: wildlife conservation, resource tenure, community-based natural resourcemanagement (CBNRM), BotswanaObjective: To develop an interdisciplinary understanding of the effects of game ranchingon wildlife conservation and CBNRM in a livestock-wildlife conflict areaResearch Focus: In the mid-1990’s, “Use it or lose it” emerged as a controversialwildlife policy slogan, indicating that wildlife would have to pay its way, throughconsumptive and non-consumptive use, if it were to survive.1 This major shift fromexisting colonial protectionist strategies is a critical part of today’s African land-useplanning discourse. Game ranching, the focus of my research, is the intentionalmanagement and maintenance of wild animal populations for subsequent human use (i.e.meat, trophy hunting).1 Touted by its proponents as a sustainable use of land that bothconserves biodiversity and enhances livelihoods,2 ranching already is an establishedindustry in South Africa and Namibia. Studies show that game ranching has less impacton land than large-scale cattle ranching,3 yet its viability for wildlife conservationcontinues to be debated. Furthermore, game ranching’s implications for community-based management of natural resources (CBNRM) has yet to be explored. CBNRM aimsto devolve management of and benefits from natural resources to communities so as tocreate incentives favoring sustainable use.4 However, rights granted under CBNRM donot guarantee that communities will benefit from a given resource.5 In Botswana,communities do not have full control over the key determinants of resource conservationand economic development—hunting quotas, market prices, robustness of wildlifepopulations, macro-economic/political conditions, and ownership over the land andwildlife itself.6 Therefore, communities rarely invest in natural resource infrastructureand conservation.7 Competition from private game ranches may also threaten CBNRMviability; however, the development of game ranching on communal lands could providenew opportunities for CBNRM projects, as game ranching by definition involves intensemanagement of natural resources. Although game ranching on communal lands is in itsinfancy in Botswana, a country noted for both conservation and CBNRM initiatives, itmerits study given its potential to affect the current community-based conservationmodel.Social and ecological aspects of environmental phenomena have repeatedly beenshown to be interdependent;8 thus, rigorous study of game ranching requires aninterdisciplinary approach. The ecological component of my research will take place onprivate game ranches because there are few community-managed game ranches inBotswana. I will address the question of whether game ranches promote overallconservation of wildlife species at levels similar to that of nearby protected areas (PAs),or merely conserve harvestable species with clear economic value. My sociologicalresearch on the implications of game ranching for CBNRM will examine how resourcemanagement capabilities and decision-making authority of communities change whengame ranching is incorporated as a community-managed program. If game ranching oncommunal lands increases community security of tenure over wildlife, do communitiesthen invest more in wildlife management?Research Hypotheses: A) Relative to PAs, game ranches (i) maintain similar densities ofeconomically valuable wildlife species (ii) show smaller densities of species with zero ornegative economic value. B) Game ranching allows for more management over naturalCopyright © 2007 by original author. All rights reserved.resources than do other forms of wildlife use. C) Community-managed game ranchesincrease security of tenure over wildlife. D) Increased community management andsecure wildlife tenure leads to community investment in wildlife management.Methods: My research will combine standard ecological sampling and field methodswith the sociological extended case method, which examines interacting effects ofexternal forces on a particular case in order to modify wider theoretical assertions.9Table 1. Integrated Ecological and Sociological Research MethodologyEcological sampling on private game farms In-depth case study at Dqãe Qare10(target sample size = 12-14 ranches in central Kalahari) (community-run game ranch in centralKalahari)• Determine distribution & abundance of species with (+), (-), • Interview key informants to determine ifand no economic value to game ranches game ranching leads to increased community• Survey methods: a) detection rates along foot transects for control over natural resources compared todirect sightings, track and scats11 b)‘capture’ rates at remote other CBNRM venturesphotographic stations12 (to ↑ chance of detecting species, ie. • Indicators of control: a) extent of legal rightselusive carnivores) over land & wildlife b) ability to self-• Compare with parallel data collected from: adjacent determine hunting quotas c) stability oflivestock ranches & nearby Central Kalahari Game Reserve revenue(CKGR) to determine game ranching’s impact on local • Conduct structured household surveys &wildlife biodiversity relative to other land uses key informant interviews with community• Other data sources: a) Dept. of Wildlife wildlife population participants in the game ranch on: a)perceivedcensus data in CKGR b) interviews with ranch managers levels of control over natural resources b)about nature and level of ranch management practices (i.e. willingness to invest in wildlife managementcontrol strategies for predators, bush clearing, fencing and c) actual levels of investment in wildlifeveterinary care) and land-use history managementExpected Results: 1) Game ranching’s effects on species’ populations vary dependingon the species’ economic value to the ranch 2) Community game ranches have increasedlevel of control over natural resources, stimulating investment in wildlife management.Significance: This research will contribute novel interdisciplinary knowledge that ismeaningful to both Botswana and the broader field of conservation science. My study siteis ideal because: 1) it encompasses a matrix of land-use types across a continuouslandscape, enabling assessment of game ranching’s impact on biodiversity with fewconfounding factors; 2) I am already familiar with Botswana’s ecology, economics, andsocio-politics and have good working relations with key stakeholders; and (3) gameranching is new in Botswana so my results can influence future policy. (I certify thisproposal represents my own work and ideas—ACG)1 Kock, R. A. 1995. Wildlife utilization: use it or lose it—a Kenyan perspective. Biodiversity and Conservation 4: 241-256.2 Luxmoore, R. 1985. Game farming in South Africa as a force for conservation. Oryx 19 (4): 225-234.3 Smet M. and D. Ward. 2006. Soil quality gradients around water-points under different management systems in a semi-arid savanna,South Africa. Journal of Arid Environments 64(2): 251-69.4 Murphree, M. and Hulme D. eds. 2001. African Wildlife and Livelihoods. Cape Town: David Philip.5 Ribot, J.C. and Peluso, N.L. 2003. A Theory of Access. Rural Sociology 68(2): 153-181.6 Barnes, J.I. 1999. Economic potential for biodiversity use in southern Africa: empirical evidence. Environment and DevelopmentEconomics 4: 203–2367 du Toit, J. et al. 2004. Conserving tropical nature: current challenges for ecologists. Trends in Ecology & Evolution 19(1): 12-17.8 Blaikie, P. and Brookfield, H. 1987. Land Degradation and Society. New York: Methuen and Co.9 Burawoy, M. 1991. The Extended Case Method. In Ethnography Unbound. UC Press: Berkeley.10 I am taking Setswana lessons (national language) and will augment this with a San language course while in Botswana11 Stander, P. E. 1998. Spoor counts as indices of large carnivore populations: the relationship between spoor frequency, samplingeffort and true density. Journal of Applied Ecology 35: 378-385.12 Carbone, C., S. Christie, K. Conforti, et al. 2001. The use of photographic rates to estimate densities of tigers and other crypticmammals. Animal Conservation 4: 75-79."
261.0,"Evaluation of Resilience Thresholds in Stream EcosystemsKey Words: aquatic ecology; geomorphology; Mediterranean climate; flow regime; salmonidsBackground: Ecological resilience has been described as the ability of an ecosystem to withstanddisturbance and maintain the processes that control its structures4. When a disturbance exceeds theresilience threshold of an ecosystem, organizing processes can shift to an alternative stable state,resulting in changes to community composition and function1. Anthropomorphic alterations to theenvironment can reduce the resilience of natural ecosystems, resulting in losses of ecological serviceswhich in turn can stress human systems7,8.The increasing demand on freshwater resources to meet human water needs has altered the flowof rivers around the world and exemplifies the tension between human and natural systems5,7,8. Wherefreshwater is limited, increased human demand is coupled with a reduction of flow available to sustainecological processes, potentially crossing a resilience threshold for the system. This is particularly trueof Mediterranean-climate watersheds which experience natural prolonged low flows each year.One indicator of reduced resilience of aquatic ecosystems is the dramatic decline ofanadromous fish populations in Pacific Coast streams over the past 150 years. Substantial researcheffort has been directed toward salmon population recovery, but has largely been focused on reducingfine sediment and improving in-stream habitat structure2. Relatively little attention has been paid to theissue of water quantity as a limiting factor to salmon recovery due to the fact that most salmon researchhas been conducted in the Pacific Northwest. Rivers of this region are characterized by less seasonalflow variability than in coastal California, due to more mesic climate conditions9 and flowmanagement from dams.Recently developed flow models for tributary streams in California’s Mediterranean climateindicate that dispersed human water extraction has detectably reduced summer flows, resulting in anaccelerated and prolonged dry season period3. However, quantitative biophysical data relating changesto the stream hydrograph with decreased habitat suitability and salmon mortality are currently notavailable. Furthermore, monitoring programs typically fail to capture fine-scale variability in streamflows, including pool characteristics, which act as important refugia for fish in the late summer.Hypotheses: This study will investigate how human-induced modifications to natural flow regimes ofnorthern California streams have affected the resilience of stream ecosystems. Specifically, myresearch shall test the following two hypotheses: (1) there is a quantifiable resilience threshold foraquatic ecosystems resulting from limited summer stream flows and (2) existing flow models do notadequately capture non-linear, small-scale dynamics of altered stream systems during the dry season.My involvement with a University of California Berkeley watershed research group and previousexperiences conducting ecological field studies and stream restoration projects provided the motivationfor this original research plan.Research Plan: (1) Resilience Thresholds Analysis: As part of an interdisciplinary team, I willinvestigate the relationship between flow regime alteration and juvenile salmonid (steelhead trout[Onchorhynchus mykiss] and Coho salmon [O. kisutch]) abundance and survivorship. This researchwill utilize data from a 10-year study monitoring fish abundance and over-summer survivorship atmultiple tributary stream sites within the Russian River watershed, northern California. Stream flowmodels are currently being developed for these same tributaries to estimate human water demands anddetermine the availability of water for ecosystem needs. I will integrate the fish survey data withmodeled flow over a gradient of flow regime alterations within specific stream reaches to evaluate ifflows are a limiting factor for salmonid survivorship. Systematic declines in salmonid abundanceassociated with low flows will be interpreted as an indication that a resilience threshold necessary forsurvivorship has been crossed. Sliding regression is an effective method for detecting non-linearthreshold responses6 and will be used in the analysis of salmonid mortality under specific flowregimes. I expect to explore alternative regression methods such as ordinal logistic regression to detectthreshold responses once the stream flow model and salmonid data are fully integrated.NSF Proposed Plan of Research Copyright 2007 original author, all rights reserved(2) Stream Monitoring: In order to evaluate the ecological effects of stream flow on finer spatial andtemporal scales, I propose to collect field data on biotic and physical habitat conditions at specificpools within multiple stream reaches. This field work will validate existing stream flow models todetermine their predictive power for water availability in north coast tributary streams and providesmall-scale, high resolution information on stream flow and pool dynamics during the dry season.Stream gauges will be installed and flow data collected throughout the summer months. Pool depthsand water temperature will also be monitored throughout the low-flow period. The monitoring shallinclude a comprehensive assessment of habitat variables, including riparian vegetation cover, channelmorphology, streambed substrate, and habitat structure (large woody debris and boulders). The effectsof reduced dry season flows on streambed composition and other geomorphic variables are ofparticular interest. The accumulation of fine sediments within salmonid spawning habitat can in part beoffset by scouring effects of high flow events which mobilize streambed particles. If the filling ofriffles and pools is accelerated by lower summer base flows, a focus on the small-scale dynamics ofstream flow and sediment transport will provide insight to ecosystem processes that control habitatquality for salmonids. I will be advised on field methods by a team of experts interested in thisresearch, including V. Resh, P. Moyle, M. Kondolf, and W.E. Dietrich.Anticipated Results and Significance: I expect to find evidence of an ecological resilience threshold(as measured by minimum stream flows) below which juvenile salmonids do not survive. Analyses ofstream flow regimes in relation to biotic and geomorphic variables will fill a gap in aquatic systemsscience by identifying processes that affect ecological integrity of stream ecosystems during low-flowperiods5. My research will focus on the effects of dispersed water extraction by individual landowners,which has been much less studied than extraction from central infrastructure (e.g., dams and canals).This dispersed water extraction may be an important impact on aquatic ecosystems that has beenoverlooked and is likely to grow in many parts of the U.S. experiencing exurban expansion. This studywill make an important contribution to our understanding of the effects of land use change on theresilience of stream ecosystems and will evaluate if resilience thresholds can be quantified – anecessary step if such measures are to be used for ecosystem management.Literature Citations:1. Carpenter, S., Walker, B., Anderies, J.M., and N. Abel. 2001. From metaphor to measurement:Resilience of what to what? Ecosystems 4: 765 – 781.2. Coey, Robert, Sarah Nossaman-Pierce, Colin Brooks and Zebulon J. Young. 2002. CaliforniaDepartment of Fish and Game: Russian River Basin - Fisheries Restoration Plan (Draft).3. Deitch, M.J., and G.M. Kondolf. 2004 (Submitted). Evaluating the effects of water rightsdiversions in coastal California streams over spatial and temporal scales. Proceedings ofSymposium on Arid Lands, American Society of Civil Engineers, Salt Lake City.4. Holling, C.S., and L.H. Gunderson. 2002. Resilience and adaptive cycles. In L.H. Gunderson andC.S. Holling, eds. Panarchy: Understanding Transformations in Human and Natural Systems.Island Press, Washington D.C.5. Nilsson, C., J. E. Pizzuto, G. E. Moglen, M. A. Palmer, E. H. Stanley, and N. E. Bockstael, and L.C. Thompson. 2003. Ecological forecasting and the urbanization of stream ecosystems: challengesfor economists, hydrologists, geomorphologists, and ecologists. Ecosystems 6: 659-674.6. Ourso, R.T. and S.A. Frenzel. 2003. Identification of linear and threshold responses in streamsalong a gradient of urbanization in Anchorage, Alaska. Hydrobiologia 501: 117 – 131.7. Postel, S., and B. Richter. 2003. Rivers for Life: Managing water for people and nature. IslandPress, Washington,8. Richter, B.D., J.V. Baumgartner, R. Wigington, and D.P. Braun. 1997. How much water does ariver need? Freshwater Biology 37: 231-249.9. Wolman, M.G., R. Gerson. 1978. Relative scales of time and effectiveness of climate in watershedgeomorphology. Earth Surface Processes and Landforms 3(2): 189-208."
